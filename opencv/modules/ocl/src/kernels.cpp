namespace cv { namespace ocl {
const char *arithm_2_mat =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics:enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics:enable\n"
"#define CV_PI   3.1415926535897932384626433832795\n"
"char round_char(double v)\n"
"{\n"
"	char v1 = (char)v;\n"
"	return convert_char_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"}\n"
"unsigned char round_uchar(double v)\n"
"{\n"
"	unsigned char v1 = (unsigned char)v;\n"
"	return convert_uchar_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"}\n"
"short round_short(double v)\n"
"{\n"
"	short v1 = (short)v;\n"
"	return convert_short_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"}\n"
"unsigned short round_ushort(double v)\n"
"{\n"
"	unsigned short v1 = (unsigned short)v;\n"
"	return convert_ushort_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"}\n"
"int round_int(double v)\n"
"{\n"
"	int v1 = (int)v;\n"
"	return convert_int_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"}\n"
"char round2_char(double v)\n"
"{\n"
"	char v1 = (char)v;\n"
"	\n"
"	if ((v - v1) == 0.5 && v1 % 2 == 0)\n"
"	{\n"
"		return v1;\n"
"	}\n"
"	else\n"
"	{\n"
"		return convert_char_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	}\n"
"}\n"
"unsigned char round2_uchar(double v)\n"
"{\n"
"	unsigned char v1 = (unsigned char)v;\n"
"	\n"
"	if ((v - v1) == 0.5 && v1 % 2 == 0)\n"
"	{\n"
"		return v1;\n"
"	}\n"
"	else\n"
"	{\n"
"		return convert_uchar_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	}\n"
"}\n"
"short round2_short(double v)\n"
"{\n"
"	short v1 = (short)v;\n"
"	\n"
"	if ((v - v1) == 0.5 && v1 % 2 == 0)\n"
"	{\n"
"		return v1;\n"
"	}\n"
"	else\n"
"	{\n"
"		return convert_short_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	}\n"
"}\n"
"unsigned short round2_ushort(double v)\n"
"{\n"
"	unsigned short v1 = (unsigned short)v;\n"
"	\n"
"	if ((v - v1) == 0.5 && v1 % 2 == 0)\n"
"	{\n"
"		return v1;\n"
"	}\n"
"	else\n"
"	{\n"
"		return convert_ushort_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	}\n"
"}\n"
"int round2_int(double v)\n"
"{\n"
"	int v1 = (int)v;\n"
"	\n"
"	if ((v - v1) == 0.5 && v1 % 2 == 0)\n"
"	{\n"
"		return v1;\n"
"	}\n"
"	else\n"
"	{\n"
"		return convert_int_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	}\n"
"}\n"
"/*****************************************EXP***************************************/\n"
"__kernel void arithm_op_exp_5(int rows, int cols, int srcStep, __global float *src1Mat,\n"
"                              __global float *dstMat, int channels)\n"
"{\n"
"	size_t x = get_global_id(0);\n"
"	size_t y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		size_t idx = y * (srcStep >> 2) + x;\n"
"		dstMat[idx] = (float)exp((float)src1Mat[idx]);\n"
"	}\n"
"}\n"
"__kernel void arithm_op_exp_6(int rows, int cols, int srcStep, __global double *src1Mat,\n"
"                              __global double *dstMat, int channels)\n"
"{\n"
"	size_t x = get_global_id(0);\n"
"	size_t y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		size_t idx = y * (srcStep >> 3) + x;\n"
"		dstMat[idx] = exp(src1Mat[idx]);\n"
"	}\n"
"}\n"
"/*****************************************LOG***************************************/\n"
"__kernel void arithm_op_log_5(int rows, int cols, int srcStep, __global float *src1Mat,\n"
"                              __global float *dstMat, int channels)\n"
"{\n"
"	size_t x = get_global_id(0);\n"
"	size_t y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		size_t idx = y * (srcStep >> 2) + x;\n"
"		dstMat[idx] = (float) log((float)src1Mat[idx]);\n"
"	}\n"
"}\n"
"__kernel void arithm_op_log_6(int rows, int cols, int srcStep, __global double *src1Mat,\n"
"                              __global double *dstMat, int channels)\n"
"{\n"
"	size_t x = get_global_id(0);\n"
"	size_t y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		size_t idx = y * (srcStep >> 3) + x;\n"
"		dstMat[idx] = log(src1Mat[idx]);\n"
"	}\n"
"}\n"
;
const char *arithm_absdiff =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////absdiff////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************adddiff *************************************/\n"
"__kernel void arithm_absdiff_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                __global uchar *src2, int src2_step, int src2_offset,\n"
"                                __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = abs_diff(src1_data, src2_data);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_absdiff_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                __global ushort *src2, int src2_step, int src2_offset,\n"
"                                __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                                int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		ushort4 tmp_data = abs_diff(src1_data, src2_data);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_absdiff_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                __global short *src2, int src2_step, int src2_offset,\n"
"                                __global short *dst,  int dst_step,  int dst_offset,\n"
"                                int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4  dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		ushort4 tmp = abs_diff(src1_data, src2_data);\n"
"		short4  tmp_data = convert_short4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_absdiff_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                __global int *src2, int src2_step, int src2_offset,\n"
"                                __global int *dst,  int dst_step,  int dst_offset,\n"
"                                int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		uint tmp = abs_diff(data1, data2);\n"
"		int  tmp_data = convert_int_sat(tmp);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_absdiff_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                __global float *src2, int src2_step, int src2_offset,\n"
"                                __global float *dst,  int dst_step,  int dst_offset,\n"
"                                int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float tmp = fabs(data1 - data2);\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_absdiff_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                __global double *src2, int src2_step, int src2_offset,\n"
"                                __global double *dst,  int dst_step,  int dst_offset,\n"
"                                int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		double tmp = fabs(data1 - data2);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"/**************************************absdiff with scalar**************************************/\n"
"__kernel void arithm_s_absdiff_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                     __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4_sat(abs_diff(convert_int4_sat(src1_data), src2_data));\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                     __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = convert_ushort2_sat(abs_diff(convert_int2_sat(src1_data), src2_data));\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                     __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		\n"
"		ushort2 tmp = convert_ushort2_sat(abs_diff(convert_int2_sat(src1_data), src2_data));\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C1_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                     __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		uint tmp_data = abs_diff(src_data1, src_data2);\n"
"		int  data = convert_int_sat(tmp_data);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C1_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                     __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *src2;\n"
"		float dst_data  = *((__global float *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float data = fabs(src_data1 - src_data2);\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C1_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                     __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src2_data = *src2;\n"
"		double dst_data  = *((__global double *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double data = fabs(src_data1 - src2_data);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                     __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4_sat(abs_diff(convert_int4_sat(src1_data), src2_data));\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                     __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*(src2), src2[1]);\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = convert_ushort2_sat(abs_diff(convert_int2_sat(src_data1), src_data2));\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                     __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 tmp = convert_ushort2_sat(abs_diff(convert_int2_sat(src_data1), src_data2));\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                     __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = convert_int2_sat(abs_diff(src_data1, src_data2));\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C2_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                     __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = (float2)(*src2, *(src2 + 1));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 data = fabs(src_data1 - src_data2);\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C2_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                     __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = fabs(src_data1 - src_data2);\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                     __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		int4 src2_data_0 = (int4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		int4 src2_data_1 = (int4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		int4 src2_data_2 = (int4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(abs_diff(convert_int4_sat(src1_data_0), src2_data_0));\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(abs_diff(convert_int4_sat(src1_data_1), src2_data_1));\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(abs_diff(convert_int4_sat(src1_data_2), src2_data_2));\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                     __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(abs_diff(convert_int2_sat(src1_data_0), src2_data_0));\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(abs_diff(convert_int2_sat(src1_data_1), src2_data_1));\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(abs_diff(convert_int2_sat(src1_data_2), src2_data_2));\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                     __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(abs_diff(convert_int2_sat(src1_data_0), src2_data_0));\n"
"		short2 tmp_data_1 = convert_short2_sat(abs_diff(convert_int2_sat(src1_data_1), src2_data_1));\n"
"		short2 tmp_data_2 = convert_short2_sat(abs_diff(convert_int2_sat(src1_data_2), src2_data_2));\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                     __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = convert_int_sat(abs_diff(src1_data_0, src2_data_0));\n"
"		int tmp_data_1 = convert_int_sat(abs_diff(src1_data_1, src2_data_1));\n"
"		int tmp_data_2 = convert_int_sat(abs_diff(src1_data_2, src2_data_2));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C3_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                     __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *src2;\n"
"		float src2_data_1 = *(src2 + 1);\n"
"		float src2_data_2 = *(src2 + 2);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_data_0 = fabs(src1_data_0 - src2_data_0);\n"
"		float tmp_data_1 = fabs(src1_data_1 - src2_data_1);\n"
"		float tmp_data_2 = fabs(src1_data_2 - src2_data_2);\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C3_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                     __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *src2;\n"
"		double src2_data_1 = *(src2 + 1);\n"
"		double src2_data_2 = *(src2 + 2);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = fabs(src1_data_0 - src2_data_0);\n"
"		double tmp_data_1 = fabs(src1_data_1 - src2_data_1);\n"
"		double tmp_data_2 = fabs(src1_data_2 - src2_data_2);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = tmp_data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                     __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		uchar4 data = convert_uchar4_sat(abs_diff(convert_int4_sat(src_data1), src_data2));\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                     __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		ushort4 data = convert_ushort4_sat(abs_diff(convert_int4_sat(src_data1), src_data2));\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                     __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		short4 data = convert_short4_sat(abs_diff(convert_int4_sat(src_data1), src_data2));\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                     __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 data = convert_int4_sat(abs_diff(src_data1, src_data2));\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C4_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                     __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__constant float4 *)src2);\n"
"		\n"
"		float4 data = fabs(src_data1 - src_data2);\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_absdiff_C4_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                     __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                     __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                     int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__constant double4 *)src2);\n"
"		\n"
"		double4 data = fabs(src_data1 - src_data2);\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_add =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////ADD////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************add without mask**************************************/\n"
"__kernel void arithm_add_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                            __global uchar *src2, int src2_step, int src2_offset,\n"
"                            __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4 tmp      = convert_short4_sat(src1_data) + convert_short4_sat(src2_data);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                            __global ushort *src2, int src2_step, int src2_offset,\n"
"                            __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		int4    tmp = convert_int4_sat(src1_data) + convert_int4_sat(src2_data);\n"
"		ushort4 tmp_data = convert_ushort4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                            __global short *src2, int src2_step, int src2_offset,\n"
"                            __global short *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		int4   tmp = convert_int4_sat(src1_data) + convert_int4_sat(src2_data);\n"
"		short4 tmp_data = convert_short4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                            __global int *src2, int src2_step, int src2_offset,\n"
"                            __global int *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		long tmp  = (long)(data1) + (long)(data2);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = convert_int_sat(tmp);\n"
"	}\n"
"}\n"
"__kernel void arithm_add_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                            __global float *src2, int src2_step, int src2_offset,\n"
"                            __global float *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float tmp = data1 + data2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"#if defined (DOUBLE_SUPPORT)\n"
"__kernel void arithm_add_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                            __global double *src2, int src2_step, int src2_offset,\n"
"                            __global double *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data1 + data2;\n"
"	}\n"
"}\n"
"#endif\n"
"/**************************************add with mask**************************************/\n"
"__kernel void arithm_add_with_mask_C1_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4 tmp = convert_short4_sat(src1_data) + convert_short4_sat(src2_data);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C1_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = vload2(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) + convert_int2_sat(src2_data);\n"
"		ushort2 tmp_data = convert_ushort2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C1_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = vload2(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) + convert_int2_sat(src2_data);\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C1_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = convert_int_sat((long)src_data1 + (long)src_data2);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C1_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float dst_data  = *((__global float *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C1_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src_data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		double dst_data  = *((__global double *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C2_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4   tmp = convert_short4_sat(src1_data) + convert_short4_sat(src2_data);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C2_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = *((__global ushort2 *)((__global char *)src2 + src2_index));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) + convert_int2_sat(src_data2);\n"
"		ushort2 data = convert_ushort2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C2_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = *((__global short2 *)((__global char *)src2 + src2_index));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) + convert_int2_sat(src_data2);\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C2_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int    *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = *((__global int2 *)((__global char *)src2 + src2_index));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = convert_int2_sat(convert_long2_sat(src_data1) + convert_long2_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C2_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = *((__global float2 *)((__global char *)src2 + src2_index));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C2_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = *((__global double2 *)((__global char *)src2 + src2_index));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C3_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		uchar4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		uchar4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(convert_short4_sat(src1_data_0) + convert_short4_sat(src2_data_0));\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(convert_short4_sat(src1_data_1) + convert_short4_sat(src2_data_1));\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(convert_short4_sat(src1_data_2) + convert_short4_sat(src2_data_2));\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C3_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 0));\n"
"		ushort2 src2_data_1 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 4));\n"
"		ushort2 src2_data_2 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(convert_int2_sat(src1_data_0) + convert_int2_sat(src2_data_0));\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(convert_int2_sat(src1_data_1) + convert_int2_sat(src2_data_1));\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(convert_int2_sat(src1_data_2) + convert_int2_sat(src2_data_2));\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C3_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 0));\n"
"		short2 src2_data_1 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 4));\n"
"		short2 src2_data_2 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(convert_int2_sat(src1_data_0) + convert_int2_sat(src2_data_0));\n"
"		short2 tmp_data_1 = convert_short2_sat(convert_int2_sat(src1_data_1) + convert_int2_sat(src2_data_1));\n"
"		short2 tmp_data_2 = convert_short2_sat(convert_int2_sat(src1_data_2) + convert_int2_sat(src2_data_2));\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C3_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *((__global int *)((__global char *)src2 + src2_index + 0));\n"
"		int src2_data_1 = *((__global int *)((__global char *)src2 + src2_index + 4));\n"
"		int src2_data_2 = *((__global int *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = convert_int_sat((long)src1_data_0 + (long)src2_data_0);\n"
"		int tmp_data_1 = convert_int_sat((long)src1_data_1 + (long)src2_data_1);\n"
"		int tmp_data_2 = convert_int_sat((long)src1_data_2 + (long)src2_data_2);\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C3_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *((__global float *)((__global char *)src2 + src2_index + 0));\n"
"		float src2_data_1 = *((__global float *)((__global char *)src2 + src2_index + 4));\n"
"		float src2_data_2 = *((__global float *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_data_0 = src1_data_0 + src2_data_0;\n"
"		float tmp_data_1 = src1_data_1 + src2_data_1;\n"
"		float tmp_data_2 = src1_data_2 + src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C3_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 24) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *((__global double *)((__global char *)src2 + src2_index + 0));\n"
"		double src2_data_1 = *((__global double *)((__global char *)src2 + src2_index + 8));\n"
"		double src2_data_2 = *((__global double *)((__global char *)src2 + src2_index + 16));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = src1_data_0 + src2_data_0;\n"
"		double tmp_data_1 = src1_data_1 + src2_data_1;\n"
"		double tmp_data_2 = src1_data_2 + src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C4_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__global uchar4 *)(src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = convert_uchar4_sat(convert_ushort4_sat(src_data1) + convert_ushort4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C4_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__global ushort4 *)((__global char *)src2 + src2_index));\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = convert_ushort4_sat(convert_int4_sat(src_data1) + convert_int4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C4_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__global short4 *)((__global char *)src2 + src2_index));\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = convert_short4_sat(convert_int4_sat(src_data1) + convert_int4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C4_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = convert_int4_sat(convert_long4_sat(src_data1) + convert_long4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C4_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		float4 dst_data  = *((__global float4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float4 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_add_with_mask_C4_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 5) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		double4 dst_data  = *((__global double4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double4 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_addWeighted =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////addWeighted//////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void addWeighted_D0(__global uchar *src1, double alpha, int src1_step, int src1_offset,\n"
"                             __global uchar *src2, double beta, int src2_step, int src2_offset,\n"
"                             double gama,\n"
"                             __global uchar *dst,  int dst_step, int dst_offset,\n"
"                             int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4 tmp      = convert_short4_sat(src1_data) * alpha + convert_short4_sat(src2_data) * beta + gama;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"		// dst[x + y * dst_step] = src1[x + y * src1_step] * alpha + src2[x + y * src2_step] * beta + gama;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void addWeighted_D2(__global ushort *src1, double alpha, int src1_step, int src1_offset,\n"
"                             __global ushort *src2, double beta, int src2_step, int src2_offset,\n"
"                             double gama,\n"
"                             __global ushort *dst,  int dst_step, int dst_offset,\n"
"                             int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		int4 tmp      = convert_int4_sat(src1_data) * alpha + convert_int4_sat(src2_data) * beta + gama;\n"
"		ushort4 tmp_data = convert_ushort4_sat(tmp);\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"	\n"
"}\n"
"__kernel void addWeighted_D3(__global short *src1, double alpha, int src1_step, int src1_offset,\n"
"                             __global short *src2, double beta, int src2_step, int src2_offset,\n"
"                             double gama,\n"
"                             __global short *dst,  int dst_step, int dst_offset,\n"
"                             int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) - (dst_align << 1));\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		int4 tmp      = convert_int4_sat(src1_data) * alpha + convert_int4_sat(src2_data) * beta + gama;\n"
"		short4 tmp_data = convert_short4_sat(tmp);\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void addWeighted_D4(__global int *src1, double alpha, int src1_step, int src1_offset,\n"
"                             __global int *src2, double beta, int src2_step, int src2_offset,\n"
"                             double gama,\n"
"                             __global int *dst,  int dst_step, int dst_offset,\n"
"                             int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define bitOfInt  (sizeof(int)== 4 ? 2: 3)\n"
"		\n"
"#define dst_align ((dst_offset >> bitOfInt) & 3)\n"
"		\n"
"		int src1_index = mad24(y, src1_step, (x << bitOfInt) + src1_offset - (dst_align << bitOfInt));\n"
"		int src2_index = mad24(y, src2_step, (x << bitOfInt) + src2_offset - (dst_align << bitOfInt));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << bitOfInt) - (dst_align << bitOfInt));\n"
"		\n"
"		int4 src1_data = vload4(0, (__global int *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = vload4(0, (__global int *)((__global char *)src2 + src2_index));\n"
"		int4 dst_data = *((__global int4 *)((__global char *)dst + dst_index));\n"
"		double4   tmp = convert_double4(src1_data) * alpha + convert_double4(src2_data) * beta + gama ;\n"
"		int4 tmp_data = convert_int4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 8 >= dst_start) && (dst_index + 8 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 12 >= dst_start) && (dst_index + 12 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void addWeighted_D5(__global float *src1, double alpha, int src1_step, int src1_offset,\n"
"                             __global float *src2, double beta, int src2_step, int src2_offset,\n"
"                             double gama,\n"
"                             __global float *dst,  int dst_step, int dst_offset,\n"
"                             int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 2) & 3)\n"
"		\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 2) - (dst_align << 2));\n"
"		\n"
"		float4 src1_data = vload4(0, (__global float *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = vload4(0, (__global float *)((__global char *)src2 + src2_index));\n"
"		float4 dst_data = *((__global float4 *)((__global char *)dst + dst_index));\n"
"		//    double4   tmp = convert_double4(src1_data) * alpha + convert_double4(src2_data) * beta + gama ;\n"
"		\n"
"		float4   tmp_data = (src1_data) * alpha + (src2_data) * beta + gama ;\n"
"		// float4 tmp_data = convert_float4(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 8 >= dst_start) && (dst_index + 8 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 12 >= dst_start) && (dst_index + 12 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void addWeighted_D6(__global double *src1, double alpha, int src1_step, int src1_offset,\n"
"                             __global double *src2, double beta, int src2_step, int src2_offset,\n"
"                             double gama,\n"
"                             __global double *dst,  int dst_step, int dst_offset,\n"
"                             int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 3) & 3)\n"
"		\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 3) - (dst_align << 3));\n"
"		\n"
"		double4 src1_data = vload4(0, (__global double *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = vload4(0, (__global double *)((__global char *)src2 + src2_index));\n"
"		double4 dst_data = *((__global double4 *)((__global char *)dst + dst_index));\n"
"		double4   tmp_data = (src1_data) * alpha + (src2_data) * beta + gama ;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 8 >= dst_start) && (dst_index + 8 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 16 >= dst_start) && (dst_index + 16 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 24 >= dst_start) && (dst_index + 24 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"}\n"
;
const char *arithm_add_scalar =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"/**************************************add with scalar without mask**************************************/\n"
"__kernel void arithm_s_add_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp = convert_int4_sat(src1_data) + src2_data;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) + src2_data;\n"
"		ushort2 tmp_data = convert_ushort2_sat(tmp);\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src1_data) + src2_data;\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C1_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = convert_int_sat((long)src_data1 + (long)src_data2);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C1_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *src2;\n"
"		float dst_data  = *((__global float *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float data = src_data1 + src_data2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C1_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src2_data = *src2;\n"
"		double dst_data  = *((__global double *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double data = src_data1 + src2_data;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp = convert_int4_sat(src1_data) + src2_data;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*(src2), src2[1]);\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) + src_data2;\n"
"		ushort2 data = convert_ushort2_sat(tmp);\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) + src_data2;\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = convert_int2_sat(convert_long2_sat(src_data1) + convert_long2_sat(src_data2));\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C2_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = (float2)(*src2, *(src2 + 1));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 data = src_data1 + src_data2;\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C2_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = src_data1 + src_data2;\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		int4 src2_data_0 = (int4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		int4 src2_data_1 = (int4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		int4 src2_data_2 = (int4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(convert_int4_sat(src1_data_0) + src2_data_0);\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(convert_int4_sat(src1_data_1) + src2_data_1);\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(convert_int4_sat(src1_data_2) + src2_data_2);\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(convert_int2_sat(src1_data_0) + src2_data_0);\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(convert_int2_sat(src1_data_1) + src2_data_1);\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(convert_int2_sat(src1_data_2) + src2_data_2);\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(convert_int2_sat(src1_data_0) + src2_data_0);\n"
"		short2 tmp_data_1 = convert_short2_sat(convert_int2_sat(src1_data_1) + src2_data_1);\n"
"		short2 tmp_data_2 = convert_short2_sat(convert_int2_sat(src1_data_2) + src2_data_2);\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = convert_int_sat((long)src1_data_0 + (long)src2_data_0);\n"
"		int tmp_data_1 = convert_int_sat((long)src1_data_1 + (long)src2_data_1);\n"
"		int tmp_data_2 = convert_int_sat((long)src1_data_2 + (long)src2_data_2);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C3_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *src2;\n"
"		float src2_data_1 = *(src2 + 1);\n"
"		float src2_data_2 = *(src2 + 2);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_data_0 = src1_data_0 + src2_data_0;\n"
"		float tmp_data_1 = src1_data_1 + src2_data_1;\n"
"		float tmp_data_2 = src1_data_2 + src2_data_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C3_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *src2;\n"
"		double src2_data_1 = *(src2 + 1);\n"
"		double src2_data_2 = *(src2 + 2);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = src1_data_0 + src2_data_0;\n"
"		double tmp_data_1 = src1_data_1 + src2_data_1;\n"
"		double tmp_data_2 = src1_data_2 + src2_data_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = tmp_data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		int4   src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		uchar4 data = convert_uchar4_sat(convert_int4_sat(src_data1) + src_data2);\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		int4    src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		ushort4 data = convert_ushort4_sat(convert_int4_sat(src_data1) + src_data2);\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		short4 data = convert_short4_sat(convert_int4_sat(src_data1) + src_data2);\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 data = convert_int4_sat(convert_long4_sat(src_data1) + convert_long4_sat(src_data2));\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C4_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__constant float4 *)src2);\n"
"		\n"
"		float4 data = src_data1 + src_data2;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_C4_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__constant double4 *)src2);\n"
"		\n"
"		double4 data = src_data1 + src_data2;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_add_scalar_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"/**************************************add with scalar with mask**************************************/\n"
"__kernel void arithm_s_add_with_mask_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp = convert_int4_sat(src1_data) + src2_data;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) + src2_data;\n"
"		ushort2 tmp_data = convert_ushort2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) + src2_data;\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C1_D4(__global   int   *src1, int src1_step, int src1_offset,\n"
"        __global   int   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = convert_int_sat((long)src_data1 + (long)src_data2);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C1_D5(__global   float   *src1, int src1_step, int src1_offset,\n"
"        __global   float   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *src2;\n"
"		float dst_data  = *((__global float *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C1_D6(__global   double   *src1, int src1_step, int src1_offset,\n"
"        __global   double   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src_data2 = *src2;\n"
"		double dst_data  = *((__global double *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4   src2_data = (int4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4  tmp = convert_int4_sat(src1_data) + src2_data;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) + src_data2;\n"
"		ushort2 data = convert_ushort2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) + src_data2;\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = convert_int2_sat(convert_long2_sat(src_data1) + convert_long2_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C2_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = (float2)(*src2, *(src2 + 1));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C2_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		int4 src2_data_0 = (int4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		int4 src2_data_1 = (int4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		int4 src2_data_2 = (int4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(convert_int4_sat(src1_data_0) + src2_data_0);\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(convert_int4_sat(src1_data_1) + src2_data_1);\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(convert_int4_sat(src1_data_2) + src2_data_2);\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(convert_int2_sat(src1_data_0) + src2_data_0);\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(convert_int2_sat(src1_data_1) + src2_data_1);\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(convert_int2_sat(src1_data_2) + src2_data_2);\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(convert_int2_sat(src1_data_0) + src2_data_0);\n"
"		short2 tmp_data_1 = convert_short2_sat(convert_int2_sat(src1_data_1) + src2_data_1);\n"
"		short2 tmp_data_2 = convert_short2_sat(convert_int2_sat(src1_data_2) + src2_data_2);\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = convert_int_sat((long)src1_data_0 + (long)src2_data_0);\n"
"		int tmp_data_1 = convert_int_sat((long)src1_data_1 + (long)src2_data_1);\n"
"		int tmp_data_2 = convert_int_sat((long)src1_data_2 + (long)src2_data_2);\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C3_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *src2;\n"
"		float src2_data_1 = *(src2 + 1);\n"
"		float src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_data_0 = src1_data_0 + src2_data_0;\n"
"		float tmp_data_1 = src1_data_1 + src2_data_1;\n"
"		float tmp_data_2 = src1_data_2 + src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C3_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *src2;\n"
"		double src2_data_1 = *(src2 + 1);\n"
"		double src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = src1_data_0 + src2_data_0;\n"
"		double tmp_data_1 = src1_data_1 + src2_data_1;\n"
"		double tmp_data_2 = src1_data_2 + src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = convert_uchar4_sat(convert_int4_sat(src_data1) + src_data2);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = convert_ushort4_sat(convert_int4_sat(src_data1) + src_data2);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = convert_short4_sat(convert_int4_sat(src_data1) + src_data2);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = convert_int4_sat(convert_long4_sat(src_data1) + convert_long4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C4_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__constant float4 *)src2);\n"
"		float4 dst_data  = *((__global float4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float4 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_add_with_mask_C4_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__constant double4 *)src2);\n"
"		double4 dst_data  = *((__global double4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double4 data = src_data1 + src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_and =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_AND////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_and without mask**************************************/\n"
"__kernel void arithm_bitwise_and_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                    __global uchar *src2, int src2_step, int src2_offset,\n"
"                                    __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_D1(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *src2, int src2_step, int src2_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		char4 dst_data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                    __global ushort *src2, int src2_step, int src2_offset,\n"
"                                    __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		ushort4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                    __global short *src2, int src2_step, int src2_offset,\n"
"                                    __global short *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		short4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                    __global int *src2, int src2_step, int src2_offset,\n"
"                                    __global int *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int tmp  = data1 & data2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_D5(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *src2, int src2_step, int src2_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 data2 = *((__global char4 *)((__global char *)src2 + src2_index));\n"
"		char4 tmp = data1 & data2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_D6(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *src2, int src2_step, int src2_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data1 & data2;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_and_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_AND////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_and with mask**************************************/\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = convert_char((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_char((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = convert_char((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = convert_char((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = vload2(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = convert_ushort((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_ushort((mask_data.y) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = vload2(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		short2 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = convert_short((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_short((mask_data.y) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__global char4 *)((__global char *)src2 + src2_index));\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C1_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = *((__global ushort2 *)((__global char *)src2 + src2_index));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = *((__global short2 *)((__global char *)src2 + src2_index));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int    *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = *((__global int2 *)((__global char *)src2 + src2_index));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C2_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__global char16 *)((__global char *)src2 + src2_index));\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		uchar4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		uchar4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 =  src1_data_0 & src2_data_0;\n"
"		uchar4 tmp_data_1 =  src1_data_1 & src2_data_1;\n"
"		uchar4 tmp_data_2 =  src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		char4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		char4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 =  src1_data_0 & src2_data_0;\n"
"		char4 tmp_data_1 =  src1_data_1 & src2_data_1;\n"
"		char4 tmp_data_2 =  src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 0));\n"
"		ushort2 src2_data_1 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 4));\n"
"		ushort2 src2_data_2 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 =  src1_data_0 & src2_data_0 ;\n"
"		ushort2 tmp_data_1 =  src1_data_1 & src2_data_1 ;\n"
"		ushort2 tmp_data_2 =  src1_data_2 & src2_data_2 ;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 0));\n"
"		short2 src2_data_1 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 4));\n"
"		short2 src2_data_2 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 =  src1_data_0 & src2_data_0 ;\n"
"		short2 tmp_data_1 =  src1_data_1 & src2_data_1 ;\n"
"		short2 tmp_data_2 =  src1_data_2 & src2_data_2 ;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *((__global int *)((__global char *)src2 + src2_index + 0));\n"
"		int src2_data_1 = *((__global int *)((__global char *)src2 + src2_index + 4));\n"
"		int src2_data_2 = *((__global int *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 =  src1_data_0 &  src2_data_0 ;\n"
"		int tmp_data_1 =  src1_data_1 &  src2_data_1 ;\n"
"		int tmp_data_2 =  src1_data_2 &  src2_data_2 ;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__global char4 *)((__global char *)src2 + src2_index + 0));\n"
"		char4 src2_data_1 = *((__global char4 *)((__global char *)src2 + src2_index + 4));\n"
"		char4 src2_data_2 = *((__global char4 *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C3_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 24) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__global char8 *)((__global char *)src2 + src2_index + 0));\n"
"		char8 src2_data_1 = *((__global char8 *)((__global char *)src2 + src2_index + 8));\n"
"		char8 src2_data_2 = *((__global char8 *)((__global char *)src2 + src2_index + 16));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__global uchar4 *)(src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__global char4 *)(src2 + src2_index));\n"
"		char4 dst_data  = *((__global char4 *)(dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__global ushort4 *)((__global char *)src2 + src2_index));\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__global short4 *)((__global char *)src2 + src2_index));\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__global char16 *)((__global char *)src2 + src2_index));\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_and_with_mask_C4_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 5) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__global char8 *)((__global char *)src2 + src2_index + 0));\n"
"		char8 src_data2_1 = *((__global char8 *)((__global char *)src2 + src2_index + 8));\n"
"		char8 src_data2_2 = *((__global char8 *)((__global char *)src2 + src2_index + 16));\n"
"		char8 src_data2_3 = *((__global char8 *)((__global char *)src2 + src2_index + 24));\n"
"		\n"
"		char8 dst_data_0  = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		char8 dst_data_1  = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		char8 dst_data_2  = *((__global char8 *)((__global char *)dst  + dst_index + 16));\n"
"		char8 dst_data_3  = *((__global char8 *)((__global char *)dst  + dst_index + 24));\n"
"		\n"
"		char8 data_0 = src_data1_0 & src_data2_0;\n"
"		char8 data_1 = src_data1_1 & src_data2_1;\n"
"		char8 data_2 = src_data1_2 & src_data2_2;\n"
"		char8 data_3 = src_data1_3 & src_data2_3;\n"
"		\n"
"		data_0 = mask_data ? data_0 : dst_data_0;\n"
"		data_1 = mask_data ? data_1 : dst_data_1;\n"
"		data_2 = mask_data ? data_2 : dst_data_2;\n"
"		data_3 = mask_data ? data_3 : dst_data_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_and_scalar =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_AND////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************and with scalar without mask**************************************/\n"
"__kernel void arithm_s_bitwise_and_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C1_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = (ushort2)(*src2, *src2);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = (short2)(*src2, *src2);\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		\n"
"		short2 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C1_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"//        int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		int data = src_data1 & src_data2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C1_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		//char4 src_data2 = (char4)( *src2,*src2,*src2,*src2);\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C1_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		//char4 src2_data = *((__constant char4 *)src2);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & (convert_char4(src2_data));\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = (ushort2)(*(src2), src2[1]);\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = (short2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 & src_data2;\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		char8 data = src_data1 & src_data2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C2_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		/* double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		 double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		 double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		 double2 data;\n"
"		data.x = src_data1.x & src_data2.x;\n"
"		data.y = src_data1.y & src_data2.y;\n"
"		\n"
"		       *((__global double2 *)((__global char *)dst + dst_index)) = data;*/\n"
"		\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data;\n"
"		data = src_data1 & src_data2;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = (uchar4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		uchar4 src2_data_1 = (uchar4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		uchar4 src2_data_2 = (uchar4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 =  src1_data_0  &  src2_data_0  ;\n"
"		uchar4 tmp_data_1 =  src1_data_1  &  src2_data_1  ;\n"
"		uchar4 tmp_data_2 =  src1_data_2  &  src2_data_2  ;\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = (char4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		char4 src2_data_1 = (char4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		char4 src2_data_2 = (char4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 =  src1_data_0  &  src2_data_0;\n"
"		char4 tmp_data_1 =  src1_data_1  &  src2_data_1;\n"
"		char4 tmp_data_2 =  src1_data_2  &  src2_data_2;\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = (ushort2)(*(src2 + 0), *(src2 + 1));\n"
"		ushort2 src2_data_1 = (ushort2)(*(src2 + 2), *(src2 + 0));\n"
"		ushort2 src2_data_2 = (ushort2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = src1_data_0  &  src2_data_0  ;\n"
"		ushort2 tmp_data_1 = src1_data_1  &  src2_data_1  ;\n"
"		ushort2 tmp_data_2 = src1_data_2  &  src2_data_2  ;\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = (short2)(*(src2 + 0), *(src2 + 1));\n"
"		short2 src2_data_1 = (short2)(*(src2 + 2), *(src2 + 0));\n"
"		short2 src2_data_2 = (short2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 =  src1_data_0  &  src2_data_0  ;\n"
"		short2 tmp_data_1 =  src1_data_1  &  src2_data_1  ;\n"
"		short2 tmp_data_2 =  src1_data_2  &  src2_data_2  ;\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		int tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		int tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__constant char4 *)src2 + 0);\n"
"		char4 src2_data_1 = *((__constant char4 *)src2 + 1);\n"
"		char4 src2_data_2 = *((__constant char4 *)src2 + 2);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C3_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src2_data_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src2_data_2 = *((__constant char8 *)src2 + 2);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = tmp_data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__constant uchar4 *)src2);\n"
"		\n"
"		uchar4 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		\n"
"		char4 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__constant ushort4 *)src2);\n"
"		\n"
"		ushort4 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__constant short4 *)src2);\n"
"		\n"
"		short4 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 data = src_data1 & src_data2;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		\n"
"		char16 data;\n"
"		data = src_data1 & src_data2;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_C4_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src_data2_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src_data2_2 = *((__constant char8 *)src2 + 2);\n"
"		char8 src_data2_3 = *((__constant char8 *)src2 + 3);\n"
"		\n"
"		char8 data_0 = src_data1_0 & src_data2_0;\n"
"		char8 data_1 = src_data1_1 & src_data2_1;\n"
"		char8 data_2 = src_data1_2 & src_data2_2;\n"
"		char8 data_3 = src_data1_3 & src_data2_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_and_scalar_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_AND////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_and with scalar with mask**************************************/\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *src2, *src2, *src2);\n"
"		// char4 src2_data = *((__constant char4 *)src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = (ushort2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = (short2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		short2 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D4(__global   int   *src1, int src1_step, int src1_offset,\n"
"        __global   int   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		// char4 src_data2 = (char4)(*src2, *src2, *src2, *src2);\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C1_D6(__global   char   *src1, int src1_step, int src1_offset,\n"
"        __global   char   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data & src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = (ushort2)(*src2, *(src2 + 1));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = (short2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global  char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		/*  char4 src_data1_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		  char4 src_data1_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		\n"
"		  char4 src_data2_0 = *src2;\n"
"		  char4 src_data2_1 = *(src2 + 4);\n"
"		\n"
"		  char4 dst_data_0 = *((__global char4 *)((__global char *)dst  + dst_index + 0));\n"
"		  char4 dst_data_1 = *((__global char4 *)((__global char *)dst  + dst_index + 4));\n"
"		\n"
"		    char4 data_0 = src_data1_0 & src_data2_0;\n"
"		    char4 data_1 = src_data1_1 & src_data2_1;\n"
"		\n"
"		  data_0 = mask_data ? data_0 : dst_data_0;\n"
"		  data_1 = mask_data ? data_1 : dst_data_1;\n"
"		\n"
"		  *((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		  *((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;*/\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		char8 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C2_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		/* double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		 double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		 double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		 double2 data;\n"
"		data.x = src_data1.x & src_data2.x;\n"
"		data.y = src_data1.y & src_data2.y;\n"
"		       data = mask_data ? data : dst_data;\n"
"		\n"
"		       *((__global double2 *)((__global char *)dst + dst_index)) = data;*/\n"
"		\n"
"		/* char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		 char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		 char8 src_data2_0 = *src2;\n"
"		 char8 src_data2_1 = *(src2 + 8);\n"
"		 char8 src_data2 = *((__constant char8 *)src2);\n"
"		 char8 dst_data_0 = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		 char8 dst_data_1 = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		\n"
"		   char8 data_0 = src_data1_0 & src_data2_0;\n"
"		   char8 data_1 = src_data1_1 & src_data2_1;\n"
"		 data_0 = mask_data ? data_0 : dst_data_0;\n"
"		 data_1 = mask_data ? data_1 : dst_data_1;\n"
"		\n"
"		 *((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		 *((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;*/\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		char16 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = (uchar4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		uchar4 src2_data_1 = (uchar4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		uchar4 src2_data_2 = (uchar4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		uchar4 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		uchar4 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = (char4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		char4 src2_data_1 = (char4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		char4 src2_data_2 = (char4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = (ushort2)(*(src2 + 0), *(src2 + 1));\n"
"		ushort2 src2_data_1 = (ushort2)(*(src2 + 2), *(src2 + 0));\n"
"		ushort2 src2_data_2 = (ushort2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		ushort2 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		ushort2 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = (short2)(*(src2 + 0), *(src2 + 1));\n"
"		short2 src2_data_1 = (short2)(*(src2 + 2), *(src2 + 0));\n"
"		short2 src2_data_2 = (short2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		short2 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		short2 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		int tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		int tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__constant char4 *)src2);\n"
"		char4 src2_data_1 = *((__constant char4 *)src2 + 1);\n"
"		char4 src2_data_2 = *((__constant char4 *)src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C3_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__constant char8 *)src2);\n"
"		char8 src2_data_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src2_data_2 = *((__constant char8 *)src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 & src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 & src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 & src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__constant uchar4 *)src2);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)(dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__constant ushort4 *)src2);\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__constant short4 *)src2);\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data;\n"
"		data = src_data1 & src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_and_with_mask_C4_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src_data2_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src_data2_2 = *((__constant char8 *)src2 + 2);\n"
"		char8 src_data2_3 = *((__constant char8 *)src2 + 3);\n"
"		\n"
"		char8 dst_data_0  = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		char8 dst_data_1  = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		char8 dst_data_2  = *((__global char8 *)((__global char *)dst  + dst_index + 16));\n"
"		char8 dst_data_3  = *((__global char8 *)((__global char *)dst  + dst_index + 24));\n"
"		\n"
"		char8 data_0 = src_data1_0 & src_data2_0;\n"
"		char8 data_1 = src_data1_1 & src_data2_1;\n"
"		char8 data_2 = src_data1_2 & src_data2_2;\n"
"		char8 data_3 = src_data1_3 & src_data2_3;\n"
"		\n"
"		data_0 = mask_data ? data_0 : dst_data_0;\n"
"		data_1 = mask_data ? data_1 : dst_data_1;\n"
"		data_2 = mask_data ? data_2 : dst_data_2;\n"
"		data_3 = mask_data ? data_3 : dst_data_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_not =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_NOT////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_not without mask**************************************/\n"
"__kernel void arithm_bitwise_not_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                    __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = ~ src1_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_not_D1(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		\n"
"		char4 dst_data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = ~ src1_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_not_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                    __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		ushort4 tmp_data = ~ src1_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_not_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                    __global short *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		short4 tmp_data = ~ src1_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_not_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                    __global int *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int tmp  = ~ data1;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_not_D5(__global char *src, int src_step, int src_offset,\n"
"                                    __global char *dst, int dst_step, int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index = mad24(y, src_step, (x << 2) + src_offset);\n"
"		int dst_index = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 data;\n"
"		\n"
"		data = *((__global char4 *)((__global char *)src + src_index));\n"
"		data = ~ data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_not_D6(__global char *src, int src_step, int src_offset,\n"
"                                    __global char *dst, int dst_step, int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index = mad24(y, src_step, (x << 3) + src_offset);\n"
"		int dst_index = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 data;\n"
"		\n"
"		data = *((__global char8 *)((__global char *)src + src_index));\n"
"		data = ~ data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_or =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_OR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_or without mask**************************************/\n"
"__kernel void arithm_bitwise_or_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_D1(__global char *src1, int src1_step, int src1_offset,\n"
"                                   __global char *src2, int src2_step, int src2_offset,\n"
"                                   __global char *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		char4 dst_data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		ushort4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global short *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		short4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global int *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int tmp  = data1 | data2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_D5(__global char *src1, int src1_step, int src1_offset,\n"
"                                   __global char *src2, int src2_step, int src2_offset,\n"
"                                   __global char *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 data2 = *((__global char4 *)((__global char *)src2 + src2_index));\n"
"		char4 tmp = data1 | data2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_D6(__global char *src1, int src1_step, int src1_offset,\n"
"                                   __global char *src2, int src2_step, int src2_offset,\n"
"                                   __global char *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data1 | data2;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_or_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_OR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_or with mask**************************************/\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = convert_char((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_char((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = convert_char((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = convert_char((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = vload2(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = convert_ushort((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_ushort((mask_data.y) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = vload2(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		short2 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = convert_short((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_short((mask_data.y) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__global char4 *)((__global char *)src2 + src2_index));\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C1_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = *((__global ushort2 *)((__global char *)src2 + src2_index));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = *((__global short2 *)((__global char *)src2 + src2_index));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int    *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = *((__global int2 *)((__global char *)src2 + src2_index));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C2_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__global char16 *)((__global char *)src2 + src2_index));\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		uchar4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		uchar4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 =  src1_data_0 | src2_data_0;\n"
"		uchar4 tmp_data_1 =  src1_data_1 | src2_data_1;\n"
"		uchar4 tmp_data_2 =  src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		char4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		char4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 =  src1_data_0 | src2_data_0;\n"
"		char4 tmp_data_1 =  src1_data_1 | src2_data_1;\n"
"		char4 tmp_data_2 =  src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 0));\n"
"		ushort2 src2_data_1 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 4));\n"
"		ushort2 src2_data_2 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 =  src1_data_0 | src2_data_0 ;\n"
"		ushort2 tmp_data_1 =  src1_data_1 | src2_data_1 ;\n"
"		ushort2 tmp_data_2 =  src1_data_2 | src2_data_2 ;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 0));\n"
"		short2 src2_data_1 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 4));\n"
"		short2 src2_data_2 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 =  src1_data_0 | src2_data_0 ;\n"
"		short2 tmp_data_1 =  src1_data_1 | src2_data_1 ;\n"
"		short2 tmp_data_2 =  src1_data_2 | src2_data_2 ;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *((__global int *)((__global char *)src2 + src2_index + 0));\n"
"		int src2_data_1 = *((__global int *)((__global char *)src2 + src2_index + 4));\n"
"		int src2_data_2 = *((__global int *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 =  src1_data_0 |  src2_data_0 ;\n"
"		int tmp_data_1 =  src1_data_1 |  src2_data_1 ;\n"
"		int tmp_data_2 =  src1_data_2 |  src2_data_2 ;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__global char4 *)((__global char *)src2 + src2_index + 0));\n"
"		char4 src2_data_1 = *((__global char4 *)((__global char *)src2 + src2_index + 4));\n"
"		char4 src2_data_2 = *((__global char4 *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C3_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 24) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__global char8 *)((__global char *)src2 + src2_index + 0));\n"
"		char8 src2_data_1 = *((__global char8 *)((__global char *)src2 + src2_index + 8));\n"
"		char8 src2_data_2 = *((__global char8 *)((__global char *)src2 + src2_index + 16));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__global uchar4 *)(src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__global char4 *)(src2 + src2_index));\n"
"		char4 dst_data  = *((__global char4 *)(dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__global ushort4 *)((__global char *)src2 + src2_index));\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__global short4 *)((__global char *)src2 + src2_index));\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__global char16 *)((__global char *)src2 + src2_index));\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_or_with_mask_C4_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 5) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__global char8 *)((__global char *)src2 + src2_index + 0));\n"
"		char8 src_data2_1 = *((__global char8 *)((__global char *)src2 + src2_index + 8));\n"
"		char8 src_data2_2 = *((__global char8 *)((__global char *)src2 + src2_index + 16));\n"
"		char8 src_data2_3 = *((__global char8 *)((__global char *)src2 + src2_index + 24));\n"
"		\n"
"		char8 dst_data_0  = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		char8 dst_data_1  = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		char8 dst_data_2  = *((__global char8 *)((__global char *)dst  + dst_index + 16));\n"
"		char8 dst_data_3  = *((__global char8 *)((__global char *)dst  + dst_index + 24));\n"
"		\n"
"		char8 data_0 = src_data1_0 | src_data2_0;\n"
"		char8 data_1 = src_data1_1 | src_data2_1;\n"
"		char8 data_2 = src_data1_2 | src_data2_2;\n"
"		char8 data_3 = src_data1_3 | src_data2_3;\n"
"		\n"
"		data_0 = mask_data ? data_0 : dst_data_0;\n"
"		data_1 = mask_data ? data_1 : dst_data_1;\n"
"		data_2 = mask_data ? data_2 : dst_data_2;\n"
"		data_3 = mask_data ? data_3 : dst_data_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_or_scalar =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_OR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************and with scalar without mask**************************************/\n"
"__kernel void arithm_s_bitwise_or_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C1_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = (ushort2)(*src2, *src2);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                        __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = (short2)(*src2, *src2);\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		\n"
"		short2 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C1_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                        __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 | src_data2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C1_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C1_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		// uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		char4 src2_data = *((__constant char4 *)src2);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		// char4 tmp_data = src1_data | (convert_char4(src2_data));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = (ushort2)(*(src2), src2[1]);\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                        __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = (short2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                        __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 | src_data2;\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 | src_data2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C2_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = (uchar4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		uchar4 src2_data_1 = (uchar4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		uchar4 src2_data_2 = (uchar4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 =  src1_data_0  |  src2_data_0  ;\n"
"		uchar4 tmp_data_1 =  src1_data_1  |  src2_data_1  ;\n"
"		uchar4 tmp_data_2 =  src1_data_2  |  src2_data_2  ;\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = (char4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		char4 src2_data_1 = (char4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		char4 src2_data_2 = (char4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 =  src1_data_0  |  src2_data_0;\n"
"		char4 tmp_data_1 =  src1_data_1  |  src2_data_1;\n"
"		char4 tmp_data_2 =  src1_data_2  |  src2_data_2;\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = (ushort2)(*(src2 + 0), *(src2 + 1));\n"
"		ushort2 src2_data_1 = (ushort2)(*(src2 + 2), *(src2 + 0));\n"
"		ushort2 src2_data_2 = (ushort2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = src1_data_0  |  src2_data_0  ;\n"
"		ushort2 tmp_data_1 = src1_data_1  |  src2_data_1  ;\n"
"		ushort2 tmp_data_2 = src1_data_2  |  src2_data_2  ;\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                        __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = (short2)(*(src2 + 0), *(src2 + 1));\n"
"		short2 src2_data_1 = (short2)(*(src2 + 2), *(src2 + 0));\n"
"		short2 src2_data_2 = (short2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 =  src1_data_0  |  src2_data_0  ;\n"
"		short2 tmp_data_1 =  src1_data_1  |  src2_data_1  ;\n"
"		short2 tmp_data_2 =  src1_data_2  |  src2_data_2  ;\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                        __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		int tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		int tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__constant char4 *)src2 + 0);\n"
"		char4 src2_data_1 = *((__constant char4 *)src2 + 1);\n"
"		char4 src2_data_2 = *((__constant char4 *)src2 + 2);\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C3_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src2_data_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src2_data_2 = *((__constant char8 *)src2 + 2);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = tmp_data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__constant uchar4 *)src2);\n"
"		\n"
"		uchar4 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		\n"
"		char4 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__constant ushort4 *)src2);\n"
"		\n"
"		ushort4 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                        __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__constant short4 *)src2);\n"
"		\n"
"		short4 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                        __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		\n"
"		char16 data = src_data1 | src_data2;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_C4_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"                                        __global   char *dst,  int dst_step,  int dst_offset,\n"
"                                        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src_data2_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src_data2_2 = *((__constant char8 *)src2 + 2);\n"
"		char8 src_data2_3 = *((__constant char8 *)src2 + 3);\n"
"		\n"
"		char8 data_0 = src_data1_0 | src_data2_0;\n"
"		char8 data_1 = src_data1_1 | src_data2_1;\n"
"		char8 data_2 = src_data1_2 | src_data2_2;\n"
"		char8 data_3 = src_data1_3 | src_data2_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_or_scalar_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_OR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_and with scalar with mask**************************************/\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = (ushort2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = (short2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		short2 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D4(__global   int   *src1, int src1_step, int src1_offset,\n"
"        __global   int   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D5(__global   char   *src1, int src1_step, int src1_offset,\n"
"        __global   char   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C1_D6(__global   char   *src1, int src1_step, int src1_offset,\n"
"        __global   char   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data | src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = (ushort2)(*src2, *(src2 + 1));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = (short2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		char8 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"		\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C2_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		char16 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = (uchar4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		uchar4 src2_data_1 = (uchar4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		uchar4 src2_data_2 = (uchar4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		uchar4 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		uchar4 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = (char4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		char4 src2_data_1 = (char4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		char4 src2_data_2 = (char4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = (ushort2)(*(src2 + 0), *(src2 + 1));\n"
"		ushort2 src2_data_1 = (ushort2)(*(src2 + 2), *(src2 + 0));\n"
"		ushort2 src2_data_2 = (ushort2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		ushort2 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		ushort2 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = (short2)(*(src2 + 0), *(src2 + 1));\n"
"		short2 src2_data_1 = (short2)(*(src2 + 2), *(src2 + 0));\n"
"		short2 src2_data_2 = (short2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		short2 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		short2 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		int tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		int tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__constant char4 *)src2 + 0);\n"
"		char4 src2_data_1 = *((__constant char4 *)src2 + 1);\n"
"		char4 src2_data_2 = *((__constant char4 *)src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"		\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C3_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src2_data_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src2_data_2 = *((__constant char8 *)src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 | src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 | src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 | src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__constant uchar4 *)src2);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)(dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__constant ushort4 *)src2);\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__constant short4 *)src2);\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 | src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_or_with_mask_C4_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src_data2_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src_data2_2 = *((__constant char8 *)src2 + 2);\n"
"		char8 src_data2_3 = *((__constant char8 *)src2 + 3);\n"
"		\n"
"		char8 dst_data_0  = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		char8 dst_data_1  = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		char8 dst_data_2  = *((__global char8 *)((__global char *)dst  + dst_index + 16));\n"
"		char8 dst_data_3  = *((__global char8 *)((__global char *)dst  + dst_index + 24));\n"
"		\n"
"		char8 data_0 = src_data1_0 | src_data2_0;\n"
"		char8 data_1 = src_data1_1 | src_data2_1;\n"
"		char8 data_2 = src_data1_2 | src_data2_2;\n"
"		char8 data_3 = src_data1_3 | src_data2_3;\n"
"		\n"
"		data_0 = mask_data ? data_0 : dst_data_0;\n"
"		data_1 = mask_data ? data_1 : dst_data_1;\n"
"		data_2 = mask_data ? data_2 : dst_data_2;\n"
"		data_3 = mask_data ? data_3 : dst_data_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_xor =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_XOR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_xor without mask**************************************/\n"
"__kernel void arithm_bitwise_xor_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                    __global uchar *src2, int src2_step, int src2_offset,\n"
"                                    __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_D1(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *src2, int src2_step, int src2_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		char4 dst_data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                    __global ushort *src2, int src2_step, int src2_offset,\n"
"                                    __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		ushort4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                    __global short *src2, int src2_step, int src2_offset,\n"
"                                    __global short *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		short4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                    __global int *src2, int src2_step, int src2_offset,\n"
"                                    __global int *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int tmp  = data1 ^ data2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_D5(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *src2, int src2_step, int src2_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 data2 = *((__global char4 *)((__global char *)src2 + src2_index));\n"
"		char4 tmp = data1 ^ data2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_D6(__global char *src1, int src1_step, int src1_offset,\n"
"                                    __global char *src2, int src2_step, int src2_offset,\n"
"                                    __global char *dst,  int dst_step,  int dst_offset,\n"
"                                    int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data1 ^ data2;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_xor_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_XOR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_xor with mask**************************************/\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = convert_char((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_char((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = convert_char((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = convert_char((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = vload2(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = convert_ushort((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_ushort((mask_data.y) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = vload2(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		short2 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = convert_short((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = convert_short((mask_data.y) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__global char4 *)((__global char *)src2 + src2_index));\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C1_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = *((__global ushort2 *)((__global char *)src2 + src2_index));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = *((__global short2 *)((__global char *)src2 + src2_index));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int    *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = *((__global int2 *)((__global char *)src2 + src2_index));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__global char8 *)((__global char *)src2 + src2_index));\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C2_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__global char16 *)((__global char *)src2 + src2_index));\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		uchar4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		uchar4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 =  src1_data_0 ^ src2_data_0;\n"
"		uchar4 tmp_data_1 =  src1_data_1 ^ src2_data_1;\n"
"		uchar4 tmp_data_2 =  src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		char4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		char4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 =  src1_data_0 ^ src2_data_0;\n"
"		char4 tmp_data_1 =  src1_data_1 ^ src2_data_1;\n"
"		char4 tmp_data_2 =  src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 0));\n"
"		ushort2 src2_data_1 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 4));\n"
"		ushort2 src2_data_2 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 =  src1_data_0 ^ src2_data_0 ;\n"
"		ushort2 tmp_data_1 =  src1_data_1 ^ src2_data_1 ;\n"
"		ushort2 tmp_data_2 =  src1_data_2 ^ src2_data_2 ;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 0));\n"
"		short2 src2_data_1 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 4));\n"
"		short2 src2_data_2 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 =  src1_data_0 ^ src2_data_0 ;\n"
"		short2 tmp_data_1 =  src1_data_1 ^ src2_data_1 ;\n"
"		short2 tmp_data_2 =  src1_data_2 ^ src2_data_2 ;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *((__global int *)((__global char *)src2 + src2_index + 0));\n"
"		int src2_data_1 = *((__global int *)((__global char *)src2 + src2_index + 4));\n"
"		int src2_data_2 = *((__global int *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 =  src1_data_0 ^  src2_data_0 ;\n"
"		int tmp_data_1 =  src1_data_1 ^  src2_data_1 ;\n"
"		int tmp_data_2 =  src1_data_2 ^  src2_data_2 ;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__global char4 *)((__global char *)src2 + src2_index + 0));\n"
"		char4 src2_data_1 = *((__global char4 *)((__global char *)src2 + src2_index + 4));\n"
"		char4 src2_data_2 = *((__global char4 *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C3_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 24) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__global char8 *)((__global char *)src2 + src2_index + 0));\n"
"		char8 src2_data_1 = *((__global char8 *)((__global char *)src2 + src2_index + 8));\n"
"		char8 src2_data_2 = *((__global char8 *)((__global char *)src2 + src2_index + 16));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__global uchar4 *)(src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D1(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__global char4 *)(src2 + src2_index));\n"
"		char4 dst_data  = *((__global char4 *)(dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__global ushort4 *)((__global char *)src2 + src2_index));\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__global short4 *)((__global char *)src2 + src2_index));\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D5(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__global char16 *)((__global char *)src2 + src2_index));\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_bitwise_xor_with_mask_C4_D6(__global char *src1, int src1_step, int src1_offset,\n"
"        __global char *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global char *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 5) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__global char8 *)((__global char *)src2 + src2_index + 0));\n"
"		char8 src_data2_1 = *((__global char8 *)((__global char *)src2 + src2_index + 8));\n"
"		char8 src_data2_2 = *((__global char8 *)((__global char *)src2 + src2_index + 16));\n"
"		char8 src_data2_3 = *((__global char8 *)((__global char *)src2 + src2_index + 24));\n"
"		\n"
"		char8 dst_data_0  = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		char8 dst_data_1  = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		char8 dst_data_2  = *((__global char8 *)((__global char *)dst  + dst_index + 16));\n"
"		char8 dst_data_3  = *((__global char8 *)((__global char *)dst  + dst_index + 24));\n"
"		\n"
"		char8 data_0 = src_data1_0 ^ src_data2_0;\n"
"		char8 data_1 = src_data1_1 ^ src_data2_1;\n"
"		char8 data_2 = src_data1_2 ^ src_data2_2;\n"
"		char8 data_3 = src_data1_3 ^ src_data2_3;\n"
"		\n"
"		data_0 = mask_data ? data_0 : dst_data_0;\n"
"		data_1 = mask_data ? data_1 : dst_data_1;\n"
"		data_2 = mask_data ? data_2 : dst_data_2;\n"
"		data_3 = mask_data ? data_3 : dst_data_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_xor_scalar =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_XOR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************xor with scalar without mask**************************************/\n"
"__kernel void arithm_s_bitwise_xor_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C1_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = (ushort2)(*src2, *src2);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = (short2)(*src2, *src2);\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		\n"
"		short2 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C1_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C1_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C1_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ convert_char4(src2_data);\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = (ushort2)(*(src2), src2[1]);\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = (short2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 ^ src_data2;\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 ^ src_data2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C2_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = (uchar4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		uchar4 src2_data_1 = (uchar4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		uchar4 src2_data_2 = (uchar4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 =  src1_data_0  ^  src2_data_0  ;\n"
"		uchar4 tmp_data_1 =  src1_data_1  ^  src2_data_1  ;\n"
"		uchar4 tmp_data_2 =  src1_data_2  ^  src2_data_2  ;\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = (char4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		char4 src2_data_1 = (char4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		char4 src2_data_2 = (char4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 =  src1_data_0  ^  src2_data_0;\n"
"		char4 tmp_data_1 =  src1_data_1  ^  src2_data_1;\n"
"		char4 tmp_data_2 =  src1_data_2  ^  src2_data_2;\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = (ushort2)(*(src2 + 0), *(src2 + 1));\n"
"		ushort2 src2_data_1 = (ushort2)(*(src2 + 2), *(src2 + 0));\n"
"		ushort2 src2_data_2 = (ushort2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = src1_data_0 ^ src2_data_0  ;\n"
"		ushort2 tmp_data_1 = src1_data_1 ^ src2_data_1  ;\n"
"		ushort2 tmp_data_2 = src1_data_2 ^ src2_data_2  ;\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = (short2)(*(src2 + 0), *(src2 + 1));\n"
"		short2 src2_data_1 = (short2)(*(src2 + 2), *(src2 + 0));\n"
"		short2 src2_data_2 = (short2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 =  src1_data_0 ^ src2_data_0  ;\n"
"		short2 tmp_data_1 =  src1_data_1 ^ src2_data_1  ;\n"
"		short2 tmp_data_2 =  src1_data_2 ^ src2_data_2  ;\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		int tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		int tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__constant char4 *)src2 + 0);\n"
"		char4 src2_data_1 = *((__constant char4 *)src2 + 1);\n"
"		char4 src2_data_2 = *((__constant char4 *)src2 + 2);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C3_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src2_data_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src2_data_2 = *((__constant char8 *)src2 + 2);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = tmp_data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__constant uchar4 *)src2);\n"
"		\n"
"		uchar4 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		\n"
"		char4 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__constant ushort4 *)src2);\n"
"		\n"
"		ushort4 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__constant short4 *)src2);\n"
"		\n"
"		short4 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		\n"
"		char16 data = src_data1 ^ src_data2;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_C4_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src_data2_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src_data2_2 = *((__constant char8 *)src2 + 2);\n"
"		char8 src_data2_3 = *((__constant char8 *)src2 + 3);\n"
"		\n"
"		char8 data_0 = src_data1_0 ^ src_data2_0;\n"
"		char8 data_1 = src_data1_1 ^ src_data2_1;\n"
"		char8 data_2 = src_data1_2 ^ src_data2_2;\n"
"		char8 data_3 = src_data1_3 ^ src_data2_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_bitwise_xor_scalar_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////BITWISE_XOR////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************bitwise_and with scalar with mask**************************************/\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = (ushort2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		ushort2 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = (short2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		short2 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D4(__global   int   *src1, int src1_step, int src1_offset,\n"
"        __global   int   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D5(__global   char   *src1, int src1_step, int src1_offset,\n"
"        __global   char   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)((__global char *)src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C1_D6(__global   char  *src1, int src1_step, int src1_offset,\n"
"        __global   char   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = (uchar4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		char4 src1_data = vload4(0, src1 + src1_index);\n"
"		char4 src2_data = (char4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		char4 data = *((__global char4 *)(dst + dst_index));\n"
"		char4 tmp_data = src1_data ^ src2_data;\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = (ushort2)(*src2, *(src2 + 1));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort2 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = (short2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short2 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1 = *((__global char8 *)((__global char *)src1 + src1_index));\n"
"		char8 src_data2 = *((__constant char8 *)src2);\n"
"		char8 dst_data  = *((__global char8 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char8 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C2_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = (uchar4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		uchar4 src2_data_1 = (uchar4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		uchar4 src2_data_2 = (uchar4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		uchar4 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		uchar4 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		char4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		char4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		char4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		char4 src2_data_0 = (char4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		char4 src2_data_1 = (char4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		char4 src2_data_2 = (char4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)(dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)(dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)(dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global char4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = (ushort2)(*(src2 + 0), *(src2 + 1));\n"
"		ushort2 src2_data_1 = (ushort2)(*(src2 + 2), *(src2 + 0));\n"
"		ushort2 src2_data_2 = (ushort2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		ushort2 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		ushort2 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = (short2)(*(src2 + 0), *(src2 + 1));\n"
"		short2 src2_data_1 = (short2)(*(src2 + 2), *(src2 + 0));\n"
"		short2 src2_data_2 = (short2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		short2 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		short2 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		int tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		int tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		char4 src1_data_0 = *((__global char4 *)((__global char *)src1 + src1_index + 0));\n"
"		char4 src1_data_1 = *((__global char4 *)((__global char *)src1 + src1_index + 4));\n"
"		char4 src1_data_2 = *((__global char4 *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		char4 src2_data_0 = *((__constant char4 *)src2 + 0);\n"
"		char4 src2_data_1 = *((__constant char4 *)src2 + 1);\n"
"		char4 src2_data_2 = *((__constant char4 *)src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char4 data_0 = *((__global char4 *)((__global char *)dst + dst_index + 0));\n"
"		char4 data_1 = *((__global char4 *)((__global char *)dst + dst_index + 4));\n"
"		char4 data_2 = *((__global char4 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		char4 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char4 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char4 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global char4 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C3_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		char8 src1_data_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src1_data_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src1_data_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		char8 src2_data_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src2_data_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src2_data_2 = *((__constant char8 *)src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		char8 data_0 = *((__global char8 *)((__global char *)dst + dst_index + 0));\n"
"		char8 data_1 = *((__global char8 *)((__global char *)dst + dst_index + 8));\n"
"		char8 data_2 = *((__global char8 *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		char8 tmp_data_0 = src1_data_0 ^ src2_data_0;\n"
"		char8 tmp_data_1 = src1_data_1 ^ src2_data_1;\n"
"		char8 tmp_data_2 = src1_data_2 ^ src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant uchar *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__constant uchar4 *)src2);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D1(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char4 src_data1 = *((__global char4 *)(src1 + src1_index));\n"
"		char4 src_data2 = *((__constant char4 *)src2);\n"
"		char4 dst_data  = *((__global char4 *)(dst  + dst_index));\n"
"		\n"
"		char4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant ushort *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__constant ushort4 *)src2);\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant short *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__constant short4 *)src2);\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D5(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char16 src_data1 = *((__global char16 *)((__global char *)src1 + src1_index));\n"
"		char16 src_data2 = *((__constant char16 *)src2);\n"
"		char16 dst_data  = *((__global char16 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		char16 data = src_data1 ^ src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global char16 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_bitwise_xor_with_mask_C4_D6(__global   char *src1, int src1_step, int src1_offset,\n"
"        __global   char *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant char *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		char8 src_data1_0 = *((__global char8 *)((__global char *)src1 + src1_index + 0));\n"
"		char8 src_data1_1 = *((__global char8 *)((__global char *)src1 + src1_index + 8));\n"
"		char8 src_data1_2 = *((__global char8 *)((__global char *)src1 + src1_index + 16));\n"
"		char8 src_data1_3 = *((__global char8 *)((__global char *)src1 + src1_index + 24));\n"
"		\n"
"		char8 src_data2_0 = *((__constant char8 *)src2 + 0);\n"
"		char8 src_data2_1 = *((__constant char8 *)src2 + 1);\n"
"		char8 src_data2_2 = *((__constant char8 *)src2 + 2);\n"
"		char8 src_data2_3 = *((__constant char8 *)src2 + 3);\n"
"		\n"
"		char8 dst_data_0  = *((__global char8 *)((__global char *)dst  + dst_index + 0));\n"
"		char8 dst_data_1  = *((__global char8 *)((__global char *)dst  + dst_index + 8));\n"
"		char8 dst_data_2  = *((__global char8 *)((__global char *)dst  + dst_index + 16));\n"
"		char8 dst_data_3  = *((__global char8 *)((__global char *)dst  + dst_index + 24));\n"
"		\n"
"		char8 data_0 = src_data1_0 ^ src_data2_0;\n"
"		char8 data_1 = src_data1_1 ^ src_data2_1;\n"
"		char8 data_2 = src_data1_2 ^ src_data2_2;\n"
"		char8 data_3 = src_data1_3 ^ src_data2_3;\n"
"		\n"
"		data_0 = mask_data ? data_0 : dst_data_0;\n"
"		data_1 = mask_data ? data_1 : dst_data_1;\n"
"		data_2 = mask_data ? data_2 : dst_data_2;\n"
"		data_3 = mask_data ? data_3 : dst_data_3;\n"
"		\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"		*((__global char8 *)((__global char *)dst + dst_index + 24)) = data_3;\n"
"	}\n"
"}\n"
;
const char *arithm_cartToPolar =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#define CV_PI   3.1415926535897932384626433832795\n"
"__kernel void arithm_cartToPolar_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                    __global float *src2, int src2_step, int src2_offset,\n"
"                                    __global float *dst1, int dst1_step, int dst1_offset, //magnitude\n"
"                                    __global float *dst2, int dst2_step, int dst2_offset, //cartToPolar\n"
"                                    int rows, int cols, int angInDegree)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		\n"
"		int dst1_index = mad24(y, dst1_step, (x << 2) + dst1_offset);\n"
"		int dst2_index = mad24(y, dst2_step, (x << 2) + dst2_offset);\n"
"		\n"
"		float x = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float y = *((__global float *)((__global char *)src2 + src2_index));\n"
"		\n"
"		float x2 = x * x;\n"
"		float y2 = y * y;\n"
"		\n"
"		float magnitude = sqrt(x2 + y2);\n"
"		float cartToPolar;\n"
"		\n"
"		float tmp = y >= 0 ? 0 : CV_PI * 2;\n"
"		tmp = x < 0 ? CV_PI : tmp;\n"
"		\n"
"		float tmp1 = y >= 0 ? CV_PI * 0.5 : CV_PI * 1.5;\n"
"		cartToPolar = y2 <= x2 ? x * y / (x2 + 0.28f * y2 + (float)DBL_EPSILON)  + tmp :\n"
"		              tmp1 - x * y / (y2 + 0.28f * x2 + (float)DBL_EPSILON);\n"
"		              \n"
"		cartToPolar = angInDegree == 0 ? cartToPolar : cartToPolar * (float)(180 / CV_PI);\n"
"		\n"
"		*((__global float *)((__global char *)dst1 + dst1_index)) = magnitude;\n"
"		*((__global float *)((__global char *)dst2 + dst2_index)) = cartToPolar;\n"
"	}\n"
"}\n"
"__kernel void arithm_cartToPolar_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                    __global double *src2, int src2_step, int src2_offset,\n"
"                                    __global double *dst1, int dst1_step, int dst1_offset,\n"
"                                    __global double *dst2, int dst2_step, int dst2_offset,\n"
"                                    int rows, int cols, int angInDegree)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		\n"
"		int dst1_index = mad24(y, dst1_step, (x << 3) + dst1_offset);\n"
"		int dst2_index = mad24(y, dst2_step, (x << 3) + dst2_offset);\n"
"		\n"
"		double x = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double y = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		double x2 = x * x;\n"
"		double y2 = y * y;\n"
"		\n"
"		double magnitude = sqrt(x2 + y2);\n"
"		double cartToPolar;\n"
"		\n"
"		float tmp = y >= 0 ? 0 : CV_PI * 2;\n"
"		tmp = x < 0 ? CV_PI : tmp;\n"
"		\n"
"		float tmp1 = y >= 0 ? CV_PI * 0.5 : CV_PI * 1.5;\n"
"		cartToPolar = y2 <= x2 ? x * y / (x2 + 0.28f * y2 + (float)DBL_EPSILON)  + tmp :\n"
"		              tmp1 - x * y / (y2 + 0.28f * x2 + (float)DBL_EPSILON);\n"
"		              \n"
"		cartToPolar = angInDegree == 0 ? cartToPolar : cartToPolar * (float)(180 / CV_PI);\n"
"		\n"
"		*((__global double *)((__global char *)dst1 + dst1_index)) = magnitude;\n"
"		*((__global double *)((__global char *)dst2 + dst2_index)) = cartToPolar;\n"
"	}\n"
"}\n"
;
const char *arithm_compare_eq =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////Compare EQ////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_compare_eq_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data == src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_eq_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data == src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_eq_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data == src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_eq_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int4 src1_data = vload4(0, (__global int *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = vload4(0, (__global int *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data == src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_eq_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                   __global float *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		float4 src1_data = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data == src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_eq_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                   __global double *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		double4 src1_data = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data == src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/***********************************Compare GT**************************/\n"
"__kernel void arithm_compare_gt_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data > src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/*__kernel void arithm_compare_gt_D1 (__global char *src1, int src1_step, int src1_offset,\n"
"                             __global char *src2, int src2_step, int src2_offset,\n"
"                             __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                             int rows, int cols, int dst_step1)\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    if (x < cols && y < rows)\n"
"    {\n"
"        x = x << 2;\n"
"        #define dst_align (dst_offset & 3)\n"
"        int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"        int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"        int dst_start  = mad24(y, dst_step, dst_offset);\n"
"        int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"        int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"        char4 src1_data = vload4(0, src1 + src1_index);\n"
"        char4 src2_data = vload4(0, src2 + src2_index);\n"
"        uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"        uchar4 tmp_data = convert_uchar4_sat(-(src1_data > src2_data));\n"
"        dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"        dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"        dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"        dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"        *((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"    }\n"
"}*/\n"
"__kernel void arithm_compare_gt_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data > src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_gt_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data > src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_gt_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int4 src1_data = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data > src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_gt_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                   __global float *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		float4 src1_data = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data > src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_gt_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                   __global double *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		double4 src1_data = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data > src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/***********************************Compare GE**************************/\n"
"__kernel void arithm_compare_ge_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data >= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/*__kernel void arithm_compare_ge_D1 (__global char *src1, int src1_step, int src1_offset,\n"
"                             __global char *src2, int src2_step, int src2_offset,\n"
"                             __global char *dst,  int dst_step,  int dst_offset,\n"
"                             int rows, int cols, int dst_step1)\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    if (x < cols && y < rows)\n"
"    {\n"
"        x = x << 2;\n"
"        #define dst_align (dst_offset & 3)\n"
"        int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"        int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"        int dst_start  = mad24(y, dst_step, dst_offset);\n"
"        int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"        int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"        char4 src1_data = vload4(0, src1 + src1_index);\n"
"        char4 src2_data = vload4(0, src2 + src2_index);\n"
"        char4 dst_data = *((__global char4 *)(dst + dst_index));\n"
"        char4 tmp_data = convert_char4_sat((src1_data >= src2_data));\n"
"        dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"        dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"        dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"        dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"        *((__global char4 *)(dst + dst_index)) = dst_data;\n"
"    }\n"
"}*/\n"
"__kernel void arithm_compare_ge_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data >= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ge_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data >= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ge_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int4 src1_data = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data >= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ge_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                   __global float *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		float4 src1_data = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data >= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ge_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                   __global double *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		double4 src1_data = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data >= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
;
const char *arithm_compare_ne =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"/***********************************Compare NE*******************************/\n"
"__kernel void arithm_compare_ne_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data != src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/*__kernel void arithm_compare_ne_D1 (__global char *src1, int src1_step, int src1_offset,\n"
"                             __global char *src2, int src2_step, int src2_offset,\n"
"                             __global char *dst,  int dst_step,  int dst_offset,\n"
"                             int rows, int cols, int dst_step1)\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    if (x < cols && y < rows)\n"
"    {\n"
"        x = x << 2;\n"
"        #define dst_align (dst_offset & 3)\n"
"        int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"        int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"        int dst_start  = mad24(y, dst_step, dst_offset);\n"
"        int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"        int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"        char4 src1_data = vload4(0, src1 + src1_index);\n"
"        char4 src2_data = vload4(0, src2 + src2_index);\n"
"        char4 dst_data = *((__global char4 *)(dst + dst_index));\n"
"        char4 tmp_data = convert_char4_sat((src1_data != src2_data));\n"
"        dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"        dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"        dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"        dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"        *((__global char4 *)(dst + dst_index)) = dst_data;\n"
"    }\n"
"}*/\n"
"__kernel void arithm_compare_ne_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data != src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ne_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data != src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ne_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int4 src1_data = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data != src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ne_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                   __global float *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		float4 src1_data = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data != src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_ne_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                   __global double *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		double4 src1_data = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data != src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/***********************************Compare LT*******************************/\n"
"__kernel void arithm_compare_lt_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global  uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data < src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/*__kernel void arithm_compare_lt_D1 (__global char *src1, int src1_step, int src1_offset,\n"
"                             __global char *src2, int src2_step, int src2_offset,\n"
"                             __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                             int rows, int cols, int dst_step1)\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    if (x < cols && y < rows)\n"
"    {\n"
"        x = x << 2;\n"
"        #define dst_align (dst_offset & 3)\n"
"        int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"        int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"        int dst_start  = mad24(y, dst_step, dst_offset);\n"
"        int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"        int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"        char4 src1_data = vload4(0, src1 + src1_index);\n"
"        char4 src2_data = vload4(0, src2 + src2_index);\n"
"        uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"        uchar4 tmp_data = convert_uchar4_sat(-(src1_data < src2_data));\n"
"        dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"        dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"        dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"        dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"        *((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"    }\n"
"}*/\n"
"__kernel void arithm_compare_lt_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data < src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_lt_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data < src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_lt_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int4 src1_data = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data < src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_lt_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                   __global float *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		float4 src1_data = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data < src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_lt_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                   __global double *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		double4 src1_data = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data < src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/***********************************Compare LE*******************************/\n"
"__kernel void arithm_compare_le_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                                   __global uchar *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data <= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"/*__kernel void arithm_compare_le_D1 (__global char *src1, int src1_step, int src1_offset,\n"
"                             __global char *src2, int src2_step, int src2_offset,\n"
"                             __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                             int rows, int cols, int dst_step1)\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    if (x < cols && y < rows)\n"
"    {\n"
"        x = x << 2;\n"
"        #define dst_align (dst_offset & 3)\n"
"        int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"        int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"        int dst_start  = mad24(y, dst_step, dst_offset);\n"
"        int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"        int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"        char4 src1_data = vload4(0, src1 + src1_index);\n"
"        char4 src2_data = vload4(0, src2 + src2_index);\n"
"        uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"        uchar4 tmp_data = convert_uchar4_sat(-(src1_data <= src2_data));\n"
"        dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"        dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"        dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"        dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"        *((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"    }\n"
"}*/\n"
"__kernel void arithm_compare_le_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                                   __global ushort *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data <= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_le_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                                   __global short *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data <= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_le_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                                   __global int *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int4 src1_data = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src2_data = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data <= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_le_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                   __global float *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		float4 src1_data = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data <= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_compare_le_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                   __global double *src2, int src2_step, int src2_offset,\n"
"                                   __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                                   int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		double4 src1_data = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src2_data = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		uchar4 tmp_data = convert_uchar4((src1_data <= src2_data));\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
;
const char *arithm_div =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"uchar round2_uchar(double v)\n"
"{\n"
"	uchar v1 = convert_uchar_sat(v);\n"
"	uchar v2 = convert_uchar_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	\n"
"	return (((v - v1) == 0.5) && (v1 % 2 == 0)) ? v1 : v2;\n"
"}\n"
"ushort round2_ushort(double v)\n"
"{\n"
"	ushort v1 = convert_ushort_sat(v);\n"
"	ushort v2 = convert_ushort_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	\n"
"	return (((v - v1) == 0.5) && (v1 % 2 == 0)) ? v1 : v2;\n"
"}\n"
"short round2_short(double v)\n"
"{\n"
"	short v1 = convert_short_sat(v);\n"
"	short v2 = convert_short_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	\n"
"	return (((v - v1) == 0.5) && (v1 % 2 == 0)) ? v1 : v2;\n"
"}\n"
"int round2_int(double v)\n"
"{\n"
"	int v1 = convert_int_sat(v);\n"
"	int v2 = convert_int_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	\n"
"	return (((v - v1) == 0.5) && (v1 % 2 == 0)) ? v1 : v2;\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////divide///////////////////////////////////////////////////\n"
"//////////////////////////////////////////////////////////////////////////////////////\n"
"/**********************************div*********************************************/\n"
"__kernel void arithm_div_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                            __global uchar *src2, int src2_step, int src2_offset,\n"
"                            __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst + dst_index));\n"
"		\n"
"		double4 tmp      = convert_double4(src1_data) * scalar;\n"
"		\n"
"		uchar4 tmp_data;\n"
"		tmp_data.x = ((tmp.x == 0) || (src2_data.x == 0)) ? 0 : round2_uchar(tmp.x / (double)src2_data.x);\n"
"		tmp_data.y = ((tmp.y == 0) || (src2_data.y == 0)) ? 0 : round2_uchar(tmp.y / (double)src2_data.y);\n"
"		tmp_data.z = ((tmp.z == 0) || (src2_data.z == 0)) ? 0 : round2_uchar(tmp.z / (double)src2_data.z);\n"
"		tmp_data.w = ((tmp.w == 0) || (src2_data.w == 0)) ? 0 : round2_uchar(tmp.w / (double)src2_data.w);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_div_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                            __global ushort *src2, int src2_step, int src2_offset,\n"
"                            __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		\n"
"		double4 tmp   = convert_double4(src1_data) * scalar;\n"
"		\n"
"		ushort4 tmp_data;\n"
"		tmp_data.x = ((tmp.x == 0) || (src2_data.x == 0)) ? 0 : round2_ushort(tmp.x / (double)src2_data.x);\n"
"		tmp_data.y = ((tmp.y == 0) || (src2_data.y == 0)) ? 0 : round2_ushort(tmp.y / (double)src2_data.y);\n"
"		tmp_data.z = ((tmp.z == 0) || (src2_data.z == 0)) ? 0 : round2_ushort(tmp.z / (double)src2_data.z);\n"
"		tmp_data.w = ((tmp.w == 0) || (src2_data.w == 0)) ? 0 : round2_ushort(tmp.w / (double)src2_data.w);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_div_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                            __global short *src2, int src2_step, int src2_offset,\n"
"                            __global short *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		\n"
"		double4 tmp   = convert_double4(src1_data) * scalar;\n"
"		\n"
"		short4 tmp_data;\n"
"		tmp_data.x = ((tmp.x == 0) || (src2_data.x == 0)) ? 0 : round2_short(tmp.x / (double)src2_data.x);\n"
"		tmp_data.y = ((tmp.y == 0) || (src2_data.y == 0)) ? 0 : round2_short(tmp.y / (double)src2_data.y);\n"
"		tmp_data.z = ((tmp.z == 0) || (src2_data.z == 0)) ? 0 : round2_short(tmp.z / (double)src2_data.z);\n"
"		tmp_data.w = ((tmp.w == 0) || (src2_data.w == 0)) ? 0 : round2_short(tmp.w / (double)src2_data.w);\n"
"		\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_div_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                            __global int *src2, int src2_step, int src2_offset,\n"
"                            __global int *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		\n"
"		double tmp  = convert_double(data1) * scalar;\n"
"		int tmp_data = (tmp == 0 || data2 == 0) ? 0 : round2_int(tmp / (convert_double)(data2));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_div_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                            __global float *src2, int src2_step, int src2_offset,\n"
"                            __global float *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		\n"
"		double tmp  = convert_double(data1) * scalar;\n"
"		float tmp_data = (tmp == 0 || data2 == 0) ? 0 : convert_float(tmp / (convert_double)(data2));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_div_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                            __global double *src2, int src2_step, int src2_offset,\n"
"                            __global double *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		double tmp  = data1 * scalar;\n"
"		double tmp_data = (tmp == 0 || data2 == 0) ? 0 : (tmp / data2);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
"/************************************div with scalar************************************/\n"
"__kernel void arithm_s_div_D0(__global uchar *src, int src_step, int src_offset,\n"
"                              __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                              int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src_index = mad24(y, src_step, x + src_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src_data = vload4(0, src + src_index);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst + dst_index));\n"
"		\n"
"		uchar4 tmp_data;\n"
"		tmp_data.x = ((scalar == 0) || (src_data.x == 0)) ? 0 : round2_uchar(scalar / (double)src_data.x);\n"
"		tmp_data.y = ((scalar == 0) || (src_data.y == 0)) ? 0 : round2_uchar(scalar / (double)src_data.y);\n"
"		tmp_data.z = ((scalar == 0) || (src_data.z == 0)) ? 0 : round2_uchar(scalar / (double)src_data.z);\n"
"		tmp_data.w = ((scalar == 0) || (src_data.w == 0)) ? 0 : round2_uchar(scalar / (double)src_data.w);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_div_D2(__global ushort *src, int src_step, int src_offset,\n"
"                              __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                              int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src_index = mad24(y, src_step, (x << 1) + src_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src_data = vload4(0, (__global ushort *)((__global char *)src + src_index));\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		\n"
"		ushort4 tmp_data;\n"
"		tmp_data.x = ((scalar == 0) || (src_data.x == 0)) ? 0 : round2_ushort(scalar / (double)src_data.x);\n"
"		tmp_data.y = ((scalar == 0) || (src_data.y == 0)) ? 0 : round2_ushort(scalar / (double)src_data.y);\n"
"		tmp_data.z = ((scalar == 0) || (src_data.z == 0)) ? 0 : round2_ushort(scalar / (double)src_data.z);\n"
"		tmp_data.w = ((scalar == 0) || (src_data.w == 0)) ? 0 : round2_ushort(scalar / (double)src_data.w);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_div_D3(__global short *src, int src_step, int src_offset,\n"
"                              __global short *dst,  int dst_step,  int dst_offset,\n"
"                              int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src_index = mad24(y, src_step, (x << 1) + src_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src_data = vload4(0, (__global short *)((__global char *)src + src_index));\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		\n"
"		short4 tmp_data;\n"
"		tmp_data.x = ((scalar == 0) || (src_data.x == 0)) ? 0 : round2_short(scalar / (double)src_data.x);\n"
"		tmp_data.y = ((scalar == 0) || (src_data.y == 0)) ? 0 : round2_short(scalar / (double)src_data.y);\n"
"		tmp_data.z = ((scalar == 0) || (src_data.z == 0)) ? 0 : round2_short(scalar / (double)src_data.z);\n"
"		tmp_data.w = ((scalar == 0) || (src_data.w == 0)) ? 0 : round2_short(scalar / (double)src_data.w);\n"
"		\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_div_D4(__global int *src, int src_step, int src_offset,\n"
"                              __global int *dst,  int dst_step,  int dst_offset,\n"
"                              int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index = mad24(y, src_step, (x << 2) + src_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data = *((__global int *)((__global char *)src + src_index));\n"
"		\n"
"		int tmp_data = (scalar == 0 || data == 0) ? 0 : round2_int(scalar / (convert_double)(data));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_div_D5(__global float *src, int src_step, int src_offset,\n"
"                              __global float *dst,  int dst_step,  int dst_offset,\n"
"                              int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index = mad24(y, src_step, (x << 2) + src_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data = *((__global float *)((__global char *)src + src_index));\n"
"		\n"
"		float tmp_data = (scalar == 0 || data == 0) ? 0 : convert_float(scalar / (convert_double)(data));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_div_D6(__global double *src, int src_step, int src_offset,\n"
"                              __global double *dst,  int dst_step,  int dst_offset,\n"
"                              int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index = mad24(y, src_step, (x << 3) + src_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data = *((__global double *)((__global char *)src + src_index));\n"
"		\n"
"		double tmp_data = (scalar == 0 || data == 0) ? 0 : (scalar / data);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"}\n"
;
const char *arithm_exp =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Wu Zailong, bullet@yeah.net\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////EXP//////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_exp_D5(int rows, int cols, int srcStep, int dstStep, int srcOffset, int dstOffset, __global float *src, __global float *dst)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		int srcIdx = mad24(y, srcStep, x + srcOffset);\n"
"		int dstIdx = mad24(y, dstStep, x + dstOffset);\n"
"		\n"
"		float src_data = *((__global float *)((__global char *)src + srcIdx));\n"
"		float dst_data = exp(src_data);\n"
"		\n"
"		*((__global float *)((__global char *)dst + dstIdx)) = dst_data;\n"
"		\n"
"	}\n"
"}\n"
"__kernel void arithm_exp_D6(int rows, int cols, int srcStep, int dstStep, int srcOffset, int dstOffset, __global double *src, __global double *dst)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 3;\n"
"		int srcIdx = mad24(y, srcStep, x + srcOffset);\n"
"		int dstIdx = mad24(y, dstStep, x + dstOffset);\n"
"		\n"
"		double src_data = *((__global double *)((__global char *)src + srcIdx));\n"
"		double dst_data = exp(src_data);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dstIdx)) = dst_data;\n"
"		// dst[dstIdx] = exp(src[srcIdx]);\n"
"	}\n"
"}\n"
;
const char *arithm_flip =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////flip rows///////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_flip_rows_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                  __global uchar *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src_index_0 = mad24(y,            src_step, x + src_offset - dst_align);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, x + src_offset - dst_align);\n"
"		\n"
"		int dst_start_0  = mad24(y,            dst_step, dst_offset);\n"
"		int dst_start_1  = mad24(rows - y - 1, dst_step, dst_offset);\n"
"		int dst_end_0    = mad24(y,            dst_step, dst_offset + dst_step1);\n"
"		int dst_end_1    = mad24(rows - y - 1, dst_step, dst_offset + dst_step1);\n"
"		int dst_index_0  = mad24(y,            dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		int dst_index_1  = mad24(rows - y - 1, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src_data_0 = vload4(0, src + src_index_0);\n"
"		uchar4 src_data_1 = vload4(0, src + src_index_1);\n"
"		\n"
"		uchar4 dst_data_0 = *((__global uchar4 *)(dst + dst_index_0));\n"
"		uchar4 dst_data_1 = *((__global uchar4 *)(dst + dst_index_1));\n"
"		\n"
"		dst_data_0.x = (dst_index_0 + 0 >= dst_start_0)                                   ? src_data_1.x : dst_data_0.x;\n"
"		dst_data_0.y = ((dst_index_0 + 1 >= dst_start_0) && (dst_index_0 + 1 < dst_end_0)) ? src_data_1.y : dst_data_0.y;\n"
"		dst_data_0.z = ((dst_index_0 + 2 >= dst_start_0) && (dst_index_0 + 2 < dst_end_0)) ? src_data_1.z : dst_data_0.z;\n"
"		dst_data_0.w = (dst_index_0 + 3 < dst_end_0)                                      ? src_data_1.w : dst_data_0.w;\n"
"		\n"
"		dst_data_1.x = (dst_index_1 + 0 >= dst_start_1)                                   ? src_data_0.x : dst_data_1.x;\n"
"		dst_data_1.y = ((dst_index_1 + 1 >= dst_start_1) && (dst_index_1 + 1 < dst_end_1)) ? src_data_0.y : dst_data_1.y;\n"
"		dst_data_1.z = ((dst_index_1 + 2 >= dst_start_1) && (dst_index_1 + 2 < dst_end_1)) ? src_data_0.z : dst_data_1.z;\n"
"		dst_data_1.w = (dst_index_1 + 3 < dst_end_1)                                      ? src_data_0.w : dst_data_1.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index_0)) = dst_data_0;\n"
"		*((__global uchar4 *)(dst + dst_index_1)) = dst_data_1;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rows_D1(__global char *src, int src_step, int src_offset,\n"
"                                  __global char *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src_index_0 = mad24(y,            src_step, x + src_offset - dst_align);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, x + src_offset - dst_align);\n"
"		\n"
"		int dst_start_0  = mad24(y,            dst_step, dst_offset);\n"
"		int dst_start_1  = mad24(rows - y - 1, dst_step, dst_offset);\n"
"		int dst_end_0    = mad24(y,            dst_step, dst_offset + dst_step1);\n"
"		int dst_end_1    = mad24(rows - y - 1, dst_step, dst_offset + dst_step1);\n"
"		int dst_index_0  = mad24(y,            dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		int dst_index_1  = mad24(rows - y - 1, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 src_data_0 = vload4(0, src + src_index_0);\n"
"		char4 src_data_1 = vload4(0, src + src_index_1);\n"
"		\n"
"		char4 dst_data_0 = *((__global char4 *)(dst + dst_index_0));\n"
"		char4 dst_data_1 = *((__global char4 *)(dst + dst_index_1));\n"
"		\n"
"		dst_data_0.x = (dst_index_0 + 0 >= dst_start_0)                                   ? src_data_1.x : dst_data_0.x;\n"
"		dst_data_0.y = ((dst_index_0 + 1 >= dst_start_0) && (dst_index_0 + 1 < dst_end_0)) ? src_data_1.y : dst_data_0.y;\n"
"		dst_data_0.z = ((dst_index_0 + 2 >= dst_start_0) && (dst_index_0 + 2 < dst_end_0)) ? src_data_1.z : dst_data_0.z;\n"
"		dst_data_0.w = (dst_index_0 + 3 < dst_end_0)                                      ? src_data_1.w : dst_data_0.w;\n"
"		\n"
"		dst_data_1.x = (dst_index_1 + 0 >= dst_start_1)                                   ? src_data_0.x : dst_data_1.x;\n"
"		dst_data_1.y = ((dst_index_1 + 1 >= dst_start_1) && (dst_index_1 + 1 < dst_end_1)) ? src_data_0.y : dst_data_1.y;\n"
"		dst_data_1.z = ((dst_index_1 + 2 >= dst_start_1) && (dst_index_1 + 2 < dst_end_1)) ? src_data_0.z : dst_data_1.z;\n"
"		dst_data_1.w = (dst_index_1 + 3 < dst_end_1)                                      ? src_data_0.w : dst_data_1.w;\n"
"		\n"
"		*((__global char4 *)(dst + dst_index_0)) = dst_data_0;\n"
"		*((__global char4 *)(dst + dst_index_1)) = dst_data_1;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rows_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                  __global ushort *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset >> 1) & 3) << 1)\n"
"		int src_index_0 = mad24(y,            src_step, (x << 1) + src_offset - dst_align);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (x << 1) + src_offset - dst_align);\n"
"		\n"
"		int dst_start_0  = mad24(y,            dst_step, dst_offset);\n"
"		int dst_start_1  = mad24(rows - y - 1, dst_step, dst_offset);\n"
"		int dst_end_0    = mad24(y,            dst_step, dst_offset + dst_step1);\n"
"		int dst_end_1    = mad24(rows - y - 1, dst_step, dst_offset + dst_step1);\n"
"		int dst_index_0  = mad24(y,            dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		int dst_index_1  = mad24(rows - y - 1, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src_data_0 = vload4(0, (__global ushort *)((__global char *)src + src_index_0));\n"
"		ushort4 src_data_1 = vload4(0, (__global ushort *)((__global char *)src + src_index_1));\n"
"		\n"
"		ushort4 dst_data_0 = *((__global ushort4 *)((__global char *)dst + dst_index_0));\n"
"		ushort4 dst_data_1 = *((__global ushort4 *)((__global char *)dst + dst_index_1));\n"
"		\n"
"		dst_data_0.x = (dst_index_0 + 0 >= dst_start_0)                                   ? src_data_1.x : dst_data_0.x;\n"
"		dst_data_0.y = ((dst_index_0 + 2 >= dst_start_0) && (dst_index_0 + 2 < dst_end_0)) ? src_data_1.y : dst_data_0.y;\n"
"		dst_data_0.z = ((dst_index_0 + 4 >= dst_start_0) && (dst_index_0 + 4 < dst_end_0)) ? src_data_1.z : dst_data_0.z;\n"
"		dst_data_0.w = (dst_index_0 + 6 < dst_end_0)                                      ? src_data_1.w : dst_data_0.w;\n"
"		\n"
"		dst_data_1.x = (dst_index_1 + 0 >= dst_start_1)                                   ? src_data_0.x : dst_data_1.x;\n"
"		dst_data_1.y = ((dst_index_1 + 2 >= dst_start_1) && (dst_index_1 + 2 < dst_end_1)) ? src_data_0.y : dst_data_1.y;\n"
"		dst_data_1.z = ((dst_index_1 + 4 >= dst_start_1) && (dst_index_1 + 4 < dst_end_1)) ? src_data_0.z : dst_data_1.z;\n"
"		dst_data_1.w = (dst_index_1 + 6 < dst_end_1)                                      ? src_data_0.w : dst_data_1.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index_0)) = dst_data_0;\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index_1)) = dst_data_1;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rows_D3(__global short *src, int src_step, int src_offset,\n"
"                                  __global short *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset >> 1) & 3) << 1)\n"
"		int src_index_0 = mad24(y,            src_step, (x << 1) + src_offset - dst_align);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (x << 1) + src_offset - dst_align);\n"
"		\n"
"		int dst_start_0  = mad24(y,            dst_step, dst_offset);\n"
"		int dst_start_1  = mad24(rows - y - 1, dst_step, dst_offset);\n"
"		int dst_end_0    = mad24(y,            dst_step, dst_offset + dst_step1);\n"
"		int dst_end_1    = mad24(rows - y - 1, dst_step, dst_offset + dst_step1);\n"
"		int dst_index_0  = mad24(y,            dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		int dst_index_1  = mad24(rows - y - 1, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src_data_0 = vload4(0, (__global short *)((__global char *)src + src_index_0));\n"
"		short4 src_data_1 = vload4(0, (__global short *)((__global char *)src + src_index_1));\n"
"		\n"
"		short4 dst_data_0 = *((__global short4 *)((__global char *)dst + dst_index_0));\n"
"		short4 dst_data_1 = *((__global short4 *)((__global char *)dst + dst_index_1));\n"
"		\n"
"		dst_data_0.x = (dst_index_0 + 0 >= dst_start_0)                                   ? src_data_1.x : dst_data_0.x;\n"
"		dst_data_0.y = ((dst_index_0 + 2 >= dst_start_0) && (dst_index_0 + 2 < dst_end_0)) ? src_data_1.y : dst_data_0.y;\n"
"		dst_data_0.z = ((dst_index_0 + 4 >= dst_start_0) && (dst_index_0 + 4 < dst_end_0)) ? src_data_1.z : dst_data_0.z;\n"
"		dst_data_0.w = (dst_index_0 + 6 < dst_end_0)                                      ? src_data_1.w : dst_data_0.w;\n"
"		\n"
"		dst_data_1.x = (dst_index_1 + 0 >= dst_start_1)                                   ? src_data_0.x : dst_data_1.x;\n"
"		dst_data_1.y = ((dst_index_1 + 2 >= dst_start_1) && (dst_index_1 + 2 < dst_end_1)) ? src_data_0.y : dst_data_1.y;\n"
"		dst_data_1.z = ((dst_index_1 + 4 >= dst_start_1) && (dst_index_1 + 4 < dst_end_1)) ? src_data_0.z : dst_data_1.z;\n"
"		dst_data_1.w = (dst_index_1 + 6 < dst_end_1)                                      ? src_data_0.w : dst_data_1.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index_0)) = dst_data_0;\n"
"		*((__global short4 *)((__global char *)dst + dst_index_1)) = dst_data_1;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rows_D4(__global int *src, int src_step, int src_offset,\n"
"                                  __global int *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2) + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (x << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2) + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data0 = *((__global int *)((__global char *)src + src_index_0));\n"
"		int data1 = *((__global int *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rows_D5(__global float *src, int src_step, int src_offset,\n"
"                                  __global float *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2) + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (x << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2) + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data0 = *((__global float *)((__global char *)src + src_index_0));\n"
"		float data1 = *((__global float *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rows_D6(__global double *src, int src_step, int src_offset,\n"
"                                  __global double *dst, int dst_step, int dst_offset,\n"
"                                  int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 3) + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (x << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 3) + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data0 = *((__global double *)((__global char *)src + src_index_0));\n"
"		double data1 = *((__global double *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////flip cols///////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_flip_cols_C1_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                     __global uchar *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x)           + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, (cols - x - 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x)           + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, (cols - x - 1) + dst_offset);\n"
"		\n"
"		uchar data0 = *(src + src_index_0);\n"
"		uchar data1 = *(src + src_index_1);\n"
"		\n"
"		*(dst + dst_index_0) = data1;\n"
"		*(dst + dst_index_1) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C1_D1(__global char *src, int src_step, int src_offset,\n"
"                                     __global char *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x)           + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, (cols - x - 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x)           + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, (cols - x - 1) + dst_offset);\n"
"		\n"
"		char data0 = *(src + src_index_0);\n"
"		char data1 = *(src + src_index_1);\n"
"		\n"
"		*(dst + dst_index_0) = data1;\n"
"		*(dst + dst_index_1) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C1_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                     __global ushort *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		ushort data0 = *((__global ushort *)((__global char *)src + src_index_0));\n"
"		ushort data1 = *((__global ushort *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C1_D3(__global short *src, int src_step, int src_offset,\n"
"                                     __global short *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		short data0 = *((__global short *)((__global char *)src + src_index_0));\n"
"		short data1 = *((__global short *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global short *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global short *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C1_D4(__global int *src, int src_step, int src_offset,\n"
"                                     __global int *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		int data0 = *((__global int *)((__global char *)src + src_index_0));\n"
"		int data1 = *((__global int *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C1_D5(__global float *src, int src_step, int src_offset,\n"
"                                     __global float *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		float data0 = *((__global float *)((__global char *)src + src_index_0));\n"
"		float data1 = *((__global float *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C1_D6(__global double *src, int src_step, int src_offset,\n"
"                                     __global double *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		double data0 = *((__global double *)((__global char *)src + src_index_0));\n"
"		double data1 = *((__global double *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                     __global uchar *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		uchar2 data0 = *((__global uchar2 *)((__global char *)src + src_index_0));\n"
"		uchar2 data1 = *((__global uchar2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global uchar2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global uchar2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D1(__global char *src, int src_step, int src_offset,\n"
"                                     __global char *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		char2 data0 = *((__global char2 *)((__global char *)src + src_index_0));\n"
"		char2 data1 = *((__global char2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global char2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global char2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                     __global ushort *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		ushort2 data0 = *((__global ushort2 *)((__global char *)src + src_index_0));\n"
"		ushort2 data1 = *((__global ushort2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D3(__global short *src, int src_step, int src_offset,\n"
"                                     __global short *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		short2 data0 = *((__global short2 *)((__global char *)src + src_index_0));\n"
"		short2 data1 = *((__global short2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D4(__global int *src, int src_step, int src_offset,\n"
"                                     __global int *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		int2 data0 = *((__global int2 *)((__global char *)src + src_index_0));\n"
"		int2 data1 = *((__global int2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D5(__global float *src, int src_step, int src_offset,\n"
"                                     __global float *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		float2 data0 = *((__global float2 *)((__global char *)src + src_index_0));\n"
"		float2 data1 = *((__global float2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C2_D6(__global double *src, int src_step, int src_offset,\n"
"                                     __global double *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 4)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 4) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 4)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 4) + dst_offset);\n"
"		\n"
"		double2 data0 = *((__global double2 *)((__global char *)src + src_index_0));\n"
"		double2 data1 = *((__global double2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                     __global uchar *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x) * 3           + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, (cols - x - 1) * 3 + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x) * 3           + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, (cols - x - 1) * 3 + dst_offset);\n"
"		\n"
"		uchar data0_0 = *(src + src_index_0 + 0);\n"
"		uchar data0_1 = *(src + src_index_0 + 1);\n"
"		uchar data0_2 = *(src + src_index_0 + 2);\n"
"		\n"
"		uchar data1_0 = *(src + src_index_1 + 0);\n"
"		uchar data1_1 = *(src + src_index_1 + 1);\n"
"		uchar data1_2 = *(src + src_index_1 + 2);\n"
"		\n"
"		*(dst + dst_index_0 + 0) = data1_0;\n"
"		*(dst + dst_index_0 + 1) = data1_1;\n"
"		*(dst + dst_index_0 + 2) = data1_2;\n"
"		\n"
"		*(dst + dst_index_1 + 0) = data0_0;\n"
"		*(dst + dst_index_1 + 1) = data0_1;\n"
"		*(dst + dst_index_1 + 2) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D1(__global char *src, int src_step, int src_offset,\n"
"                                     __global char *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x) * 3           + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, (cols - x - 1) * 3 + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x) * 3           + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, (cols - x - 1) * 3 + dst_offset);\n"
"		\n"
"		char data0_0 = *(src + src_index_0 + 0);\n"
"		char data0_1 = *(src + src_index_0 + 1);\n"
"		char data0_2 = *(src + src_index_0 + 2);\n"
"		\n"
"		char data1_0 = *(src + src_index_1 + 0);\n"
"		char data1_1 = *(src + src_index_1 + 1);\n"
"		char data1_2 = *(src + src_index_1 + 2);\n"
"		\n"
"		*(dst + dst_index_0 + 0) = data1_0;\n"
"		*(dst + dst_index_0 + 1) = data1_1;\n"
"		*(dst + dst_index_0 + 2) = data1_2;\n"
"		\n"
"		*(dst + dst_index_1 + 0) = data0_0;\n"
"		*(dst + dst_index_1 + 1) = data0_1;\n"
"		*(dst + dst_index_1 + 2) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                     __global ushort *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x * 3 << 1)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) * 3 << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x * 3 << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) * 3 << 1) + dst_offset);\n"
"		\n"
"		ushort data0_0 = *((__global ushort *)((__global char *)src + src_index_0 + 0));\n"
"		ushort data0_1 = *((__global ushort *)((__global char *)src + src_index_0 + 2));\n"
"		ushort data0_2 = *((__global ushort *)((__global char *)src + src_index_0 + 4));\n"
"		\n"
"		ushort data1_0 = *((__global ushort *)((__global char *)src + src_index_1 + 0));\n"
"		ushort data1_1 = *((__global ushort *)((__global char *)src + src_index_1 + 2));\n"
"		ushort data1_2 = *((__global ushort *)((__global char *)src + src_index_1 + 4));\n"
"		\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0 + 2)) = data1_1;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0 + 4)) = data1_2;\n"
"		\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1 + 2)) = data0_1;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1 + 4)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D3(__global short *src, int src_step, int src_offset,\n"
"                                     __global short *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x * 3 << 1)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) * 3 << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x * 3 << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) * 3 << 1) + dst_offset);\n"
"		\n"
"		short data0_0 = *((__global short *)((__global char *)src + src_index_0 + 0));\n"
"		short data0_1 = *((__global short *)((__global char *)src + src_index_0 + 2));\n"
"		short data0_2 = *((__global short *)((__global char *)src + src_index_0 + 4));\n"
"		\n"
"		short data1_0 = *((__global short *)((__global char *)src + src_index_1 + 0));\n"
"		short data1_1 = *((__global short *)((__global char *)src + src_index_1 + 2));\n"
"		short data1_2 = *((__global short *)((__global char *)src + src_index_1 + 4));\n"
"		\n"
"		*((__global short *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global short *)((__global char *)dst + dst_index_0 + 2)) = data1_1;\n"
"		*((__global short *)((__global char *)dst + dst_index_0 + 4)) = data1_2;\n"
"		\n"
"		*((__global short *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global short *)((__global char *)dst + dst_index_1 + 2)) = data0_1;\n"
"		*((__global short *)((__global char *)dst + dst_index_1 + 4)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D4(__global int *src, int src_step, int src_offset,\n"
"                                     __global int *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x * 3 << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) * 3 << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x * 3 << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) * 3 << 2) + dst_offset);\n"
"		\n"
"		int data0_0 = *((__global int *)((__global char *)src + src_index_0 + 0));\n"
"		int data0_1 = *((__global int *)((__global char *)src + src_index_0 + 4));\n"
"		int data0_2 = *((__global int *)((__global char *)src + src_index_0 + 8));\n"
"		\n"
"		int data1_0 = *((__global int *)((__global char *)src + src_index_1 + 0));\n"
"		int data1_1 = *((__global int *)((__global char *)src + src_index_1 + 4));\n"
"		int data1_2 = *((__global int *)((__global char *)src + src_index_1 + 8));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global int *)((__global char *)dst + dst_index_0 + 4)) = data1_1;\n"
"		*((__global int *)((__global char *)dst + dst_index_0 + 8)) = data1_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global int *)((__global char *)dst + dst_index_1 + 4)) = data0_1;\n"
"		*((__global int *)((__global char *)dst + dst_index_1 + 8)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D5(__global float *src, int src_step, int src_offset,\n"
"                                     __global float *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x * 3 << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) * 3 << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x * 3 << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) * 3 << 2) + dst_offset);\n"
"		\n"
"		float data0_0 = *((__global float *)((__global char *)src + src_index_0 + 0));\n"
"		float data0_1 = *((__global float *)((__global char *)src + src_index_0 + 4));\n"
"		float data0_2 = *((__global float *)((__global char *)src + src_index_0 + 8));\n"
"		\n"
"		float data1_0 = *((__global float *)((__global char *)src + src_index_1 + 0));\n"
"		float data1_1 = *((__global float *)((__global char *)src + src_index_1 + 4));\n"
"		float data1_2 = *((__global float *)((__global char *)src + src_index_1 + 8));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global float *)((__global char *)dst + dst_index_0 + 4)) = data1_1;\n"
"		*((__global float *)((__global char *)dst + dst_index_0 + 8)) = data1_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global float *)((__global char *)dst + dst_index_1 + 4)) = data0_1;\n"
"		*((__global float *)((__global char *)dst + dst_index_1 + 8)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C3_D6(__global double *src, int src_step, int src_offset,\n"
"                                     __global double *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x * 3 << 3)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) * 3 << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x * 3 << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) * 3 << 3) + dst_offset);\n"
"		\n"
"		double data0_0 = *((__global double *)((__global char *)src + src_index_0 + 0));\n"
"		double data0_1 = *((__global double *)((__global char *)src + src_index_0 + 8));\n"
"		double data0_2 = *((__global double *)((__global char *)src + src_index_0 + 16));\n"
"		\n"
"		double data1_0 = *((__global double *)((__global char *)src + src_index_1 + 0));\n"
"		double data1_1 = *((__global double *)((__global char *)src + src_index_1 + 8));\n"
"		double data1_2 = *((__global double *)((__global char *)src + src_index_1 + 16));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global double *)((__global char *)dst + dst_index_0 + 8)) = data1_1;\n"
"		*((__global double *)((__global char *)dst + dst_index_0 + 16)) = data1_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global double *)((__global char *)dst + dst_index_1 + 8)) = data0_1;\n"
"		*((__global double *)((__global char *)dst + dst_index_1 + 16)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                     __global uchar *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		uchar4 data0 = *((__global uchar4 *)(src + src_index_0));\n"
"		uchar4 data1 = *((__global uchar4 *)(src + src_index_1));\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index_0)) = data1;\n"
"		*((__global uchar4 *)(dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D1(__global char *src, int src_step, int src_offset,\n"
"                                     __global char *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		char4 data0 = *((__global char4 *)(src + src_index_0));\n"
"		char4 data1 = *((__global char4 *)(src + src_index_1));\n"
"		\n"
"		*((__global char4 *)(dst + dst_index_0)) = data1;\n"
"		*((__global char4 *)(dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                     __global ushort *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		ushort4 data0 = *((__global ushort4 *)((__global char *)src + src_index_0));\n"
"		ushort4 data1 = *((__global ushort4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D3(__global short *src, int src_step, int src_offset,\n"
"                                     __global short *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		short4 data0 = *((__global short4 *)((__global char *)src + src_index_0));\n"
"		short4 data1 = *((__global short4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global short4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D4(__global int *src, int src_step, int src_offset,\n"
"                                     __global int *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 4)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 4) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 4)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 4) + dst_offset);\n"
"		\n"
"		int4 data0 = *((__global int4 *)((__global char *)src + src_index_0));\n"
"		int4 data1 = *((__global int4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D5(__global float *src, int src_step, int src_offset,\n"
"                                     __global float *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 4)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 4) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 4)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 4) + dst_offset);\n"
"		\n"
"		float4 data0 = *((__global float4 *)((__global char *)src + src_index_0));\n"
"		float4 data1 = *((__global float4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_cols_C4_D6(__global double *src, int src_step, int src_offset,\n"
"                                     __global double *dst, int dst_step, int dst_offset,\n"
"                                     int rows, int cols, int thread_cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < thread_cols && y < rows)\n"
"	{\n"
"		int src_index_0 = mad24(y, src_step, (x << 5)             + src_offset);\n"
"		int src_index_1 = mad24(y, src_step, ((cols - x - 1) << 5) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y, dst_step, (x << 5)             + dst_offset);\n"
"		int dst_index_1 = mad24(y, dst_step, ((cols - x - 1) << 5) + dst_offset);\n"
"		\n"
"		double4 data0 = *((__global double4 *)((__global char *)src + src_index_0));\n"
"		double4 data1 = *((__global double4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
;
const char *arithm_flip_rc =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////flip rows and cols///////////////////////////////////////\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_flip_rc_C1_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                   __global uchar *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x)           + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (cols - x - 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x)           + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (cols - x - 1) + dst_offset);\n"
"		\n"
"		uchar data0 = *(src + src_index_0);\n"
"		uchar data1 = *(src + src_index_1);\n"
"		\n"
"		*(dst + dst_index_0) = data1;\n"
"		*(dst + dst_index_1) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C1_D1(__global char *src, int src_step, int src_offset,\n"
"                                   __global char *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x)           + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (cols - x - 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x)           + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (cols - x - 1) + dst_offset);\n"
"		\n"
"		char data0 = *(src + src_index_0);\n"
"		char data1 = *(src + src_index_1);\n"
"		\n"
"		*(dst + dst_index_0) = data1;\n"
"		*(dst + dst_index_1) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C1_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                   __global ushort *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		ushort data0 = *((__global ushort *)((__global char *)src + src_index_0));\n"
"		ushort data1 = *((__global ushort *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C1_D3(__global short *src, int src_step, int src_offset,\n"
"                                   __global short *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		short data0 = *((__global short *)((__global char *)src + src_index_0));\n"
"		short data1 = *((__global short *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global short *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global short *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C1_D4(__global int *src, int src_step, int src_offset,\n"
"                                   __global int *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		int data0 = *((__global int *)((__global char *)src + src_index_0));\n"
"		int data1 = *((__global int *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C1_D5(__global float *src, int src_step, int src_offset,\n"
"                                   __global float *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		float data0 = *((__global float *)((__global char *)src + src_index_0));\n"
"		float data1 = *((__global float *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C1_D6(__global double *src, int src_step, int src_offset,\n"
"                                   __global double *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		double data0 = *((__global double *)((__global char *)src + src_index_0));\n"
"		double data1 = *((__global double *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                   __global uchar *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		uchar2 data0 = *((__global uchar2 *)(src + src_index_0));\n"
"		uchar2 data1 = *((__global uchar2 *)(src + src_index_1));\n"
"		\n"
"		*((__global uchar2 *)(dst + dst_index_0)) = data1;\n"
"		*((__global uchar2 *)(dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D1(__global char *src, int src_step, int src_offset,\n"
"                                   __global char *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 1)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 1) + dst_offset);\n"
"		\n"
"		char2 data0 = *((__global char2 *)(src + src_index_0));\n"
"		char2 data1 = *((__global char2 *)(src + src_index_1));\n"
"		\n"
"		*((__global char2 *)(dst + dst_index_0)) = data1;\n"
"		*((__global char2 *)(dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                   __global ushort *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		ushort2 data0 = *((__global ushort2 *)((__global char *)src + src_index_0));\n"
"		ushort2 data1 = *((__global ushort2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D3(__global short *src, int src_step, int src_offset,\n"
"                                   __global short *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		short2 data0 = *((__global short2 *)((__global char *)src + src_index_0));\n"
"		short2 data1 = *((__global short2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D4(__global int *src, int src_step, int src_offset,\n"
"                                   __global int *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		int2 data0 = *((__global int2 *)((__global char *)src + src_index_0));\n"
"		int2 data1 = *((__global int2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D5(__global float *src, int src_step, int src_offset,\n"
"                                   __global float *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		float2 data0 = *((__global float2 *)((__global char *)src + src_index_0));\n"
"		float2 data1 = *((__global float2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C2_D6(__global double *src, int src_step, int src_offset,\n"
"                                   __global double *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 4)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 4) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 4)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 4) + dst_offset);\n"
"		\n"
"		double2 data0 = *((__global double2 *)((__global char *)src + src_index_0));\n"
"		double2 data1 = *((__global double2 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double2 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                   __global uchar *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3)            + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (cols - x - 1) * 3  + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3)           + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (cols - x - 1) * 3 + dst_offset);\n"
"		\n"
"		\n"
"		uchar data0_0 = *(src + src_index_0 + 0);\n"
"		uchar data0_1 = *(src + src_index_0 + 1);\n"
"		uchar data0_2 = *(src + src_index_0 + 2);\n"
"		\n"
"		uchar data1_0 = *(src + src_index_1 + 0);\n"
"		uchar data1_1 = *(src + src_index_1 + 1);\n"
"		uchar data1_2 = *(src + src_index_1 + 2);\n"
"		\n"
"		*(dst + dst_index_0 + 0) = data1_0;\n"
"		*(dst + dst_index_0 + 1) = data1_1;\n"
"		*(dst + dst_index_0 + 2) = data1_2;\n"
"		\n"
"		*(dst + dst_index_1 + 0) = data0_0;\n"
"		*(dst + dst_index_1 + 1) = data0_1;\n"
"		*(dst + dst_index_1 + 2) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D1(__global char *src, int src_step, int src_offset,\n"
"                                   __global char *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3)            + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, (cols - x - 1) * 3  + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3)           + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, (cols - x - 1) * 3 + dst_offset);\n"
"		\n"
"		\n"
"		char data0_0 = *(src + src_index_0 + 0);\n"
"		char data0_1 = *(src + src_index_0 + 1);\n"
"		char data0_2 = *(src + src_index_0 + 2);\n"
"		\n"
"		char data1_0 = *(src + src_index_1 + 0);\n"
"		char data1_1 = *(src + src_index_1 + 1);\n"
"		char data1_2 = *(src + src_index_1 + 2);\n"
"		\n"
"		*(dst + dst_index_0 + 0) = data1_0;\n"
"		*(dst + dst_index_0 + 1) = data1_1;\n"
"		*(dst + dst_index_0 + 2) = data1_2;\n"
"		\n"
"		*(dst + dst_index_1 + 0) = data0_0;\n"
"		*(dst + dst_index_1 + 1) = data0_1;\n"
"		*(dst + dst_index_1 + 2) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                   __global ushort *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3 << 1)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) * 3 << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3 << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) * 3 << 1) + dst_offset);\n"
"		\n"
"		ushort data0_0 = *((__global ushort *)((__global char *)src + src_index_0 + 0));\n"
"		ushort data0_1 = *((__global ushort *)((__global char *)src + src_index_0 + 2));\n"
"		ushort data0_2 = *((__global ushort *)((__global char *)src + src_index_0 + 4));\n"
"		\n"
"		ushort data1_0 = *((__global ushort *)((__global char *)src + src_index_1 + 0));\n"
"		ushort data1_1 = *((__global ushort *)((__global char *)src + src_index_1 + 2));\n"
"		ushort data1_2 = *((__global ushort *)((__global char *)src + src_index_1 + 4));\n"
"		\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0 + 2)) = data1_1;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_0 + 4)) = data1_2;\n"
"		\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1 + 2)) = data0_1;\n"
"		*((__global ushort *)((__global char *)dst + dst_index_1 + 4)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D3(__global short *src, int src_step, int src_offset,\n"
"                                   __global short *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3 << 1)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) * 3 << 1) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3 << 1)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) * 3 << 1) + dst_offset);\n"
"		\n"
"		short data0_0 = *((__global short *)((__global char *)src + src_index_0 + 0));\n"
"		short data0_1 = *((__global short *)((__global char *)src + src_index_0 + 2));\n"
"		short data0_2 = *((__global short *)((__global char *)src + src_index_0 + 4));\n"
"		\n"
"		short data1_0 = *((__global short *)((__global char *)src + src_index_1 + 0));\n"
"		short data1_1 = *((__global short *)((__global char *)src + src_index_1 + 2));\n"
"		short data1_2 = *((__global short *)((__global char *)src + src_index_1 + 4));\n"
"		\n"
"		*((__global short *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global short *)((__global char *)dst + dst_index_0 + 2)) = data1_1;\n"
"		*((__global short *)((__global char *)dst + dst_index_0 + 4)) = data1_2;\n"
"		\n"
"		*((__global short *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global short *)((__global char *)dst + dst_index_1 + 2)) = data0_1;\n"
"		*((__global short *)((__global char *)dst + dst_index_1 + 4)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D4(__global int *src, int src_step, int src_offset,\n"
"                                   __global int *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3 << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) * 3 << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3 << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) * 3 << 2) + dst_offset);\n"
"		\n"
"		int data0_0 = *((__global int *)((__global char *)src + src_index_0 + 0));\n"
"		int data0_1 = *((__global int *)((__global char *)src + src_index_0 + 4));\n"
"		int data0_2 = *((__global int *)((__global char *)src + src_index_0 + 8));\n"
"		\n"
"		int data1_0 = *((__global int *)((__global char *)src + src_index_1 + 0));\n"
"		int data1_1 = *((__global int *)((__global char *)src + src_index_1 + 4));\n"
"		int data1_2 = *((__global int *)((__global char *)src + src_index_1 + 8));\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global int *)((__global char *)dst + dst_index_0 + 4)) = data1_1;\n"
"		*((__global int *)((__global char *)dst + dst_index_0 + 8)) = data1_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global int *)((__global char *)dst + dst_index_1 + 4)) = data0_1;\n"
"		*((__global int *)((__global char *)dst + dst_index_1 + 8)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D5(__global float *src, int src_step, int src_offset,\n"
"                                   __global float *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3 << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) * 3 << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3 << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) * 3 << 2) + dst_offset);\n"
"		\n"
"		float data0_0 = *((__global float *)((__global char *)src + src_index_0 + 0));\n"
"		float data0_1 = *((__global float *)((__global char *)src + src_index_0 + 4));\n"
"		float data0_2 = *((__global float *)((__global char *)src + src_index_0 + 8));\n"
"		\n"
"		float data1_0 = *((__global float *)((__global char *)src + src_index_1 + 0));\n"
"		float data1_1 = *((__global float *)((__global char *)src + src_index_1 + 4));\n"
"		float data1_2 = *((__global float *)((__global char *)src + src_index_1 + 8));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global float *)((__global char *)dst + dst_index_0 + 4)) = data1_1;\n"
"		*((__global float *)((__global char *)dst + dst_index_0 + 8)) = data1_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global float *)((__global char *)dst + dst_index_1 + 4)) = data0_1;\n"
"		*((__global float *)((__global char *)dst + dst_index_1 + 8)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C3_D6(__global double *src, int src_step, int src_offset,\n"
"                                   __global double *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x * 3 << 3)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) * 3 << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x * 3 << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) * 3 << 3) + dst_offset);\n"
"		\n"
"		double data0_0 = *((__global double *)((__global char *)src + src_index_0 + 0));\n"
"		double data0_1 = *((__global double *)((__global char *)src + src_index_0 + 8));\n"
"		double data0_2 = *((__global double *)((__global char *)src + src_index_0 + 16));\n"
"		\n"
"		double data1_0 = *((__global double *)((__global char *)src + src_index_1 + 0));\n"
"		double data1_1 = *((__global double *)((__global char *)src + src_index_1 + 8));\n"
"		double data1_2 = *((__global double *)((__global char *)src + src_index_1 + 16));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_0 + 0)) = data1_0;\n"
"		*((__global double *)((__global char *)dst + dst_index_0 + 8)) = data1_1;\n"
"		*((__global double *)((__global char *)dst + dst_index_0 + 16)) = data1_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index_1 + 0)) = data0_0;\n"
"		*((__global double *)((__global char *)dst + dst_index_1 + 8)) = data0_1;\n"
"		*((__global double *)((__global char *)dst + dst_index_1 + 16)) = data0_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D0(__global uchar *src, int src_step, int src_offset,\n"
"                                   __global uchar *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		uchar4 data0 = *((__global uchar4 *)(src + src_index_0));\n"
"		uchar4 data1 = *((__global uchar4 *)(src + src_index_1));\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index_0)) = data1;\n"
"		*((__global uchar4 *)(dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D1(__global char *src, int src_step, int src_offset,\n"
"                                   __global char *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 2)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 2) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 2)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 2) + dst_offset);\n"
"		\n"
"		char4 data0 = *((__global char4 *)(src + src_index_0));\n"
"		char4 data1 = *((__global char4 *)(src + src_index_1));\n"
"		\n"
"		*((__global char4 *)(dst + dst_index_0)) = data1;\n"
"		*((__global char4 *)(dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D2(__global ushort *src, int src_step, int src_offset,\n"
"                                   __global ushort *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		ushort4 data0 = *((__global ushort4 *)((__global char *)src + src_index_0));\n"
"		ushort4 data1 = *((__global ushort4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D3(__global short *src, int src_step, int src_offset,\n"
"                                   __global short *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 3)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 3) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 3)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 3) + dst_offset);\n"
"		\n"
"		short4 data0 = *((__global short4 *)((__global char *)src + src_index_0));\n"
"		short4 data1 = *((__global short4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global short4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D4(__global int *src, int src_step, int src_offset,\n"
"                                   __global int *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 4)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 4) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 4)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 4) + dst_offset);\n"
"		\n"
"		int4 data0 = *((__global int4 *)((__global char *)src + src_index_0));\n"
"		int4 data1 = *((__global int4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global int4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D5(__global float *src, int src_step, int src_offset,\n"
"                                   __global float *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 4)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 4) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 4)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 4) + dst_offset);\n"
"		\n"
"		float4 data0 = *((__global float4 *)((__global char *)src + src_index_0));\n"
"		float4 data1 = *((__global float4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global float4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
"__kernel void arithm_flip_rc_C4_D6(__global double *src, int src_step, int src_offset,\n"
"                                   __global double *dst, int dst_step, int dst_offset,\n"
"                                   int rows, int cols, int thread_rows, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < thread_rows)\n"
"	{\n"
"		int src_index_0 = mad24(y,            src_step, (x << 5)             + src_offset);\n"
"		int src_index_1 = mad24(rows - y - 1, src_step, ((cols - x - 1) << 5) + src_offset);\n"
"		\n"
"		int dst_index_0 = mad24(y,            dst_step, (x << 5)             + dst_offset);\n"
"		int dst_index_1 = mad24(rows - y - 1, dst_step, ((cols - x - 1) << 5) + dst_offset);\n"
"		\n"
"		double4 data0 = *((__global double4 *)((__global char *)src + src_index_0));\n"
"		double4 data1 = *((__global double4 *)((__global char *)src + src_index_1));\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index_0)) = data1;\n"
"		*((__global double4 *)((__global char *)dst + dst_index_1)) = data0;\n"
"	}\n"
"}\n"
;
const char *arithm_log =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Wu Zailong, bullet@yeah.net\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#define INF_FLOAT -88.029694\n"
"#define INF_DOUBLE -709.0895657128241\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////LOG/////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_log_D5(int rows, int cols, int srcStep, int dstStep, int srcOffset, int dstOffset, __global float *src, __global float *dst)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		int srcIdx = mad24(y, srcStep, x + srcOffset);\n"
"		int dstIdx = mad24(y, dstStep, x + dstOffset);\n"
"		\n"
"		float src_data = *((__global float *)((__global char *)src + srcIdx));\n"
"		float dst_data = (src_data == 0) ? INF_FLOAT : log(fabs(src_data));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dstIdx)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_log_D6(int rows, int cols, int srcStep, int dstStep, int srcOffset, int dstOffset, __global double *src, __global double *dst)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 3;\n"
"		int srcIdx = mad24(y, srcStep, x + srcOffset);\n"
"		int dstIdx = mad24(y, dstStep, x + dstOffset);\n"
"		\n"
"		double src_data = *((__global double *)((__global char *)src + srcIdx));\n"
"		double dst_data = (src_data == 0) ? INF_DOUBLE : log(fabs(src_data));\n"
"		*((__global double *)((__global char *)dst + dstIdx)) = dst_data;\n"
"		\n"
"	}\n"
"}\n"
;
const char *arithm_LUT =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Rock Li, Rock.li@amd.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#pragma OPENCL EXTENSION cl_amd_printf : enable\n"
"__kernel\n"
"void LUT_C1_D0(__global uchar *dst,\n"
"               __global const uchar *src,\n"
"               __constant uchar *table,\n"
"               int rows,\n"
"               int cols,\n"
"               int channels,\n"
"               int whole_rows,\n"
"               int whole_cols,\n"
"               int src_offset,\n"
"               int dst_offset,\n"
"               int lut_offset,\n"
"               int src_step,\n"
"               int dst_step)\n"
"{\n"
"	int gidx = get_global_id(0) << 2;\n"
"	int gidy = get_global_id(1);\n"
"	int lidx = get_local_id(0);\n"
"	int lidy = get_local_id(1);\n"
"	\n"
"	__local uchar l[256];\n"
"	l[(lidy << 4) + lidx] = table[(lidy << 4) + lidx + lut_offset];\n"
"	//mem_fence(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	\n"
"	//clamp(gidx,mask,cols-1);\n"
"	gidx = gidx >= cols - 4 ? cols - 4 : gidx;\n"
"	gidy = gidy >= rows ? rows - 1 : gidy;\n"
"	\n"
"	int src_index = src_offset + mad24(gidy, src_step, gidx);\n"
"	int dst_index = dst_offset + mad24(gidy, dst_step, gidx);\n"
"	uchar4 p, q;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	p.x = src[src_index];\n"
"	p.y = src[src_index + 1];\n"
"	p.z = src[src_index + 2];\n"
"	p.w = src[src_index + 3];\n"
"	\n"
"	q.x = l[p.x];\n"
"	q.y = l[p.y];\n"
"	q.z = l[p.z];\n"
"	q.w = l[p.w];\n"
"	*(__global uchar4 *)(dst + dst_index) = q;\n"
"}\n"
"__kernel\n"
"void LUT2_C1_D0(__global uchar *dst,\n"
"                __global const uchar *src,\n"
"                __constant uchar *table,\n"
"                int rows,\n"
"                int precols,\n"
"                int channels,\n"
"                int whole_rows,\n"
"                int cols,\n"
"                int src_offset,\n"
"                int dst_offset,\n"
"                int lut_offset,\n"
"                int src_step,\n"
"                int dst_step)\n"
"{\n"
"	int gidx = get_global_id(0);\n"
"	int gidy = get_global_id(1);\n"
"	//int lidx = get_local_id(0);\n"
"	int lidy = get_local_id(1);\n"
"	\n"
"	__local uchar l[256];\n"
"	l[lidy] = table[lidy + lut_offset];\n"
"	//mem_fence(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	\n"
"	//clamp(gidx,mask,cols-1);\n"
"	gidx = gidx >= precols ? cols + gidx : gidx;\n"
"	gidy = gidy >= rows ? rows - 1 : gidy;\n"
"	\n"
"	int src_index = src_offset + mad24(gidy, src_step, gidx);\n"
"	int dst_index = dst_offset + mad24(gidy, dst_step, gidx);\n"
"	//uchar4 p,q;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	uchar p = src[src_index];\n"
"	uchar q = l[p];\n"
"	dst[dst_index] = q;\n"
"}\n"
"__kernel\n"
"void LUT_C4_D0(__global uchar4 *dst,\n"
"               __global uchar4 *src,\n"
"               __constant uchar *table,\n"
"               uint rows,\n"
"               uint cols,\n"
"               uint channels,\n"
"               uint whole_rows,\n"
"               uint whole_cols,\n"
"               uint src_offset,\n"
"               uint dst_offset,\n"
"               uint lut_offset,\n"
"               uint src_step,\n"
"               uint dst_step)\n"
"{\n"
"	uint gidx = get_global_id(0);\n"
"	uint gidy = get_global_id(1);\n"
"	\n"
"	uint lidx = get_local_id(0);\n"
"	uint lidy = get_local_id(1);\n"
"	\n"
"	__local uchar l[256];\n"
"	l[lidy * 16 + lidx] = table[lidy * 16 + lidx + lut_offset];\n"
"	mem_fence(CLK_LOCAL_MEM_FENCE);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	gidx = gidx >= cols ? cols - 1 : gidx;\n"
"	gidy = gidy >= rows ? rows - 1 : gidy;\n"
"	\n"
"	uint src_index = src_offset / 4 + gidy * src_step / 4 + gidx;\n"
"	\n"
"	uint dst_index = dst_offset / 4 + gidy * dst_step / 4 + gidx;\n"
"	\n"
"	uchar4 p = src[src_index];\n"
"	dst[dst_index].x = l[p.x];\n"
"	dst[dst_index].y = l[p.y];\n"
"	dst[dst_index].z = l[p.z];\n"
"	dst[dst_index].w = l[p.w];\n"
"}\n"
;
const char *arithm_magnitude =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"__kernel void arithm_magnitude_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                  __global float *src2, int src2_step, int src2_offset,\n"
"                                  __global float *dst,  int dst_step,  int dst_offset,\n"
"                                  int rows, int cols)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		\n"
"		float tmp = sqrt(data1 * data1 + data2 * data2);\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_magnitude_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                  __global double *src2, int src2_step, int src2_offset,\n"
"                                  __global double *dst,  int dst_step,  int dst_offset,\n"
"                                  int rows, int cols)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		double tmp = sqrt(data1 * data1 + data2 * data2);\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
;
const char *arithm_magnitudeSqr =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this softwareif advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////magnitudeSqr//////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void magnitudeSqr_C1_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                 __global float *src2, int src2_step, int src2_offset,\n"
"                                 __global float *dst,  int dst_step, int dst_offset,\n"
"                                 int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 2) & 3)\n"
"		\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset - (dst_align << 2));\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset - (dst_align << 2));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 2) - (dst_align << 2));\n"
"		\n"
"		float4 src1_data = vload4(0, (__global float *)((__global char *)src1 + src1_index));\n"
"		float4 src2_data = vload4(0, (__global float *)((__global char *)src2 + src2_index));\n"
"		float4 dst_data = *((__global float4 *)((__global char *)dst + dst_index));\n"
"		\n"
"		float4   tmp_data  ;\n"
"		tmp_data.x = src1_data.x * src1_data.x + src2_data.x * src2_data.x;\n"
"		\n"
"		tmp_data.y = src1_data.y * src1_data.y + src2_data.y * src2_data.y;\n"
"		\n"
"		tmp_data.z = src1_data.z * src1_data.z + src2_data.z * src2_data.z;\n"
"		\n"
"		tmp_data.w = src1_data.w * src1_data.w + src2_data.w * src2_data.w;\n"
"		\n"
"		\n"
"		\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 8 >= dst_start) && (dst_index + 8 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 12 >= dst_start) && (dst_index + 12 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void magnitudeSqr_C2_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                 __global float *dst,  int dst_step, int dst_offset,\n"
"                                 int rows,  int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	\n"
"	\n"
"	{\n"
"	\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 2) & 3)\n"
"		\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset - (dst_align << 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 2) - (dst_align << 2));\n"
"		\n"
"		float8 src1_data = vload8(0, (__global float *)((__global char *)src1 + src1_index));\n"
"		float4 dst_data = *((__global float4 *)((__global char *)dst + dst_index));\n"
"		\n"
"		float4   tmp_data  ;\n"
"		tmp_data.x = src1_data.s0 * src1_data.s0 + src1_data.s1 * src1_data.s1;\n"
"		\n"
"		tmp_data.y = src1_data.s2 * src1_data.s2 + src1_data.s3 * src1_data.s3;\n"
"		\n"
"		tmp_data.z = src1_data.s4 * src1_data.s4 + src1_data.s5 * src1_data.s5;\n"
"		\n"
"		tmp_data.w = src1_data.s6 * src1_data.s6 + src1_data.s7 * src1_data.s7;\n"
"		\n"
"		\n"
"		\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 8 >= dst_start) && (dst_index + 8 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 12 >= dst_start) && (dst_index + 12 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"	\n"
"}\n"
;
const char *arithm_minMax =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define VEC_TYPE uchar8\n"
"#define CONVERT_TYPE convert_uchar8\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 255\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define VEC_TYPE char8\n"
"#define CONVERT_TYPE convert_char8\n"
"#define MIN_VAL -128\n"
"#define MAX_VAL 127\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define VEC_TYPE ushort8\n"
"#define CONVERT_TYPE convert_ushort8\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 65535\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define VEC_TYPE short8\n"
"#define CONVERT_TYPE convert_short8\n"
"#define MIN_VAL -32768\n"
"#define MAX_VAL 32767\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define VEC_TYPE int8\n"
"#define CONVERT_TYPE convert_int8\n"
"#define MIN_VAL INT_MIN\n"
"#define MAX_VAL INT_MAX\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define VEC_TYPE float8\n"
"#define CONVERT_TYPE convert_float8\n"
"#define MIN_VAL (-FLT_MAX)\n"
"#define MAX_VAL FLT_MAX\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define VEC_TYPE double8\n"
"#define CONVERT_TYPE convert_double8\n"
"#define MIN_VAL (-DBL_MAX)\n"
"#define MAX_VAL DBL_MAX\n"
"#endif\n"
"#if defined (REPEAT_S0)\n"
"#define repeat_s(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_S1)\n"
"#define repeat_s(a) a.s0 = a.s1;\n"
"#endif\n"
"#if defined (REPEAT_S2)\n"
"#define repeat_s(a) a.s0 = a.s2;a.s1 = a.s2;\n"
"#endif\n"
"#if defined (REPEAT_S3)\n"
"#define repeat_s(a) a.s0 = a.s3;a.s1 = a.s3;a.s2 = a.s3;\n"
"#endif\n"
"#if defined (REPEAT_S4)\n"
"#define repeat_s(a) a.s0 = a.s4;a.s1 = a.s4;a.s2 = a.s4;a.s3 = a.s4;\n"
"#endif\n"
"#if defined (REPEAT_S5)\n"
"#define repeat_s(a) a.s0 = a.s5;a.s1 = a.s5;a.s2 = a.s5;a.s3 = a.s5;a.s4 = a.s5;\n"
"#endif\n"
"#if defined (REPEAT_S6)\n"
"#define repeat_s(a) a.s0 = a.s6;a.s1 = a.s6;a.s2 = a.s6;a.s3 = a.s6;a.s4 = a.s6;a.s5 = a.s6;\n"
"#endif\n"
"#if defined (REPEAT_S7)\n"
"#define repeat_s(a) a.s0 = a.s7;a.s1 = a.s7;a.s2 = a.s7;a.s3 = a.s7;a.s4 = a.s7;a.s5 = a.s7;a.s6 = a.s7;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_e(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_e(a) a.s7 = a.s6;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_e(a) a.s7 = a.s5;a.s6 = a.s5;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_e(a) a.s7 = a.s4;a.s6 = a.s4;a.s5 = a.s4;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_e(a) a.s7 = a.s3;a.s6 = a.s3;a.s5 = a.s3;a.s4 = a.s3;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_e(a) a.s7 = a.s2;a.s6 = a.s2;a.s5 = a.s2;a.s4 = a.s2;a.s3 = a.s2;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_e(a) a.s7 = a.s1;a.s6 = a.s1;a.s5 = a.s1;a.s4 = a.s1;a.s3 = a.s1;a.s2 = a.s1;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_e(a) a.s7 = a.s0;a.s6 = a.s0;a.s5 = a.s0;a.s4 = a.s0;a.s3 = a.s0;a.s2 = a.s0;a.s1 = a.s0;\n"
"#endif\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics:enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics:enable\n"
"/**************************************Array minMax**************************************/\n"
"__kernel void arithm_op_minMax(int cols, int invalid_cols, int offset, int elemnum, int groupnum,\n"
"                               __global VEC_TYPE *src, __global VEC_TYPE *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = offset + id + (id / cols) * invalid_cols;\n"
"	__local VEC_TYPE localmem_max[128], localmem_min[128];\n"
"	VEC_TYPE minval, maxval, temp;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = src[idx];\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"		}\n"
"		\n"
"		minval = temp;\n"
"		maxval = temp;\n"
"	}\n"
"	else\n"
"	{\n"
"		minval = MAX_VAL;\n"
"		maxval = MIN_VAL;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = offset + id + (id / cols) * invalid_cols;\n"
"		temp = src[idx];\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"		}\n"
"		\n"
"		minval = min(minval, temp);\n"
"		maxval = max(maxval, temp);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_min[lid - 128] = minval;\n"
"		localmem_max[lid - 128] = maxval;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_min[lid] = min(minval, localmem_min[lid]);\n"
"		localmem_max[lid] = max(maxval, localmem_max[lid]);\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_min[lid] = min(localmem_min[lid] , localmem_min[lid2]);\n"
"			localmem_max[lid] = max(localmem_max[lid] , localmem_max[lid2]);\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = localmem_min[0];\n"
"		dst[gid + groupnum] = localmem_max[0];\n"
"	}\n"
"}\n"
;
const char *arithm_minMaxLoc =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan, yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define VEC_TYPE uchar8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_uchar8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 255\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define VEC_TYPE char8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_char8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL -128\n"
"#define MAX_VAL 127\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define VEC_TYPE ushort8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_ushort8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 65535\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define VEC_TYPE short8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_short8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL -32768\n"
"#define MAX_VAL 32767\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define VEC_TYPE int8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_int8\n"
"#define CONDITION_FUNC(a,b,c) ((a) ? b : c)\n"
"#define MIN_VAL INT_MIN\n"
"#define MAX_VAL INT_MAX\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define VEC_TYPE float8\n"
"#define VEC_TYPE_LOC float8\n"
"#define CONVERT_TYPE convert_float8\n"
"#define CONDITION_FUNC(a,b,c) ((a) ? b : c)\n"
"#define MIN_VAL (-FLT_MAX)\n"
"#define MAX_VAL FLT_MAX\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define VEC_TYPE double8\n"
"#define VEC_TYPE_LOC double8\n"
"#define CONVERT_TYPE convert_double8\n"
"#define CONDITION_FUNC(a,b,c) ((a) ? b : c)\n"
"#define MIN_VAL (-DBL_MAX)\n"
"#define MAX_VAL DBL_MAX\n"
"#endif\n"
"#if defined (REPEAT_S0)\n"
"#define repeat_s(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_S1)\n"
"#define repeat_s(a) a.s0 = a.s1;\n"
"#endif\n"
"#if defined (REPEAT_S2)\n"
"#define repeat_s(a) a.s0 = a.s2;a.s1 = a.s2;\n"
"#endif\n"
"#if defined (REPEAT_S3)\n"
"#define repeat_s(a) a.s0 = a.s3;a.s1 = a.s3;a.s2 = a.s3;\n"
"#endif\n"
"#if defined (REPEAT_S4)\n"
"#define repeat_s(a) a.s0 = a.s4;a.s1 = a.s4;a.s2 = a.s4;a.s3 = a.s4;\n"
"#endif\n"
"#if defined (REPEAT_S5)\n"
"#define repeat_s(a) a.s0 = a.s5;a.s1 = a.s5;a.s2 = a.s5;a.s3 = a.s5;a.s4 = a.s5;\n"
"#endif\n"
"#if defined (REPEAT_S6)\n"
"#define repeat_s(a) a.s0 = a.s6;a.s1 = a.s6;a.s2 = a.s6;a.s3 = a.s6;a.s4 = a.s6;a.s5 = a.s6;\n"
"#endif\n"
"#if defined (REPEAT_S7)\n"
"#define repeat_s(a) a.s0 = a.s7;a.s1 = a.s7;a.s2 = a.s7;a.s3 = a.s7;a.s4 = a.s7;a.s5 = a.s7;a.s6 = a.s7;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_e(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_e(a) a.s7 = a.s6;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_e(a) a.s7 = a.s5;a.s6 = a.s5;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_e(a) a.s7 = a.s4;a.s6 = a.s4;a.s5 = a.s4;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_e(a) a.s7 = a.s3;a.s6 = a.s3;a.s5 = a.s3;a.s4 = a.s3;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_e(a) a.s7 = a.s2;a.s6 = a.s2;a.s5 = a.s2;a.s4 = a.s2;a.s3 = a.s2;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_e(a) a.s7 = a.s1;a.s6 = a.s1;a.s5 = a.s1;a.s4 = a.s1;a.s3 = a.s1;a.s2 = a.s1;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_e(a) a.s7 = a.s0;a.s6 = a.s0;a.s5 = a.s0;a.s4 = a.s0;a.s3 = a.s0;a.s2 = a.s0;a.s1 = a.s0;\n"
"#endif\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics:enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics:enable\n"
"/**************************************Array minMax**************************************/\n"
"__kernel void arithm_op_minMaxLoc(int cols, int invalid_cols, int offset, int elemnum, int groupnum,\n"
"                                  __global VEC_TYPE *src, __global double8 *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = offset + id + (id / cols) * invalid_cols;\n"
"	__local VEC_TYPE localmem_max[128], localmem_min[128];\n"
"	VEC_TYPE minval, maxval, temp;\n"
"	__local VEC_TYPE_LOC localmem_maxloc[128], localmem_minloc[128];\n"
"	VEC_TYPE_LOC minloc, maxloc, temploc, negative = -1;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = src[idx];\n"
"		int idx_c = idx << 3;\n"
"		temploc = (VEC_TYPE_LOC)(idx_c, idx_c + 1, idx_c + 2, idx_c + 3, idx_c + 4, idx_c + 5, idx_c + 6, idx_c + 7);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"			repeat_s(temploc);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"			repeat_e(temploc);\n"
"		}\n"
"		\n"
"		minval = temp;\n"
"		maxval = temp;\n"
"		minloc = temploc;\n"
"		maxloc = temploc;\n"
"	}\n"
"	else\n"
"	{\n"
"		minval = MAX_VAL;\n"
"		maxval = MIN_VAL;\n"
"		minloc = negative;\n"
"		maxloc = negative;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = offset + id + (id / cols) * invalid_cols;\n"
"		temp = src[idx];\n"
"		int idx_c = idx << 3;\n"
"		temploc = (VEC_TYPE_LOC)(idx_c, idx_c + 1, idx_c + 2, idx_c + 3, idx_c + 4, idx_c + 5, idx_c + 6, idx_c + 7);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"			repeat_s(temploc);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"			repeat_e(temploc);\n"
"		}\n"
"		\n"
"		minval = min(minval, temp);\n"
"		maxval = max(maxval, temp);\n"
"		minloc = CONDITION_FUNC(minval == temp, temploc , minloc);\n"
"		maxloc = CONDITION_FUNC(maxval == temp, temploc , maxloc);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_min[lid - 128] = minval;\n"
"		localmem_max[lid - 128] = maxval;\n"
"		localmem_minloc[lid - 128] = minloc;\n"
"		localmem_maxloc[lid - 128] = maxloc;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_min[lid] = min(minval, localmem_min[lid]);\n"
"		localmem_max[lid] = max(maxval, localmem_max[lid]);\n"
"		localmem_minloc[lid] = CONDITION_FUNC(localmem_min[lid] == minval, minloc , localmem_minloc[lid]);\n"
"		localmem_maxloc[lid] = CONDITION_FUNC(localmem_max[lid] == maxval, maxloc , localmem_maxloc[lid]);\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_min[lid] = min(localmem_min[lid] , localmem_min[lid2]);\n"
"			localmem_max[lid] = max(localmem_max[lid] , localmem_max[lid2]);\n"
"			localmem_minloc[lid] =\n"
"			    CONDITION_FUNC(localmem_min[lid] == localmem_min[lid2], localmem_minloc[lid2] , localmem_minloc[lid]);\n"
"			localmem_maxloc[lid] =\n"
"			    CONDITION_FUNC(localmem_max[lid] == localmem_max[lid2], localmem_maxloc[lid2] , localmem_maxloc[lid]);\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = convert_double8(localmem_min[0]);\n"
"		dst[gid + groupnum] = convert_double8(localmem_max[0]);\n"
"		dst[gid + 2 * groupnum] = convert_double8(localmem_minloc[0]);\n"
"		dst[gid + 3 * groupnum] = convert_double8(localmem_maxloc[0]);\n"
"	}\n"
"}\n"
"#if defined (REPEAT_S0)\n"
"#define repeat_ms(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_S1)\n"
"#define repeat_ms(a) a.s0 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S2)\n"
"#define repeat_ms(a) a.s0 = 0;a.s1 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S3)\n"
"#define repeat_ms(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S4)\n"
"#define repeat_ms(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S5)\n"
"#define repeat_ms(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S6)\n"
"#define repeat_ms(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S7)\n"
"#define repeat_ms(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;a.s5 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_me(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_me(a) a.s7 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;a.s1 = 0;\n"
"#endif\n"
"/**************************************Array minMax mask**************************************/\n"
"__kernel void arithm_op_minMaxLoc_mask(int cols, int invalid_cols, int offset, int elemnum, int groupnum, __global VEC_TYPE *src,\n"
"                                       int minvalid_cols, int moffset, __global uchar8 *mask, __global double8  *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = offset + id + (id / cols) * invalid_cols;\n"
"	unsigned int midx = moffset + id + (id / cols) * minvalid_cols;\n"
"	__local VEC_TYPE localmem_max[128], localmem_min[128];\n"
"	VEC_TYPE minval, maxval, temp, max_val = MAX_VAL, min_val = MIN_VAL, zero = 0, m_temp;\n"
"	__local VEC_TYPE_LOC localmem_maxloc[128], localmem_minloc[128];\n"
"	VEC_TYPE_LOC minloc, maxloc, temploc, negative = -1;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = src[idx];\n"
"		m_temp = CONVERT_TYPE(mask[midx]);\n"
"		int idx_c = idx << 3;\n"
"		temploc = (VEC_TYPE_LOC)(idx_c, idx_c + 1, idx_c + 2, idx_c + 3, idx_c + 4, idx_c + 5, idx_c + 6, idx_c + 7);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_ms(m_temp);\n"
"			repeat_s(temploc);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_me(m_temp);\n"
"			repeat_e(temploc);\n"
"		}\n"
"		\n"
"		minval = m_temp > zero ? temp : max_val;\n"
"		maxval = m_temp > zero ? temp : min_val;\n"
"		minloc = CONDITION_FUNC(m_temp > zero, temploc , negative);\n"
"		maxloc = minloc;\n"
"	}\n"
"	else\n"
"	{\n"
"		minval = MAX_VAL;\n"
"		maxval = MIN_VAL;\n"
"		minloc = negative;\n"
"		maxloc = negative;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = offset + id + (id / cols) * invalid_cols;\n"
"		midx = moffset + id + (id / cols) * minvalid_cols;\n"
"		temp = src[idx];\n"
"		m_temp = CONVERT_TYPE(mask[midx]);\n"
"		int idx_c = idx << 3;\n"
"		temploc = (VEC_TYPE_LOC)(idx_c, idx_c + 1, idx_c + 2, idx_c + 3, idx_c + 4, idx_c + 5, idx_c + 6, idx_c + 7);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_ms(m_temp);\n"
"			repeat_s(temploc);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_me(m_temp);\n"
"			repeat_e(temploc);\n"
"		}\n"
"		\n"
"		minval = min(minval, m_temp > zero ? temp : max_val);\n"
"		maxval = max(maxval, m_temp > zero ? temp : min_val);\n"
"		\n"
"		temploc = CONDITION_FUNC(m_temp > zero, temploc , negative);\n"
"		minloc = CONDITION_FUNC(minval == temp, temploc , minloc);\n"
"		maxloc = CONDITION_FUNC(maxval == temp, temploc , maxloc);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_min[lid - 128] = minval;\n"
"		localmem_max[lid - 128] = maxval;\n"
"		localmem_minloc[lid - 128] = minloc;\n"
"		localmem_maxloc[lid - 128] = maxloc;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_min[lid] = min(minval, localmem_min[lid]);\n"
"		localmem_max[lid] = max(maxval, localmem_max[lid]);\n"
"		localmem_minloc[lid] = CONDITION_FUNC(localmem_min[lid] == minval, minloc , localmem_minloc[lid]);\n"
"		localmem_maxloc[lid] = CONDITION_FUNC(localmem_max[lid] == maxval, maxloc , localmem_maxloc[lid]);\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_min[lid] = min(localmem_min[lid] , localmem_min[lid2]);\n"
"			localmem_max[lid] = max(localmem_max[lid] , localmem_max[lid2]);\n"
"			localmem_minloc[lid] =\n"
"			    CONDITION_FUNC(localmem_min[lid] == localmem_min[lid2], localmem_minloc[lid2] , localmem_minloc[lid]);\n"
"			localmem_maxloc[lid] =\n"
"			    CONDITION_FUNC(localmem_max[lid] == localmem_max[lid2], localmem_maxloc[lid2] , localmem_maxloc[lid]);\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = convert_double8(localmem_min[0]);\n"
"		dst[gid + groupnum] = convert_double8(localmem_max[0]);\n"
"		dst[gid + 2 * groupnum] = convert_double8(localmem_minloc[0]);\n"
"		dst[gid + 3 * groupnum] = convert_double8(localmem_maxloc[0]);\n"
"	}\n"
"}\n"
;
const char *arithm_minMaxLoc_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan, yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define TYPE uchar\n"
"#define VEC_TYPE uchar8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_uchar8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 255\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define TYPE char\n"
"#define VEC_TYPE char8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_char8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL -128\n"
"#define MAX_VAL 127\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define TYPE ushort\n"
"#define VEC_TYPE ushort8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_ushort8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 65535\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define TYPE short\n"
"#define VEC_TYPE short8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_short8\n"
"#define CONDITION_FUNC(a,b,c) (convert_int8(a) ? b : c)\n"
"#define MIN_VAL -32768\n"
"#define MAX_VAL 32767\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define TYPE int\n"
"#define VEC_TYPE int8\n"
"#define VEC_TYPE_LOC int8\n"
"#define CONVERT_TYPE convert_int8\n"
"#define CONDITION_FUNC(a,b,c) ((a) ? b : c)\n"
"#define MIN_VAL INT_MIN\n"
"#define MAX_VAL INT_MAX\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define TYPE float\n"
"#define VEC_TYPE float8\n"
"#define VEC_TYPE_LOC float8\n"
"#define CONVERT_TYPE convert_float8\n"
"#define CONDITION_FUNC(a,b,c) ((a) ? b : c)\n"
"#define MIN_VAL (-FLT_MAX)\n"
"#define MAX_VAL FLT_MAX\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define TYPE double\n"
"#define VEC_TYPE double8\n"
"#define VEC_TYPE_LOC double8\n"
"#define CONVERT_TYPE convert_double8\n"
"#define CONDITION_FUNC(a,b,c) ((a) ? b : c)\n"
"#define MIN_VAL (-DBL_MAX)\n"
"#define MAX_VAL DBL_MAX\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_e(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_e(a) a.s7 = a.s6;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_e(a) a.s7 = a.s5;a.s6 = a.s5;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_e(a) a.s7 = a.s4;a.s6 = a.s4;a.s5 = a.s4;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_e(a) a.s7 = a.s3;a.s6 = a.s3;a.s5 = a.s3;a.s4 = a.s3;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_e(a) a.s7 = a.s2;a.s6 = a.s2;a.s5 = a.s2;a.s4 = a.s2;a.s3 = a.s2;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_e(a) a.s7 = a.s1;a.s6 = a.s1;a.s5 = a.s1;a.s4 = a.s1;a.s3 = a.s1;a.s2 = a.s1;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_e(a) a.s7 = a.s0;a.s6 = a.s0;a.s5 = a.s0;a.s4 = a.s0;a.s3 = a.s0;a.s2 = a.s0;a.s1 = a.s0;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_me(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_me(a) a.s7 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;a.s1 = 0;\n"
"#endif\n"
"/**************************************Array minMax mask**************************************/\n"
"__kernel void arithm_op_minMaxLoc_mask(int cols, int invalid_cols, int offset, int elemnum, int groupnum, __global TYPE *src,\n"
"                                       int minvalid_cols, int moffset, __global uchar *mask, __global double8  *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = id + (id / cols) * invalid_cols;\n"
"	unsigned int midx = id + (id / cols) * minvalid_cols;\n"
"	__local VEC_TYPE lm_max[128], lm_min[128];\n"
"	VEC_TYPE minval, maxval, temp, m_temp;\n"
"	__local VEC_TYPE_LOC lm_maxloc[128], lm_minloc[128];\n"
"	VEC_TYPE_LOC minloc, maxloc, temploc, negative = -1, one = 1, zero = 0;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = vload8(idx, &src[offset]);\n"
"		m_temp = CONVERT_TYPE(vload8(midx, &mask[moffset]));\n"
"		int idx_c = (idx << 3) + offset;\n"
"		temploc = (VEC_TYPE_LOC)(idx_c, idx_c + 1, idx_c + 2, idx_c + 3, idx_c + 4, idx_c + 5, idx_c + 6, idx_c + 7);\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_me(m_temp);\n"
"			repeat_e(temploc);\n"
"		}\n"
"		\n"
"		minval = m_temp != 0 ? temp : MAX_VAL;\n"
"		maxval = m_temp != 0 ? temp : MIN_VAL;\n"
"		minloc = CONDITION_FUNC(m_temp != 0, temploc , negative);\n"
"		maxloc = minloc;\n"
"	}\n"
"	else\n"
"	{\n"
"		minval = MAX_VAL;\n"
"		maxval = MIN_VAL;\n"
"		minloc = negative;\n"
"		maxloc = negative;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = id + (id / cols) * invalid_cols;\n"
"		midx = id + (id / cols) * minvalid_cols;\n"
"		temp = vload8(idx, &src[offset]);\n"
"		m_temp = CONVERT_TYPE(vload8(midx, &mask[moffset]));\n"
"		int idx_c = (idx << 3) + offset;\n"
"		temploc = (VEC_TYPE_LOC)(idx_c, idx_c + 1, idx_c + 2, idx_c + 3, idx_c + 4, idx_c + 5, idx_c + 6, idx_c + 7);\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_me(m_temp);\n"
"			repeat_e(temploc);\n"
"		}\n"
"		\n"
"		minval = min(minval, m_temp != 0 ? temp : minval);\n"
"		maxval = max(maxval, m_temp != 0 ? temp : maxval);\n"
"		\n"
"		minloc = CONDITION_FUNC((minval == temp) && (m_temp != 0), temploc , minloc);\n"
"		maxloc = CONDITION_FUNC((maxval == temp) && (m_temp != 0), temploc , maxloc);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		lm_min[lid - 128] = minval;\n"
"		lm_max[lid - 128] = maxval;\n"
"		lm_minloc[lid - 128] = minloc;\n"
"		lm_maxloc[lid - 128] = maxloc;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		lm_min[lid] = min(minval, lm_min[lid]);\n"
"		lm_max[lid] = max(maxval, lm_max[lid]);\n"
"		VEC_TYPE con_min = CONVERT_TYPE(minloc != negative ? one : zero);\n"
"		VEC_TYPE con_max = CONVERT_TYPE(maxloc != negative ? one : zero);\n"
"		lm_minloc[lid] = CONDITION_FUNC((lm_min[lid] == minval) && (con_min != 0), minloc , lm_minloc[lid]);\n"
"		lm_maxloc[lid] = CONDITION_FUNC((lm_max[lid] == maxval) && (con_max != 0), maxloc , lm_maxloc[lid]);\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			lm_min[lid] = min(lm_min[lid] , lm_min[lid2]);\n"
"			lm_max[lid] = max(lm_max[lid] , lm_max[lid2]);\n"
"			VEC_TYPE con_min = CONVERT_TYPE(lm_minloc[lid2] != negative ? one : zero);\n"
"			VEC_TYPE con_max = CONVERT_TYPE(lm_maxloc[lid2] != negative ? one : zero);\n"
"			lm_minloc[lid] =\n"
"			    CONDITION_FUNC((lm_min[lid] == lm_min[lid2]) && (con_min != 0), lm_minloc[lid2] , lm_minloc[lid]);\n"
"			lm_maxloc[lid] =\n"
"			    CONDITION_FUNC((lm_max[lid] == lm_max[lid2]) && (con_max != 0), lm_maxloc[lid2] , lm_maxloc[lid]);\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = convert_double8(lm_min[0]);\n"
"		dst[gid + groupnum] = convert_double8(lm_max[0]);\n"
"		dst[gid + 2 * groupnum] = convert_double8(lm_minloc[0]);\n"
"		dst[gid + 3 * groupnum] = convert_double8(lm_maxloc[0]);\n"
"	}\n"
"}\n"
;
const char *arithm_minMax_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define VEC_TYPE uchar8\n"
"#define TYPE uchar\n"
"#define CONVERT_TYPE convert_uchar8\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 255\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define VEC_TYPE char8\n"
"#define TYPE char\n"
"#define CONVERT_TYPE convert_char8\n"
"#define MIN_VAL -128\n"
"#define MAX_VAL 127\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define VEC_TYPE ushort8\n"
"#define TYPE ushort\n"
"#define CONVERT_TYPE convert_ushort8\n"
"#define MIN_VAL 0\n"
"#define MAX_VAL 65535\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define VEC_TYPE short8\n"
"#define TYPE short\n"
"#define CONVERT_TYPE convert_short8\n"
"#define MIN_VAL -32768\n"
"#define MAX_VAL 32767\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define VEC_TYPE int8\n"
"#define TYPE int\n"
"#define CONVERT_TYPE convert_int8\n"
"#define MIN_VAL INT_MIN\n"
"#define MAX_VAL INT_MAX\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define VEC_TYPE float8\n"
"#define TYPE float\n"
"#define CONVERT_TYPE convert_float8\n"
"#define MIN_VAL (-FLT_MAX)\n"
"#define MAX_VAL FLT_MAX\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define VEC_TYPE double8\n"
"#define TYPE double\n"
"#define CONVERT_TYPE convert_double8\n"
"#define MIN_VAL (-DBL_MAX)\n"
"#define MAX_VAL DBL_MAX\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_me(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_me(a) a.s7 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_me(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;a.s1 = 0;\n"
"#endif\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics:enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics:enable\n"
"/**************************************Array minMax mask**************************************/\n"
"__kernel void arithm_op_minMax_mask(int cols, int invalid_cols, int offset, int elemnum, int groupnum, __global TYPE *src,\n"
"                                    int minvalid_cols, int moffset, __global uchar *mask, __global VEC_TYPE *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = id + (id / cols) * invalid_cols;\n"
"	unsigned int midx = id + (id / cols) * minvalid_cols;\n"
"	__local VEC_TYPE localmem_max[128], localmem_min[128];\n"
"	VEC_TYPE minval, maxval, temp, m_temp;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = vload8(idx, &src[offset]);\n"
"		m_temp = CONVERT_TYPE(vload8(midx, &mask[moffset]));\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_me(m_temp);\n"
"		}\n"
"		\n"
"		minval = m_temp != 0 ? temp : MAX_VAL;\n"
"		maxval = m_temp != 0 ? temp : MIN_VAL;\n"
"	}\n"
"	else\n"
"	{\n"
"		minval = MAX_VAL;\n"
"		maxval = MIN_VAL;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = id + (id / cols) * invalid_cols;\n"
"		midx = id + (id / cols) * minvalid_cols;\n"
"		temp = vload8(idx, &src[offset]);\n"
"		m_temp = CONVERT_TYPE(vload8(midx, &mask[moffset]));\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_me(m_temp);\n"
"		}\n"
"		\n"
"		minval = min(minval, m_temp != 0 ? temp : minval);\n"
"		maxval = max(maxval, m_temp != 0 ? temp : maxval);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_min[lid - 128] = minval;\n"
"		localmem_max[lid - 128] = maxval;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_min[lid] = min(minval, localmem_min[lid]);\n"
"		localmem_max[lid] = max(maxval, localmem_max[lid]);\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_min[lid] = min(localmem_min[lid] , localmem_min[lid2]);\n"
"			localmem_max[lid] = max(localmem_max[lid] , localmem_max[lid2]);\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = localmem_min[0];\n"
"		dst[gid + groupnum] = localmem_max[0];\n"
"	}\n"
"}\n"
;
const char *arithm_mul =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"int4 round_int4(float4 v)\n"
"{\n"
"	v.s0 = v.s0 + (v.s0 > 0 ? 0.5 : -0.5);\n"
"	v.s1 = v.s1 + (v.s1 > 0 ? 0.5 : -0.5);\n"
"	v.s2 = v.s2 + (v.s2 > 0 ? 0.5 : -0.5);\n"
"	v.s3 = v.s3 + (v.s3 > 0 ? 0.5 : -0.5);\n"
"	\n"
"	return convert_int4_sat(v);\n"
"}\n"
"uint4 round_uint4(float4 v)\n"
"{\n"
"	v.s0 = v.s0 + (v.s0 > 0 ? 0.5 : -0.5);\n"
"	v.s1 = v.s1 + (v.s1 > 0 ? 0.5 : -0.5);\n"
"	v.s2 = v.s2 + (v.s2 > 0 ? 0.5 : -0.5);\n"
"	v.s3 = v.s3 + (v.s3 > 0 ? 0.5 : -0.5);\n"
"	\n"
"	return convert_uint4_sat(v);\n"
"}\n"
"long round_long(float v)\n"
"{\n"
"	v = v + (v > 0 ? 0.5 : -0.5);\n"
"	\n"
"	return convert_long_sat(v);\n"
"}\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////multiply//////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************add without mask**************************************/\n"
"__kernel void arithm_mul_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                            __global uchar *src2, int src2_step, int src2_offset,\n"
"                            __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, float scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp      = convert_int4_sat(src1_data) * convert_int4_sat(src2_data);\n"
"		tmp = round_int4(convert_float4(tmp) * scalar);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_mul_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                            __global ushort *src2, int src2_step, int src2_offset,\n"
"                            __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, float scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		uint4    tmp = convert_uint4_sat(src1_data) * convert_uint4_sat(src2_data);\n"
"		tmp = round_uint4(convert_float4(tmp) * scalar);\n"
"		ushort4 tmp_data = convert_ushort4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_mul_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                            __global short *src2, int src2_step, int src2_offset,\n"
"                            __global short *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, float scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		int4   tmp = convert_int4_sat(src1_data) * convert_int4_sat(src2_data);\n"
"		tmp = round_int4(convert_float4(tmp) * scalar);\n"
"		short4 tmp_data = convert_short4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_mul_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                            __global int *src2, int src2_step, int src2_offset,\n"
"                            __global int *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		long tmp  = (long)(data1) * (long)(data2);\n"
"		tmp = round_long((double)tmp * scalar);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = convert_int_sat(tmp);\n"
"	}\n"
"}\n"
"__kernel void arithm_mul_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                            __global float *src2, int src2_step, int src2_offset,\n"
"                            __global float *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, float scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float tmp = data1 * data2;\n"
"		tmp = tmp * scalar;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_mul_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                            __global double *src2, int src2_step, int src2_offset,\n"
"                            __global double *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1, double scalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		double tmp = data1 * data2;\n"
"		tmp = tmp * scalar;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
;
const char *arithm_nonzero =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define VEC_TYPE uchar8\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define VEC_TYPE char8\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define VEC_TYPE ushort8\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define VEC_TYPE short8\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define VEC_TYPE int8\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define VEC_TYPE float8\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define VEC_TYPE double8\n"
"#endif\n"
"#if defined (REPEAT_S0)\n"
"#define repeat_s(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_S1)\n"
"#define repeat_s(a) a.s0 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S2)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S3)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S4)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S5)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S6)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S7)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;a.s5 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_e(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_e(a) a.s7 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;a.s1 = 0;\n"
"#endif\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics:enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics:enable\n"
"/**************************************Count NonZero**************************************/\n"
"__kernel void arithm_op_nonzero(int cols, int invalid_cols, int offset, int elemnum, int groupnum,\n"
"                                __global VEC_TYPE *src, __global int8 *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = offset + id + (id / cols) * invalid_cols;\n"
"	__local int8 localmem_nonzero[128];\n"
"	int8 nonzero;\n"
"	VEC_TYPE zero = 0, one = 1, temp;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = src[idx];\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"		}\n"
"		\n"
"		nonzero = convert_int8(temp == zero ? zero : one);\n"
"	}\n"
"	else\n"
"	{\n"
"		nonzero = 0;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = offset + id + (id / cols) * invalid_cols;\n"
"		temp = src[idx];\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"		}\n"
"		\n"
"		nonzero = nonzero + convert_int8(temp == zero ? zero : one);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_nonzero[lid - 128] = nonzero;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_nonzero[lid] = nonzero + localmem_nonzero[lid];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_nonzero[lid] = localmem_nonzero[lid] + localmem_nonzero[lid2];\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = localmem_nonzero[0];\n"
"	}\n"
"}\n"
;
const char *arithm_phase =
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#define CV_PI 3.1415926535898\n"
"/**************************************phase inradians**************************************/\n"
"__kernel void arithm_phase_inradians_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                        __global float *src2, int src2_step, int src2_offset,\n"
"                                        __global float *dst,  int dst_step,  int dst_offset,\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float tmp = atan2(data2, data1);\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"	\n"
"}\n"
"#if defined (DOUBLE_SUPPORT)\n"
"__kernel void arithm_phase_inradians_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                        __global double *src2, int src2_step, int src2_offset,\n"
"                                        __global double *dst,  int dst_step,  int dst_offset,\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = atan2(data2, data1);\n"
"	}\n"
"	\n"
"}\n"
"#endif\n"
"/**************************************phase indegrees**************************************/\n"
"__kernel void arithm_phase_indegrees_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                                        __global float *src2, int src2_step, int src2_offset,\n"
"                                        __global float *dst,  int dst_step,  int dst_offset,\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float tmp = atan2(data2, data1);\n"
"		float tmp_data = 180 * tmp / CV_PI;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"	\n"
"}\n"
"#if defined (DOUBLE_SUPPORT)\n"
"__kernel void arithm_phase_indegrees_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                                        __global double *src2, int src2_step, int src2_offset,\n"
"                                        __global double *dst,  int dst_step,  int dst_offset,\n"
"                                        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		double tmp = atan2(data2, data1);\n"
"		double tmp_data = 180 * tmp / CV_PI;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp_data;\n"
"	}\n"
"	\n"
"}\n"
"#endif\n"
;
const char *arithm_polarToCart =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#define CV_PI   3.1415926535897932384626433832795\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////polarToCart with magnitude//////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_polarToCart_mag_D5(__global float *src1, int src1_step, int src1_offset, //magnitue\n"
"                                        __global float *src2, int src2_step, int src2_offset,//angle\n"
"                                        __global float *dst1, int dst1_step, int dst1_offset,\n"
"                                        __global float *dst2, int dst2_step, int dst2_offset,\n"
"                                        int rows, int cols, int angInDegree)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		\n"
"		int dst1_index = mad24(y, dst1_step, (x << 2) + dst1_offset);\n"
"		int dst2_index = mad24(y, dst2_step, (x << 2) + dst2_offset);\n"
"		\n"
"		float x = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float y = *((__global float *)((__global char *)src2 + src2_index));\n"
"		\n"
"		float ascale = CV_PI / 180.0;\n"
"		float alpha  = angInDegree == 1 ? y * ascale : y;\n"
"		float a = cos(alpha) * x;\n"
"		float b = sin(alpha) * x;\n"
"		\n"
"		*((__global float *)((__global char *)dst1 + dst1_index)) = a;\n"
"		*((__global float *)((__global char *)dst2 + dst2_index)) = b;\n"
"	}\n"
"}\n"
"__kernel void arithm_polarToCart_mag_D6(__global double *src1, int src1_step, int src1_offset, //magnitue\n"
"                                        __global double *src2, int src2_step, int src2_offset,//angle\n"
"                                        __global double *dst1, int dst1_step, int dst1_offset,\n"
"                                        __global double *dst2, int dst2_step, int dst2_offset,\n"
"                                        int rows, int cols, int angInDegree)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		\n"
"		int dst1_index = mad24(y, dst1_step, (x << 3) + dst1_offset);\n"
"		int dst2_index = mad24(y, dst2_step, (x << 3) + dst2_offset);\n"
"		\n"
"		double x = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double y = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		float ascale = CV_PI / 180.0;\n"
"		double alpha  = angInDegree == 1 ? y * ascale : y;\n"
"		double a = cos(alpha) * x;\n"
"		double b = sin(alpha) * x;\n"
"		\n"
"		*((__global double *)((__global char *)dst1 + dst1_index)) = a;\n"
"		*((__global double *)((__global char *)dst2 + dst2_index)) = b;\n"
"	}\n"
"}\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////polarToCart without magnitude//////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void arithm_polarToCart_D5(__global float *src,  int src_step,  int src_offset, //angle\n"
"                                    __global float *dst1, int dst1_step, int dst1_offset,\n"
"                                    __global float *dst2, int dst2_step, int dst2_offset,\n"
"                                    int rows, int cols, int angInDegree)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index  = mad24(y, src_step, (x << 2) + src_offset);\n"
"		\n"
"		int dst1_index = mad24(y, dst1_step, (x << 2) + dst1_offset);\n"
"		int dst2_index = mad24(y, dst2_step, (x << 2) + dst2_offset);\n"
"		\n"
"		float y = *((__global float *)((__global char *)src + src_index));\n"
"		\n"
"		float ascale = CV_PI / 180.0;\n"
"		float alpha  = angInDegree == 1 ? y * ascale : y;\n"
"		float a = cos(alpha);\n"
"		float b = sin(alpha);\n"
"		\n"
"		*((__global float *)((__global char *)dst1 + dst1_index)) = a;\n"
"		*((__global float *)((__global char *)dst2 + dst2_index)) = b;\n"
"	}\n"
"}\n"
"__kernel void arithm_polarToCart_D6(__global float *src,  int src_step,  int src_offset, //angle\n"
"                                    __global float *dst1, int dst1_step, int dst1_offset,\n"
"                                    __global float *dst2, int dst2_step, int dst2_offset,\n"
"                                    int rows, int cols, int angInDegree)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src_index  = mad24(y, src_step, (x << 3) + src_offset);\n"
"		\n"
"		int dst1_index = mad24(y, dst1_step, (x << 3) + dst1_offset);\n"
"		int dst2_index = mad24(y, dst2_step, (x << 3) + dst2_offset);\n"
"		\n"
"		double y = *((__global double *)((__global char *)src + src_index));\n"
"		\n"
"		float ascale = CV_PI / 180.0;\n"
"		double alpha  = angInDegree == 1 ? y * ascale : y;\n"
"		double a = cos(alpha);\n"
"		double b = sin(alpha);\n"
"		\n"
"		*((__global double *)((__global char *)dst1 + dst1_index)) = a;\n"
"		*((__global double *)((__global char *)dst2 + dst2_index)) = b;\n"
"	}\n"
"}\n"
;
const char *arithm_pow =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jiang Liyuan, jlyuan001.good@163.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"/************************************** pow **************************************/\n"
"__kernel void arithm_pow_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                            __global float *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1,\n"
"                            double p)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float src1_data = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float tmp = src1_data > 0 ? exp(p * log(src1_data)) : (src1_data == 0 ? 0 : exp(p * log(fabs(src1_data))));\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"	\n"
"}\n"
"#if defined (DOUBLE_SUPPORT)\n"
"__kernel void arithm_pow_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                            __global double *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1,\n"
"                            double p)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double src1_data = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double tmp = src1_data > 0 ? exp(p * log(src1_data)) : (src1_data == 0 ? 0 : exp(p * log(fabs(src1_data))));\n"
"		*((__global double *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"	\n"
"}\n"
"#endif\n"
;
const char *arithm_sub =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////////SUB////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/**************************************sub without mask**************************************/\n"
"__kernel void arithm_sub_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"                            __global uchar *src2, int src2_step, int src2_offset,\n"
"                            __global uchar *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4 tmp      = convert_short4_sat(src1_data) - convert_short4_sat(src2_data);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"                            __global ushort *src2, int src2_step, int src2_offset,\n"
"                            __global ushort *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		ushort4 src1_data = vload4(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort4 src2_data = vload4(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		\n"
"		ushort4 dst_data = *((__global ushort4 *)((__global char *)dst + dst_index));\n"
"		int4    tmp = convert_int4_sat(src1_data) - convert_int4_sat(src2_data);\n"
"		ushort4 tmp_data = convert_ushort4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_D3(__global short *src1, int src1_step, int src1_offset,\n"
"                            __global short *src2, int src2_step, int src2_offset,\n"
"                            __global short *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffff8);\n"
"		\n"
"		short4 src1_data = vload4(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short4 src2_data = vload4(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		\n"
"		short4 dst_data = *((__global short4 *)((__global char *)dst + dst_index));\n"
"		int4   tmp = convert_int4_sat(src1_data) - convert_int4_sat(src2_data);\n"
"		short4 tmp_data = convert_short4_sat(tmp);\n"
"		\n"
"		dst_data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : dst_data.x;\n"
"		dst_data.y = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.y : dst_data.y;\n"
"		dst_data.z = ((dst_index + 4 >= dst_start) && (dst_index + 4 < dst_end)) ? tmp_data.z : dst_data.z;\n"
"		dst_data.w = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end)) ? tmp_data.w : dst_data.w;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = dst_data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_D4(__global int *src1, int src1_step, int src1_offset,\n"
"                            __global int *src2, int src2_step, int src2_offset,\n"
"                            __global int *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		long tmp  = (long)(data1) - (long)(data2);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = convert_int_sat(tmp);\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_D5(__global float *src1, int src1_step, int src1_offset,\n"
"                            __global float *src2, int src2_step, int src2_offset,\n"
"                            __global float *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float tmp = data1 - data2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_D6(__global double *src1, int src1_step, int src1_offset,\n"
"                            __global double *src2, int src2_step, int src2_offset,\n"
"                            __global double *dst,  int dst_step,  int dst_offset,\n"
"                            int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data1 - data2;\n"
"	}\n"
"}\n"
"/**************************************sub with mask**************************************/\n"
"__kernel void arithm_sub_with_mask_C1_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4 tmp = convert_short4_sat(src1_data) - convert_short4_sat(src2_data);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C1_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		ushort2 src2_data = vload2(0, (__global ushort *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) - convert_int2_sat(src2_data);\n"
"		ushort2 tmp_data = convert_ushort2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C1_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		short2 src2_data = vload2(0, (__global short *)((__global char *)src2 + src2_index));\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) - convert_int2_sat(src2_data);\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C1_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *((__global int *)((__global char *)src2 + src2_index));\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int data = convert_int_sat((long)src_data1 - (long)src_data2);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C1_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *((__global float *)((__global char *)src2 + src2_index));\n"
"		float dst_data  = *((__global float *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float data = src_data1 - src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C1_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src_data2 = *((__global double *)((__global char *)src2 + src2_index));\n"
"		double dst_data  = *((__global double *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double data = src_data1 - src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C2_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		uchar4 src2_data = vload4(0, src2 + src2_index);\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		short4   tmp = convert_short4_sat(src1_data) - convert_short4_sat(src2_data);\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C2_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		ushort2 src_data2 = *((__global ushort2 *)((__global char *)src2 + src2_index));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) - convert_int2_sat(src_data2);\n"
"		ushort2 data = convert_ushort2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C2_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		short2 src_data2 = *((__global short2 *)((__global char *)src2 + src2_index));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) - convert_int2_sat(src_data2);\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C2_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int    *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = *((__global int2 *)((__global char *)src2 + src2_index));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2 data = convert_int2_sat(convert_long2_sat(src_data1) - convert_long2_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C2_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = *((__global float2 *)((__global char *)src2 + src2_index));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 data = src_data1 - src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C2_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = *((__global double2 *)((__global char *)src2 + src2_index));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = src_data1 - src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C3_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int src2_index = mad24(y, src2_step, (x * 3) + src2_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		uchar4 src2_data_0 = vload4(0, src2 + src2_index + 0);\n"
"		uchar4 src2_data_1 = vload4(0, src2 + src2_index + 4);\n"
"		uchar4 src2_data_2 = vload4(0, src2 + src2_index + 8);\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(convert_short4_sat(src1_data_0) - convert_short4_sat(src2_data_0));\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(convert_short4_sat(src1_data_1) - convert_short4_sat(src2_data_1));\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(convert_short4_sat(src1_data_2) - convert_short4_sat(src2_data_2));\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C3_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		ushort2 src2_data_0 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 0));\n"
"		ushort2 src2_data_1 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 4));\n"
"		ushort2 src2_data_2 = vload2(0, (__global ushort *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(convert_int2_sat(src1_data_0) - convert_int2_sat(src2_data_0));\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(convert_int2_sat(src1_data_1) - convert_int2_sat(src2_data_1));\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(convert_int2_sat(src1_data_2) - convert_int2_sat(src2_data_2));\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C3_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int src2_index = mad24(y, src2_step, (x * 6) + src2_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		short2 src2_data_0 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 0));\n"
"		short2 src2_data_1 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 4));\n"
"		short2 src2_data_2 = vload2(0, (__global short *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(convert_int2_sat(src1_data_0) - convert_int2_sat(src2_data_0));\n"
"		short2 tmp_data_1 = convert_short2_sat(convert_int2_sat(src1_data_1) - convert_int2_sat(src2_data_1));\n"
"		short2 tmp_data_2 = convert_short2_sat(convert_int2_sat(src1_data_2) - convert_int2_sat(src2_data_2));\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C3_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *((__global int *)((__global char *)src2 + src2_index + 0));\n"
"		int src2_data_1 = *((__global int *)((__global char *)src2 + src2_index + 4));\n"
"		int src2_data_2 = *((__global int *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int tmp_data_0 = convert_int_sat((long)src1_data_0 - (long)src2_data_0);\n"
"		int tmp_data_1 = convert_int_sat((long)src1_data_1 - (long)src2_data_1);\n"
"		int tmp_data_2 = convert_int_sat((long)src1_data_2 - (long)src2_data_2);\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C3_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 12) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *((__global float *)((__global char *)src2 + src2_index + 0));\n"
"		float src2_data_1 = *((__global float *)((__global char *)src2 + src2_index + 4));\n"
"		float src2_data_2 = *((__global float *)((__global char *)src2 + src2_index + 8));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_data_0 = src1_data_0 - src2_data_0;\n"
"		float tmp_data_1 = src1_data_1 - src2_data_1;\n"
"		float tmp_data_2 = src1_data_2 - src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C3_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x * 24) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *((__global double *)((__global char *)src2 + src2_index + 0));\n"
"		double src2_data_1 = *((__global double *)((__global char *)src2 + src2_index + 8));\n"
"		double src2_data_2 = *((__global double *)((__global char *)src2 + src2_index + 16));\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = src1_data_0 - src2_data_0;\n"
"		double tmp_data_1 = src1_data_1 - src2_data_1;\n"
"		double tmp_data_2 = src1_data_2 - src2_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C4_D0(__global uchar *src1, int src1_step, int src1_offset,\n"
"        __global uchar *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global uchar *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 2) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		uchar4 src_data2 = *((__global uchar4 *)(src2 + src2_index));\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		uchar4 data = convert_uchar4_sat(convert_short4_sat(src_data1) - convert_short4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C4_D2(__global ushort *src1, int src1_step, int src1_offset,\n"
"        __global ushort *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global ushort *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		ushort4 src_data2 = *((__global ushort4 *)((__global char *)src2 + src2_index));\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		ushort4 data = convert_ushort4_sat(convert_int4_sat(src_data1) - convert_int4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C4_D3(__global short *src1, int src1_step, int src1_offset,\n"
"        __global short *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global short *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 3) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		short4 src_data2 = *((__global short4 *)((__global char *)src2 + src2_index));\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		short4 data = convert_short4_sat(convert_int4_sat(src_data1) - convert_int4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C4_D4(__global int   *src1, int src1_step, int src1_offset,\n"
"        __global int   *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global int   *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__global int4 *)((__global char *)src2 + src2_index));\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4 data = convert_int4_sat(convert_long4_sat(src_data1) - convert_long4_sat(src_data2));\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C4_D5(__global float *src1, int src1_step, int src1_offset,\n"
"        __global float *src2, int src2_step, int src2_offset,\n"
"        __global uchar *mask, int mask_step, int mask_offset,\n"
"        __global float *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 4) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__global float4 *)((__global char *)src2 + src2_index));\n"
"		float4 dst_data  = *((__global float4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float4 data = src_data1 - src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_sub_with_mask_C4_D6(__global double *src1, int src1_step, int src1_offset,\n"
"        __global double *src2, int src2_step, int src2_offset,\n"
"        __global uchar  *mask, int mask_step, int mask_offset,\n"
"        __global double *dst,  int dst_step,  int dst_offset,\n"
"        int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int src2_index = mad24(y, src2_step, (x << 5) + src2_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__global double4 *)((__global char *)src2 + src2_index));\n"
"		double4 dst_data  = *((__global double4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double4 data = src_data1 - src_data2;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_sub_scalar =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"/**************************************sub with scalar without mask**************************************/\n"
"__kernel void arithm_s_sub_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *src2, *src2, *src2);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp = convert_int4_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.x = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		ushort2 tmp_data = convert_ushort2_sat(tmp);\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		\n"
"		int2   tmp = convert_int2_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = (dst_index + 0 >= dst_start) ? tmp_data.x : data.x;\n"
"		data.y = (dst_index + 2 <  dst_end) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C1_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		\n"
"		long tmp = (long)src_data1 - (long)src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		int data = convert_int_sat(tmp);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C1_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *src2;\n"
"		\n"
"		float tmp = src_data1 - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C1_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src2_data = *src2;\n"
"		\n"
"		double data = src_data1 - src2_data;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp = convert_int4_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.xy = (dst_index + 0 >= dst_start) ? tmp_data.xy : data.xy;\n"
"		data.zw = (dst_index + 2 <  dst_end) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2    = (int2)(*(src2), src2[1]);\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		ushort2 data = convert_ushort2_sat(tmp);\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		long2 tmp = convert_long2_sat(src_data1) - convert_long2_sat(src_data2);\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		int2 data = convert_int2_sat(tmp);\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C2_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = (float2)(*src2, *(src2 + 1));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 tmp = src_data1 - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C2_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		int4 src2_data_0 = (int4)(*src2,       *(src2 + 1), *(src2 + 2), *src2);\n"
"		int4 src2_data_1 = (int4)(*(src2 + 1), *(src2 + 2), *src2,       *(src2 + 1));\n"
"		int4 src2_data_2 = (int4)(*(src2 + 2), *src2      , *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		int4 tmp_0 = convert_int4_sat(src1_data_0) - src2_data_0;\n"
"		int4 tmp_1 = convert_int4_sat(src1_data_1) - src2_data_1;\n"
"		int4 tmp_2 = convert_int4_sat(src1_data_2) - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(tmp_0);\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(tmp_1);\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(tmp_2);\n"
"		\n"
"		data_0.xyz = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int2 tmp_0 = convert_int2_sat(src1_data_0) - src2_data_0;\n"
"		int2 tmp_1 = convert_int2_sat(src1_data_1) - src2_data_1;\n"
"		int2 tmp_2 = convert_int2_sat(src1_data_2) - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(tmp_0);\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(tmp_1);\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(tmp_2);\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int2 tmp_0 = convert_int2_sat(src1_data_0) - src2_data_0;\n"
"		int2 tmp_1 = convert_int2_sat(src1_data_1) - src2_data_1;\n"
"		int2 tmp_2 = convert_int2_sat(src1_data_2) - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(tmp_0);\n"
"		short2 tmp_data_1 = convert_short2_sat(tmp_1);\n"
"		short2 tmp_data_2 = convert_short2_sat(tmp_2);\n"
"		\n"
"		data_0.xy = ((dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		long tmp_0 = (long)src1_data_0 - (long)src2_data_0;\n"
"		long tmp_1 = (long)src1_data_1 - (long)src2_data_1;\n"
"		long tmp_2 = (long)src1_data_2 - (long)src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		int tmp_data_0 = convert_int_sat(tmp_0);\n"
"		int tmp_data_1 = convert_int_sat(tmp_1);\n"
"		int tmp_data_2 = convert_int_sat(tmp_2);\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = tmp_data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C3_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *src2;\n"
"		float src2_data_1 = *(src2 + 1);\n"
"		float src2_data_2 = *(src2 + 2);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_0 = src1_data_0 - src2_data_0;\n"
"		float tmp_1 = src1_data_1 - src2_data_1;\n"
"		float tmp_2 = src1_data_2 - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = tmp_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = tmp_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = tmp_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C3_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *src2;\n"
"		double src2_data_1 = *(src2 + 1);\n"
"		double src2_data_2 = *(src2 + 2);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = src1_data_0 - src2_data_0;\n"
"		double tmp_data_1 = src1_data_1 - src2_data_1;\n"
"		double tmp_data_2 = src1_data_2 - src2_data_2;\n"
"		\n"
"		tmp_data_0 = isMatSubScalar ? tmp_data_0 : -tmp_data_0;\n"
"		tmp_data_1 = isMatSubScalar ? tmp_data_1 : -tmp_data_1;\n"
"		tmp_data_2 = isMatSubScalar ? tmp_data_2 : -tmp_data_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = tmp_data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = tmp_data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = tmp_data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"                                 __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		int4   src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 tmp = convert_int4_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		uchar4 data = convert_uchar4_sat(tmp);\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"                                 __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		\n"
"		int4 tmp = convert_int4_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		ushort4 data = convert_ushort4_sat(tmp);\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"                                 __global   short *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		int4 tmp = convert_int4_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		short4 data = convert_short4_sat(tmp);\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"                                 __global   int *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		\n"
"		long4 tmp = convert_long4_sat(src_data1) - convert_long4_sat(src_data2);\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		int4 data = convert_int4_sat(tmp);\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C4_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"                                 __global   float *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__constant float4 *)src2);\n"
"		\n"
"		float4 tmp = src_data1 - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = tmp;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_C4_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"                                 __global   double *dst,  int dst_step,  int dst_offset,\n"
"                                 __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"                                 int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__constant double4 *)src2);\n"
"		\n"
"		double4 data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_sub_scalar_mask =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"/**************************************sub with scalar with mask**************************************/\n"
"__kernel void arithm_s_sub_with_mask_C1_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (dst_offset & 3)\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - dst_align);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *src2, *src2, *src2);\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4 tmp = convert_int4_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 1 >= dst_start) && (dst_index + 1 < dst_end)) ? tmp_data.y : data.y;\n"
"		data.z = ((mask_data.z) && (dst_index + 2 >= dst_start) && (dst_index + 2 < dst_end)) ? tmp_data.z : data.z;\n"
"		data.w = ((mask_data.w) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end)) ? tmp_data.w : data.w;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C1_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 src1_data = vload2(0, (__global ushort *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data = *((__global ushort2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		ushort2 tmp_data = convert_ushort2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C1_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 src1_data = vload2(0, (__global short *)((__global char *)src1 + src1_index));\n"
"		int2 src2_data = (int2)(*src2, *src2);\n"
"		uchar2  mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data = *((__global short2 *)((__global uchar *)dst + dst_index));\n"
"		int2    tmp = convert_int2_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		short2 tmp_data = convert_short2_sat(tmp);\n"
"		\n"
"		data.x = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.x : data.x;\n"
"		data.y = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.y : data.y;\n"
"		\n"
"		*((__global short2 *)((__global uchar *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C1_D4(__global   int   *src1, int src1_step, int src1_offset,\n"
"        __global   int   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int src_data1 = *((__global int *)((__global char *)src1 + src1_index));\n"
"		int src_data2 = *src2;\n"
"		int dst_data  = *((__global int *)((__global char *)dst  + dst_index));\n"
"		\n"
"		long tmp = (long)src_data1 - (long)src_data2;\n"
"		tmp = isMatSubScalar ? tmp : - tmp;\n"
"		int data = convert_int_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C1_D5(__global   float   *src1, int src1_step, int src1_offset,\n"
"        __global   float   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float src_data1 = *((__global float *)((__global char *)src1 + src1_index));\n"
"		float src_data2 = *src2;\n"
"		float dst_data  = *((__global float *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C1_D6(__global   double   *src1, int src1_step, int src1_offset,\n"
"        __global   double   *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double   *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double src_data1 = *((__global double *)((__global char *)src1 + src1_index));\n"
"		double src_data2 = *src2;\n"
"		double dst_data  = *((__global double *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C2_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align ((dst_offset >> 1) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - (dst_align << 1));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		uchar4 src1_data = vload4(0, src1 + src1_index);\n"
"		int4 src2_data = (int4)(*src2, *(src2 + 1), *src2, *(src2 + 1));\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		uchar4 data = *((__global uchar4 *)(dst + dst_index));\n"
"		int4   tmp = convert_int4_sat(src1_data) - src2_data;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		uchar4 tmp_data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data.xy : data.xy;\n"
"		data.zw = ((mask_data.y) && (dst_index + 2 <  dst_end)) ? tmp_data.zw : data.zw;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C2_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort2 src_data1 = *((__global ushort2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		ushort2 dst_data  = *((__global ushort2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		ushort2 data = convert_ushort2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C2_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short2 src_data1 = *((__global short2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		short2 dst_data  = *((__global short2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int2    tmp = convert_int2_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		short2 data = convert_short2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C2_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int2 src_data1 = *((__global int2 *)((__global char *)src1 + src1_index));\n"
"		int2 src_data2 = (int2)(*src2, *(src2 + 1));\n"
"		int2 dst_data  = *((__global int2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		long2 tmp = convert_long2_sat(src_data1) - convert_long2_sat(src_data2);\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		int2 data = convert_int2_sat(tmp);\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C2_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float2 src_data1 = *((__global float2 *)((__global char *)src1 + src1_index));\n"
"		float2 src_data2 = (float2)(*src2, *(src2 + 1));\n"
"		float2 dst_data  = *((__global float2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float2 data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C2_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double2 src_data1 = *((__global double2 *)((__global char *)src1 + src1_index));\n"
"		double2 src_data2 = (double2)(*src2, *(src2 + 1));\n"
"		double2 dst_data  = *((__global double2 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double2 data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double2 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C3_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 3 ) & 3)\n"
"		int src1_index = mad24(y, src1_step, (x * 3) + src1_offset - (dst_align * 3));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 3) - (dst_align * 3));\n"
"		\n"
"		uchar4 src1_data_0 = vload4(0, src1 + src1_index + 0);\n"
"		uchar4 src1_data_1 = vload4(0, src1 + src1_index + 4);\n"
"		uchar4 src1_data_2 = vload4(0, src1 + src1_index + 8);\n"
"		\n"
"		int4 src2_data_0 = (int4)(*(src2 + 0), *(src2 + 1), *(src2 + 2), *(src2 + 0));\n"
"		int4 src2_data_1 = (int4)(*(src2 + 1), *(src2 + 2), *(src2 + 0), *(src2 + 1));\n"
"		int4 src2_data_2 = (int4)(*(src2 + 2), *(src2 + 0), *(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar4 mask_data = vload4(0, mask + mask_index);\n"
"		\n"
"		uchar4 data_0 = *((__global uchar4 *)(dst + dst_index + 0));\n"
"		uchar4 data_1 = *((__global uchar4 *)(dst + dst_index + 4));\n"
"		uchar4 data_2 = *((__global uchar4 *)(dst + dst_index + 8));\n"
"		\n"
"		int4 tmp_0 = convert_int4_sat(src1_data_0) - src2_data_0;\n"
"		int4 tmp_1 = convert_int4_sat(src1_data_1) - src2_data_1;\n"
"		int4 tmp_2 = convert_int4_sat(src1_data_2) - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		uchar4 tmp_data_0 = convert_uchar4_sat(tmp_0);\n"
"		uchar4 tmp_data_1 = convert_uchar4_sat(tmp_1);\n"
"		uchar4 tmp_data_2 = convert_uchar4_sat(tmp_2);\n"
"		\n"
"		data_0.xyz = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xyz : data_0.xyz;\n"
"		data_0.w   = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_0.w : data_0.w;\n"
"		             \n"
"		data_1.xy  = ((mask_data.y) && (dst_index + 3 >= dst_start) && (dst_index + 3 < dst_end))\n"
"		             ? tmp_data_1.xy : data_1.xy;\n"
"		data_1.zw  = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_1.zw : data_1.zw;\n"
"		             \n"
"		data_2.x   = ((mask_data.z) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		             ? tmp_data_2.x : data_2.x;\n"
"		data_2.yzw = ((mask_data.w) && (dst_index + 9 >= dst_start) && (dst_index + 9 < dst_end))\n"
"		             ? tmp_data_2.yzw : data_2.yzw;\n"
"		             \n"
"		*((__global uchar4 *)(dst + dst_index + 0)) = data_0;\n"
"		*((__global uchar4 *)(dst + dst_index + 4)) = data_1;\n"
"		*((__global uchar4 *)(dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C3_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		ushort2 src1_data_0 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 0));\n"
"		ushort2 src1_data_1 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 4));\n"
"		ushort2 src1_data_2 = vload2(0, (__global ushort *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		ushort2 data_0 = *((__global ushort2 *)((__global char *)dst + dst_index + 0));\n"
"		ushort2 data_1 = *((__global ushort2 *)((__global char *)dst + dst_index + 4));\n"
"		ushort2 data_2 = *((__global ushort2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int2 tmp_0 = convert_int2_sat(src1_data_0) - src2_data_0;\n"
"		int2 tmp_1 = convert_int2_sat(src1_data_1) - src2_data_1;\n"
"		int2 tmp_2 = convert_int2_sat(src1_data_2) - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		ushort2 tmp_data_0 = convert_ushort2_sat(tmp_0);\n"
"		ushort2 tmp_data_1 = convert_ushort2_sat(tmp_1);\n"
"		ushort2 tmp_data_2 = convert_ushort2_sat(tmp_2);\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global ushort2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C3_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align (((dst_offset % dst_step) / 6 ) & 1)\n"
"		int src1_index = mad24(y, src1_step, (x * 6) + src1_offset - (dst_align * 6));\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 6) - (dst_align * 6));\n"
"		\n"
"		short2 src1_data_0 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 0));\n"
"		short2 src1_data_1 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 4));\n"
"		short2 src1_data_2 = vload2(0, (__global short *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int2 src2_data_0 = (int2)(*(src2 + 0), *(src2 + 1));\n"
"		int2 src2_data_1 = (int2)(*(src2 + 2), *(src2 + 0));\n"
"		int2 src2_data_2 = (int2)(*(src2 + 1), *(src2 + 2));\n"
"		\n"
"		uchar2 mask_data = vload2(0, mask + mask_index);\n"
"		\n"
"		short2 data_0 = *((__global short2 *)((__global char *)dst + dst_index + 0));\n"
"		short2 data_1 = *((__global short2 *)((__global char *)dst + dst_index + 4));\n"
"		short2 data_2 = *((__global short2 *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		int2 tmp_0 = convert_int2_sat(src1_data_0) - src2_data_0;\n"
"		int2 tmp_1 = convert_int2_sat(src1_data_1) - src2_data_1;\n"
"		int2 tmp_2 = convert_int2_sat(src1_data_2) - src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		short2 tmp_data_0 = convert_short2_sat(tmp_0);\n"
"		short2 tmp_data_1 = convert_short2_sat(tmp_1);\n"
"		short2 tmp_data_2 = convert_short2_sat(tmp_2);\n"
"		\n"
"		data_0.xy = ((mask_data.x) && (dst_index + 0 >= dst_start)) ? tmp_data_0.xy : data_0.xy;\n"
"		\n"
"		data_1.x  = ((mask_data.x) && (dst_index + 0 >= dst_start) && (dst_index + 0 < dst_end))\n"
"		            ? tmp_data_1.x : data_1.x;\n"
"		data_1.y  = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_1.y : data_1.y;\n"
"		            \n"
"		data_2.xy = ((mask_data.y) && (dst_index + 6 >= dst_start) && (dst_index + 6 < dst_end))\n"
"		            ? tmp_data_2.xy : data_2.xy;\n"
"		            \n"
"		*((__global short2 *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global short2 *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C3_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		int src1_data_0 = *((__global int *)((__global char *)src1 + src1_index + 0));\n"
"		int src1_data_1 = *((__global int *)((__global char *)src1 + src1_index + 4));\n"
"		int src1_data_2 = *((__global int *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		int src2_data_0 = *src2;\n"
"		int src2_data_1 = *(src2 + 1);\n"
"		int src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		int data_0 = *((__global int *)((__global char *)dst + dst_index + 0));\n"
"		int data_1 = *((__global int *)((__global char *)dst + dst_index + 4));\n"
"		int data_2 = *((__global int *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		long tmp_0 = (long)src1_data_0 - (long)src2_data_0;\n"
"		long tmp_1 = (long)src1_data_1 - (long)src2_data_1;\n"
"		long tmp_2 = (long)src1_data_2 - (long)src2_data_2;\n"
"		\n"
"		tmp_0 = isMatSubScalar ? tmp_0 : -tmp_0;\n"
"		tmp_1 = isMatSubScalar ? tmp_1 : -tmp_1;\n"
"		tmp_2 = isMatSubScalar ? tmp_2 : -tmp_2;\n"
"		\n"
"		int tmp_data_0 = convert_int_sat(tmp_0);\n"
"		int tmp_data_1 = convert_int_sat(tmp_1);\n"
"		int tmp_data_2 = convert_int_sat(tmp_2);\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global int *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global int *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global int *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C3_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 12) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 12));\n"
"		\n"
"		float src1_data_0 = *((__global float *)((__global char *)src1 + src1_index + 0));\n"
"		float src1_data_1 = *((__global float *)((__global char *)src1 + src1_index + 4));\n"
"		float src1_data_2 = *((__global float *)((__global char *)src1 + src1_index + 8));\n"
"		\n"
"		float src2_data_0 = *src2;\n"
"		float src2_data_1 = *(src2 + 1);\n"
"		float src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		float data_0 = *((__global float *)((__global char *)dst + dst_index + 0));\n"
"		float data_1 = *((__global float *)((__global char *)dst + dst_index + 4));\n"
"		float data_2 = *((__global float *)((__global char *)dst + dst_index + 8));\n"
"		\n"
"		float tmp_data_0 = src1_data_0 - src2_data_0;\n"
"		float tmp_data_1 = src1_data_1 - src2_data_1;\n"
"		float tmp_data_2 = src1_data_2 - src2_data_2;\n"
"		\n"
"		tmp_data_0 = isMatSubScalar ? tmp_data_0 : -tmp_data_0;\n"
"		tmp_data_1 = isMatSubScalar ? tmp_data_1 : -tmp_data_1;\n"
"		tmp_data_2 = isMatSubScalar ? tmp_data_2 : -tmp_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global float *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global float *)((__global char *)dst + dst_index + 4)) = data_1;\n"
"		*((__global float *)((__global char *)dst + dst_index + 8)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C3_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar  *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x * 24) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step, x + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x * 24));\n"
"		\n"
"		double src1_data_0 = *((__global double *)((__global char *)src1 + src1_index + 0));\n"
"		double src1_data_1 = *((__global double *)((__global char *)src1 + src1_index + 8));\n"
"		double src1_data_2 = *((__global double *)((__global char *)src1 + src1_index + 16));\n"
"		\n"
"		double src2_data_0 = *src2;\n"
"		double src2_data_1 = *(src2 + 1);\n"
"		double src2_data_2 = *(src2 + 2);\n"
"		\n"
"		uchar mask_data = * (mask + mask_index);\n"
"		\n"
"		double data_0 = *((__global double *)((__global char *)dst + dst_index + 0));\n"
"		double data_1 = *((__global double *)((__global char *)dst + dst_index + 8));\n"
"		double data_2 = *((__global double *)((__global char *)dst + dst_index + 16));\n"
"		\n"
"		double tmp_data_0 = src1_data_0 - src2_data_0;\n"
"		double tmp_data_1 = src1_data_1 - src2_data_1;\n"
"		double tmp_data_2 = src1_data_2 - src2_data_2;\n"
"		\n"
"		tmp_data_0 = isMatSubScalar ? tmp_data_0 : -tmp_data_0;\n"
"		tmp_data_1 = isMatSubScalar ? tmp_data_1 : -tmp_data_1;\n"
"		tmp_data_2 = isMatSubScalar ? tmp_data_2 : -tmp_data_2;\n"
"		\n"
"		data_0 = mask_data ? tmp_data_0 : data_0;\n"
"		data_1 = mask_data ? tmp_data_1 : data_1;\n"
"		data_2 = mask_data ? tmp_data_2 : data_2;\n"
"		\n"
"		*((__global double *)((__global char *)dst + dst_index + 0)) = data_0;\n"
"		*((__global double *)((__global char *)dst + dst_index + 8)) = data_1;\n"
"		*((__global double *)((__global char *)dst + dst_index + 16)) = data_2;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C4_D0(__global   uchar *src1, int src1_step, int src1_offset,\n"
"        __global   uchar *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 2) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 2) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		uchar4 src_data1 = *((__global uchar4 *)(src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dst  + dst_index));\n"
"		\n"
"		int4 tmp = convert_int4_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		uchar4 data = convert_uchar4_sat(tmp);\n"
"		\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global uchar4 *)(dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C4_D2(__global   ushort *src1, int src1_step, int src1_offset,\n"
"        __global   ushort *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		ushort4 dst_data  = *((__global ushort4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4    tmp = convert_int4_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		ushort4 data = convert_ushort4_sat(tmp);\n"
"		\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global ushort4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C4_D3(__global   short *src1, int src1_step, int src1_offset,\n"
"        __global   short *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 3) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 3) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		short4 dst_data  = *((__global short4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		int4    tmp = convert_int4_sat(src_data1) - src_data2;\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		short4 data = convert_short4_sat(tmp);\n"
"		\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global short4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C4_D4(__global   int *src1, int src1_step, int src1_offset,\n"
"        __global   int *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant int *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		int4 src_data1 = *((__global int4 *)((__global char *)src1 + src1_index));\n"
"		int4 src_data2 = *((__constant int4 *)src2);\n"
"		int4 dst_data  = *((__global int4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		long4 tmp = convert_long4_sat(src_data1) - convert_long4_sat(src_data2);\n"
"		tmp = isMatSubScalar ? tmp : -tmp;\n"
"		int4 data = convert_int4_sat(tmp);\n"
"		\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global int4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C4_D5(__global   float *src1, int src1_step, int src1_offset,\n"
"        __global   float *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant float *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 4) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 4) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		float4 src_data1 = *((__global float4 *)((__global char *)src1 + src1_index));\n"
"		float4 src_data2 = *((__constant float4 *)src2);\n"
"		float4 dst_data  = *((__global float4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		float4 data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
"__kernel void arithm_s_sub_with_mask_C4_D6(__global   double *src1, int src1_step, int src1_offset,\n"
"        __global   double *dst,  int dst_step,  int dst_offset,\n"
"        __global   uchar *mask, int mask_step, int mask_offset,\n"
"        __constant double *src2 __attribute__((max_constant_size(16384))),\n"
"        int rows, int cols, int dst_step1, int isMatSubScalar)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int src1_index = mad24(y, src1_step, (x << 5) + src1_offset);\n"
"		int mask_index = mad24(y, mask_step,  x       + mask_offset);\n"
"		int dst_index  = mad24(y, dst_step, (x << 5) + dst_offset);\n"
"		\n"
"		uchar mask_data = *(mask + mask_index);\n"
"		\n"
"		double4 src_data1 = *((__global double4 *)((__global char *)src1 + src1_index));\n"
"		double4 src_data2 = *((__constant double4 *)src2);\n"
"		double4 dst_data  = *((__global double4 *)((__global char *)dst  + dst_index));\n"
"		\n"
"		double4 data = src_data1 - src_data2;\n"
"		data = isMatSubScalar ? data : -data;\n"
"		data = mask_data ? data : dst_data;\n"
"		\n"
"		*((__global double4 *)((__global char *)dst + dst_index)) = data;\n"
"	}\n"
"}\n"
;
const char *arithm_sum =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define VEC_TYPE uchar8\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define VEC_TYPE char8\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define VEC_TYPE ushort8\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define VEC_TYPE short8\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define VEC_TYPE int8\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define VEC_TYPE float8\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define VEC_TYPE double8\n"
"#endif\n"
"#if defined (FUNC_TYPE_0)\n"
"#define FUNC(a,b) b += a;\n"
"#endif\n"
"#if defined (FUNC_TYPE_1)\n"
"#define FUNC(a,b) b = b + (a >= 0 ? a : -a);\n"
"#endif\n"
"#if defined (FUNC_TYPE_2)\n"
"#define FUNC(a,b) b = b + a * a;\n"
"#endif\n"
"#if defined (REPEAT_S0)\n"
"#define repeat_s(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_S1)\n"
"#define repeat_s(a) a.s0 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S2)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S3)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S4)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S5)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S6)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_S7)\n"
"#define repeat_s(a) a.s0 = 0;a.s1 = 0;a.s2 = 0;a.s3 = 0;a.s4 = 0;a.s5 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_e(a) a = a;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_e(a) a.s7 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_e(a) a.s7 = 0;a.s6 = 0;a.s5 = 0;a.s4 = 0;a.s3 = 0;a.s2 = 0;a.s1 = 0;\n"
"#endif\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics:enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics:enable\n"
"/**************************************Array buffer SUM**************************************/\n"
"__kernel void arithm_op_sum(int cols, int invalid_cols, int offset, int elemnum, int groupnum,\n"
"                            __global VEC_TYPE *src, __global double8 *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int  id = get_global_id(0);\n"
"	unsigned int idx = offset + id + (id / cols) * invalid_cols;\n"
"	__local double8 localmem_sum[128];\n"
"	double8 sum = 0, temp;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp = convert_double8(src[idx]);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"		}\n"
"		\n"
"		FUNC(temp, sum);\n"
"	}\n"
"	else\n"
"	{\n"
"		sum = 0;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = offset + id + (id / cols) * invalid_cols;\n"
"		temp = convert_double8(src[idx]);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp);\n"
"		}\n"
"		\n"
"		FUNC(temp, sum);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_sum[lid - 128] = sum;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_sum[lid] = sum + localmem_sum[lid];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_sum[lid] = localmem_sum[lid] + localmem_sum[lid2];\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid] = localmem_sum[0];\n"
"	}\n"
"}\n"
;
const char *arithm_sum_3 =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define VEC_TYPE uchar4\n"
"#endif\n"
"#if defined (DEPTH_1)\n"
"#define VEC_TYPE char4\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define VEC_TYPE ushort4\n"
"#endif\n"
"#if defined (DEPTH_3)\n"
"#define VEC_TYPE short4\n"
"#endif\n"
"#if defined (DEPTH_4)\n"
"#define VEC_TYPE int4\n"
"#endif\n"
"#if defined (DEPTH_5)\n"
"#define VEC_TYPE float4\n"
"#endif\n"
"#if defined (DEPTH_6)\n"
"#define VEC_TYPE double4\n"
"#endif\n"
"#if defined (FUNC_TYPE_0)\n"
"#define FUNC(a,b) b += a;\n"
"#endif\n"
"#if defined (FUNC_TYPE_1)\n"
"#define FUNC(a,b) b = b + (a >= 0 ? a : -a);\n"
"#endif\n"
"#if defined (FUNC_TYPE_2)\n"
"#define FUNC(a,b) b = b + a * a;\n"
"#endif\n"
"#if defined (REPEAT_S0)\n"
"#define repeat_s(a,b,c) a=a; b =b; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S1)\n"
"#define repeat_s(a,b,c) a.s0=0; b=b; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S2)\n"
"#define repeat_s(a,b,c) a.s0=0; a.s1=0; b=b; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S3)\n"
"#define repeat_s(a,b,c) a.s0=0; a.s1=0; a.s2=0; b=b; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S4)\n"
"#define repeat_s(a,b,c) a=0;b=b; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S5)\n"
"#define repeat_s(a,b,c) a=0; b.s0=0;c=c;\n"
"#endif\n"
"#if defined (REPEAT_S6)\n"
"#define repeat_s(a,b,c) a=0; b.s0=0; b.s1=0; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S7)\n"
"#define repeat_s(a,b,c) a=0; b.s0=0; b.s1=0; b.s2=0; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S8)\n"
"#define repeat_s(a,b,c) a=0; b=0; c=c;\n"
"#endif\n"
"#if defined (REPEAT_S9)\n"
"#define repeat_s(a,b,c) a=0; b=0; c.s0=0;\n"
"#endif\n"
"#if defined (REPEAT_S10)\n"
"#define repeat_s(a,b,c) a=0; b=0; c.s0=0; c.s1=0;\n"
"#endif\n"
"#if defined (REPEAT_S11)\n"
"#define repeat_s(a,b,c) a=0; b=0; c.s0=0; c.s1=0; c.s2=0;\n"
"#endif\n"
"#if defined (REPEAT_E0)\n"
"#define repeat_e(a,b,c) a=a; b =b; c=c;\n"
"#endif\n"
"#if defined (REPEAT_E1)\n"
"#define repeat_e(a,b,c) a=a; b=b; c.s3=0;\n"
"#endif\n"
"#if defined (REPEAT_E2)\n"
"#define repeat_e(a,b,c) a=a; b=b; c.s3=0; c.s2=0;\n"
"#endif\n"
"#if defined (REPEAT_E3)\n"
"#define repeat_e(a,b,c) a=a; b=b; c.s3=0; c.s2=0; c.s1=0;\n"
"#endif\n"
"#if defined (REPEAT_E4)\n"
"#define repeat_e(a,b,c) a=a; b=b; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E5)\n"
"#define repeat_e(a,b,c) a=a; b.s3=0; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E6)\n"
"#define repeat_e(a,b,c) a=a; b.s3=0; b.s2=0; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E7)\n"
"#define repeat_e(a,b,c) a=a; b.s3=0; b.s2=0; b.s1=0; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E8)\n"
"#define repeat_e(a,b,c) a=a; b=0; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E9)\n"
"#define repeat_e(a,b,c) a.s3=0; b=0; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E10)\n"
"#define repeat_e(a,b,c) a.s3=0; a.s2=0; b=0; c=0;\n"
"#endif\n"
"#if defined (REPEAT_E11)\n"
"#define repeat_e(a,b,c) a.s3=0; a.s2=0; a.s1=0; b=0; c=0;\n"
"#endif\n"
"__kernel void arithm_op_sum_3(int cols, int invalid_cols, int offset, int elemnum, int groupnum,\n"
"                              __global VEC_TYPE *src, __global double4 *dst)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	unsigned int id = get_global_id(0);\n"
"	unsigned int idx = offset + id + (id  / cols) * invalid_cols;\n"
"	idx = idx * 3;\n"
"	__local double4 localmem_sum1[128];\n"
"	__local double4 localmem_sum2[128];\n"
"	__local double4 localmem_sum3[128];\n"
"	double4 sum1 = 0, sum2 = 0, sum3 = 0, temp1, temp2, temp3;\n"
"	\n"
"	if (id < elemnum)\n"
"	{\n"
"		temp1 = convert_double4(src[idx]);\n"
"		temp2 = convert_double4(src[idx + 1]);\n"
"		temp3 = convert_double4(src[idx + 2]);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp1, temp2, temp3);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp1, temp2, temp3);\n"
"		}\n"
"		\n"
"		FUNC(temp1, sum1);\n"
"		FUNC(temp2, sum2);\n"
"		FUNC(temp3, sum3);\n"
"	}\n"
"	else\n"
"	{\n"
"		sum1 = 0;\n"
"		sum2 = 0;\n"
"		sum3 = 0;\n"
"	}\n"
"	\n"
"	for (id = id + (groupnum << 8); id < elemnum; id = id + (groupnum << 8))\n"
"	{\n"
"		idx = offset + id + (id / cols) * invalid_cols;\n"
"		idx = idx * 3;\n"
"		temp1 = convert_double4(src[idx]);\n"
"		temp2 = convert_double4(src[idx + 1]);\n"
"		temp3 = convert_double4(src[idx + 2]);\n"
"		\n"
"		if (id % cols == 0)\n"
"		{\n"
"			repeat_s(temp1, temp2, temp3);\n"
"		}\n"
"		\n"
"		if (id % cols == cols - 1)\n"
"		{\n"
"			repeat_e(temp1, temp2, temp3);\n"
"		}\n"
"		\n"
"		FUNC(temp1, sum1);\n"
"		FUNC(temp2, sum2);\n"
"		FUNC(temp3, sum3);\n"
"	}\n"
"	\n"
"	if (lid > 127)\n"
"	{\n"
"		localmem_sum1[lid - 128] = sum1;\n"
"		localmem_sum2[lid - 128] = sum2;\n"
"		localmem_sum3[lid - 128] = sum3;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid < 128)\n"
"	{\n"
"		localmem_sum1[lid] = sum1 + localmem_sum1[lid];\n"
"		localmem_sum2[lid] = sum2 + localmem_sum2[lid];\n"
"		localmem_sum3[lid] = sum3 + localmem_sum3[lid];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int lsize = 64; lsize > 0; lsize >>= 1)\n"
"	{\n"
"		if (lid < lsize)\n"
"		{\n"
"			int lid2 = lsize + lid;\n"
"			localmem_sum1[lid] = localmem_sum1[lid] + localmem_sum1[lid2];\n"
"			localmem_sum2[lid] = localmem_sum2[lid] + localmem_sum2[lid2];\n"
"			localmem_sum3[lid] = localmem_sum3[lid] + localmem_sum3[lid2];\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		dst[gid * 3]   = localmem_sum1[0];\n"
"		dst[gid * 3 + 1] = localmem_sum2[0];\n"
"		dst[gid * 3 + 2] = localmem_sum3[0];\n"
"	}\n"
"}\n"
;
const char *arithm_transpose =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#define TILE_DIM      32\n"
"#define BLOCK_ROWS    8\n"
"#define LDS_STEP     (TILE_DIM + 1)\n"
"//8UC1 is not unoptimized, as the size of write per thread is 8\n"
"//which will use completepath\n"
"__kernel void transpose_C1_D0(__global uchar *src, int src_step, int src_offset,\n"
"                              __global uchar *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local uchar title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, x);\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *(src + src_offset + index_src);\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, x_index);\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*(dst + dst_offset + index_dst) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void transpose_C1_D4(__global int *src, int src_step, int src_offset,\n"
"                              __global int *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local int title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, (x << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *((__global int *)((__global char *)src + src_offset + index_src));\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, (x_index << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*((__global int *)((__global char *)dst + dst_offset + index_dst)) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void transpose_C1_D5(__global float *src, int src_step, int src_offset,\n"
"                              __global float *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local float title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, (x << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *((__global float *)((__global char *)src + src_offset + index_src));\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, (x_index << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*((__global float *)((__global char *)dst + dst_offset + index_dst)) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void transpose_C2_D2(__global ushort *src, int src_step, int src_offset,\n"
"                              __global ushort *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local ushort2 title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, (x << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *((__global ushort2 *)((__global char *)src + src_offset + index_src));\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, (x_index << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*((__global ushort2 *)((__global char *)dst + dst_offset + index_dst)) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void transpose_C2_D3(__global short *src, int src_step, int src_offset,\n"
"                              __global short *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local short2 title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, (x << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *((__global short2 *)((__global char *)src + src_offset + index_src));\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, (x_index << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*((__global short2 *)((__global char *)dst + dst_offset + index_dst)) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void transpose_C4_D0(__global uchar *src, int src_step, int src_offset,\n"
"                              __global uchar *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local uchar4 title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, (x << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *((__global uchar4 *)(src + src_offset + index_src));\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, (x_index << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*((__global uchar4 *)(dst + dst_offset + index_dst)) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void transpose_C4_D1(__global char *src, int src_step, int src_offset,\n"
"                              __global char *dst, int dst_step, int dst_offset,\n"
"                              int src_rows, int src_cols)\n"
"{\n"
"	int gp_x = get_group_id(0),   gp_y = get_group_id(1);\n"
"	int gs_x = get_num_groups(0), gs_y = get_num_groups(1);\n"
"	\n"
"	int groupId_x, groupId_y;\n"
"	\n"
"	if (src_rows == src_cols)\n"
"	{\n"
"		groupId_y = gp_x;\n"
"		groupId_x = (gp_x + gp_y) % gs_x;\n"
"	}\n"
"	else\n"
"	{\n"
"		int bid = gp_x + gs_x * gp_y;\n"
"		groupId_y =  bid % gs_y;\n"
"		groupId_x = ((bid / gs_y) + groupId_y) % gs_x;\n"
"	}\n"
"	\n"
"	int lx = get_local_id(0);\n"
"	int ly = get_local_id(1);\n"
"	\n"
"	int x = groupId_x * TILE_DIM + lx;\n"
"	int y = groupId_y * TILE_DIM + ly;\n"
"	\n"
"	int x_index = groupId_y * TILE_DIM + lx;\n"
"	int y_index = groupId_x * TILE_DIM + ly;\n"
"	\n"
"	__local char4 title[TILE_DIM * LDS_STEP];\n"
"	\n"
"	if (x < src_cols && y < src_rows)\n"
"	{\n"
"		int index_src = mad24(y, src_step, (x << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if (y + i < src_rows)\n"
"			{\n"
"				title[(ly + i) * LDS_STEP + lx] = *((__global char4 *)(src + src_offset + index_src));\n"
"				index_src = mad24(BLOCK_ROWS, src_step, index_src);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x_index < src_rows && y_index < src_cols)\n"
"	{\n"
"		int index_dst = mad24(y_index, dst_step, (x_index << 2));\n"
"		\n"
"#pragma unroll\n"
"		\n"
"		for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS)\n"
"		{\n"
"			if ((y_index + i) < src_cols)\n"
"			{\n"
"				*((__global char4 *)(dst + dst_offset + index_dst)) = title[lx * LDS_STEP + ly + i];\n"
"				index_dst +=  dst_step * BLOCK_ROWS ;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
;
const char *convertC3C4 =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zero Lin, zero.lin@amd.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"__kernel void convertC3C4_D0(__global const char4 *restrict src, __global char4 *dst, int cols, int rows,\n"
"                             int srcStep, int dstStep)\n"
"{\n"
"	int id = get_global_id(0);\n"
"	int y = id / cols;\n"
"	int x = id % cols;\n"
"	\n"
"	int d = y * srcStep + x * 3;\n"
"	char8 data = (char8)(src[d >> 2], src[(d >> 2) + 1]);\n"
"	char temp[8] = {data.s0, data.s1, data.s2, data.s3, data.s4, data.s5, data.s6, data.s7};\n"
"	\n"
"	int start = d & 3;\n"
"	char4 ndata = (char4)(temp[start], temp[start + 1], temp[start + 2], 0);\n"
"	\n"
"	if (y < rows)\n"
"	{\n"
"		dst[y * dstStep + x] = ndata;\n"
"	}\n"
"}\n"
"__kernel void convertC3C4_D1(__global const short *restrict src, __global short4 *dst, int cols, int rows,\n"
"                             int srcStep, int dstStep)\n"
"{\n"
"	int id = get_global_id(0);\n"
"	int y = id / cols;\n"
"	int x = id % cols;\n"
"	\n"
"	int d = (y * srcStep + x * 6) >> 1;\n"
"	short4 data = *(__global short4 *)(src + ((d >> 1) << 1));\n"
"	short temp[4] = {data.s0, data.s1, data.s2, data.s3};\n"
"	\n"
"	int start = d & 1;\n"
"	short4 ndata = (short4)(temp[start], temp[start + 1], temp[start + 2], 0);\n"
"	\n"
"	if (y < rows)\n"
"	{\n"
"		dst[y * dstStep + x] = ndata;\n"
"	}\n"
"}\n"
"__kernel void convertC3C4_D2(__global const int *restrict src, __global int4 *dst, int cols, int rows,\n"
"                             int srcStep, int dstStep)\n"
"{\n"
"	int id = get_global_id(0);\n"
"	int y = id / cols;\n"
"	int x = id % cols;\n"
"	\n"
"	int d = (y * srcStep + x * 12) >> 2;\n"
"	int4 data = *(__global int4 *)(src + d);\n"
"	data.z = 0;\n"
"	\n"
"	if (y < rows)\n"
"	{\n"
"		dst[y * dstStep + x] = data;\n"
"	}\n"
"}\n"
"__kernel void convertC4C3_D2(__global const int4 *restrict src, __global int *dst, int cols, int rows,\n"
"                             int srcStep, int dstStep)\n"
"{\n"
"	int id = get_global_id(0);\n"
"	int y = id / cols;\n"
"	int x = id % cols;\n"
"	\n"
"	int4 data = src[y * srcStep + x];\n"
"	\n"
"	if (y < rows)\n"
"	{\n"
"		int d = y * dstStep + x * 3;\n"
"		dst[d] = data.x;\n"
"		dst[d + 1] = data.y;\n"
"		dst[d + 2] = data.z;\n"
"	}\n"
"}\n"
"__kernel void convertC4C3_D1(__global const short4 *restrict src, __global short *dst, int cols, int rows,\n"
"                             int srcStep, int dstStep)\n"
"{\n"
"	int id = get_global_id(0);\n"
"	int y = id / cols;\n"
"	int x = id % cols;\n"
"	\n"
"	short4 data = src[y * srcStep + x];\n"
"	\n"
"	if (y < rows)\n"
"	{\n"
"		int d = y * dstStep + x * 3;\n"
"		dst[d] = data.x;\n"
"		dst[d + 1] = data.y;\n"
"		dst[d + 2] = data.z;\n"
"	}\n"
"}\n"
"__kernel void convertC4C3_D0(__global const char4 *restrict src, __global char *dst, int cols, int rows,\n"
"                             int srcStep, int dstStep)\n"
"{\n"
"	int id = get_global_id(0);\n"
"	int y = id / cols;\n"
"	int x = id % cols;\n"
"	\n"
"	char4 data = src[y * srcStep + x];\n"
"	\n"
"	if (y < rows)\n"
"	{\n"
"		int d = y * dstStep + x * 3;\n"
"		dst[d] = data.x;\n"
"		dst[d + 1] = data.y;\n"
"		dst[d + 2] = data.z;\n"
"	}\n"
"}\n"
;
const char *cvt_color =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"/**************************************PUBLICFUNC*************************************/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#if defined (DEPTH_0)\n"
"#define DATA_TYPE uchar\n"
"#endif\n"
"#if defined (DEPTH_2)\n"
"#define DATA_TYPE ushort\n"
"#endif\n"
"#define CV_DESCALE(x,n) (((x) + (1 << ((n)-1))) >> (n))\n"
"enum\n"
"{\n"
"	yuv_shift  = 14,\n"
"	xyz_shift  = 12,\n"
"	R2Y        = 4899,\n"
"	G2Y        = 9617,\n"
"	B2Y        = 1868,\n"
"	BLOCK_SIZE = 256\n"
"};\n"
"__kernel void RGB2Gray(int cols, int rows, int src_step, int dst_step, int channels,\n"
"                       int bidx, __global const DATA_TYPE *src, __global DATA_TYPE *dst)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);\n"
"	\n"
"	if (y < rows && x < cols)\n"
"	{\n"
"		int src_idx = y * src_step + x * channels * sizeof(DATA_TYPE);\n"
"		int dst_idx = y * dst_step + x * sizeof(DATA_TYPE);\n"
"		dst[dst_idx] = (DATA_TYPE)CV_DESCALE((src[src_idx + bidx] * B2Y + src[src_idx + 1] * G2Y + src[src_idx + (bidx ^ 2)] * R2Y), yuv_shift);\n"
"	}\n"
"}\n"
;
const char *filtering_boxFilter =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zhang Ying, zhangying913@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////Macro for border type////////////////////////////////////////////\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#ifdef BORDER_REPLICATE\n"
"//BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (l_edge)   : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (r_edge)-1 : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (t_edge)   :(i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (b_edge)-1 :(addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT\n"
"//BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)-1               : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-1+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)-1 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-1+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT_101\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)                 : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-2+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)                 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-2+((b_edge)<<1) : (addr))\n"
"#endif\n"
"//blur function does not support BORDER_WRAP\n"
"#ifdef BORDER_WRAP\n"
"//BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (i)+(r_edge) : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (i)-(r_edge) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (i)+(b_edge) : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (i)-(b_edge) : (addr))\n"
"#endif\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////8uC1////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#define THREADS 256\n"
"#define ELEM(i, l_edge, r_edge, elem1, elem2) (i) >= (l_edge) && (i) < (r_edge) ? (elem1) : (elem2)\n"
"__kernel void boxFilter_C1_D0(__global const uchar *restrict src, __global uchar *dst, float alpha,\n"
"                              int src_offset, int src_whole_rows, int src_whole_cols, int src_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step\n"
"                             )\n"
"{\n"
"	int col = get_local_id(0);\n"
"	const int gX = get_group_id(0);\n"
"	const int gY = get_group_id(1);\n"
"	int src_x_off = src_offset % src_step;\n"
"	int src_y_off = src_offset / src_step;\n"
"	int dst_x_off = dst_offset % dst_step;\n"
"	int dst_y_off = dst_offset / dst_step;\n"
"	\n"
"	int head_off = dst_x_off % 4;\n"
"	int startX = ((gX * (THREADS - ksX + 1) - anX) * 4) - head_off + src_x_off;\n"
"	int startY = (gY << 1) - anY + src_y_off;\n"
"	int dst_startX = (gX * (THREADS - ksX + 1) * 4) - head_off + dst_x_off;\n"
"	int dst_startY = (gY << 1) + dst_y_off;\n"
"	\n"
"	uint4 data[ksY + 1];\n"
"	__local uint4 temp[(THREADS << 1)];\n"
"	\n"
"#ifdef BORDER_CONSTANT\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		if (startY + i >= 0 && startY + i < src_whole_rows && startX + col * 4 >= 0 && startX + col * 4 + 3 < src_whole_cols)\n"
"		{\n"
"			data[i] = convert_uint4(vload4(col, (__global uchar *)(src + (startY + i) * src_step + startX)));\n"
"		}\n"
"		else\n"
"		{\n"
"			data[i] = 0;\n"
"			int con = startY + i >= 0 && startY + i < src_whole_rows && startX + col * 4 >= 0 && startX + col * 4 < src_whole_cols;\n"
"			\n"
"			if (con)\n"
"			{\n"
"				data[i].s0 = *(src + (startY + i) * src_step + startX + col * 4);\n"
"			}\n"
"			\n"
"			con = startY + i >= 0 && startY + i < src_whole_rows && startX + col * 4 + 1 >= 0 && startX + col * 4 + 1 < src_whole_cols;\n"
"			\n"
"			if (con)\n"
"			{\n"
"				data[i].s1 = *(src + (startY + i) * src_step + startX + col * 4 + 1) ;\n"
"			}\n"
"			\n"
"			con = startY + i >= 0 && startY + i < src_whole_rows && startX + col * 4 + 2 >= 0 && startX + col * 4 + 2 < src_whole_cols;\n"
"			\n"
"			if (con)\n"
"			{\n"
"				data[i].s2 = *(src + (startY + i) * src_step + startX + col * 4 + 2);\n"
"			}\n"
"			\n"
"			con = startY + i >= 0 && startY + i < src_whole_rows && startX + col * 4 + 3 >= 0 && startX + col * 4 + 3 < src_whole_cols;\n"
"			\n"
"			if (con)\n"
"			{\n"
"				data[i].s3 = *(src + (startY + i) * src_step + startX + col * 4 + 3);\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"#else\n"
"	int not_all_in_range;\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		not_all_in_range = (startX + col * 4 < 0) | (startX + col * 4 + 3 > src_whole_cols - 1)\n"
"		                   | (startY + i < 0) | (startY + i > src_whole_rows - 1);\n"
"	\n"
"		if (not_all_in_range)\n"
"		{\n"
"			int selected_row;\n"
"			int4 selected_col;\n"
"			selected_row = ADDR_H(startY + i, 0, src_whole_rows);\n"
"			selected_row = ADDR_B(startY + i, src_whole_rows, selected_row);\n"
"	\n"
"			selected_col.x = ADDR_L(startX + col * 4, 0, src_whole_cols);\n"
"			selected_col.x = ADDR_R(startX + col * 4, src_whole_cols, selected_col.x);\n"
"	\n"
"			selected_col.y = ADDR_L(startX + col * 4 + 1, 0, src_whole_cols);\n"
"			selected_col.y = ADDR_R(startX + col * 4 + 1, src_whole_cols, selected_col.y);\n"
"	\n"
"			selected_col.z = ADDR_L(startX + col * 4 + 2, 0, src_whole_cols);\n"
"			selected_col.z = ADDR_R(startX + col * 4 + 2, src_whole_cols, selected_col.z);\n"
"	\n"
"			selected_col.w = ADDR_L(startX + col * 4 + 3, 0, src_whole_cols);\n"
"			selected_col.w = ADDR_R(startX + col * 4 + 3, src_whole_cols, selected_col.w);\n"
"	\n"
"			data[i].x = *(src + selected_row * src_step + selected_col.x);\n"
"			data[i].y = *(src + selected_row * src_step + selected_col.y);\n"
"			data[i].z = *(src + selected_row * src_step + selected_col.z);\n"
"			data[i].w = *(src + selected_row * src_step + selected_col.w);\n"
"		}\n"
"		else\n"
"		{\n"
"			data[i] =  convert_uint4(vload4(col, (__global uchar *)(src + (startY + i) * src_step + startX)));\n"
"		}\n"
"	}\n"
"	\n"
"#endif\n"
"	uint4 sum0 = 0, sum1 = 0, sum2 = 0;\n"
"	\n"
"	for (int i = 1; i < ksY; i++)\n"
"	{\n"
"		sum0 += (data[i]);\n"
"	}\n"
"	\n"
"	sum1 = sum0 + (data[0]);\n"
"	sum2 = sum0 + (data[ksY]);\n"
"	\n"
"	temp[col] = sum1;\n"
"	temp[col + THREADS] = sum2;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (col >= anX && col < (THREADS - ksX + anX + 1))\n"
"	{\n"
"		int posX = dst_startX - dst_x_off + (col - anX) * 4;\n"
"		int posY = (gY << 1);\n"
"		uint4 tmp_sum1 = 0, tmp_sum2 = 0;\n"
"		\n"
"		for (int i = -anX; i <= anX; i++)\n"
"		{\n"
"			tmp_sum1 += vload4(col, (__local uint *)temp + i);\n"
"		}\n"
"		\n"
"		for (int i = -anX; i <= anX; i++)\n"
"		{\n"
"			tmp_sum2 += vload4(col, (__local uint *)(temp + THREADS) + i);\n"
"		}\n"
"		\n"
"		if (posY < dst_rows && posX < dst_cols)\n"
"		{\n"
"			if (posX >= 0 && posX < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + (col - anX) * 4) = tmp_sum1.x / alpha;\n"
"			}\n"
"			\n"
"			if (posX + 1 >= 0 && posX + 1 < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + 1 + (col - anX) * 4) = tmp_sum1.y / alpha;\n"
"			}\n"
"			\n"
"			if (posX + 2 >= 0 && posX + 2 < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + 2 + (col - anX) * 4) = tmp_sum1.z / alpha;\n"
"			}\n"
"			\n"
"			if (posX + 3 >= 0 && posX + 3 < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + 3 + (col - anX) * 4) = tmp_sum1.w / alpha;\n"
"			}\n"
"		}\n"
"		\n"
"		if (posY + 1 < dst_rows && posX < dst_cols)\n"
"		{\n"
"			dst_startY += 1;\n"
"			\n"
"			if (posX >= 0 && posX < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + (col - anX) * 4) = tmp_sum2.x / alpha;\n"
"			}\n"
"			\n"
"			if (posX + 1 >= 0 && posX + 1 < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + 1 + (col - anX) * 4) = tmp_sum2.y / alpha;\n"
"			}\n"
"			\n"
"			if (posX + 2 >= 0 && posX + 2 < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + 2 + (col - anX) * 4) = tmp_sum2.z / alpha;\n"
"			}\n"
"			\n"
"			if (posX + 3 >= 0 && posX + 3 < dst_cols)\n"
"			{\n"
"				*(dst + dst_startY * dst_step + dst_startX + 3 + (col - anX) * 4) = tmp_sum2.w / alpha;\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////8uC4////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void boxFilter_C4_D0(__global const uchar4 *restrict src, __global uchar4 *dst, float alpha,\n"
"                              int src_offset, int src_whole_rows, int src_whole_cols, int src_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step\n"
"                             )\n"
"{\n"
"	int col = get_local_id(0);\n"
"	const int gX = get_group_id(0);\n"
"	const int gY = get_group_id(1);\n"
"	\n"
"	int src_x_off = (src_offset % src_step) >> 2;\n"
"	int src_y_off = src_offset / src_step;\n"
"	int dst_x_off = (dst_offset % dst_step) >> 2;\n"
"	int dst_y_off = dst_offset / dst_step;\n"
"	\n"
"	int startX = gX * (THREADS - ksX + 1) - anX + src_x_off;\n"
"	int startY = (gY << 1) - anY + src_y_off;\n"
"	int dst_startX = gX * (THREADS - ksX + 1) + dst_x_off;\n"
"	int dst_startY = (gY << 1) + dst_y_off;\n"
"	\n"
"	uint4 data[ksY + 1];\n"
"	__local uint4 temp[2][THREADS];\n"
"#ifdef BORDER_CONSTANT\n"
"	bool con;\n"
"	uint4 ss;\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		con = startX + col >= 0 && startX + col < src_whole_cols && startY + i >= 0 && startY + i < src_whole_rows;\n"
"		ss = convert_uint4(src[(startY + i) * (src_step >> 2) + (startX + col)]);\n"
"		data[i] = con ? ss : 0;\n"
"	}\n"
"	\n"
"#else\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		int selected_row;\n"
"		int selected_col;\n"
"		selected_row = ADDR_H(startY + i, 0, src_whole_rows);\n"
"		selected_row = ADDR_B(startY + i, src_whole_rows, selected_row);\n"
"	\n"
"		selected_col = ADDR_L(startX + col, 0, src_whole_cols);\n"
"		selected_col = ADDR_R(startX + col, src_whole_cols, selected_col);\n"
"	\n"
"		data[i] = convert_uint4(src[selected_row * (src_step >> 2) + selected_col]);\n"
"	}\n"
"	\n"
"#endif\n"
"	uint4 sum0 = 0, sum1 = 0, sum2 = 0;\n"
"	\n"
"	for (int i = 1; i < ksY; i++)\n"
"	{\n"
"		sum0 += (data[i]);\n"
"	}\n"
"	\n"
"	sum1 = sum0 + (data[0]);\n"
"	sum2 = sum0 + (data[ksY]);\n"
"	temp[0][col] = sum1;\n"
"	temp[1][col] = sum2;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (col < (THREADS - (ksX - 1)))\n"
"	{\n"
"		col += anX;\n"
"		int posX = dst_startX - dst_x_off + col - anX;\n"
"		int posY = (gY << 1);\n"
"		\n"
"		uint4 tmp_sum[2] = {(uint4)(0, 0, 0, 0), (uint4)(0, 0, 0, 0)};\n"
"		\n"
"		for (int k = 0; k < 2; k++)\n"
"			for (int i = -anX; i <= anX; i++)\n"
"			{\n"
"				tmp_sum[k] += temp[k][col + i];\n"
"			}\n"
"			\n"
"		for (int i = 0; i < 2; i++)\n"
"		{\n"
"			if (posX < dst_cols && (posY + i) < dst_rows)\n"
"			{\n"
"				dst[(dst_startY + i) * (dst_step >> 2) + dst_startX + col - anX] = convert_uchar4(tmp_sum[i] / alpha);\n"
"			}\n"
"		}\n"
"		\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////32fC1////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void boxFilter_C1_D5(__global const float *restrict src, __global float *dst, float alpha,\n"
"                              int src_offset, int src_whole_rows, int src_whole_cols, int src_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step\n"
"                             )\n"
"{\n"
"	int col = get_local_id(0);\n"
"	const int gX = get_group_id(0);\n"
"	const int gY = get_group_id(1);\n"
"	\n"
"	int src_x_off = (src_offset % src_step) >> 2;\n"
"	int src_y_off = src_offset / src_step;\n"
"	int dst_x_off = (dst_offset % dst_step) >> 2;\n"
"	int dst_y_off = dst_offset / dst_step;\n"
"	\n"
"	int startX = gX * (THREADS - ksX + 1) - anX + src_x_off;\n"
"	int startY = (gY << 1) - anY + src_y_off;\n"
"	int dst_startX = gX * (THREADS - ksX + 1) + dst_x_off;\n"
"	int dst_startY = (gY << 1) + dst_y_off;\n"
"	\n"
"	float data[ksY + 1];\n"
"	__local float temp[2][THREADS];\n"
"#ifdef BORDER_CONSTANT\n"
"	bool con;\n"
"	float ss;\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		con = startX + col >= 0 && startX + col < src_whole_cols && startY + i >= 0 && startY + i < src_whole_rows;\n"
"		ss = src[(startY + i) * (src_step >> 2) + (startX + col)];\n"
"		data[i] = con ? ss : 0.0;\n"
"	}\n"
"	\n"
"#else\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		int selected_row;\n"
"		int selected_col;\n"
"		selected_row = ADDR_H(startY + i, 0, src_whole_rows);\n"
"		selected_row = ADDR_B(startY + i, src_whole_rows, selected_row);\n"
"	\n"
"		selected_col = ADDR_L(startX + col, 0, src_whole_cols);\n"
"		selected_col = ADDR_R(startX + col, src_whole_cols, selected_col);\n"
"	\n"
"		data[i] = src[selected_row * (src_step >> 2) + selected_col];\n"
"	}\n"
"	\n"
"#endif\n"
"	float sum0 = 0.0, sum1 = 0.0, sum2 = 0.0;\n"
"	\n"
"	for (int i = 1; i < ksY; i++)\n"
"	{\n"
"		sum0 += (data[i]);\n"
"	}\n"
"	\n"
"	sum1 = sum0 + (data[0]);\n"
"	sum2 = sum0 + (data[ksY]);\n"
"	temp[0][col] = sum1;\n"
"	temp[1][col] = sum2;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (col < (THREADS - (ksX - 1)))\n"
"	{\n"
"		col += anX;\n"
"		int posX = dst_startX - dst_x_off + col - anX;\n"
"		int posY = (gY << 1);\n"
"		\n"
"		float tmp_sum[2] = {0.0, 0.0};\n"
"		\n"
"		for (int k = 0; k < 2; k++)\n"
"			for (int i = -anX; i <= anX; i++)\n"
"			{\n"
"				tmp_sum[k] += temp[k][col + i];\n"
"			}\n"
"			\n"
"		for (int i = 0; i < 2; i++)\n"
"		{\n"
"			if (posX < dst_cols && (posY + i) < dst_rows)\n"
"			{\n"
"				dst[(dst_startY + i) * (dst_step >> 2) + dst_startX + col - anX] = tmp_sum[i] / alpha;\n"
"			}\n"
"		}\n"
"		\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////32fC4////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void boxFilter_C4_D5(__global const float4 *restrict src, __global float4 *dst, float alpha,\n"
"                              int src_offset, int src_whole_rows, int src_whole_cols, int src_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step\n"
"                             )\n"
"{\n"
"	int col = get_local_id(0);\n"
"	const int gX = get_group_id(0);\n"
"	const int gY = get_group_id(1);\n"
"	\n"
"	int src_x_off = (src_offset % src_step) >> 4;\n"
"	int src_y_off = src_offset / src_step;\n"
"	int dst_x_off = (dst_offset % dst_step) >> 4;\n"
"	int dst_y_off = dst_offset / dst_step;\n"
"	\n"
"	int startX = gX * (THREADS - ksX + 1) - anX + src_x_off;\n"
"	int startY = (gY << 1) - anY + src_y_off;\n"
"	int dst_startX = gX * (THREADS - ksX + 1) + dst_x_off;\n"
"	int dst_startY = (gY << 1) + dst_y_off;\n"
"	\n"
"	float4 data[ksY + 1];\n"
"	__local float4 temp[2][THREADS];\n"
"#ifdef BORDER_CONSTANT\n"
"	bool con;\n"
"	float4 ss;\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		con = startX + col >= 0 && startX + col < src_whole_cols && startY + i >= 0 && startY + i < src_whole_rows;\n"
"		ss = src[(startY + i) * (src_step >> 4) + (startX + col)];\n"
"		data[i] = con ? ss : (float4)(0.0, 0.0, 0.0, 0.0);\n"
"	}\n"
"	\n"
"#else\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		int selected_row;\n"
"		int selected_col;\n"
"		selected_row = ADDR_H(startY + i, 0, src_whole_rows);\n"
"		selected_row = ADDR_B(startY + i, src_whole_rows, selected_row);\n"
"	\n"
"		selected_col = ADDR_L(startX + col, 0, src_whole_cols);\n"
"		selected_col = ADDR_R(startX + col, src_whole_cols, selected_col);\n"
"	\n"
"		data[i] = src[selected_row * (src_step >> 4) + selected_col];\n"
"	}\n"
"	\n"
"#endif\n"
"	float4 sum0 = 0.0, sum1 = 0.0, sum2 = 0.0;\n"
"	\n"
"	for (int i = 1; i < ksY; i++)\n"
"	{\n"
"		sum0 += (data[i]);\n"
"	}\n"
"	\n"
"	sum1 = sum0 + (data[0]);\n"
"	sum2 = sum0 + (data[ksY]);\n"
"	temp[0][col] = sum1;\n"
"	temp[1][col] = sum2;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (col < (THREADS - (ksX - 1)))\n"
"	{\n"
"		col += anX;\n"
"		int posX = dst_startX - dst_x_off + col - anX;\n"
"		int posY = (gY << 1);\n"
"		\n"
"		float4 tmp_sum[2] = {(float4)(0.0, 0.0, 0.0, 0.0), (float4)(0.0, 0.0, 0.0, 0.0)};\n"
"		\n"
"		for (int k = 0; k < 2; k++)\n"
"			for (int i = -anX; i <= anX; i++)\n"
"			{\n"
"				tmp_sum[k] += temp[k][col + i];\n"
"			}\n"
"			\n"
"		for (int i = 0; i < 2; i++)\n"
"		{\n"
"			if (posX < dst_cols && (posY + i) < dst_rows)\n"
"			{\n"
"				dst[(dst_startY + i) * (dst_step >> 4) + dst_startX + col - anX] = tmp_sum[i] / alpha;\n"
"			}\n"
"		}\n"
"		\n"
"	}\n"
"}\n"
;
const char *filtering_dilateFilter =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zhang Ying, zhangying913@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#pragma OPENCL FP_CONTRACT ON\n"
"#define UCHAR_MIN 0\n"
"__kernel void dilate_C4_D5(__global const float4 *restrict src, __global float4 *dst, int srcOffset, int dstOffset,\n"
"                           int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                           int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = get_global_id(0);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	float4 maxVal = (float4)(-FLT_MAX);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			float4 v = *((__global float4 *)(src + srcOffset + kY * srcStep + kX));\n"
"			uchar now = mat_kernel[k++];\n"
"			float4 flag = (kX >= mincols &kX <= maxcols &kY >= minrows &kY <= maxrows &now != 0) ? v : (float4)(-FLT_MAX);\n"
"			maxVal = max(maxVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mX < cols && mY < rows)\n"
"	{\n"
"		dst[mY * dstStep + mX + dstOffset] = (maxVal);\n"
"	}\n"
"}\n"
"__kernel void dilate_C1_D5(__global float4 *src, __global float *dst, int srcOffset, int dstOffset,\n"
"                           int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                           int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = (get_global_id(0) << 2) - (dstOffset & 3);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	float4 maxVal = (float4)(-FLT_MAX);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			int start = srcOffset + kY * srcStep + kX;\n"
"			float8 sVal = (float8)(src[start >> 2], src[(start >> 2) + 1]);\n"
"			\n"
"			float sAry[8] = {sVal.s0, sVal.s1, sVal.s2, sVal.s3, sVal.s4, sVal.s5, sVal.s6, sVal.s7};\n"
"			int det = start & 3;\n"
"			float4 v = (float4)(sAry[det], sAry[det + 1], sAry[det + 2], sAry[det + 3]);\n"
"			uchar now = mat_kernel[k++];\n"
"			float4 flag = (kY >= minrows &kY <= maxrows &now != 0) ? v : maxVal;\n"
"			flag.x = (kX >= mincols &kX <= maxcols) ? flag.x : -FLT_MAX;\n"
"			flag.y = (kX + 1 >= mincols &kX + 1 <= maxcols) ? flag.y : -FLT_MAX;\n"
"			flag.z = (kX + 2 >= mincols &kX + 2 <= maxcols) ? flag.z : -FLT_MAX;\n"
"			flag.w = (kX + 3 >= mincols &kX + 3 <= maxcols) ? flag.w : -FLT_MAX;\n"
"			\n"
"			maxVal = max(maxVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mY < rows && mX < cols)\n"
"	{\n"
"		__global float4 *d = (__global float4 *)(dst + mY * dstStep + mX + dstOffset);\n"
"		float4 dVal = *d;\n"
"		maxVal.x = (mX >= 0 & mX < cols) ? maxVal.x : dVal.x;\n"
"		maxVal.y = (mX + 1 >= 0 & mX + 1 < cols) ? maxVal.y : dVal.y;\n"
"		maxVal.z = (mX + 2 >= 0 & mX + 2 < cols) ? maxVal.z : dVal.z;\n"
"		maxVal.w = (mX + 3 >= 0 & mX + 3 < cols) ? maxVal.w : dVal.w;\n"
"		\n"
"		*d = (maxVal);\n"
"	}\n"
"}\n"
"__kernel void dilate_C1_D0(__global const uchar4 *restrict src, __global uchar *dst, int srcOffset, int dstOffset,\n"
"                           int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                           int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = (get_global_id(0) << 2) - (dstOffset & 3);;\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	uchar4 maxVal = (uchar4)(UCHAR_MIN);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			int start = srcOffset + kY * srcStep + kX;\n"
"			uchar8 sVal = (uchar8)(src[start >> 2], src[(start >> 2) + 1]);\n"
"			\n"
"			uchar sAry[8] = {sVal.s0, sVal.s1, sVal.s2, sVal.s3, sVal.s4, sVal.s5, sVal.s6, sVal.s7};\n"
"			int det = start & 3;\n"
"			uchar4 v = (uchar4)(sAry[det], sAry[det + 1], sAry[det + 2], sAry[det + 3]);\n"
"			\n"
"			uchar4 flag = (kY >= minrows &kY <= maxrows & mat_kernel[k++] != 0) ? v : maxVal;\n"
"			flag.x = (kX >= mincols &kX <= maxcols) ? flag.x : UCHAR_MIN;\n"
"			flag.y = (kX + 1 >= mincols &kX + 1 <= maxcols) ? flag.y : UCHAR_MIN;\n"
"			flag.z = (kX + 2 >= mincols &kX + 2 <= maxcols) ? flag.z : UCHAR_MIN;\n"
"			flag.w = (kX + 3 >= mincols &kX + 3 <= maxcols) ? flag.w : UCHAR_MIN;\n"
"			\n"
"			maxVal = max(maxVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mY < rows)\n"
"	{\n"
"		__global uchar4 *d = (__global uchar4 *)(dst + mY * dstStep + mX + dstOffset);\n"
"		uchar4 dVal = *d;\n"
"		\n"
"		maxVal.x = (mX >= 0 & mX < cols) ? maxVal.x : dVal.x;\n"
"		maxVal.y = (mX + 1 >= 0 & mX + 1 < cols) ? maxVal.y : dVal.y;\n"
"		maxVal.z = (mX + 2 >= 0 & mX + 2 < cols) ? maxVal.z : dVal.z;\n"
"		maxVal.w = (mX + 3 >= 0 & mX + 3 < cols) ? maxVal.w : dVal.w;\n"
"		\n"
"		*d = (maxVal);\n"
"	}\n"
"}\n"
"__kernel void dilate_C4_D0(__global const uchar4 *restrict src, __global uchar4 *dst, int srcOffset, int dstOffset,\n"
"                           int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                           int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = get_global_id(0);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	uchar4 maxVal = (uchar4)(UCHAR_MIN);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			uchar4 v = src[kY * srcStep + kX + srcOffset];\n"
"			uchar now = mat_kernel[k++];\n"
"			uchar4 flag = (kX >= mincols &kX <= maxcols &kY >= minrows &kY <= maxrows &now != 0) ? v : maxVal;\n"
"			maxVal = max(maxVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mX < cols && mY < rows)\n"
"	{\n"
"		dst[mY * dstStep + mX + dstOffset] = (maxVal);\n"
"	}\n"
"}\n"
;
const char *filtering_erodeFilter =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Zero Lin, zero.lin@amd.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"__kernel void erode_C4_D5(__global const float4 *restrict src, __global float4 *dst, int srcOffset, int dstOffset,\n"
"                          int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                          int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = get_global_id(0);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	float4 minVal = (float4)(3.4e+38);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			float4 v = *((__global float4 *)(src + srcOffset + kY * srcStep + kX));\n"
"			uchar now = mat_kernel[k++];\n"
"			float4 flag = (kX >= mincols &kX <= maxcols &kY >= minrows &kY <= maxrows &now != 0) ? v : (float4)(3.4e+38);\n"
"			minVal = min(minVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mX < cols && mY < rows)\n"
"	{\n"
"		dst[mY * dstStep + mX + dstOffset] = (minVal);\n"
"	}\n"
"}\n"
"__kernel void erode_C1_D5(__global float4 *src, __global float *dst, int srcOffset, int dstOffset,\n"
"                          int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                          int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = (get_global_id(0) << 2) - (dstOffset & 3);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	float4 minVal = (float4)(3.4e+38);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			int start = srcOffset + kY * srcStep + kX;\n"
"			float8 sVal = (float8)(src[start >> 2], src[(start >> 2) + 1]);\n"
"			\n"
"			float sAry[8] = {sVal.s0, sVal.s1, sVal.s2, sVal.s3, sVal.s4, sVal.s5, sVal.s6, sVal.s7};\n"
"			int det = start & 3;\n"
"			float4 v = (float4)(sAry[det], sAry[det + 1], sAry[det + 2], sAry[det + 3]);\n"
"			uchar now = mat_kernel[k++];\n"
"			float4 flag = (kY >= minrows &kY <= maxrows &now != 0) ? v : (float4)(3.4e+38);\n"
"			flag.x = (kX >= mincols &kX <= maxcols) ? flag.x : 3.4e+38;\n"
"			flag.y = (kX + 1 >= mincols &kX + 1 <= maxcols) ? flag.y : 3.4e+38;\n"
"			flag.z = (kX + 2 >= mincols &kX + 2 <= maxcols) ? flag.z : 3.4e+38;\n"
"			flag.w = (kX + 3 >= mincols &kX + 3 <= maxcols) ? flag.w : 3.4e+38;\n"
"			\n"
"			minVal = min(minVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mY < rows && mX < cols)\n"
"	{\n"
"		__global float4 *d = (__global float4 *)(dst + mY * dstStep + mX + dstOffset);\n"
"		float4 dVal = *d;\n"
"		minVal.x = (mX >= 0 & mX < cols) ? minVal.x : dVal.x;\n"
"		minVal.y = (mX + 1 >= 0 & mX + 1 < cols) ? minVal.y : dVal.y;\n"
"		minVal.z = (mX + 2 >= 0 & mX + 2 < cols) ? minVal.z : dVal.z;\n"
"		minVal.w = (mX + 3 >= 0 & mX + 3 < cols) ? minVal.w : dVal.w;\n"
"		\n"
"		*d = (minVal);\n"
"	}\n"
"}\n"
"__kernel void erode_C1_D0(__global const uchar4 *restrict src, __global uchar *dst, int srcOffset, int dstOffset,\n"
"                          int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                          int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = (get_global_id(0) << 2) - (dstOffset & 3);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	uchar4 minVal = (uchar4)(0xff);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			int start = srcOffset + kY * srcStep + kX;\n"
"			uchar8 sVal = (uchar8)(src[start >> 2], src[(start >> 2) + 1]);\n"
"			\n"
"			uchar sAry[8] = {sVal.s0, sVal.s1, sVal.s2, sVal.s3, sVal.s4, sVal.s5, sVal.s6, sVal.s7};\n"
"			int det = start & 3;\n"
"			uchar4 v = (uchar4)(sAry[det], sAry[det + 1], sAry[det + 2], sAry[det + 3]);\n"
"			\n"
"			uchar4 flag = (kY >= minrows &kY <= maxrows & mat_kernel[k++] != 0) ? v : (uchar4)(0xff);\n"
"			flag.x = (kX >= mincols &kX <= maxcols) ? flag.x : 0xff;\n"
"			flag.y = (kX + 1 >= mincols &kX + 1 <= maxcols) ? flag.y : 0xff;\n"
"			flag.z = (kX + 2 >= mincols &kX + 2 <= maxcols) ? flag.z : 0xff;\n"
"			flag.w = (kX + 3 >= mincols &kX + 3 <= maxcols) ? flag.w : 0xff;\n"
"			\n"
"			minVal = min(minVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mY < rows)\n"
"	{\n"
"		__global uchar4 *d = (__global uchar4 *)(dst + mY * dstStep + mX + dstOffset);\n"
"		uchar4 dVal = *d;\n"
"		\n"
"		minVal.x = (mX >= 0 & mX < cols) ? minVal.x : dVal.x;\n"
"		minVal.y = (mX + 1 >= 0 & mX + 1 < cols) ? minVal.y : dVal.y;\n"
"		minVal.z = (mX + 2 >= 0 & mX + 2 < cols) ? minVal.z : dVal.z;\n"
"		minVal.w = (mX + 3 >= 0 & mX + 3 < cols) ? minVal.w : dVal.w;\n"
"		\n"
"		*d = (minVal);\n"
"	}\n"
"}\n"
"__kernel void erode_C4_D0(__global const uchar4 *restrict src, __global uchar4 *dst, int srcOffset, int dstOffset,\n"
"                          int mincols, int maxcols, int minrows, int maxrows, int cols, int rows,\n"
"                          int srcStep, int dstStep, __constant uchar *mat_kernel)\n"
"{\n"
"	int mX = get_global_id(0);\n"
"	int mY = get_global_id(1);\n"
"	int kX = mX - anX, kY = mY - anY;\n"
"	\n"
"	uchar4 minVal = (uchar4)(0xff);\n"
"	int k = 0;\n"
"	\n"
"	for (int i = 0; i < ksY; i++, kY++ , kX = mX - anX)\n"
"	{\n"
"		for (int j = 0; j < ksX; j++, kX++)\n"
"		{\n"
"			uchar4 v = src[kY * srcStep + kX + srcOffset];\n"
"			uchar now = mat_kernel[k++];\n"
"			uchar4 flag = (kX >= mincols &kX <= maxcols &kY >= minrows &kY <= maxrows &now != 0) ? v : (uchar4)(0xff);\n"
"			minVal = min(minVal , flag);\n"
"		}\n"
"	}\n"
"	\n"
"	if (mX < cols && mY < rows)\n"
"	{\n"
"		dst[mY * dstStep + mX + dstOffset] = (minVal);\n"
"	}\n"
"}\n"
;
const char *filtering_laplacian =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#define BORDER_REFLECT_101\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////Macro for border type////////////////////////////////////////////\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#ifdef BORDER_REPLICATE\n"
"//BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (l_edge)   : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (r_edge)-1 : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (t_edge)   :(i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (b_edge)-1 :(addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT\n"
"//BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)-1               : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-1+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)-1 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-1+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT_101\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)                 : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-2+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)                 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-2+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_WRAP\n"
"//BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (i)+(r_edge) : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (i)-(r_edge) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (i)+(b_edge) : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (i)-(b_edge) : (addr))\n"
"#endif\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////Macro for define elements number per thread/////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#define ANCHOR                  3\n"
"#define ANX                     1\n"
"#define ANY                     1\n"
"#define ROWS_PER_GROUP          4\n"
"#define ROWS_PER_GROUP_BITS     2\n"
"#define ROWS_FETCH              (ROWS_PER_GROUP + ANY + ANY)   //(ROWS_PER_GROUP + anY * 2)\n"
"#define THREADS_PER_ROW         64\n"
"#define THREADS_PER_ROW_BIT     6\n"
"#define ELEMENTS_PER_THREAD     4\n"
"#define ELEMENTS_PER_THREAD_BIT 2\n"
"#define LOCAL_MEM_STEP          260 //divup((get_local_size(0) + anX * 2), 4) * 4\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////8uC1////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void filter2D_C1_D0(__global uchar *src, int src_step, int src_offset_x, int src_offset_y,\n"
"                             __global uchar *dst, int dst_step, int dst_offset_x, int dst_offset_y,\n"
"                             __constant int *mat_kernel __attribute__((max_constant_size(16384))),\n"
"                             int cols, int rows, int operate_cols, int wholecols, int wholerows)\n"
"{\n"
"	int gX = get_global_id(0);\n"
"	int gY = get_global_id(1);\n"
"	\n"
"	int lX = get_local_id(0);\n"
"	\n"
"	int groupX_size = get_local_size(0);\n"
"	int groupX_id   = get_group_id(0);\n"
"	\n"
"#define dst_align (dst_offset_x & 3)\n"
"	int cols_start_index_group = src_offset_x - dst_align + groupX_size * groupX_id - ANX;\n"
"	int rows_start_index       = src_offset_y + (gY << ROWS_PER_GROUP_BITS) - ANY;\n"
"	\n"
"	__local uchar local_data[LOCAL_MEM_STEP * ROWS_FETCH];\n"
"	\n"
"	if ((gY << 2) < rows)\n"
"	{\n"
"		for (int i = 0; i < ROWS_FETCH; ++i)\n"
"		{\n"
"			if ((rows_start_index - src_offset_y) + i < rows + ANY)\n"
"			{\n"
"#ifdef BORDER_CONSTANT\n"
"				int selected_row  = rows_start_index + i;\n"
"				int selected_cols = cols_start_index_group + lX;\n"
"				\n"
"				uchar data = *(src + selected_row * src_step + selected_cols);\n"
"				int con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"				data = con ? data : 0;\n"
"				local_data[i * LOCAL_MEM_STEP + lX ] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					\n"
"					data = *(src + selected_row * src_step + selected_cols);\n"
"					con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"					data = con ? data : 0;\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#else\n"
"				int selected_row = ADDR_H(rows_start_index + i,  0, wholerows);\n"
"				selected_row     = ADDR_B(rows_start_index + i, wholerows, selected_row);\n"
"				\n"
"				int selected_cols = ADDR_L(cols_start_index_group + lX, 0, wholecols);\n"
"				selected_cols     = ADDR_R(cols_start_index_group + lX, wholecols, selected_cols);\n"
"				\n"
"				uchar data = *(src + selected_row * src_step + selected_cols);\n"
"				\n"
"				local_data[i * LOCAL_MEM_STEP + lX ] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					selected_cols = ADDR_R(selected_cols, wholecols, selected_cols);\n"
"				\n"
"					data = *(src + selected_row * src_step + selected_cols);\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#endif\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int process_col = groupX_size * groupX_id + ((lX % THREADS_PER_ROW) << 2);\n"
"	\n"
"	if (((gY << 2) < rows) && (process_col < operate_cols))\n"
"	{\n"
"		int dst_cols_start = dst_offset_x;\n"
"		int dst_cols_end   = dst_offset_x + cols;\n"
"		int dst_cols_index = (dst_offset_x + process_col) & 0xfffffffc;\n"
"		\n"
"		int dst_rows_end   = dst_offset_y + rows;\n"
"		int dst_rows_index = dst_offset_y + (gY << ROWS_PER_GROUP_BITS) + (lX >> THREADS_PER_ROW_BIT);\n"
"		\n"
"		uchar4 dst_data = *((__global uchar4 *)(dst + dst_rows_index * dst_step + dst_cols_index));\n"
"		\n"
"		int4 sum = (int4)(0);\n"
"		uchar4 data;\n"
"		\n"
"		for (int i = 0; i < ANCHOR; i++)\n"
"		{\n"
"#pragma unroll 3\n"
"		\n"
"			for (int j = 0; j < ANCHOR; j++)\n"
"			{\n"
"				if (dst_rows_index < dst_rows_end)\n"
"				{\n"
"					int local_row = (lX >> THREADS_PER_ROW_BIT) + i;\n"
"					int local_cols = ((lX % THREADS_PER_ROW) << ELEMENTS_PER_THREAD_BIT) + j;\n"
"					\n"
"					data = vload4(0, local_data + local_row * LOCAL_MEM_STEP + local_cols);\n"
"					sum = sum + (mat_kernel[i * ANCHOR + j] * convert_int4_sat(data));\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		if (dst_rows_index < dst_rows_end)\n"
"		{\n"
"			sum.x = ((dst_cols_index + 0 >= dst_cols_start) && (dst_cols_index + 0 < dst_cols_end)) ? sum.x : dst_data.x;\n"
"			sum.y = ((dst_cols_index + 1 >= dst_cols_start) && (dst_cols_index + 1 < dst_cols_end)) ? sum.y : dst_data.y;\n"
"			sum.z = ((dst_cols_index + 2 >= dst_cols_start) && (dst_cols_index + 2 < dst_cols_end)) ? sum.z : dst_data.z;\n"
"			sum.w = ((dst_cols_index + 3 >= dst_cols_start) && (dst_cols_index + 3 < dst_cols_end)) ? sum.w : dst_data.w;\n"
"			*((__global uchar4 *)(dst + dst_rows_index * dst_step + dst_cols_index)) = convert_uchar4_sat(sum);\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////32FC1////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void filter2D_C1_D5(__global float *src, int src_step, int src_offset_x, int src_offset_y,\n"
"                             __global float *dst, int dst_step, int dst_offset_x, int dst_offset_y,\n"
"                             __constant int *mat_kernel __attribute__((max_constant_size(16384))),\n"
"                             int cols, int rows, int operate_cols, int wholecols, int wholerows)\n"
"{\n"
"	int gX = get_global_id(0);\n"
"	int gY = get_global_id(1);\n"
"	\n"
"	int lX = get_local_id(0);\n"
"	\n"
"	int groupX_size = get_local_size(0);\n"
"	int groupX_id   = get_group_id(0);\n"
"	\n"
"#define dst_align (dst_offset_x & 3)\n"
"	int cols_start_index_group = src_offset_x - dst_align + groupX_size * groupX_id - ANX;\n"
"	int rows_start_index       = src_offset_y + (gY << ROWS_PER_GROUP_BITS) - ANY;\n"
"	\n"
"	__local float local_data[LOCAL_MEM_STEP * ROWS_FETCH];\n"
"	\n"
"	if (((gY << 2) < rows))\n"
"	{\n"
"		for (int i = 0; i < ROWS_FETCH; ++i)\n"
"		{\n"
"			if ((rows_start_index - src_offset_y) + i < rows + ANY)\n"
"			{\n"
"#ifdef BORDER_CONSTANT\n"
"				int selected_row  = rows_start_index + i;\n"
"				int selected_cols = cols_start_index_group + lX;\n"
"				\n"
"				float data = *((__global float *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"				int con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"				data = con ? data : 0;\n"
"				local_data[i * LOCAL_MEM_STEP + lX ] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					\n"
"					data = *((__global float *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"					con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"					data = con ? data : 0;\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#else\n"
"				int selected_row = ADDR_H(rows_start_index + i,  0, wholerows);\n"
"				selected_row     = ADDR_B(rows_start_index + i, wholerows, selected_row);\n"
"				\n"
"				int selected_cols = ADDR_L(cols_start_index_group + lX, 0, wholecols);\n"
"				selected_cols     = ADDR_R(cols_start_index_group + lX, wholecols, selected_cols);\n"
"				\n"
"				float data = *((__global float *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"				local_data[i * LOCAL_MEM_STEP + lX] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					selected_cols = ADDR_R(selected_cols, wholecols, selected_cols);\n"
"				\n"
"					data = *((__global float *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#endif\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int process_col = groupX_size * groupX_id + ((lX % THREADS_PER_ROW) << 2);\n"
"	\n"
"	if (((gY << 2) < rows) && (process_col < operate_cols))\n"
"	{\n"
"		int dst_cols_start = dst_offset_x;\n"
"		int dst_cols_end   = dst_offset_x + cols;\n"
"		int dst_cols_index = (dst_offset_x + process_col) & 0xfffffffc;\n"
"		\n"
"		int dst_rows_end   = dst_offset_y + rows;\n"
"		int dst_rows_index = dst_offset_y + (gY << ROWS_PER_GROUP_BITS) + (lX >> THREADS_PER_ROW_BIT);\n"
"		\n"
"		float4 dst_data = *((__global float4 *)((__global char *)dst + dst_rows_index * dst_step + (dst_cols_index << 2)));\n"
"		\n"
"		float4 sum = (float4)(0);\n"
"		float4 data;\n"
"		\n"
"		for (int i = 0; i < ANCHOR; i++)\n"
"		{\n"
"#pragma unroll 3\n"
"		\n"
"			for (int j = 0; j < ANCHOR; j++)\n"
"			{\n"
"				if (dst_rows_index < dst_rows_end)\n"
"				{\n"
"					int local_row = (lX >> THREADS_PER_ROW_BIT) + i;\n"
"					int local_cols = ((lX % THREADS_PER_ROW) << ELEMENTS_PER_THREAD_BIT) + j;\n"
"					\n"
"					data = vload4(0, local_data + local_row * LOCAL_MEM_STEP + local_cols);\n"
"					sum = sum + (mat_kernel[i * ANCHOR + j] * data);\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		if (dst_rows_index < dst_rows_end)\n"
"		{\n"
"			sum.x = ((dst_cols_index + 0 >= dst_cols_start) && (dst_cols_index + 0 < dst_cols_end)) ? sum.x : dst_data.x;\n"
"			sum.y = ((dst_cols_index + 1 >= dst_cols_start) && (dst_cols_index + 1 < dst_cols_end)) ? sum.y : dst_data.y;\n"
"			sum.z = ((dst_cols_index + 2 >= dst_cols_start) && (dst_cols_index + 2 < dst_cols_end)) ? sum.z : dst_data.z;\n"
"			sum.w = ((dst_cols_index + 3 >= dst_cols_start) && (dst_cols_index + 3 < dst_cols_end)) ? sum.w : dst_data.w;\n"
"			\n"
"			*((__global float4 *)((__global char *)dst + dst_rows_index * dst_step + (dst_cols_index << 2))) = sum;\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////8uC4////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void filter2D_C4_D0(__global uchar4 *src, int src_step, int src_offset_x, int src_offset_y,\n"
"                             __global uchar4 *dst, int dst_step, int dst_offset_x, int dst_offset_y,\n"
"                             __constant int *mat_kernel __attribute__((max_constant_size(16384))),\n"
"                             int cols, int rows, int operate_cols, int wholecols, int wholerows)\n"
"{\n"
"	int gX = get_global_id(0);\n"
"	int gY = get_global_id(1);\n"
"	\n"
"	int lX = get_local_id(0);\n"
"	\n"
"	int groupX_size = get_local_size(0);\n"
"	int groupX_id   = get_group_id(0);\n"
"	\n"
"#define dst_align (dst_offset_x & 3)\n"
"	int cols_start_index_group = src_offset_x - dst_align + groupX_size * groupX_id - ANX;\n"
"	int rows_start_index       = src_offset_y + (gY << ROWS_PER_GROUP_BITS) - ANY;\n"
"	\n"
"	__local uchar4 local_data[LOCAL_MEM_STEP * ROWS_FETCH];\n"
"	\n"
"	if (((gY << 2) < rows))\n"
"	{\n"
"		for (int i = 0; i < ROWS_FETCH; ++i)\n"
"		{\n"
"			if ((rows_start_index - src_offset_y) + i < rows + ANY)\n"
"			{\n"
"#ifdef BORDER_CONSTANT\n"
"				int selected_row  = rows_start_index + i;\n"
"				int selected_cols = cols_start_index_group + lX;\n"
"				\n"
"				uchar4 data = *((__global uchar4 *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"				int con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"				data = con ? data : 0;\n"
"				local_data[i * LOCAL_MEM_STEP + lX ] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					\n"
"					data = *((__global uchar4 *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"					con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"					data = con ? data : 0;\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#else\n"
"				int selected_row = ADDR_H(rows_start_index + i,  0, wholerows);\n"
"				selected_row     = ADDR_B(rows_start_index + i, wholerows, selected_row);\n"
"				\n"
"				int selected_cols = ADDR_L(cols_start_index_group + lX, 0, wholecols);\n"
"				selected_cols     = ADDR_R(cols_start_index_group + lX, wholecols, selected_cols);\n"
"				\n"
"				uchar4 data = *((__global uchar4 *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"				\n"
"				local_data[i * LOCAL_MEM_STEP + lX] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					selected_cols = ADDR_R(selected_cols, wholecols, selected_cols);\n"
"				\n"
"					data = *((__global uchar4 *)((__global char *)src + selected_row * src_step + (selected_cols << 2)));\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#endif\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int process_col = groupX_size * groupX_id + ((lX % THREADS_PER_ROW) << 2);\n"
"	\n"
"	if (((gY << 2) < rows) && (process_col < operate_cols))\n"
"	{\n"
"		int dst_cols_start = dst_offset_x;\n"
"		int dst_cols_end   = dst_offset_x + cols;\n"
"		int dst_cols_index = (dst_offset_x + process_col) & 0xfffffffc;\n"
"		\n"
"		int dst_rows_end   = dst_offset_y + rows;\n"
"		int dst_rows_index = dst_offset_y + (gY << ROWS_PER_GROUP_BITS) + (lX >> THREADS_PER_ROW_BIT);\n"
"		\n"
"		uchar16 dst_data;\n"
"		dst_data = *((__global uchar16 *)((__global char *)dst + dst_rows_index * dst_step + (dst_cols_index << 2)));\n"
"		\n"
"		int16 sum = (int16)(0);\n"
"		uchar16 data;\n"
"		\n"
"		for (int i = 0; i < ANCHOR; i++)\n"
"		{\n"
"#pragma unroll 3\n"
"		\n"
"			for (int j = 0; j < ANCHOR; j++)\n"
"			{\n"
"				if (dst_rows_index < dst_rows_end)\n"
"				{\n"
"					int local_row = (lX >> THREADS_PER_ROW_BIT) + i;\n"
"					int local_cols = ((lX % THREADS_PER_ROW) << ELEMENTS_PER_THREAD_BIT) + j;\n"
"					\n"
"					data = vload16(0, (__local uchar *)(local_data + local_row * LOCAL_MEM_STEP + local_cols));\n"
"					sum = sum + (mat_kernel[i * ANCHOR + j] * convert_int16_sat(data));\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		if (dst_rows_index < dst_rows_end)\n"
"		{\n"
"			uchar16 sum1 = convert_uchar16_sat(sum);\n"
"			sum1.s0123 = ((dst_cols_index + 0 >= dst_cols_start) && (dst_cols_index + 0 < dst_cols_end)) ?\n"
"			             sum1.s0123 : dst_data.s0123;\n"
"			sum1.s4567 = ((dst_cols_index + 1 >= dst_cols_start) && (dst_cols_index + 1 < dst_cols_end)) ?\n"
"			             sum1.s4567 : dst_data.s4567;\n"
"			sum1.s89ab = ((dst_cols_index + 2 >= dst_cols_start) && (dst_cols_index + 2 < dst_cols_end)) ?\n"
"			             sum1.s89ab : dst_data.s89ab;\n"
"			sum1.scdef = ((dst_cols_index + 3 >= dst_cols_start) && (dst_cols_index + 3 < dst_cols_end)) ?\n"
"			             sum1.scdef : dst_data.scedf;\n"
"			             \n"
"			*((__global uchar16 *)((__global char *)dst + dst_rows_index * dst_step + (dst_cols_index << 2))) = sum1;\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////////32FC4////////////////////////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#define ROWS_FETCH_C4              (1 + ANY + ANY)   //(ROWS_PER_GROUP + anY * 2)\n"
"#define LOCAL_MEM_STEP_C4           260 //divup((get_local_size(0) + anX * 2), 4) * 4)\n"
"__kernel void filter2D_C4_D5(__global float4 *src, int src_step, int src_offset_x, int src_offset_y,\n"
"                             __global float4 *dst, int dst_step, int dst_offset_x, int dst_offset_y,\n"
"                             __constant int *mat_kernel __attribute__((max_constant_size(16384))),\n"
"                             int cols, int rows, int operate_cols, int wholecols, int wholerows)\n"
"{\n"
"	int gX = get_global_id(0);\n"
"	int gY = get_global_id(1);\n"
"	\n"
"	int lX = get_local_id(0);\n"
"	\n"
"	int groupX_size = get_local_size(0);\n"
"	int groupX_id   = get_group_id(0);\n"
"	\n"
"	int cols_start_index_group = src_offset_x + groupX_size * groupX_id - ANX;\n"
"	int rows_start_index       = src_offset_y + gY - ANY;\n"
"	\n"
"	__local float4 local_data[LOCAL_MEM_STEP_C4 * ROWS_FETCH_C4];\n"
"	\n"
"	if ((gY < rows) && (gX < (operate_cols + ANX + ANX)))\n"
"	{\n"
"		for (int i = 0; i < ROWS_FETCH_C4; ++i)\n"
"		{\n"
"			if ((rows_start_index - src_offset_y) + i < rows + ANY)\n"
"			{\n"
"#ifdef BORDER_CONSTANT\n"
"				int selected_row  = rows_start_index + i;\n"
"				int selected_cols = cols_start_index_group + lX;\n"
"				\n"
"				float4 data = *((__global float4 *)((__global char *)src + selected_row * src_step + (selected_cols << 4)));\n"
"				int con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"				data = con ? data : 0;\n"
"				local_data[i * LOCAL_MEM_STEP + lX ] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					\n"
"					data = *((__global float4 *)((__global char *)src + selected_row * src_step + (selected_cols << 4)));\n"
"					con = selected_row >= 0 && selected_row < wholerows && selected_cols >= 0 && selected_cols < wholecols;\n"
"					data = con ? data : 0;\n"
"					local_data[i * LOCAL_MEM_STEP + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#else\n"
"				int selected_row = ADDR_H(rows_start_index + i,  0, wholerows);\n"
"				selected_row     = ADDR_B(rows_start_index + i, wholerows, selected_row);\n"
"				\n"
"				int selected_cols = ADDR_L(cols_start_index_group + lX, 0, wholecols);\n"
"				selected_cols     = ADDR_R(cols_start_index_group + lX, wholecols, selected_cols);\n"
"				\n"
"				float4 data = *((__global float4 *)((__global char *)src + selected_row * src_step + (selected_cols << 4)));\n"
"				local_data[i * LOCAL_MEM_STEP_C4 + lX] = data;\n"
"				\n"
"				if (lX < (ANX << 1))\n"
"				{\n"
"					selected_cols = cols_start_index_group + lX + groupX_size;\n"
"					selected_cols = ADDR_R(selected_cols, wholecols, selected_cols);\n"
"				\n"
"					data = *((__global float4 *)((__global char *)src + selected_row * src_step + (selected_cols << 4)));\n"
"					local_data[i * LOCAL_MEM_STEP_C4 + lX + groupX_size] = data;\n"
"				}\n"
"				\n"
"#endif\n"
"			}\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if ((gY < rows) && (gX < operate_cols))\n"
"	{\n"
"		int dst_cols_index = dst_offset_x + gX;\n"
"		int dst_rows_index = dst_offset_y + gY;\n"
"		\n"
"		float4 sum = (float4)(0);\n"
"		\n"
"		for (int i = 0; i < ANCHOR; i++)\n"
"		{\n"
"			for (int j = 0; j < ANCHOR; j++)\n"
"			{\n"
"				int local_cols = lX + j;\n"
"				sum = sum + mat_kernel[i * ANCHOR + j] * local_data[i * LOCAL_MEM_STEP_C4 + local_cols];\n"
"			}\n"
"		}\n"
"		\n"
"		*((__global float4 *)((__global char *)dst + dst_rows_index * dst_step + (dst_cols_index << 4))) = sum;\n"
"	}\n"
"}\n"
;
const char *filter_sep_col =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#define READ_TIMES_COL ((2*(RADIUSY+LSIZE1)-1)/LSIZE1)\n"
"#define RADIUS 1\n"
"#if CN ==1\n"
"#define ALIGN (((RADIUS)+3)>>2<<2)\n"
"#elif CN==2\n"
"#define ALIGN (((RADIUS)+1)>>1<<1)\n"
"#elif CN==3\n"
"#define ALIGN (((RADIUS)+3)>>2<<2)\n"
"#elif CN==4\n"
"#define ALIGN (RADIUS)\n"
"#define READ_TIMES_ROW ((2*(RADIUS+LSIZE0)-1)/LSIZE0)\n"
"#endif\n"
"#ifdef BORDER_CONSTANT\n"
"//BORDER_CONSTANT:      iiiiii|abcdefgh|iiiiiii\n"
"#define ELEM(i,l_edge,r_edge,elem1,elem2) (i)<(l_edge) | (i) >= (r_edge) ? (elem1) : (elem2)\n"
"#endif\n"
"#ifdef BORDER_REPLICATE\n"
"//BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n"
"#define ADDR_L(i,l_edge,r_edge)  (i) < (l_edge) ? (l_edge) : (i)\n"
"#define ADDR_R(i,r_edge,addr)   (i) >= (r_edge) ? (r_edge)-1 : (addr)\n"
"#endif\n"
"#ifdef BORDER_REFLECT\n"
"//BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n"
"#define ADDR_L(i,l_edge,r_edge)  (i) < (l_edge) ? -(i)-1 : (i)\n"
"#define ADDR_R(i,r_edge,addr) (i) >= (r_edge) ? -(i)-1+((r_edge)<<1) : (addr)\n"
"#endif\n"
"#ifdef BORDER_REFLECT_101\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define ADDR_L(i,l_edge,r_edge)  (i) < (l_edge) ? -(i) : (i)\n"
"#define ADDR_R(i,r_edge,addr) (i) >= (r_edge) ? -(i)-2+((r_edge)<<1) : (addr)\n"
"#endif\n"
"#ifdef BORDER_WRAP\n"
"//BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n"
"#define ADDR_L(i,l_edge,r_edge)  (i) < (l_edge) ? (i)+(r_edge) : (i)\n"
"#define ADDR_R(i,r_edge,addr)   (i) >= (r_edge) ?   (i)-(r_edge) : (addr)\n"
"#endif\n"
"/**********************************************************************************\n"
"These kernels are written for separable filters such as Sobel, Scharr, GaussianBlur.\n"
"Now(6/29/2011) the kernels only support 8U data type and the anchor of the convovle\n"
"kernel must be in the center. ROI is not supported either.\n"
"Each kernels read 4 elements(not 4 pixels), save them to LDS and read the data needed\n"
"from LDS to calculate the result.\n"
"The length of the convovle kernel supported is only related to the MAX size of LDS,\n"
"which is HW related.\n"
"Niko\n"
"6/29/2011\n"
"***********************************************************************************/\n"
"/*\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1)))void col_filter_C1_D0\n"
"						(__global const float * restrict src,\n"
"						 __global uchar * dst,\n"
"                         const int cols,\n"
"                         const int rows,\n"
"						 //const int src_whole_cols,\n"
"						 const int src_whole_rows,\n"
"                         const int src_step_in_pixel,\n"
"                         const int src_offset_x,\n"
"                         const int src_offset_y,\n"
"                         const int dst_step_in_pixel,\n"
"                         const int dst_offset_in_pixel,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<2;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0)<<2;\n"
"    int l_y = get_local_id(1);\n"
"	int i=0;\n"
"	float4 temp[READ_TIMES_COL];\n"
"	int baseindex[READ_TIMES_COL];\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		baseindex[j]=mad24(y+src_offset_y+j*LSIZE1-RADIUS,src_step_in_pixel,x+src_offset_x);\n"
"	}\n"
"    float4 sum = 0.0f;\n"
"	__local float LDS_DAT[READ_TIMES_COL*LSIZE1][LSIZE0*4+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = vload4(0,src+baseindex[j]);\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = ELEM(y+src_offset_y+j*LSIZE1-RADIUS,0,src_whole_rows,0.0f,temp[j]);\n"
"	}\n"
"	#else\n"
"	int not_all_in_range = (y+src_offset_y-RADIUS<0) | (y+src_offset_y+(READ_TIMES_COL-1)*LSIZE1-RADIUS>=src_whole_rows);\n"
"	int index[READ_TIMES_COL];\n"
"	if(not_all_in_range)\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			index[j] = ADDR_L(y+src_offset_y+j*LSIZE1-RADIUS,0,src_whole_rows);\n"
"			index[j] = ADDR_R(y+src_offset_y+j*LSIZE1-RADIUS,src_whole_rows,index[j]);\n"
"		}\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			baseindex[j]=mad24(index[j],src_step_in_pixel,x+src_offset_x);\n"
"		}\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	#endif\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		vstore4(temp[j],0,&LDS_DAT[l_y+j*LSIZE1][l_x]);\n"
"	}\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum = vload4(0,&LDS_DAT[l_y+RADIUS][l_x])*mat_kernel[RADIUS];\n"
"	float4 prefetch_LDS[2];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		prefetch_LDS[0]=vload4(0,&LDS_DAT[l_y+RADIUS-i][l_x]);\n"
"		prefetch_LDS[1]=vload4(0,&LDS_DAT[l_y+RADIUS+i][l_x]);\n"
"		sum += prefetch_LDS[0] * mat_kernel[RADIUS-i]+prefetch_LDS[1] * mat_kernel[RADIUS+i];\n"
"	}\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	vstore4(sum,0,&LDS_DAT[l_y][l_x]);\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	i = mad24(y,dst_step_in_pixel,x+dst_offset_in_pixel & 0xfffffffc);\n"
"	int off = dst_offset_in_pixel & 3;\n"
"	//uchar4 out = convert_uchar4_sat(sum);\n"
"	if((x< cols) & (y < rows))\n"
"	{\n"
"		uchar4 out = *(__global uchar4*)&dst[i];\n"
"		uchar4 temp = convert_uchar4_sat(vload4(0,&LDS_DAT[l_y][l_x-off]));\n"
"		size_t dst_addr_start = mad24(y,dst_step_in_pixel,dst_offset_in_pixel);\n"
"		size_t dst_addr_end = mad24(y,dst_step_in_pixel,cols+dst_offset_in_pixel);\n"
"		out.x = (i>=dst_addr_start)&(i<dst_addr_end) ? temp.x : out.x;\n"
"		out.y = (i+1>=dst_addr_start)&(i+1<dst_addr_end) ? temp.y : out.y;\n"
"		out.z = (i+2>=dst_addr_start)&(i+2<dst_addr_end) ? temp.z : out.z;\n"
"		out.w = (i+3>=dst_addr_start)&(i+3<dst_addr_end) ? temp.w : out.w;\n"
"		*(__global uchar4*)&dst[i] = out;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1)))void col_filter_C2_D0\n"
"						(__global const float * restrict src,\n"
"						 __global uchar * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<2;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0)<<2;\n"
"    int l_y = get_local_id(1);\n"
"	int i=0;\n"
"	int index[READ_TIMES_COL];\n"
"	float4 temp[READ_TIMES_COL];\n"
"	int baseindex[READ_TIMES_COL];\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		baseindex[j]=mad24(y+j*LSIZE1-RADIUS,src_pix_per_row,x);\n"
"	}\n"
"    float4 sum = 0.0f;\n"
"	__local float LDS_DAT[READ_TIMES_COL*LSIZE1][LSIZE0*4+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = ELEM(y+j*LSIZE1-RADIUS,0,src_rows,0.0f,temp[j]);\n"
"	}\n"
"	#else\n"
"	int not_all_in_range = (y-RADIUS<0) | (y+(READ_TIMES_COL-1)*LSIZE1-RADIUS>=src_rows);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			index[j] = ADDR_L(y+j*LSIZE1-RADIUS,0,src_rows);\n"
"			index[j] = ADDR_R(y+j*LSIZE1-RADIUS,src_rows,index[j]);\n"
"		}\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			baseindex[j]=mad24(index[j],src_pix_per_row,x);\n"
"		}\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	#endif\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		vstore4(temp[j],0,&LDS_DAT[l_y+j*LSIZE1][l_x]);\n"
"	}\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum = vload4(0,&LDS_DAT[l_y+RADIUS][l_x])*mat_kernel[RADIUS];\n"
"	float4 prefetch_LDS[2];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		prefetch_LDS[0]=vload4(0,&LDS_DAT[l_y+RADIUS-i][l_x]);\n"
"		prefetch_LDS[1]=vload4(0,&LDS_DAT[l_y+RADIUS+i][l_x]);\n"
"		sum += prefetch_LDS[0] * mat_kernel[RADIUS-i]+prefetch_LDS[1] * mat_kernel[RADIUS+i];\n"
"	}\n"
"	i = mad24(y,dst_pix_per_row,x);\n"
"	uchar4 out = convert_uchar4_sat(sum);\n"
"	if((x< (dst_cols<<1)) & (y < dst_rows))\n"
"	{\n"
"		*(__global uchar4*)&dst[i] = out;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1)))void col_filter_C3_D0\n"
"						(__global const float * restrict src,\n"
"						 __global uchar * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<2;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0)<<2;\n"
"    int l_y = get_local_id(1);\n"
"	int i=0;\n"
"	int index[READ_TIMES_COL];\n"
"	float4 temp[READ_TIMES_COL];\n"
"	int baseindex[READ_TIMES_COL];\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		baseindex[j]=mad24(y+j*LSIZE1-RADIUS,src_pix_per_row,x);\n"
"	}\n"
"    float4 sum = 0.0f;\n"
"	__local float LDS_DAT[READ_TIMES_COL*LSIZE1][LSIZE0*4+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = ELEM(y+j*LSIZE1-RADIUS,0,src_rows,0.0f,temp[j]);\n"
"	}\n"
"	#else\n"
"	int not_all_in_range = (y-RADIUS<0) | (y+(READ_TIMES_COL-1)*LSIZE1-RADIUS>=src_rows);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			index[j] = ADDR_L(y+j*LSIZE1-RADIUS,0,src_rows);\n"
"			index[j] = ADDR_R(y+j*LSIZE1-RADIUS,src_rows,index[j]);\n"
"		}\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			baseindex[j]=mad24(index[j],src_pix_per_row,x);\n"
"		}\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	#endif\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		vstore4(temp[j],0,&LDS_DAT[l_y+j*LSIZE1][l_x]);\n"
"	}\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	for(;i<=2*RADIUS;i++)\n"
"	{\n"
"		float4 prefetch_LDS=vload4(0,&LDS_DAT[l_y+i][l_x]);\n"
"		sum += prefetch_LDS * mat_kernel[i];\n"
"	}\n"
"	i = mad24(y,dst_pix_per_row,x);\n"
"	uchar4 out = convert_uchar4_sat(sum);\n"
"	if((x< dst_cols*3) & (y < dst_rows))\n"
"	{\n"
"		*(__global uchar4*)&dst[i] = out;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1)))void col_filter_C4_D0\n"
"						(__global const float * restrict src,\n"
"						 __global uchar * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<2;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0)<<2;\n"
"    int l_y = get_local_id(1);\n"
"	int i=0;\n"
"	int index[READ_TIMES_COL];\n"
"	float4 temp[READ_TIMES_COL];\n"
"	int baseindex[READ_TIMES_COL];\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		baseindex[j]=mad24(y+j*LSIZE1-RADIUS,src_pix_per_row,x);\n"
"	}\n"
"    float4 sum = 0.0f;\n"
"	__local float LDS_DAT[READ_TIMES_COL*LSIZE1][LSIZE0*4+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = ELEM(y+j*LSIZE1-RADIUS,0,src_rows,0.0f,temp[j]);\n"
"	}\n"
"	#else\n"
"	int not_all_in_range = (y-RADIUS<0) | (y+(READ_TIMES_COL-1)*LSIZE1-RADIUS>=src_rows);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			index[j] = ADDR_L(y+j*LSIZE1-RADIUS,0,src_rows);\n"
"			index[j] = ADDR_R(y+j*LSIZE1-RADIUS,src_rows,index[j]);\n"
"		}\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			baseindex[j]=mad24(index[j],src_pix_per_row,x);\n"
"		}\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = *(__global float4*)(src+baseindex[j]);\n"
"	}\n"
"	#endif\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		vstore4(temp[j],0,&LDS_DAT[l_y+j*LSIZE1][l_x]);\n"
"	}\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum = vload4(0,&LDS_DAT[l_y+RADIUS][l_x])*mat_kernel[RADIUS];\n"
"	float4 prefetch_LDS[2];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		prefetch_LDS[0]=vload4(0,&LDS_DAT[l_y+RADIUS-i][l_x]);\n"
"		prefetch_LDS[1]=vload4(0,&LDS_DAT[l_y+RADIUS+i][l_x]);\n"
"		sum += prefetch_LDS[0] * mat_kernel[RADIUS-i]+prefetch_LDS[1] * mat_kernel[RADIUS+i];\n"
"	}\n"
"	i = mad24(y,dst_pix_per_row,x);\n"
"	uchar4 out = convert_uchar4_sat(sum);\n"
"	if((x< (dst_cols<<2)) & (y < dst_rows))\n"
"	{\n"
"		*(__global uchar4*)&dst[i] = out;\n"
"	}\n"
"}\n"
"/*\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1)))void col_filter_C1_D5\n"
"						(__global const float * restrict src,\n"
"						 __global float * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0);\n"
"    int l_y = get_local_id(1);\n"
"	int i;\n"
"    float sum;\n"
"	float temp[READ_TIMES_COL];\n"
"	int baseindex[READ_TIMES_COL];\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		baseindex[j]=mad24(y+j*LSIZE1-RADIUS,src_pix_per_row,x);\n"
"	}\n"
"	__local float LDS_DAT[READ_TIMES_COL*LSIZE1][LSIZE0+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = src[baseindex[j]];\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = ELEM(y+j*LSIZE1-RADIUS,0,src_rows,0.0f,temp[j]);\n"
"	}\n"
"	#else\n"
"	int index[READ_TIMES_COL];\n"
"	int not_all_in_range = (y-RADIUS<0) | (y+(READ_TIMES_COL-1)*LSIZE1-RADIUS>=src_rows);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			index[j] = ADDR_L(y+j*LSIZE1-RADIUS,0,src_rows);\n"
"			index[j] = ADDR_R(y+j*LSIZE1-RADIUS,src_rows,index[j]);\n"
"		}\n"
"		for(int j=0;j<READ_TIMES_COL;j++)\n"
"		{\n"
"			baseindex[j]=mad24(index[j],src_pix_per_row,x);\n"
"		}\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		temp[j] = src[baseindex[j]];\n"
"	}\n"
"	#endif\n"
"	for(int j=0;j<READ_TIMES_COL;j++)\n"
"	{\n"
"		LDS_DAT[l_y+j*LSIZE1][l_x]=temp[j];\n"
"	}\n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum = LDS_DAT[l_y+RADIUS][l_x]*mat_kernel[RADIUS];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		temp[0]=LDS_DAT[l_y+RADIUS-i][l_x];\n"
"		temp[1]=LDS_DAT[l_y+RADIUS+i][l_x];\n"
"		sum += temp[0] * mat_kernel[RADIUS-i]+temp[1] * mat_kernel[RADIUS+i];\n"
"	}\n"
"	i = mad24(y,dst_pix_per_row,x);\n"
"	if((x< dst_cols) & (y < dst_rows))\n"
"	{\n"
"		dst[i] = sum;\n"
"	}\n"
"}\n"
"*/\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void col_filter_C1_D0\n"
"(__global const float *restrict src,\n"
" __global uchar *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" //const int src_whole_cols,\n"
" //const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" //const int src_offset_x,\n"
" //const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int dst_offset_in_pixel,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSY + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_addr = mad24(y, src_step_in_pixel, x);\n"
"	int i;\n"
"	float sum;\n"
"	float temp[READ_TIMES_COL];\n"
"	\n"
"	__local float LDS_DAT[LSIZE1 * READ_TIMES_COL][LSIZE0 + 1];\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE1 * src_step_in_pixel];\n"
"	}\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		LDS_DAT[l_y + i * LSIZE1][l_x] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	//read pixels from lds and calculate the result\n"
"	sum = LDS_DAT[l_y + RADIUSY][l_x] * mat_kernel[RADIUSY];\n"
"	\n"
"	for (i = 1; i <= RADIUSY; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y + RADIUSY - i][l_x];\n"
"		temp[1] = LDS_DAT[l_y + RADIUSY + i][l_x];\n"
"		sum += temp[0] * mat_kernel[RADIUSY - i] + temp[1] * mat_kernel[RADIUSY + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x + dst_offset_in_pixel);\n"
"		dst[start_addr] = convert_uchar_sat(sum);\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void col_filter_C4_D0\n"
"(__global const float4 *restrict src,\n"
" __global uchar4 *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" //const int src_whole_cols,\n"
" //const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" //const int src_offset_x,\n"
" //const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int dst_offset_in_pixel,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSY + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_addr = mad24(y, src_step_in_pixel, x);\n"
"	int i;\n"
"	float4 sum;\n"
"	float4 temp[READ_TIMES_COL];\n"
"	\n"
"	__local float4 LDS_DAT[LSIZE1 * READ_TIMES_COL][LSIZE0 + 1];\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE1 * src_step_in_pixel];\n"
"	}\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		LDS_DAT[l_y + i * LSIZE1][l_x] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	//read pixels from lds and calculate the result\n"
"	sum = LDS_DAT[l_y + RADIUSY][l_x] * mat_kernel[RADIUSY];\n"
"	\n"
"	for (i = 1; i <= RADIUSY; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y + RADIUSY - i][l_x];\n"
"		temp[1] = LDS_DAT[l_y + RADIUSY + i][l_x];\n"
"		sum += temp[0] * mat_kernel[RADIUSY - i] + temp[1] * mat_kernel[RADIUSY + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x + dst_offset_in_pixel);\n"
"		dst[start_addr] = convert_uchar4_sat(sum);\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void col_filter_C1_D5\n"
"(__global const float *restrict src,\n"
" __global float *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" //const int src_whole_cols,\n"
" //const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" //const int src_offset_x,\n"
" //const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int dst_offset_in_pixel,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSY + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_addr = mad24(y, src_step_in_pixel, x);\n"
"	int i;\n"
"	float sum;\n"
"	float temp[READ_TIMES_COL];\n"
"	\n"
"	__local float LDS_DAT[LSIZE1 * READ_TIMES_COL][LSIZE0 + 1];\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE1 * src_step_in_pixel];\n"
"	}\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		LDS_DAT[l_y + i * LSIZE1][l_x] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	//read pixels from lds and calculate the result\n"
"	sum = LDS_DAT[l_y + RADIUSY][l_x] * mat_kernel[RADIUSY];\n"
"	\n"
"	for (i = 1; i <= RADIUSY; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y + RADIUSY - i][l_x];\n"
"		temp[1] = LDS_DAT[l_y + RADIUSY + i][l_x];\n"
"		sum += temp[0] * mat_kernel[RADIUSY - i] + temp[1] * mat_kernel[RADIUSY + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x + dst_offset_in_pixel);\n"
"		dst[start_addr] = sum;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void col_filter_C4_D5\n"
"(__global const float4 *restrict src,\n"
" __global float4 *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" //const int src_whole_cols,\n"
" //const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" //const int src_offset_x,\n"
" //const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int dst_offset_in_pixel,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSY + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_addr = mad24(y, src_step_in_pixel, x);\n"
"	int i;\n"
"	float4 sum;\n"
"	float4 temp[READ_TIMES_COL];\n"
"	\n"
"	__local float4 LDS_DAT[LSIZE1 * READ_TIMES_COL][LSIZE0 + 1];\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE1 * src_step_in_pixel];\n"
"	}\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_COL; i++)\n"
"	{\n"
"		LDS_DAT[l_y + i * LSIZE1][l_x] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	//read pixels from lds and calculate the result\n"
"	sum = LDS_DAT[l_y + RADIUSY][l_x] * mat_kernel[RADIUSY];\n"
"	\n"
"	for (i = 1; i <= RADIUSY; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y + RADIUSY - i][l_x];\n"
"		temp[1] = LDS_DAT[l_y + RADIUSY + i][l_x];\n"
"		sum += temp[0] * mat_kernel[RADIUSY - i] + temp[1] * mat_kernel[RADIUSY + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x + dst_offset_in_pixel);\n"
"		dst[start_addr] = sum;\n"
"	}\n"
"}\n"
;
const char *filter_sep_row =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#define READ_TIMES_ROW ((2*(RADIUSX+LSIZE0)-1)/LSIZE0) //for c4 only\n"
"#define READ_TIMES_COL ((2*(RADIUSY+LSIZE1)-1)/LSIZE1)\n"
"//#pragma OPENCL EXTENSION cl_amd_printf : enable\n"
"#define RADIUS 1\n"
"#if CN ==1\n"
"#define ALIGN (((RADIUS)+3)>>2<<2)\n"
"#elif CN==2\n"
"#define ALIGN (((RADIUS)+1)>>1<<1)\n"
"#elif CN==3\n"
"#define ALIGN (((RADIUS)+3)>>2<<2)\n"
"#elif CN==4\n"
"#define ALIGN (RADIUS)\n"
"#endif\n"
"#ifdef BORDER_CONSTANT\n"
"//BORDER_CONSTANT:      iiiiii|abcdefgh|iiiiiii\n"
"#define ELEM(i,l_edge,r_edge,elem1,elem2) (i)<(l_edge) | (i) >= (r_edge) ? (elem1) : (elem2)\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#endif\n"
"#ifdef BORDER_REPLICATE\n"
"//BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n"
"#define ADDR_L(i,l_edge,r_edge,addr)  (i) < (l_edge) ? (l_edge) : (addr)\n"
"#define ADDR_R(i,r_edge,addr)   (i) >= (r_edge) ? (r_edge)-1 : (addr)\n"
"#endif\n"
"#ifdef BORDER_REFLECT\n"
"//BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n"
"#define ADDR_L(i,l_edge,r_edge,addr)  (i) < (l_edge) ? -(i)-1 : (addr)\n"
"#define ADDR_R(i,r_edge,addr) (i) >= (r_edge) ? -(i)-1+((r_edge)<<1) : (addr)\n"
"#endif\n"
"#ifdef BORDER_REFLECT_101\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define ADDR_L(i,l_edge,r_edge,addr)  (i) < (l_edge) ? -(i) : (addr)\n"
"#define ADDR_R(i,r_edge,addr) (i) >= (r_edge) ? -(i)-2+((r_edge)<<1) : (addr)\n"
"#endif\n"
"#ifdef BORDER_WRAP\n"
"//BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n"
"#define ADDR_L(i,l_edge,r_edge,addr)  (i) < (l_edge) ? (i)+(r_edge) : (addr)\n"
"#define ADDR_R(i,r_edge,addr)   (i) >= (r_edge) ?   (i)-(r_edge) : (addr)\n"
"#endif\n"
"/**********************************************************************************\n"
"These kernels are written for separable filters such as Sobel, Scharr, GaussianBlur.\n"
"Now(6/29/2011) the kernels only support 8U data type and the anchor of the convovle\n"
"kernel must be in the center. ROI is not supported either.\n"
"For channels =1,2,4, each kernels read 4 elements(not 4 pixels), and for channels =3,\n"
"the kernel read 4 pixels, save them to LDS and read the data needed from LDS to\n"
"calculate the result.\n"
"The length of the convovle kernel supported is related to the LSIZE0 and the MAX size\n"
"of LDS, which is HW related.\n"
"For channels = 1,3 the RADIUS is no more than LSIZE0*2\n"
"For channels = 2, the RADIUS is no more than LSIZE0\n"
"For channels = 4, arbitary RADIUS is supported unless the LDS is not enough\n"
"Niko\n"
"6/29/2011\n"
"***********************************************************************************/\n"
"/*\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1))) void row_filter_C1_D0\n"
"						(__global const uchar * restrict src,\n"
"						 __global float * dst,\n"
"                         const int cols,\n"
"                         const int rows,\n"
"						 const int src_whole_cols,\n"
"						 //const int src_whole_rows,\n"
"                         const int src_step_in_pixel,\n"
"                         const int src_offset_x,\n"
"                         const int src_offset_y,\n"
"                         const int dst_step_in_pixel,\n"
"                         const int dst_offset_in_pixel,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<2;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0);\n"
"    int l_y = get_local_id(1);\n"
"	int align = (src_offset_x - RADIUS) & 0xfffffffc;\n"
"	int inv_align = (src_offset_x - RADIUS) & 3;\n"
"    int i=0;\n"
"    float4 sum=0.0f;\n"
"	uchar4 temp[2];\n"
"	//int baseindex = mad24(y,src_step_in_pixel,x);\n"
"	int baserow = mad24(y,src_step_in_pixel,src_offset_y);\n"
"	__local uchar4 LDS_DAT[LSIZE1][LSIZE0*2+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	temp[0] = *(__global uchar4*)&src[baserow+x+align];\n"
"	temp[1] = *(__global uchar4*)&src[baserow+LSIZE0*4+x+align];\n"
"	temp[0].x = ELEM(x+align,0,src_whole_cols,0,temp[0].x);\n"
"	temp[0].y = ELEM(x+align+1,0,src_whole_cols,0,temp[0].y);\n"
"	temp[0].z = ELEM(x+align+2,0,src_whole_cols,0,temp[0].z);\n"
"	temp[0].w = ELEM(x+align+3,0,src_whole_cols,0,temp[0].w);\n"
"	temp[1].x = ELEM(x+LSIZE0*4+align,0,src_whole_cols,0,temp[1].x);\n"
"	temp[1].y = ELEM(x+LSIZE0*4+align+1,0,src_whole_cols,0,temp[1].y);\n"
"	temp[1].z = ELEM(x+LSIZE0*4+align+2,0,src_whole_cols,0,temp[1].z);\n"
"	temp[1].w = ELEM(x+LSIZE0*4+align+3,0,src_whole_cols,0,temp[1].w);\n"
"	#else\n"
"	int not_all_in_range = (x+offset_x-RADIUS<0) | (x+LSIZE0*4+align+4>src_whole_cols);\n"
"	int4 index[2];\n"
"	if(not_all_in_range)\n"
"	{\n"
"		index[0].x = ADDR_L(x+align,0,src_whole_cols);\n"
"		index[0].y = ADDR_L(x+align+1,0,src_whole_cols);\n"
"		index[0].z = ADDR_L(x+align+2,0,src_whole_cols);\n"
"		index[0].w = ADDR_L(x+align+3,0,src_whole_cols);\n"
"		index[0].x = ADDR_R(x+align,src_whole_cols,index[0].x);\n"
"		index[0].y = ADDR_R(x+align+1,src_whole_cols,index[0].y);\n"
"		index[0].z = ADDR_R(x+align+2,src_whole_cols,index[0].z);\n"
"		index[0].w = ADDR_R(x+align+3,src_whole_cols,index[0].w);\n"
"		index[1].x = ADDR_L(x+LSIZE0*4+align,0,src_whole_cols);\n"
"		index[1].y = ADDR_L(x+LSIZE0*4+align+1,0,src_whole_cols);\n"
"		index[1].z = ADDR_L(x+LSIZE0*4+align+2,0,src_whole_cols);\n"
"		index[1].w = ADDR_L(x+LSIZE0*4+align+3,0,src_whole_cols);\n"
"		index[1].x = ADDR_R(x+LSIZE0*4+align,src_whole_cols,index[1].x);\n"
"		index[1].y = ADDR_R(x+LSIZE0*4+align+1,src_whole_cols,index[1].y);\n"
"		index[1].z = ADDR_R(x+LSIZE0*4+align+2,src_whole_cols,index[1].z);\n"
"		index[1].w = ADDR_R(x+LSIZE0*4+align+3,src_whole_cols,index[1].w);\n"
"		temp[0].x = src[baserow+index[0].x];\n"
"		temp[0].y = src[baserow+index[0].y];\n"
"		temp[0].z = src[baserow+index[0].z];\n"
"		temp[0].w = src[baserow+index[0].w];\n"
"		temp[1].x = src[baserow+index[1].x];\n"
"		temp[1].y = src[baserow+index[1].y];\n"
"		temp[1].z = src[baserow+index[1].z];\n"
"		temp[1].w = src[baserow+index[1].w];\n"
"	}\n"
"	else\n"
"	{\n"
"		temp[0] = *(__global uchar4*)&src[baserow+x+align];\n"
"		temp[1] = *(__global uchar4*)&src[baserow+x+LSIZE0*4+align];\n"
"	}\n"
"	#endif\n"
"	LDS_DAT[l_y][l_x] = temp[0];\n"
"	LDS_DAT[l_y][l_x+LSIZE0] = temp[1];\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	int baseindex = mad24(y,dst_step_in_pixel,x+dst_offset_in_pixel);\n"
"	sum =convert_float4(vload4(0,(__local uchar*)&LDS_DAT[l_y][l_x]+inv_align+RADIUS))*mat_kernel[RADIUS];\n"
"	float4 prefetch_LDS[2];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		prefetch_LDS[0]=convert_float4(vload4(0,(__local uchar*)&LDS_DAT[l_y][l_x]+inv_align+RADIUS-i));\n"
"		prefetch_LDS[1]=convert_float4(vload4(0,(__local uchar*)&LDS_DAT[l_y][l_x]+inv_align+RADIUS+i));\n"
"		sum += prefetch_LDS[0]*mat_kernel[RADIUS-i]+prefetch_LDS[1]*mat_kernel[RADIUS+i];\n"
"	}\n"
"	if((x+3< cols) & (y < rows))\n"
"	{\n"
"		vstore4(sum,0,dst+baseindex);\n"
"	}\n"
"	else if((x< cols) & (y < rows))\n"
"	{\n"
"		size_t dst_addr_start = mad24(y,dst_step_in_pixel,dst_offset_in_pixel);\n"
"		size_t dst_addr_end = mad24(y,dst_step_in_pixel,cols+dst_offset_in_pixel);\n"
"		float4 temp_dst = vload4(0,dst+baseindex);\n"
"		temp_dst.x = (baseindex>=dst_addr_start)&(baseindex<dst_addr_end) ? sum.x : temp_dst.x;\n"
"		temp_dst.y = (baseindex+1>=dst_addr_start)&(baseindex+1<dst_addr_end) ? sum.y : temp_dst.y;\n"
"		temp_dst.z = (baseindex+2>=dst_addr_start)&(baseindex+2<dst_addr_end) ? sum.z : temp_dst.z;\n"
"		temp_dst.w = (baseindex+3>=dst_addr_start)&(baseindex+3<dst_addr_end) ? sum.w : temp_dst.w;\n"
"		vstore4(temp_dst,0,dst+baseindex);\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1))) void row_filter_C2_D0\n"
"						(__global const uchar * restrict src,\n"
"						 __global float * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<1;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0);\n"
"    int l_y = get_local_id(1);\n"
"    int i=0;\n"
"    float4 sum=0.0f;\n"
"	int2 index[2];\n"
"	uchar4 temp[2];\n"
"	int baseindex = mad24(y,src_pix_per_row,x<<1);\n"
"	int baserow = mul24(y,src_pix_per_row);\n"
"	__local uchar4 LDS_DAT[LSIZE1][LSIZE0*2];\n"
"	#ifdef BORDER_CONSTANT\n"
"	temp[0] = *(__global uchar4*)&src[baseindex-ALIGN*2];\n"
"	temp[1] = *(__global uchar4*)&src[baseindex+LSIZE0*4-ALIGN*2];\n"
"	temp[0].xy = ELEM(x-ALIGN,0,src_cols,0,temp[0].xy);\n"
"	temp[0].zw = ELEM(x-ALIGN+1,0,src_cols,0,temp[0].zw);\n"
"	temp[1].xy = ELEM(x+LSIZE0*2-ALIGN,0,src_cols,0,temp[1].xy);\n"
"	temp[1].zw = ELEM(x+LSIZE0*2-ALIGN+1,0,src_cols,0,temp[1].zw);\n"
"	#else\n"
"	int not_all_in_range = (x-RADIUS<0) | (x+LSIZE0*2-ALIGN+2>src_cols);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		index[0].x = ADDR_L(x-ALIGN,0,src_cols);\n"
"		index[0].y = ADDR_L(x-ALIGN+1,0,src_cols);\n"
"		index[0].x = ADDR_R(x-ALIGN,src_cols,index[0].x);\n"
"		index[0].y = ADDR_R(x-ALIGN+1,src_cols,index[0].y);\n"
"		index[1].x = ADDR_L(x+LSIZE0*2-ALIGN,0,src_cols);\n"
"		index[1].y = ADDR_L(x+LSIZE0*2-ALIGN+1,0,src_cols);\n"
"		index[1].x = ADDR_R(x+LSIZE0*2-ALIGN,src_cols,index[1].x);\n"
"		index[1].y = ADDR_R(x+LSIZE0*2-ALIGN+1,src_cols,index[1].y);\n"
"		temp[0].xy = *(__global uchar2*)&src[baserow+(index[0].x<<1)];\n"
"		temp[0].zw = *(__global uchar2*)&src[baserow+(index[0].y<<1)];\n"
"		temp[1].xy = *(__global uchar2*)&src[baserow+(index[1].x<<1)];\n"
"		temp[1].zw = *(__global uchar2*)&src[baserow+(index[1].y<<1)];\n"
"	}\n"
"	else\n"
"	{\n"
"		temp[0] = *(__global uchar4*)&src[baseindex-(ALIGN<<1)];\n"
"		temp[1] = *(__global uchar4*)&src[baseindex+((LSIZE0*2-ALIGN)<<1)];\n"
"	}\n"
"	#endif\n"
"	LDS_DAT[l_y][l_x] = temp[0];\n"
"	LDS_DAT[l_y][l_x+LSIZE0] = temp[1];\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum = convert_float4(LDS_DAT[l_y][l_x+ALIGN/2]);\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		float2 prefetch_LDS[4];\n"
"		prefetch_LDS[0]=convert_float2(vload2(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*2+RADIUS*2-2*i));\n"
"		prefetch_LDS[1]=convert_float2(vload2(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*2+RADIUS*2+2-2*i));\n"
"		prefetch_LDS[2]=convert_float2(vload2(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*2+RADIUS*2+2*i));\n"
"		prefetch_LDS[3]=convert_float2(vload2(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*2+RADIUS*2+2+2*i));\n"
"		sum.xy += prefetch_LDS[0]*mat_kernel[RADIUS-i]+prefetch_LDS[2]*mat_kernel[RADIUS+i];\n"
"		sum.zw += prefetch_LDS[1]*mat_kernel[RADIUS-i]+prefetch_LDS[3]*mat_kernel[RADIUS+i];\n"
"	}\n"
"	baseindex = mad24(y,dst_pix_per_row,x<<1);\n"
"	if((x< dst_cols) & (y < dst_rows))\n"
"	{\n"
"		*(__global float4*)&dst[baseindex] =sum;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1))) void row_filter_C3_D0\n"
"						(__global const uchar * restrict src,\n"
"						 __global float * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0)<<2;\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0)*3;\n"
"    int l_y = get_local_id(1);\n"
"    int i=0;\n"
"    float4 sum[3];\n"
"	int4 index[2];\n"
"	uchar4 temp[2*3];\n"
"	int baseindex = mad24(y,src_pix_per_row,x*3);\n"
"	int baserow = mul24(y,src_pix_per_row);\n"
"	__local uchar4 LDS_DAT[LSIZE1][LSIZE0*2*3+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	temp[0] = *(__global uchar4*)&src[baseindex-ALIGN*3];\n"
"	temp[1] = *(__global uchar4*)&src[baseindex-ALIGN*3+4];\n"
"	temp[2] = *(__global uchar4*)&src[baseindex-ALIGN*3+8];\n"
"	temp[3] = *(__global uchar4*)&src[baseindex+LSIZE0*12-ALIGN*3];\n"
"	temp[4] = *(__global uchar4*)&src[baseindex+LSIZE0*12-ALIGN*3+4];\n"
"	temp[5] = *(__global uchar4*)&src[baseindex+LSIZE0*12-ALIGN*3+8];\n"
"	temp[0].x = ELEM(x-ALIGN,0,src_cols,0,temp[0].x);\n"
"	temp[0].y = ELEM(x-ALIGN,0,src_cols,0,temp[0].y);\n"
"	temp[0].z = ELEM(x-ALIGN,0,src_cols,0,temp[0].z);\n"
"	temp[0].w = ELEM(x-ALIGN+1,0,src_cols,0,temp[0].w);\n"
"	temp[1].x = ELEM(x-ALIGN+1,0,src_cols,0,temp[1].x);\n"
"	temp[1].y = ELEM(x-ALIGN+1,0,src_cols,0,temp[1].y);\n"
"	temp[1].z = ELEM(x-ALIGN+2,0,src_cols,0,temp[1].z);\n"
"	temp[1].w = ELEM(x-ALIGN+2,0,src_cols,0,temp[1].w);\n"
"	temp[2].x = ELEM(x-ALIGN+2,0,src_cols,0,temp[2].x);\n"
"	temp[2].y = ELEM(x-ALIGN+3,0,src_cols,0,temp[2].y);\n"
"	temp[2].z = ELEM(x-ALIGN+3,0,src_cols,0,temp[2].z);\n"
"	temp[2].w = ELEM(x-ALIGN+3,0,src_cols,0,temp[2].w);\n"
"	temp[3].x = ELEM(x+LSIZE0*4-ALIGN,0,src_cols,0,temp[3].x);\n"
"	temp[3].y = ELEM(x+LSIZE0*4-ALIGN,0,src_cols,0,temp[3].y);\n"
"	temp[3].z = ELEM(x+LSIZE0*4-ALIGN,0,src_cols,0,temp[3].z);\n"
"	temp[3].w = ELEM(x+LSIZE0*4-ALIGN+1,0,src_cols,0,temp[3].w);\n"
"	temp[4].x = ELEM(x+LSIZE0*4-ALIGN+1,0,src_cols,0,temp[4].x);\n"
"	temp[4].y = ELEM(x+LSIZE0*4-ALIGN+1,0,src_cols,0,temp[4].y);\n"
"	temp[4].z = ELEM(x+LSIZE0*4-ALIGN+2,0,src_cols,0,temp[4].z);\n"
"	temp[4].w = ELEM(x+LSIZE0*4-ALIGN+2,0,src_cols,0,temp[4].w);\n"
"	temp[5].x = ELEM(x+LSIZE0*4-ALIGN+2,0,src_cols,0,temp[5].x);\n"
"	temp[5].y = ELEM(x+LSIZE0*4-ALIGN+3,0,src_cols,0,temp[5].y);\n"
"	temp[5].z = ELEM(x+LSIZE0*4-ALIGN+3,0,src_cols,0,temp[5].z);\n"
"	temp[5].w = ELEM(x+LSIZE0*4-ALIGN+3,0,src_cols,0,temp[5].w);\n"
"	#else\n"
"	int not_all_in_range = (x-RADIUS<0) | (x+LSIZE0*4-ALIGN+4>src_cols);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		index[0].x = ADDR_L(x-ALIGN,0,src_cols);\n"
"		index[0].x = ADDR_R(x-ALIGN,src_cols,index[0].x);\n"
"		index[0].y = ADDR_L(x-ALIGN+1,0,src_cols);\n"
"		index[0].y = ADDR_R(x-ALIGN+1,src_cols,index[0].y);\n"
"		index[0].z = ADDR_L(x-ALIGN+2,0,src_cols);\n"
"		index[0].z = ADDR_R(x-ALIGN+2,src_cols,index[0].z);\n"
"		index[0].w = ADDR_L(x-ALIGN+3,0,cols);\n"
"		index[0].w = ADDR_R(x-ALIGN+3,src_cols,index[0].w);\n"
"		index[1].x = ADDR_L(x+LSIZE0*4-ALIGN,0,src_cols);\n"
"		index[1].x = ADDR_R(x+LSIZE0*4-ALIGN,src_cols,index[1].x);\n"
"		index[1].y = ADDR_L(x+LSIZE0*4-ALIGN+1,0,src_cols);\n"
"		index[1].y = ADDR_R(x+LSIZE0*4-ALIGN+1,src_cols,index[1].y);\n"
"		index[1].z = ADDR_L(x+LSIZE0*4-ALIGN+2,0,src_cols);\n"
"		index[1].z = ADDR_R(x+LSIZE0*4-ALIGN+2,src_cols,index[1].z);\n"
"		index[1].w = ADDR_L(x+LSIZE0*4-ALIGN+3,0,src_cols);\n"
"		index[1].w = ADDR_R(x+LSIZE0*4-ALIGN+3,src_cols,index[1].w);\n"
"		index[0] = mad24(index[0],3,baserow);\n"
"		index[1] = mad24(index[1],3,baserow);\n"
"		temp[0].x =src[index[0].x];\n"
"		temp[0].y =src[index[0].x+1];\n"
"		temp[0].z =src[index[0].x+2];\n"
"		temp[0].w =src[index[0].y];\n"
"		temp[1].x =src[index[0].y+1];\n"
"		temp[1].y =src[index[0].y+2];\n"
"		temp[1].z =src[index[0].z];\n"
"		temp[1].w =src[index[0].z+1];\n"
"		temp[2].x =src[index[0].z+2];\n"
"		temp[2].y =src[index[0].w];\n"
"		temp[2].z =src[index[0].w+1];\n"
"		temp[2].w =src[index[0].w+2];\n"
"		temp[3].x =src[index[1].x];\n"
"		temp[3].y =src[index[1].x+1];\n"
"		temp[3].z =src[index[1].x+2];\n"
"		temp[3].w =src[index[1].y];\n"
"		temp[4].x =src[index[1].y+1];\n"
"		temp[4].y =src[index[1].y+2];\n"
"		temp[4].z =src[index[1].z];\n"
"		temp[4].w =src[index[1].z+1];\n"
"		temp[5].x =src[index[1].z+2];\n"
"		temp[5].y =src[index[1].w];\n"
"		temp[5].z =src[index[1].w+1];\n"
"		temp[5].w =src[index[1].w+2];\n"
"	}\n"
"	else\n"
"	{\n"
"		temp[0] = *(__global uchar4*)&src[baseindex-ALIGN*3];\n"
"		temp[1] = *(__global uchar4*)&src[baseindex-ALIGN*3+4];\n"
"		temp[2] = *(__global uchar4*)&src[baseindex-ALIGN*3+8];\n"
"		temp[3] = *(__global uchar4*)&src[baseindex+LSIZE0*12-ALIGN*3];\n"
"		temp[4] = *(__global uchar4*)&src[baseindex+LSIZE0*12-ALIGN*3+4];\n"
"		temp[5] = *(__global uchar4*)&src[baseindex+LSIZE0*12-ALIGN*3+8];\n"
"	}\n"
"	#endif\n"
"	LDS_DAT[l_y][l_x] = temp[0];\n"
"	LDS_DAT[l_y][l_x+1] = temp[1];\n"
"	LDS_DAT[l_y][l_x+2] = temp[2];\n"
"	LDS_DAT[l_y][l_x+LSIZE0*3] = temp[3];\n"
"	LDS_DAT[l_y][l_x+LSIZE0*3+1] = temp[4];\n"
"	LDS_DAT[l_y][l_x+LSIZE0*3+2] = temp[5];\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum[0] = 0.0f;\n"
"	sum[1] = 0.0f;\n"
"	sum[2] = 0.0f;\n"
"	for(;i<=2*RADIUS;i++)\n"
"	{\n"
"		float3 prefetch_LDS[4];\n"
"		prefetch_LDS[0]=convert_float3(vload3(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*3-RADIUS*3+3*i));\n"
"		prefetch_LDS[1]=convert_float3(vload3(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*3-RADIUS*3+3+3*i));\n"
"		prefetch_LDS[2]=convert_float3(vload3(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*3-RADIUS*3+6+3*i));\n"
"		prefetch_LDS[3]=convert_float3(vload3(0,(__local uchar*)&LDS_DAT[l_y][l_x]+ALIGN*3-RADIUS*3+9+3*i));\n"
"		sum[0].xyz += prefetch_LDS[0]*mat_kernel[i];\n"
"		sum[0].w += prefetch_LDS[1].x*mat_kernel[i];\n"
"		sum[1].xy += prefetch_LDS[1].yz*mat_kernel[i];\n"
"		sum[1].zw += prefetch_LDS[2].xy*mat_kernel[i];\n"
"		sum[2].x += prefetch_LDS[2].z*mat_kernel[i];\n"
"		sum[2].yzw += prefetch_LDS[3]*mat_kernel[i];\n"
"	}\n"
"	baseindex = mad24(y,dst_pix_per_row,x*3);\n"
"	if((x< dst_cols) & (y < dst_rows))\n"
"	{\n"
"		*(__global float4*)&dst[baseindex] = sum[0];\n"
"		*(__global float4*)&dst[baseindex+4] = sum[1];\n"
"		*(__global float4*)&dst[baseindex+8] = sum[2];\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1))) void row_filter_C4_D0\n"
"						(__global const uchar * restrict src,\n"
"						 __global float * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0);\n"
"    int l_y = get_local_id(1);\n"
"    int i=0;\n"
"    float4 sum=0.0f;\n"
"	int index[READ_TIMES_ROW];\n"
"	uchar4 temp[READ_TIMES_ROW];\n"
"	int baseindex = mad24(y,src_pix_per_row,x<<2);\n"
"	int baserow = mul24(y,src_pix_per_row);\n"
"	__local uchar4 LDS_DAT[LSIZE1][LSIZE0*READ_TIMES_ROW];\n"
"	#ifdef BORDER_CONSTANT\n"
"	for(int j=0;j<READ_TIMES_ROW;j++)\n"
"	{\n"
"		temp[j] = *(__global uchar4*)&src[baseindex+LSIZE0*4*j-ALIGN*4];\n"
"	}\n"
"	for(int j=0;j<READ_TIMES_ROW;j++)\n"
"	{\n"
"		temp[j] = ELEM(x+j*LSIZE0-ALIGN,0,src_cols,0,temp[j]);\n"
"	}\n"
"	#else\n"
"	int not_all_in_range = (x-RADIUS<0) | (x+READ_TIMES_ROW*LSIZE0-ALIGN>src_cols);\n"
"	if(not_all_in_range)\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_ROW;j++)\n"
"		{\n"
"			index[j] = ADDR_L(x+j*LSIZE0-ALIGN,0,src_cols);\n"
"			index[j] = ADDR_R(x+j*LSIZE0-ALIGN,src_cols,index[j]);\n"
"		}\n"
"		for(int j=0;j<READ_TIMES_ROW;j++)\n"
"		{\n"
"			temp[j] = *(__global uchar4*)&src[baserow+(index[j]<<2)];\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		for(int j=0;j<READ_TIMES_ROW;j++)\n"
"		{\n"
"			temp[j] = *(__global uchar4*)&src[baseindex+((j*LSIZE0-ALIGN)<<2)];\n"
"		}\n"
"	}\n"
"	#endif\n"
"	for(int j=0;j<READ_TIMES_ROW;j++)\n"
"	{\n"
"		LDS_DAT[l_y][l_x+j*LSIZE0] = temp[j];\n"
"	}\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	sum = convert_float4(LDS_DAT[l_y][l_x+RADIUS])*mat_kernel[RADIUS];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		float4 prefetch_LDS[2];\n"
"		prefetch_LDS[0]=convert_float4(LDS_DAT[l_y][l_x+RADIUS-i]);\n"
"		prefetch_LDS[1]=convert_float4(LDS_DAT[l_y][l_x+RADIUS+i]);\n"
"		sum += prefetch_LDS[0]*mat_kernel[RADIUS-i]+prefetch_LDS[1]*mat_kernel[RADIUS+i];\n"
"	}\n"
"	baseindex = mad24(y,dst_pix_per_row,x<<2);\n"
"	if((x< dst_cols) & (y < dst_rows))\n"
"	{\n"
"		*(__global float4*)&dst[baseindex] = sum;\n"
"	}\n"
"}\n"
"/*\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1))) void row_filter_C1_D5\n"
"						(__global const float * restrict src,\n"
"						 __global float * dst,\n"
"                         const int src_cols,\n"
"                         const int src_rows,\n"
"                         const int src_pix_per_row,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"                         const int dst_pix_per_row,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUS+1)))))\n"
"{\n"
"    int x = get_global_id(0);\n"
"    int y = get_global_id(1);\n"
"    int l_x = get_local_id(0);\n"
"    int l_y = get_local_id(1);\n"
"    int i;\n"
"    float sum;\n"
"	float temp[2];\n"
"	int baseindex = mad24(y,src_pix_per_row,x);\n"
"	int baserow = mul24(y,src_pix_per_row);\n"
"	__local float LDS_DAT[LSIZE1][LSIZE0*2+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	temp[0] = src[baseindex-RADIUS];\n"
"	temp[1] = src[baseindex+LSIZE0-RADIUS];\n"
"	temp[0] = ELEM(x-RADIUS,0,src_cols,0.0f,temp[0]);\n"
"	temp[1] = ELEM(x+LSIZE0-RADIUS,0,src_cols,0.0f,temp[1]);\n"
"	#else\n"
"	int index[2];\n"
"	index[0] = ADDR_L(x-RADIUS,0,src_cols);\n"
"	index[0] = ADDR_R(x-RADIUS,src_cols,index[0]);\n"
"	index[1] = ADDR_L(x+LSIZE0-RADIUS,0,src_cols);\n"
"	index[1] = ADDR_R(x+LSIZE0-RADIUS,src_cols,index[1]);\n"
"	temp[0] = src[baserow+index[0]];\n"
"	temp[1] = src[baserow+index[1]];\n"
"	#endif\n"
"	LDS_DAT[l_y][l_x] = temp[0];\n"
"	LDS_DAT[l_y][l_x+LSIZE0] = temp[1];\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	baseindex = mad24(y,dst_pix_per_row,x);\n"
"	sum =LDS_DAT[l_y][l_x+RADIUS]*mat_kernel[RADIUS];\n"
"	for(i=1;i<=RADIUS;i++)\n"
"	{\n"
"		temp[0]=LDS_DAT[l_y][l_x+RADIUS-i];\n"
"		temp[1]=LDS_DAT[l_y][l_x+RADIUS+i];\n"
"		sum += temp[0]*mat_kernel[RADIUS-i]+temp[1]*mat_kernel[RADIUS+i];\n"
"	}\n"
"	if((x< dst_cols) & (y < dst_rows))\n"
"	{\n"
"		dst[baseindex] = sum;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0,LSIZE1,1))) void row_filter_C1_D0\n"
"						(__global const uchar * restrict src,\n"
"						 __global float * dst,\n"
"                         const int dst_cols,\n"
"                         const int dst_rows,\n"
"						 const int src_whole_cols,\n"
"						 const int src_whole_rows,\n"
"                         const int src_step_in_pixel,\n"
"                         const int src_offset_x,\n"
"                         const int src_offset_y,\n"
"                         const int dst_step_in_pixel,\n"
"                         const int radiusy,\n"
"                         __constant float * mat_kernel __attribute__((max_constant_size(4*(2*RADIUSX+1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_x = x+src_offset_x-RADIUSX;\n"
"	int start_y = y+src_offset_y-radiusy;\n"
"	int start_addr = mad24(start_y,src_step_in_pixel,start_x);\n"
"	int i;\n"
"	float sum;\n"
"	uchar temp[READ_TIMES_ROW];\n"
"	__local uchar LDS_DAT[LSIZE1][READ_TIMES_ROW*LSIZE0+1];\n"
"	#ifdef BORDER_CONSTANT\n"
"	//read pixels from src\n"
"	for(i = 0;i<READ_TIMES_ROW;i++)\n"
"	{\n"
"		temp[i] = src[start_addr+i*LSIZE0];\n"
"	}\n"
"	//judge if read out of boundary\n"
"	for(i = 0;i<READ_TIMES_ROW;i++)\n"
"	{\n"
"		temp[i]= ELEM(start_x+i*LSIZE0,0,src_whole_cols,0,temp[i]);\n"
"		temp[i]= ELEM(start_y,0,src_whole_rows,0,temp[i]);\n"
"	}\n"
"	#else\n"
"	int index[READ_TIMES_ROW];\n"
"	//judge if read out of boundary\n"
"	for(i = 0;i<READ_TIMES_ROW;i++)\n"
"	{\n"
"		index[i]= ADDR_L(start_x+i*LSIZE0,0,src_whole_cols,start_x+i*LSIZE0);\n"
"		index[i]= ADDR_R(start_x+i*LSIZE0,src_whole_cols,index[i]);\n"
"		index[i]= ADDR_L(start_y,0,src_whole_rows,index[i]);\n"
"		index[i]= ADDR_R(start_y,src_whole_rows,index[i]);\n"
"	}\n"
"	//read pixels from src\n"
"	for(i = 0;i<READ_TIMES_ROW;i++)\n"
"	{\n"
"		temp[i] = src[start_addr+i*LSIZE0];\n"
"	}\n"
"	#endif\n"
"	//save pixels to lds\n"
"	for(i = 0;i<READ_TIMES_ROW;i++)\n"
"	{\n"
"		LDS_DAT[l_y][l_x+i*LSIZE0]=temp[i];\n"
"	}\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	//read pixels from lds and calculate the result\n"
"	sum =convert_float(LDS_DAT[l_y][l_x+RADIUSX])*mat_kernel[RADIUSX];\n"
"	for(i=1;i<=RADIUSX;i++)\n"
"	{\n"
"		temp[0]=LDS_DAT[l_y][l_x+RADIUSX-i];\n"
"		temp[1]=LDS_DAT[l_y][l_x+RADIUSX+i];\n"
"		sum += convert_float(temp[0])*mat_kernel[RADIUSX-i]+convert_float(temp[1])*mat_kernel[RADIUSX+i];\n"
"	}\n"
"	//write the result to dst\n"
"	if((x<dst_cols) & y<(dst_rows))\n"
"	{\n"
"		start_addr = mad24(y,dst_step_in_pixel,x);\n"
"		dst[start_addr] = sum;\n"
"	}\n"
"}*/\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void row_filter_C1_D0\n"
"(__global const uchar *restrict src,\n"
" __global float *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" const int src_whole_cols,\n"
" const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" const int src_offset_x,\n"
" const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int radiusy,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSX + 1)))))\n"
"{\n"
"	int x = get_global_id(0) << 2;\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_x = x + src_offset_x - RADIUSX & 0xfffffffc;\n"
"	int offset = src_offset_x - RADIUSX & 3;\n"
"	int start_y = y + src_offset_y - radiusy;\n"
"	int start_addr = mad24(start_y, src_step_in_pixel, start_x);\n"
"	int i;\n"
"	float4 sum;\n"
"	uchar4 temp[READ_TIMES_ROW];\n"
"	\n"
"	__local uchar4 LDS_DAT[LSIZE1][READ_TIMES_ROW * LSIZE0 + 1];\n"
"#ifdef BORDER_CONSTANT\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = *(__global uchar4 *)&src[start_addr + i * LSIZE0 * 4];\n"
"	}\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i].x = ELEM(start_x + i * LSIZE0 * 4, 0, src_whole_cols, 0, temp[i].x);\n"
"		temp[i].y = ELEM(start_x + i * LSIZE0 * 4 + 1, 0, src_whole_cols, 0, temp[i].y);\n"
"		temp[i].z = ELEM(start_x + i * LSIZE0 * 4 + 2, 0, src_whole_cols, 0, temp[i].z);\n"
"		temp[i].w = ELEM(start_x + i * LSIZE0 * 4 + 3, 0, src_whole_cols, 0, temp[i].w);\n"
"		temp[i] = ELEM(start_y, 0, src_whole_rows, 0, temp[i]);\n"
"	}\n"
"	\n"
"#else\n"
"	int not_all_in_range = (start_x < 0) | (start_x + READ_TIMES_ROW * LSIZE0 * 4 + 4 > src_whole_cols) | (start_y < 0) | (start_y >= src_whole_rows);\n"
"	int4 index[READ_TIMES_ROW];\n"
"	int4 addr;\n"
"	int s_y;\n"
"	\n"
"	if (not_all_in_range)\n"
"	{\n"
"		//judge if read out of boundary\n"
"		for (i = 0; i < READ_TIMES_ROW; i++)\n"
"		{\n"
"			index[i].x = ADDR_L(start_x + i * LSIZE0 * 4, 0, src_whole_cols, start_x + i * LSIZE0 * 4);\n"
"			index[i].x = ADDR_R(start_x + i * LSIZE0 * 4, src_whole_cols, index[i].x);\n"
"			index[i].y = ADDR_L(start_x + i * LSIZE0 * 4 + 1, 0, src_whole_cols, start_x + i * LSIZE0 * 4 + 1);\n"
"			index[i].y = ADDR_R(start_x + i * LSIZE0 * 4 + 1, src_whole_cols, index[i].y);\n"
"			index[i].z = ADDR_L(start_x + i * LSIZE0 * 4 + 2, 0, src_whole_cols, start_x + i * LSIZE0 * 4 + 2);\n"
"			index[i].z = ADDR_R(start_x + i * LSIZE0 * 4 + 2, src_whole_cols, index[i].z);\n"
"			index[i].w = ADDR_L(start_x + i * LSIZE0 * 4 + 3, 0, src_whole_cols, start_x + i * LSIZE0 * 4 + 3);\n"
"			index[i].w = ADDR_R(start_x + i * LSIZE0 * 4 + 3, src_whole_cols, index[i].w);\n"
"		}\n"
"	\n"
"		s_y = ADDR_L(start_y, 0, src_whole_rows, start_y);\n"
"		s_y = ADDR_R(start_y, src_whole_rows, s_y);\n"
"	\n"
"		//read pixels from src\n"
"		for (i = 0; i < READ_TIMES_ROW; i++)\n"
"		{\n"
"			addr = mad24((int4)s_y, (int4)src_step_in_pixel, index[i]);\n"
"			temp[i].x = src[addr.x];\n"
"			temp[i].y = src[addr.y];\n"
"			temp[i].z = src[addr.z];\n"
"			temp[i].w = src[addr.w];\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		//read pixels from src\n"
"		for (i = 0; i < READ_TIMES_ROW; i++)\n"
"		{\n"
"			temp[i] = *(__global uchar4 *)&src[start_addr + i * LSIZE0 * 4];\n"
"		}\n"
"	}\n"
"	\n"
"#endif\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		LDS_DAT[l_y][l_x + i * LSIZE0] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	//read pixels from lds and calculate the result\n"
"	sum = convert_float4(vload4(0, (__local uchar *)&LDS_DAT[l_y][l_x] + RADIUSX + offset)) * mat_kernel[RADIUSX];\n"
"	\n"
"	for (i = 1; i <= RADIUSX; i++)\n"
"	{\n"
"		temp[0] = vload4(0, (__local uchar *)&LDS_DAT[l_y][l_x] + RADIUSX + offset - i);\n"
"		temp[1] = vload4(0, (__local uchar *)&LDS_DAT[l_y][l_x] + RADIUSX + offset + i);\n"
"		sum += convert_float4(temp[0]) * mat_kernel[RADIUSX - i] + convert_float4(temp[1]) * mat_kernel[RADIUSX + i];\n"
"	}\n"
"	\n"
"	start_addr = mad24(y, dst_step_in_pixel, x);\n"
"	\n"
"	//write the result to dst\n"
"	if ((x + 3 < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		*(__global float4 *)&dst[start_addr] = sum;\n"
"	}\n"
"	else if ((x + 2 < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		dst[start_addr] = sum.x;\n"
"		dst[start_addr + 1] = sum.y;\n"
"		dst[start_addr + 2] = sum.z;\n"
"	}\n"
"	else if ((x + 1 < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		dst[start_addr] = sum.x;\n"
"		dst[start_addr + 1] = sum.y;\n"
"	}\n"
"	else if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		dst[start_addr] = sum.x;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void row_filter_C4_D0\n"
"(__global const uchar4 *restrict src,\n"
" __global float4 *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" const int src_whole_cols,\n"
" const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" const int src_offset_x,\n"
" const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int radiusy,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSX + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_x = x + src_offset_x - RADIUSX;\n"
"	int start_y = y + src_offset_y - radiusy;\n"
"	int start_addr = mad24(start_y, src_step_in_pixel, start_x);\n"
"	int i;\n"
"	float4 sum;\n"
"	uchar4 temp[READ_TIMES_ROW];\n"
"	\n"
"	__local uchar4 LDS_DAT[LSIZE1][READ_TIMES_ROW * LSIZE0 + 1];\n"
"#ifdef BORDER_CONSTANT\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE0];\n"
"	}\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = ELEM(start_x + i * LSIZE0, 0, src_whole_cols, 0, temp[i]);\n"
"		temp[i] = ELEM(start_y, 0, src_whole_rows, 0, temp[i]);\n"
"	}\n"
"	\n"
"#else\n"
"	int index[READ_TIMES_ROW];\n"
"	int s_x, s_y;\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		s_x = ADDR_L(start_x + i * LSIZE0, 0, src_whole_cols, start_x + i * LSIZE0);\n"
"		s_x = ADDR_R(start_x + i * LSIZE0, src_whole_cols, s_x);\n"
"		s_y = ADDR_L(start_y, 0, src_whole_rows, start_y);\n"
"		s_y = ADDR_R(start_y, src_whole_rows, s_y);\n"
"		index[i] = mad24(s_y, src_step_in_pixel, s_x);\n"
"	}\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = src[index[i]];\n"
"	}\n"
"	\n"
"#endif\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		LDS_DAT[l_y][l_x + i * LSIZE0] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	//read pixels from lds and calculate the result\n"
"	sum = convert_float4(LDS_DAT[l_y][l_x + RADIUSX]) * mat_kernel[RADIUSX];\n"
"	\n"
"	for (i = 1; i <= RADIUSX; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y][l_x + RADIUSX - i];\n"
"		temp[1] = LDS_DAT[l_y][l_x + RADIUSX + i];\n"
"		sum += convert_float4(temp[0]) * mat_kernel[RADIUSX - i] + convert_float4(temp[1]) * mat_kernel[RADIUSX + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x);\n"
"		dst[start_addr] = sum;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void row_filter_C1_D5\n"
"(__global const float *restrict src,\n"
" __global float *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" const int src_whole_cols,\n"
" const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" const int src_offset_x,\n"
" const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int radiusy,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSX + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_x = x + src_offset_x - RADIUSX;\n"
"	int start_y = y + src_offset_y - radiusy;\n"
"	int start_addr = mad24(start_y, src_step_in_pixel, start_x);\n"
"	int i;\n"
"	float sum;\n"
"	float temp[READ_TIMES_ROW];\n"
"	\n"
"	__local float LDS_DAT[LSIZE1][READ_TIMES_ROW * LSIZE0 + 1];\n"
"#ifdef BORDER_CONSTANT\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE0];\n"
"	}\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = ELEM(start_x + i * LSIZE0, 0, src_whole_cols, 0, temp[i]);\n"
"		temp[i] = ELEM(start_y, 0, src_whole_rows, 0, temp[i]);\n"
"	}\n"
"	\n"
"#else\n"
"	int index[READ_TIMES_ROW];\n"
"	int s_x, s_y;\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		s_x = ADDR_L(start_x + i * LSIZE0, 0, src_whole_cols, start_x + i * LSIZE0);\n"
"		s_x = ADDR_R(start_x + i * LSIZE0, src_whole_cols, s_x);\n"
"		s_y = ADDR_L(start_y, 0, src_whole_rows, start_y);\n"
"		s_y = ADDR_R(start_y, src_whole_rows, s_y);\n"
"		index[i] = mad24(s_y, src_step_in_pixel, s_x);\n"
"	}\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = src[index[i]];\n"
"	}\n"
"	\n"
"#endif\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		LDS_DAT[l_y][l_x + i * LSIZE0] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	//read pixels from lds and calculate the result\n"
"	sum = LDS_DAT[l_y][l_x + RADIUSX] * mat_kernel[RADIUSX];\n"
"	\n"
"	for (i = 1; i <= RADIUSX; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y][l_x + RADIUSX - i];\n"
"		temp[1] = LDS_DAT[l_y][l_x + RADIUSX + i];\n"
"		sum += temp[0] * mat_kernel[RADIUSX - i] + temp[1] * mat_kernel[RADIUSX + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x);\n"
"		dst[start_addr] = sum;\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(LSIZE0, LSIZE1, 1))) void row_filter_C4_D5\n"
"(__global const float4 *restrict src,\n"
" __global float4 *dst,\n"
" const int dst_cols,\n"
" const int dst_rows,\n"
" const int src_whole_cols,\n"
" const int src_whole_rows,\n"
" const int src_step_in_pixel,\n"
" const int src_offset_x,\n"
" const int src_offset_y,\n"
" const int dst_step_in_pixel,\n"
" const int radiusy,\n"
" __constant float *mat_kernel __attribute__((max_constant_size(4 * (2 * RADIUSX + 1)))))\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int l_x = get_local_id(0);\n"
"	int l_y = get_local_id(1);\n"
"	int start_x = x + src_offset_x - RADIUSX;\n"
"	int start_y = y + src_offset_y - radiusy;\n"
"	int start_addr = mad24(start_y, src_step_in_pixel, start_x);\n"
"	int i;\n"
"	float4 sum;\n"
"	float4 temp[READ_TIMES_ROW];\n"
"	\n"
"	__local float4 LDS_DAT[LSIZE1][READ_TIMES_ROW * LSIZE0 + 1];\n"
"#ifdef BORDER_CONSTANT\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = src[start_addr + i * LSIZE0];\n"
"	}\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = ELEM(start_x + i * LSIZE0, 0, src_whole_cols, 0, temp[i]);\n"
"		temp[i] = ELEM(start_y, 0, src_whole_rows, 0, temp[i]);\n"
"	}\n"
"	\n"
"#else\n"
"	int index[READ_TIMES_ROW];\n"
"	int s_x, s_y;\n"
"	\n"
"	//judge if read out of boundary\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		s_x = ADDR_L(start_x + i * LSIZE0, 0, src_whole_cols, start_x + i * LSIZE0);\n"
"		s_x = ADDR_R(start_x + i * LSIZE0, src_whole_cols, s_x);\n"
"		s_y = ADDR_L(start_y, 0, src_whole_rows, start_y);\n"
"		s_y = ADDR_R(start_y, src_whole_rows, s_y);\n"
"		index[i] = mad24(s_y, src_step_in_pixel, s_x);\n"
"	}\n"
"	\n"
"	//read pixels from src\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		temp[i] = src[index[i]];\n"
"	}\n"
"	\n"
"#endif\n"
"	\n"
"	//save pixels to lds\n"
"	for (i = 0; i < READ_TIMES_ROW; i++)\n"
"	{\n"
"		LDS_DAT[l_y][l_x + i * LSIZE0] = temp[i];\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	//read pixels from lds and calculate the result\n"
"	sum = LDS_DAT[l_y][l_x + RADIUSX] * mat_kernel[RADIUSX];\n"
"	\n"
"	for (i = 1; i <= RADIUSX; i++)\n"
"	{\n"
"		temp[0] = LDS_DAT[l_y][l_x + RADIUSX - i];\n"
"		temp[1] = LDS_DAT[l_y][l_x + RADIUSX + i];\n"
"		sum += temp[0] * mat_kernel[RADIUSX - i] + temp[1] * mat_kernel[RADIUSX + i];\n"
"	}\n"
"	\n"
"	//write the result to dst\n"
"	if ((x < dst_cols) & y < (dst_rows))\n"
"	{\n"
"		start_addr = mad24(y, dst_step_in_pixel, x);\n"
"		dst[start_addr] = sum;\n"
"	}\n"
"}\n"
;
const char *haarobjectdetect =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Wang Weiyan, wangweiyanster@gmail.com\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#pragma OPENCL EXTENSION cl_amd_printf : enable\n"
"#define CV_HAAR_FEATURE_MAX           3\n"
"#define calc_sum(rect,offset)        (sum[(rect).p0+offset] - sum[(rect).p1+offset] - sum[(rect).p2+offset] + sum[(rect).p3+offset])\n"
"#define calc_sum1(rect,offset,i)     (sum[(rect).p0[i]+offset] - sum[(rect).p1[i]+offset] - sum[(rect).p2[i]+offset] + sum[(rect).p3[i]+offset])\n"
"typedef int   sumtype;\n"
"typedef float sqsumtype;\n"
"typedef struct  __attribute__((aligned(128)))  GpuHidHaarFeature\n"
"{\n"
"    struct __attribute__((aligned(32)))\n"
"{\n"
"	int p0 __attribute__((aligned(4)));\n"
"	int p1 __attribute__((aligned(4)));\n"
"	int p2 __attribute__((aligned(4)));\n"
"	int p3 __attribute__((aligned(4)));\n"
"	float weight __attribute__((aligned(4)));\n"
"}\n"
"rect[CV_HAAR_FEATURE_MAX] __attribute__((aligned(32)));\n"
"}\n"
"GpuHidHaarFeature;\n"
"typedef struct __attribute__((aligned(128))) GpuHidHaarTreeNode\n"
"{\n"
"    int p[CV_HAAR_FEATURE_MAX][4] __attribute__((aligned(64)));\n"
"    float weight[CV_HAAR_FEATURE_MAX] /*__attribute__((aligned (16)))*/;\n"
"    float threshold /*__attribute__((aligned (4)))*/;\n"
"    float alpha[2] __attribute__((aligned(8)));\n"
"    int left __attribute__((aligned(4)));\n"
"    int right __attribute__((aligned(4)));\n"
"}\n"
"GpuHidHaarTreeNode;\n"
"typedef struct __attribute__((aligned(32))) GpuHidHaarClassifier\n"
"{\n"
"    int count __attribute__((aligned(4)));\n"
"    GpuHidHaarTreeNode *node __attribute__((aligned(8)));\n"
"    float *alpha __attribute__((aligned(8)));\n"
"}\n"
"GpuHidHaarClassifier;\n"
"typedef struct __attribute__((aligned(64))) GpuHidHaarStageClassifier\n"
"{\n"
"    int  count __attribute__((aligned(4)));\n"
"    float threshold __attribute__((aligned(4)));\n"
"    int two_rects __attribute__((aligned(4)));\n"
"    int reserved0 __attribute__((aligned(8)));\n"
"    int reserved1 __attribute__((aligned(8)));\n"
"    int reserved2 __attribute__((aligned(8)));\n"
"    int reserved3 __attribute__((aligned(8)));\n"
"}\n"
"GpuHidHaarStageClassifier;\n"
"typedef struct __attribute__((aligned(64))) GpuHidHaarClassifierCascade\n"
"{\n"
"    int  count __attribute__((aligned(4)));\n"
"    int  is_stump_based __attribute__((aligned(4)));\n"
"    int  has_tilted_features __attribute__((aligned(4)));\n"
"    int  is_tree __attribute__((aligned(4)));\n"
"    int pq0 __attribute__((aligned(4)));\n"
"    int pq1 __attribute__((aligned(4)));\n"
"    int pq2 __attribute__((aligned(4)));\n"
"    int pq3 __attribute__((aligned(4)));\n"
"    int p0 __attribute__((aligned(4)));\n"
"    int p1 __attribute__((aligned(4)));\n"
"    int p2 __attribute__((aligned(4)));\n"
"    int p3 __attribute__((aligned(4)));\n"
"    float inv_window_area __attribute__((aligned(4)));\n"
"} GpuHidHaarClassifierCascade;\n"
"__kernel void __attribute__((reqd_work_group_size(8, 8, 1)))gpuRunHaarClassifierCascade( //constant GpuHidHaarClassifierCascade * cascade,\n"
"    global GpuHidHaarStageClassifier *stagecascadeptr,\n"
"    global int4 *info,\n"
"    global GpuHidHaarTreeNode *nodeptr,\n"
"    global const int *restrict sum1,\n"
"    global const float *restrict sqsum1,\n"
"    global int4 *candidate,\n"
"    const int pixelstep,\n"
"    const int loopcount,\n"
"    const int start_stage,\n"
"    const int split_stage,\n"
"    const int end_stage,\n"
"    const int startnode,\n"
"    const int splitnode,\n"
"    const int4 p,\n"
"    const int4 pq,\n"
"    const float correction\n"
"    //const int width,\n"
"    //const int height,\n"
"    //const int grpnumperline,\n"
"    //const int totalgrp\n"
")\n"
"{\n"
"	int grpszx = get_local_size(0);\n"
"	int grpszy = get_local_size(1);\n"
"	int grpnumx = get_num_groups(0);\n"
"	int grpidx = get_group_id(0);\n"
"	int lclidx = get_local_id(0);\n"
"	int lclidy = get_local_id(1);\n"
"	\n"
"	int lcl_sz = mul24(grpszx, grpszy);\n"
"	int lcl_id = mad24(lclidy, grpszx, lclidx);\n"
"	\n"
"	//assume lcl_sz == 256 or 128 or 64\n"
"	//int lcl_sz_shift = (lcl_sz == 256) ? 8 : 7;\n"
"	//lcl_sz_shift = (lcl_sz == 64) ? 6 : lcl_sz_shift;\n"
"	__local int lclshare[1024];\n"
"	\n"
"#define OFF 0\n"
"	__local int *lcldata = lclshare + OFF;//for save win data\n"
"	__local int *glboutindex = lcldata + 28 * 28; //for save global out index\n"
"	__local int *lclcount = glboutindex + 1;//for save the numuber of temp pass pixel\n"
"	__local int *lcloutindex = lclcount + 1;//for save info of temp pass pixel\n"
"	__local float *partialsum = (__local float *)(lcloutindex + (lcl_sz << 1));\n"
"	glboutindex[0] = 0;\n"
"	int outputoff = mul24(grpidx, 256);\n"
"	\n"
"	//assume window size is 20X20\n"
"#define WINDOWSIZE 20+1\n"
"	//make sure readwidth is the multiple of 4\n"
"	//ystep =1, from host code\n"
"	int readwidth = ((grpszx - 1 + WINDOWSIZE + 3) >> 2) << 2;\n"
"	int readheight = grpszy - 1 + WINDOWSIZE;\n"
"	int read_horiz_cnt = readwidth >> 2;//each read int4\n"
"	int total_read = mul24(read_horiz_cnt, readheight);\n"
"	int read_loop = (total_read + lcl_sz - 1) >> 6;\n"
"	candidate[outputoff + (lcl_id << 2)] = (int4)0;\n"
"	candidate[outputoff + (lcl_id << 2) + 1] = (int4)0;\n"
"	candidate[outputoff + (lcl_id << 2) + 2] = (int4)0;\n"
"	candidate[outputoff + (lcl_id << 2) + 3] = (int4)0;\n"
"	\n"
"	for (int scalei = 0; scalei < loopcount; scalei++)\n"
"	{\n"
"		int4 scaleinfo1 = info[scalei];\n"
"		int width = (scaleinfo1.x & 0xffff0000) >> 16;\n"
"		int height = scaleinfo1.x & 0xffff;\n"
"		int grpnumperline = (scaleinfo1.y & 0xffff0000) >> 16;\n"
"		int totalgrp = scaleinfo1.y & 0xffff;\n"
"		int imgoff = scaleinfo1.z;\n"
"		float factor = as_float(scaleinfo1.w);\n"
"		//int ystep =1;// factor > 2.0 ? 1 : 2;\n"
"		\n"
"		__global const int *sum = sum1 + imgoff;\n"
"		__global const float *sqsum = sqsum1 + imgoff;\n"
"		\n"
"		for (int grploop = grpidx; grploop < totalgrp; grploop += grpnumx)\n"
"		{\n"
"			int grpidy = grploop / grpnumperline;\n"
"			int grpidx = grploop - mul24(grpidy, grpnumperline);\n"
"			int x = mad24(grpidx, grpszx, lclidx);\n"
"			int y = mad24(grpidy, grpszy, lclidy);\n"
"			//candidate_result.x = convert_int_rtn(x*factor);\n"
"			//candidate_result.y = convert_int_rtn(y*factor);\n"
"			int grpoffx = x - lclidx;\n"
"			int grpoffy = y - lclidy;\n"
"			\n"
"			for (int i = 0; i < read_loop; i++)\n"
"			{\n"
"				int pos_id = mad24(i, lcl_sz, lcl_id);\n"
"				pos_id = pos_id < total_read ? pos_id : 0;\n"
"				\n"
"				int lcl_y = pos_id / read_horiz_cnt;\n"
"				int lcl_x = pos_id - mul24(lcl_y, read_horiz_cnt);\n"
"				\n"
"				int glb_x = grpoffx + (lcl_x << 2);\n"
"				int glb_y = grpoffy + lcl_y;\n"
"				\n"
"				int glb_off = mad24(glb_y, pixelstep, glb_x);\n"
"				int4 data = *(__global int4 *)&sum[glb_off];\n"
"				int lcl_off = mad24(lcl_y, readwidth, lcl_x << 2);\n"
"				\n"
"				lcldata[lcl_off] = data.x;\n"
"				lcldata[lcl_off + 1] = data.y;\n"
"				lcldata[lcl_off + 2] = data.z;\n"
"				lcldata[lcl_off + 3] = data.w;\n"
"			}\n"
"			\n"
"			lcloutindex[lcl_id] = 0;\n"
"			lclcount[0] = 0;\n"
"			int result = 1;\n"
"			int nodecounter = startnode;\n"
"			float mean, variance_norm_factor;\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			\n"
"			int lcl_off = mad24(lclidy, readwidth, lclidx);\n"
"			int4 cascadeinfo1, cascadeinfo2;\n"
"			cascadeinfo1 = p;\n"
"			cascadeinfo2 = pq;// + mad24(y, pixelstep, x);\n"
"			\n"
"			\n"
"			//if((x < width) && (y < height))\n"
"			{\n"
"				cascadeinfo1.x += lcl_off;\n"
"				cascadeinfo1.z += lcl_off;\n"
"				mean = (lcldata[mad24(cascadeinfo1.y, readwidth, cascadeinfo1.x)] - lcldata[mad24(cascadeinfo1.y, readwidth, cascadeinfo1.z)] -\n"
"				        lcldata[mad24(cascadeinfo1.w, readwidth, cascadeinfo1.x)] + lcldata[mad24(cascadeinfo1.w, readwidth, cascadeinfo1.z)])\n"
"				       * correction;\n"
"				       \n"
"				int p_offset = mad24(y, pixelstep, x);\n"
"				\n"
"				cascadeinfo2.x += p_offset;\n"
"				cascadeinfo2.z += p_offset;\n"
"				variance_norm_factor = sqsum[mad24(cascadeinfo2.y, pixelstep, cascadeinfo2.x)] - sqsum[mad24(cascadeinfo2.y, pixelstep, cascadeinfo2.z)] -\n"
"				                       sqsum[mad24(cascadeinfo2.w, pixelstep, cascadeinfo2.x)] + sqsum[mad24(cascadeinfo2.w, pixelstep, cascadeinfo2.z)];\n"
"				                       \n"
"				variance_norm_factor = variance_norm_factor * correction - mean * mean;\n"
"				variance_norm_factor = variance_norm_factor >= 0.f ? sqrt(variance_norm_factor) : 1.f;\n"
"				\n"
"				//if( cascade->is_stump_based )\n"
"				//{\n"
"				for (int stageloop = start_stage; (stageloop < split_stage)  && result; stageloop++)\n"
"				{\n"
"					float stage_sum = 0.f;\n"
"					int2 stageinfo = *(global int2 *)(stagecascadeptr + stageloop);\n"
"					float stagethreshold = as_float(stageinfo.y);\n"
"					\n"
"					for (int nodeloop = 0; nodeloop < stageinfo.x; nodeloop++)\n"
"					{\n"
"						__global GpuHidHaarTreeNode *currentnodeptr = (nodeptr + nodecounter);\n"
"						\n"
"						int4 info1 = *(__global int4 *)(&(currentnodeptr->p[0][0]));\n"
"						int4 info2 = *(__global int4 *)(&(currentnodeptr->p[1][0]));\n"
"						int4 info3 = *(__global int4 *)(&(currentnodeptr->p[2][0]));\n"
"						float4 w = *(__global float4 *)(&(currentnodeptr->weight[0]));\n"
"						float2 alpha2 = *(__global float2 *)(&(currentnodeptr->alpha[0]));\n"
"						float nodethreshold  = w.w * variance_norm_factor;\n"
"						\n"
"						info1.x += lcl_off;\n"
"						info1.z += lcl_off;\n"
"						info2.x += lcl_off;\n"
"						info2.z += lcl_off;\n"
"						\n"
"						float classsum = (lcldata[mad24(info1.y, readwidth, info1.x)] - lcldata[mad24(info1.y, readwidth, info1.z)] -\n"
"						                  lcldata[mad24(info1.w, readwidth, info1.x)] + lcldata[mad24(info1.w, readwidth, info1.z)]) * w.x;\n"
"						                  \n"
"						                  \n"
"						classsum += (lcldata[mad24(info2.y, readwidth, info2.x)] - lcldata[mad24(info2.y, readwidth, info2.z)] -\n"
"						             lcldata[mad24(info2.w, readwidth, info2.x)] + lcldata[mad24(info2.w, readwidth, info2.z)]) * w.y;\n"
"						             \n"
"						             \n"
"						//if((info3.z - info3.x) && (!stageinfo.z))\n"
"						//{\n"
"						info3.x += lcl_off;\n"
"						info3.z += lcl_off;\n"
"						classsum += (lcldata[mad24(info3.y, readwidth, info3.x)] - lcldata[mad24(info3.y, readwidth, info3.z)] -\n"
"						             lcldata[mad24(info3.w, readwidth, info3.x)] + lcldata[mad24(info3.w, readwidth, info3.z)]) * w.z;\n"
"						//}\n"
"						stage_sum += classsum >= nodethreshold ? alpha2.y : alpha2.x;\n"
"						nodecounter++;\n"
"					}\n"
"					\n"
"					result = (stage_sum >= stagethreshold);\n"
"				}\n"
"				\n"
"				if (result && (x < width) && (y < height))\n"
"				{\n"
"					int queueindex = atomic_inc(lclcount);\n"
"					lcloutindex[queueindex << 1] = (lclidy << 16) | lclidx;\n"
"					lcloutindex[(queueindex << 1) + 1] = as_int(variance_norm_factor);\n"
"				}\n"
"				\n"
"				barrier(CLK_LOCAL_MEM_FENCE);\n"
"				int queuecount  = lclcount[0];\n"
"				nodecounter = splitnode;\n"
"				\n"
"				for (int stageloop = split_stage; stageloop < end_stage && queuecount > 0; stageloop++)\n"
"				{\n"
"					lclcount[0] = 0;\n"
"					barrier(CLK_LOCAL_MEM_FENCE);\n"
"					\n"
"					int2 stageinfo = *(global int2 *)(stagecascadeptr + stageloop);\n"
"					float stagethreshold = as_float(stageinfo.y);\n"
"					\n"
"					int perfscale = queuecount > 4 ? 3 : 2;\n"
"					int queuecount_loop = (queuecount + (1 << perfscale) - 1) >> perfscale;\n"
"					int lcl_compute_win = lcl_sz >> perfscale;\n"
"					int lcl_compute_win_id = (lcl_id >> (6 - perfscale));\n"
"					int lcl_loops = (stageinfo.x + lcl_compute_win - 1) >> (6 - perfscale);\n"
"					int lcl_compute_id = lcl_id - (lcl_compute_win_id << (6 - perfscale));\n"
"					\n"
"					for (int queueloop = 0; queueloop < queuecount_loop && lcl_compute_win_id < queuecount; queueloop++)\n"
"					{\n"
"						float stage_sum = 0.f;\n"
"						int temp_coord = lcloutindex[lcl_compute_win_id << 1];\n"
"						float variance_norm_factor = as_float(lcloutindex[(lcl_compute_win_id << 1) + 1]);\n"
"						int queue_pixel = mad24(((temp_coord  & (int)0xffff0000) >> 16), readwidth, temp_coord & 0xffff);\n"
"						\n"
"						int tempnodecounter = lcl_compute_id;\n"
"						float part_sum = 0.f;\n"
"						\n"
"						for (int lcl_loop = 0; lcl_loop < lcl_loops && tempnodecounter < stageinfo.x; lcl_loop++)\n"
"						{\n"
"							__global GpuHidHaarTreeNode *currentnodeptr = (nodeptr + nodecounter + tempnodecounter);\n"
"							\n"
"							int4 info1 = *(__global int4 *)(&(currentnodeptr->p[0][0]));\n"
"							int4 info2 = *(__global int4 *)(&(currentnodeptr->p[1][0]));\n"
"							int4 info3 = *(__global int4 *)(&(currentnodeptr->p[2][0]));\n"
"							float4 w = *(__global float4 *)(&(currentnodeptr->weight[0]));\n"
"							float2 alpha2 = *(__global float2 *)(&(currentnodeptr->alpha[0]));\n"
"							float nodethreshold  = w.w * variance_norm_factor;\n"
"							\n"
"							info1.x += queue_pixel;\n"
"							info1.z += queue_pixel;\n"
"							info2.x += queue_pixel;\n"
"							info2.z += queue_pixel;\n"
"							\n"
"							float classsum = (lcldata[mad24(info1.y, readwidth, info1.x)] - lcldata[mad24(info1.y, readwidth, info1.z)] -\n"
"							                  lcldata[mad24(info1.w, readwidth, info1.x)] + lcldata[mad24(info1.w, readwidth, info1.z)]) * w.x;\n"
"							                  \n"
"							                  \n"
"							classsum += (lcldata[mad24(info2.y, readwidth, info2.x)] - lcldata[mad24(info2.y, readwidth, info2.z)] -\n"
"							             lcldata[mad24(info2.w, readwidth, info2.x)] + lcldata[mad24(info2.w, readwidth, info2.z)]) * w.y;\n"
"							//if((info3.z - info3.x) && (!stageinfo.z))\n"
"							//{\n"
"							info3.x += queue_pixel;\n"
"							info3.z += queue_pixel;\n"
"							classsum += (lcldata[mad24(info3.y, readwidth, info3.x)] - lcldata[mad24(info3.y, readwidth, info3.z)] -\n"
"							             lcldata[mad24(info3.w, readwidth, info3.x)] + lcldata[mad24(info3.w, readwidth, info3.z)]) * w.z;\n"
"							//}\n"
"							part_sum += classsum >= nodethreshold ? alpha2.y : alpha2.x;\n"
"							tempnodecounter += lcl_compute_win;\n"
"						}//end for(int lcl_loop=0;lcl_loop<lcl_loops;lcl_loop++)\n"
"						\n"
"						partialsum[lcl_id] = part_sum;\n"
"						barrier(CLK_LOCAL_MEM_FENCE);\n"
"						\n"
"						for (int i = 0; i < lcl_compute_win && (lcl_compute_id == 0); i++)\n"
"						{\n"
"							stage_sum += partialsum[lcl_id + i];\n"
"						}\n"
"						\n"
"						if (stage_sum >= stagethreshold && (lcl_compute_id == 0))\n"
"						{\n"
"							int queueindex = atomic_inc(lclcount);\n"
"							lcloutindex[queueindex << 1] = temp_coord;\n"
"							lcloutindex[(queueindex << 1) + 1] = as_int(variance_norm_factor);\n"
"						}\n"
"						\n"
"						lcl_compute_win_id += (1 << perfscale);\n"
"						barrier(CLK_LOCAL_MEM_FENCE);\n"
"					}//end for(int queueloop=0;queueloop<queuecount_loop;queueloop++)\n"
"					\n"
"					queuecount = lclcount[0];\n"
"					nodecounter += stageinfo.x;\n"
"				}//end for(int stageloop = splitstage; stageloop< endstage && queuecount>0;stageloop++)\n"
"				\n"
"				if (lcl_id < queuecount)\n"
"				{\n"
"					int temp = lcloutindex[lcl_id << 1];\n"
"					int x = mad24(grpidx, grpszx, temp & 0xffff);\n"
"					int y = mad24(grpidy, grpszy, ((temp & (int)0xffff0000) >> 16));\n"
"					temp = glboutindex[0];\n"
"					int4 candidate_result;\n"
"					candidate_result.zw = (int2)convert_int_rtn(factor * 20.f);\n"
"					candidate_result.x = convert_int_rtn(x * factor);\n"
"					candidate_result.y = convert_int_rtn(y * factor);\n"
"					atomic_inc(glboutindex);\n"
"					candidate[outputoff + temp + lcl_id] = candidate_result;\n"
"				}\n"
"				\n"
"				barrier(CLK_LOCAL_MEM_FENCE);\n"
"			}//end if((x < width) && (y < height))\n"
"		}//end for(int grploop=grpidx;grploop<totalgrp;grploop+=grpnumx)\n"
"		\n"
"		//outputoff +=mul24(width,height);\n"
"	}//end for(int scalei = 0; scalei <loopcount; scalei++)\n"
"}\n"
"/*\n"
"if(stagecascade->two_rects)\n"
"{\n"
"    #pragma unroll\n"
"    for( n = 0; n < stagecascade->count; n++ )\n"
"    {\n"
"        t1 = *(node + counter);\n"
"        t = t1.threshold * variance_norm_factor;\n"
"        classsum = calc_sum1(t1,p_offset,0) * t1.weight[0];\n"
"        classsum  += calc_sum1(t1, p_offset,1) * t1.weight[1];\n"
"        stage_sum += classsum >= t ? t1.alpha[1]:t1.alpha[0];\n"
"        counter++;\n"
"    }\n"
"}\n"
"else\n"
"{\n"
"    #pragma unroll\n"
"    for( n = 0; n < stagecascade->count; n++ )\n"
"    {\n"
"        t = node[counter].threshold*variance_norm_factor;\n"
"        classsum = calc_sum1(node[counter],p_offset,0) * node[counter].weight[0];\n"
"        classsum += calc_sum1(node[counter],p_offset,1) * node[counter].weight[1];\n"
"        if( node[counter].p0[2] )\n"
"            classsum += calc_sum1(node[counter],p_offset,2) * node[counter].weight[2];\n"
"        stage_sum += classsum >= t ? node[counter].alpha[1]:node[counter].alpha[0];// modify\n"
"        counter++;\n"
"    }\n"
"}\n"
"*/\n"
"/*\n"
"__kernel void gpuRunHaarClassifierCascade_ScaleWindow(\n"
"						  constant GpuHidHaarClassifierCascade * _cascade,\n"
"						  global GpuHidHaarStageClassifier * stagecascadeptr,\n"
"                          //global GpuHidHaarClassifier * classifierptr,\n"
"						  global GpuHidHaarTreeNode * nodeptr,\n"
"                          global int * sum,\n"
"						  global float * sqsum,\n"
"						  global int * _candidate,\n"
"                          int pixel_step,\n"
"						  int cols,\n"
"						  int rows,\n"
"						  int start_stage,\n"
"						  int end_stage,\n"
"                          //int counts,\n"
"						  int nodenum,\n"
"						  int ystep,\n"
"						  int detect_width,\n"
"						  //int detect_height,\n"
"						  int loopcount,\n"
"						  int outputstep)\n"
"						  //float scalefactor)\n"
"{\n"
"unsigned int x1 = get_global_id(0);\n"
"unsigned int y1 = get_global_id(1);\n"
"int p_offset;\n"
"int m, n;\n"
"int result;\n"
"int counter;\n"
"float mean, variance_norm_factor;\n"
"for(int i=0;i<loopcount;i++)\n"
"{\n"
"constant GpuHidHaarClassifierCascade * cascade = _cascade + i;\n"
"global int * candidate = _candidate + i*outputstep;\n"
"int window_width = cascade->p1 - cascade->p0;\n"
"int window_height = window_width;\n"
"result = 1;\n"
"counter = 0;\n"
"unsigned int x = mul24(x1,ystep);\n"
"unsigned int y = mul24(y1,ystep);\n"
"if((x < cols - window_width - 1) && (y < rows - window_height -1))\n"
"{\n"
"global GpuHidHaarStageClassifier *stagecascade = stagecascadeptr +cascade->count*i+ start_stage;\n"
"//global GpuHidHaarClassifier      *classifier   = classifierptr;\n"
"global GpuHidHaarTreeNode        *node         = nodeptr + nodenum*i;\n"
"p_offset = mad24(y, pixel_step, x);// modify\n"
"mean = (*(sum + p_offset + (int)cascade->p0) - *(sum + p_offset + (int)cascade->p1) -\n"
"	*(sum + p_offset + (int)cascade->p2) + *(sum + p_offset + (int)cascade->p3))\n"
"	*cascade->inv_window_area;\n"
"variance_norm_factor = *(sqsum + p_offset + cascade->p0) - *(sqsum + cascade->p1 + p_offset) -\n"
"					*(sqsum + p_offset + cascade->p2) + *(sqsum + cascade->p3 + p_offset);\n"
"variance_norm_factor = variance_norm_factor * cascade->inv_window_area - mean * mean;\n"
"variance_norm_factor = variance_norm_factor >=0.f ? sqrt(variance_norm_factor) : 1;//modify\n"
"// if( cascade->is_stump_based )\n"
"//{\n"
"for( m = start_stage; m < end_stage; m++ )\n"
"{\n"
" float stage_sum = 0.f;\n"
" float t,  classsum;\n"
" GpuHidHaarTreeNode t1;\n"
" //#pragma unroll\n"
" for( n = 0; n < stagecascade->count; n++ )\n"
" {\n"
"      t1 = *(node + counter);\n"
"      t  = t1.threshold * variance_norm_factor;\n"
"      classsum = calc_sum1(t1, p_offset ,0) * t1.weight[0] + calc_sum1(t1, p_offset ,1) * t1.weight[1];\n"
"      if((t1.p0[2]) && (!stagecascade->two_rects))\n"
"          classsum += calc_sum1(t1, p_offset, 2) * t1.weight[2];\n"
"      stage_sum += classsum >= t ? t1.alpha[1] : t1.alpha[0];// modify\n"
"      counter++;\n"
" }\n"
" if (stage_sum < stagecascade->threshold)\n"
" {\n"
"	result = 0;\n"
"     break;\n"
" }\n"
" stagecascade++;\n"
"}\n"
"if(result)\n"
"{\n"
"	candidate[4 * (y1 * detect_width + x1)]     = x;\n"
"	candidate[4 * (y1 * detect_width + x1) + 1] = y;\n"
"	candidate[4 * (y1 * detect_width + x1)+2]     = window_width;\n"
"	candidate[4 * (y1 * detect_width + x1) + 3] = window_height;\n"
"}\n"
"//}\n"
"}\n"
"}\n"
"}\n"
"*/\n"
;
const char *haarobjectdetect_scaled2 =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Wu Xinglong, wxl370@126.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"// Enter your kernel in this window\n"
"#pragma OPENCL EXTENSION cl_amd_printf:enable\n"
"#define CV_HAAR_FEATURE_MAX           3\n"
"typedef int   sumtype;\n"
"typedef float sqsumtype;\n"
"typedef struct  __attribute__((aligned(128)))  GpuHidHaarFeature\n"
"{\n"
"    struct __attribute__((aligned(32)))\n"
"{\n"
"	int p0 __attribute__((aligned(4)));\n"
"	int p1 __attribute__((aligned(4)));\n"
"	int p2 __attribute__((aligned(4)));\n"
"	int p3 __attribute__((aligned(4)));\n"
"	float weight __attribute__((aligned(4)));\n"
"}\n"
"rect[CV_HAAR_FEATURE_MAX] __attribute__((aligned(32)));\n"
"}\n"
"GpuHidHaarFeature;\n"
"typedef struct __attribute__((aligned(128))) GpuHidHaarTreeNode\n"
"{\n"
"    int p[CV_HAAR_FEATURE_MAX][4] __attribute__((aligned(64)));\n"
"    float weight[CV_HAAR_FEATURE_MAX] /*__attribute__((aligned (16)))*/;\n"
"    float threshold /*__attribute__((aligned (4)))*/;\n"
"    float alpha[2] __attribute__((aligned(8)));\n"
"    int left __attribute__((aligned(4)));\n"
"    int right __attribute__((aligned(4)));\n"
"}\n"
"GpuHidHaarTreeNode;\n"
"typedef struct __attribute__((aligned(32))) GpuHidHaarClassifier\n"
"{\n"
"    int count __attribute__((aligned(4)));\n"
"    GpuHidHaarTreeNode *node __attribute__((aligned(8)));\n"
"    float *alpha __attribute__((aligned(8)));\n"
"}\n"
"GpuHidHaarClassifier;\n"
"typedef struct __attribute__((aligned(64))) GpuHidHaarStageClassifier\n"
"{\n"
"    int  count __attribute__((aligned(4)));\n"
"    float threshold __attribute__((aligned(4)));\n"
"    int two_rects __attribute__((aligned(4)));\n"
"    int reserved0 __attribute__((aligned(8)));\n"
"    int reserved1 __attribute__((aligned(8)));\n"
"    int reserved2 __attribute__((aligned(8)));\n"
"    int reserved3 __attribute__((aligned(8)));\n"
"}\n"
"GpuHidHaarStageClassifier;\n"
"typedef struct __attribute__((aligned(64))) GpuHidHaarClassifierCascade\n"
"{\n"
"    int  count __attribute__((aligned(4)));\n"
"    int  is_stump_based __attribute__((aligned(4)));\n"
"    int  has_tilted_features __attribute__((aligned(4)));\n"
"    int  is_tree __attribute__((aligned(4)));\n"
"    int pq0 __attribute__((aligned(4)));\n"
"    int pq1 __attribute__((aligned(4)));\n"
"    int pq2 __attribute__((aligned(4)));\n"
"    int pq3 __attribute__((aligned(4)));\n"
"    int p0 __attribute__((aligned(4)));\n"
"    int p1 __attribute__((aligned(4)));\n"
"    int p2 __attribute__((aligned(4)));\n"
"    int p3 __attribute__((aligned(4)));\n"
"    float inv_window_area __attribute__((aligned(4)));\n"
"} GpuHidHaarClassifierCascade;\n"
"__kernel void gpuRunHaarClassifierCascade_scaled2(\n"
"    global GpuHidHaarStageClassifier *stagecascadeptr,\n"
"    global int4 *info,\n"
"    global GpuHidHaarTreeNode *nodeptr,\n"
"    global const int *restrict sum,\n"
"    global const float   *restrict sqsum,\n"
"    global int4 *candidate,\n"
"    const int step,\n"
"    const int loopcount,\n"
"    const int start_stage,\n"
"    const int split_stage,\n"
"    const int end_stage,\n"
"    const int startnode,\n"
"    const int splitnode,\n"
"    global int4 *p,\n"
"    //const int4 * pq,\n"
"    global float *correction,\n"
"    const int nodecount)\n"
"{\n"
"	int grpszx = get_local_size(0);\n"
"	int grpszy = get_local_size(1);\n"
"	int grpnumx = get_num_groups(0);\n"
"	int grpidx = get_group_id(0);\n"
"	int lclidx = get_local_id(0);\n"
"	int lclidy = get_local_id(1);\n"
"	int lcl_sz = mul24(grpszx, grpszy);\n"
"	int lcl_id = mad24(lclidy, grpszx, lclidx);\n"
"	__local int lclshare[1024];\n"
"	__local int *glboutindex = lclshare + 0;\n"
"	__local int *lclcount = glboutindex + 1;\n"
"	__local int *lcloutindex = lclcount + 1;\n"
"	__local float *partialsum = (__local float *)(lcloutindex + (lcl_sz << 1));\n"
"	glboutindex[0] = 0;\n"
"	int outputoff = mul24(grpidx, 256);\n"
"	candidate[outputoff + (lcl_id << 2)] = (int4)0;\n"
"	candidate[outputoff + (lcl_id << 2) + 1] = (int4)0;\n"
"	candidate[outputoff + (lcl_id << 2) + 2] = (int4)0;\n"
"	candidate[outputoff + (lcl_id << 2) + 3] = (int4)0;\n"
"	\n"
"	for (int scalei = 0; scalei < loopcount; scalei++)\n"
"	{\n"
"		int4 scaleinfo1;\n"
"		scaleinfo1 = info[scalei];\n"
"		int width = (scaleinfo1.x & 0xffff0000) >> 16;\n"
"		int height = scaleinfo1.x & 0xffff;\n"
"		int grpnumperline = (scaleinfo1.y & 0xffff0000) >> 16;\n"
"		int totalgrp = scaleinfo1.y & 0xffff;\n"
"		float factor = as_float(scaleinfo1.w);\n"
"		float correction_t = correction[scalei];\n"
"		int ystep = (int)(max(2.0f, factor) + 0.5f);\n"
"		\n"
"		for (int grploop = get_group_id(0); grploop < totalgrp; grploop += grpnumx)\n"
"		{\n"
"			int4 cascadeinfo = p[scalei];\n"
"			int grpidy = grploop / grpnumperline;\n"
"			int grpidx = grploop - mul24(grpidy, grpnumperline);\n"
"			int ix = mad24(grpidx, grpszx, lclidx);\n"
"			int iy = mad24(grpidy, grpszy, lclidy);\n"
"			int x = ix * ystep;\n"
"			int y = iy * ystep;\n"
"			lcloutindex[lcl_id] = 0;\n"
"			lclcount[0] = 0;\n"
"			int result = 1, nodecounter;\n"
"			float mean, variance_norm_factor;\n"
"			//if((ix < width) && (iy < height))\n"
"			{\n"
"				const int p_offset = mad24(y, step, x);\n"
"				cascadeinfo.x += p_offset;\n"
"				cascadeinfo.z += p_offset;\n"
"				mean = (sum[mad24(cascadeinfo.y, step, cascadeinfo.x)] - sum[mad24(cascadeinfo.y, step, cascadeinfo.z)] -\n"
"				        sum[mad24(cascadeinfo.w, step, cascadeinfo.x)] + sum[mad24(cascadeinfo.w, step, cascadeinfo.z)])\n"
"				       * correction_t;\n"
"				variance_norm_factor = sqsum[mad24(cascadeinfo.y, step, cascadeinfo.x)] - sqsum[mad24(cascadeinfo.y, step, cascadeinfo.z)] -\n"
"				                       sqsum[mad24(cascadeinfo.w, step, cascadeinfo.x)] + sqsum[mad24(cascadeinfo.w, step, cascadeinfo.z)];\n"
"				variance_norm_factor = variance_norm_factor * correction_t - mean * mean;\n"
"				variance_norm_factor = variance_norm_factor >= 0.f ? sqrt(variance_norm_factor) : 1.f;\n"
"				result = 1;\n"
"				nodecounter = startnode + nodecount * scalei;\n"
"				\n"
"				for (int stageloop = start_stage; stageloop < split_stage && result; stageloop++)\n"
"				{\n"
"					float stage_sum = 0.f;\n"
"					int4 stageinfo = *(global int4 *)(stagecascadeptr + stageloop);\n"
"					float stagethreshold = as_float(stageinfo.y);\n"
"					\n"
"					for (int nodeloop = 0; nodeloop < stageinfo.x; nodeloop++)\n"
"					{\n"
"						__global GpuHidHaarTreeNode *currentnodeptr = (nodeptr + nodecounter);\n"
"						int4 info1 = *(__global int4 *)(&(currentnodeptr->p[0][0]));\n"
"						int4 info2 = *(__global int4 *)(&(currentnodeptr->p[1][0]));\n"
"						int4 info3 = *(__global int4 *)(&(currentnodeptr->p[2][0]));\n"
"						float4 w = *(__global float4 *)(&(currentnodeptr->weight[0]));\n"
"						float2 alpha2 = *(__global float2 *)(&(currentnodeptr->alpha[0]));\n"
"						float nodethreshold  = w.w * variance_norm_factor;\n"
"						info1.x += p_offset;\n"
"						info1.z += p_offset;\n"
"						info2.x += p_offset;\n"
"						info2.z += p_offset;\n"
"						float classsum = (sum[mad24(info1.y, step, info1.x)] - sum[mad24(info1.y, step, info1.z)] -\n"
"						                  sum[mad24(info1.w, step, info1.x)] + sum[mad24(info1.w, step, info1.z)]) * w.x;\n"
"						classsum += (sum[mad24(info2.y, step, info2.x)] - sum[mad24(info2.y, step, info2.z)] -\n"
"						             sum[mad24(info2.w, step, info2.x)] + sum[mad24(info2.w, step, info2.z)]) * w.y;\n"
"						info3.x += p_offset;\n"
"						info3.z += p_offset;\n"
"						classsum += (sum[mad24(info3.y, step, info3.x)] - sum[mad24(info3.y, step, info3.z)] -\n"
"						             sum[mad24(info3.w, step, info3.x)] + sum[mad24(info3.w, step, info3.z)]) * w.z;\n"
"						stage_sum += classsum >= nodethreshold ? alpha2.y : alpha2.x;\n"
"						nodecounter++;\n"
"					}\n"
"					\n"
"					result = (stage_sum >= stagethreshold);\n"
"				}\n"
"				\n"
"				if (result && (ix < width) && (iy < height))\n"
"				{\n"
"					int queueindex = atomic_inc(lclcount);\n"
"					lcloutindex[queueindex << 1] = (y << 16) | x;\n"
"					lcloutindex[(queueindex << 1) + 1] = as_int(variance_norm_factor);\n"
"				}\n"
"				\n"
"				barrier(CLK_LOCAL_MEM_FENCE);\n"
"				int queuecount = lclcount[0];\n"
"				nodecounter = splitnode + nodecount * scalei;\n"
"				\n"
"				for (int stageloop = split_stage; stageloop < end_stage && queuecount > 0; stageloop++)\n"
"				{\n"
"					lclcount[0] = 0;\n"
"					barrier(CLK_LOCAL_MEM_FENCE);\n"
"					int2 stageinfo = *(global int2 *)(stagecascadeptr + stageloop);\n"
"					float stagethreshold = as_float(stageinfo.y);\n"
"					int perfscale = queuecount > 4 ? 3 : 2;\n"
"					int queuecount_loop = (queuecount + (1 << perfscale) - 1) >> perfscale;\n"
"					int lcl_compute_win = lcl_sz >> perfscale;\n"
"					int lcl_compute_win_id = (lcl_id >> (6 - perfscale));\n"
"					int lcl_loops = (stageinfo.x + lcl_compute_win - 1) >> (6 - perfscale);\n"
"					int lcl_compute_id = lcl_id - (lcl_compute_win_id << (6 - perfscale));\n"
"					\n"
"					for (int queueloop = 0; queueloop < queuecount_loop && lcl_compute_win_id < queuecount; queueloop++)\n"
"					{\n"
"						float stage_sum = 0.f;\n"
"						int temp_coord = lcloutindex[lcl_compute_win_id << 1];\n"
"						float variance_norm_factor = as_float(lcloutindex[(lcl_compute_win_id << 1) + 1]);\n"
"						int queue_offset = mad24(((temp_coord & (int)0xffff0000) >> 16), step, temp_coord & 0xffff);\n"
"						int tempnodecounter = lcl_compute_id;\n"
"						float part_sum = 0.f;\n"
"						\n"
"						for (int lcl_loop = 0; lcl_loop < lcl_loops && tempnodecounter < stageinfo.x; lcl_loop++)\n"
"						{\n"
"							__global  GpuHidHaarTreeNode *currentnodeptr = (nodeptr + nodecounter + tempnodecounter);\n"
"							int4 info1 = *(__global int4 *)(&(currentnodeptr->p[0][0]));\n"
"							int4 info2 = *(__global int4 *)(&(currentnodeptr->p[1][0]));\n"
"							int4 info3 = *(__global int4 *)(&(currentnodeptr->p[2][0]));\n"
"							float4 w = *(__global float4 *)(&(currentnodeptr->weight[0]));\n"
"							float2 alpha2 = *(__global float2 *)(&(currentnodeptr->alpha[0]));\n"
"							float nodethreshold  = w.w * variance_norm_factor;\n"
"							info1.x += queue_offset;\n"
"							info1.z += queue_offset;\n"
"							info2.x += queue_offset;\n"
"							info2.z += queue_offset;\n"
"							float classsum = (sum[mad24(info1.y, step, info1.x)] - sum[mad24(info1.y, step, info1.z)] -\n"
"							                  sum[mad24(info1.w, step, info1.x)] + sum[mad24(info1.w, step, info1.z)]) * w.x;\n"
"							classsum += (sum[mad24(info2.y, step, info2.x)] - sum[mad24(info2.y, step, info2.z)] -\n"
"							             sum[mad24(info2.w, step, info2.x)] + sum[mad24(info2.w, step, info2.z)]) * w.y;\n"
"							             \n"
"							info3.x += queue_offset;\n"
"							info3.z += queue_offset;\n"
"							classsum += (sum[mad24(info3.y, step, info3.x)] - sum[mad24(info3.y, step, info3.z)] -\n"
"							             sum[mad24(info3.w, step, info3.x)] + sum[mad24(info3.w, step, info3.z)]) * w.z;\n"
"							part_sum += classsum >= nodethreshold ? alpha2.y : alpha2.x;\n"
"							tempnodecounter += lcl_compute_win;\n"
"						}\n"
"						\n"
"						partialsum[lcl_id] = part_sum;\n"
"						barrier(CLK_LOCAL_MEM_FENCE);\n"
"						\n"
"						for (int i = 0; i < lcl_compute_win && (lcl_compute_id == 0); i++)\n"
"						{\n"
"							stage_sum += partialsum[lcl_id + i];\n"
"						}\n"
"						\n"
"						if (stage_sum >= stagethreshold && (lcl_compute_id == 0))\n"
"						{\n"
"							int queueindex = atomic_inc(lclcount);\n"
"							lcloutindex[queueindex << 1] = temp_coord;\n"
"							lcloutindex[(queueindex << 1) + 1] = as_int(variance_norm_factor);\n"
"						}\n"
"						\n"
"						lcl_compute_win_id += (1 << perfscale);\n"
"						barrier(CLK_LOCAL_MEM_FENCE);\n"
"					}\n"
"					\n"
"					queuecount = lclcount[0];\n"
"					nodecounter += stageinfo.x;\n"
"				}\n"
"				\n"
"				if (lcl_id < queuecount)\n"
"				{\n"
"					int temp = lcloutindex[lcl_id << 1];\n"
"					int x = temp & 0xffff;\n"
"					int y = (temp & (int)0xffff0000) >> 16;\n"
"					temp = glboutindex[0];\n"
"					int4 candidate_result;\n"
"					candidate_result.zw = (int2)convert_int_rtn(factor * 20.f);\n"
"					candidate_result.x = x;\n"
"					candidate_result.y = y;\n"
"					atomic_inc(glboutindex);\n"
"					candidate[outputoff + temp + lcl_id] = candidate_result;\n"
"				}\n"
"				\n"
"				barrier(CLK_LOCAL_MEM_FENCE);\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void gpuscaleclassifier(global GpuHidHaarTreeNode *orinode, global GpuHidHaarTreeNode *newnode, float scale, float weight_scale, int nodenum)\n"
"{\n"
"	int counter = get_global_id(0);\n"
"	int tr_x[3], tr_y[3], tr_h[3], tr_w[3], i = 0;\n"
"	GpuHidHaarTreeNode t1 = *(orinode + counter);\n"
"#pragma unroll\n"
"	\n"
"	for (i = 0; i < 3; i++)\n"
"	{\n"
"		tr_x[i] = (int)(t1.p[i][0] * scale + 0.5f);\n"
"		tr_y[i] = (int)(t1.p[i][1] * scale + 0.5f);\n"
"		tr_w[i] = (int)(t1.p[i][2] * scale + 0.5f);\n"
"		tr_h[i] = (int)(t1.p[i][3] * scale + 0.5f);\n"
"	}\n"
"	\n"
"	t1.weight[0] = t1.p[2][0] ? -(t1.weight[1] * tr_h[1] * tr_w[1] + t1.weight[2] * tr_h[2] * tr_w[2]) / (tr_h[0] * tr_w[0]) : -t1.weight[1] * tr_h[1] * tr_w[1] / (tr_h[0] * tr_w[0]);\n"
"	counter += nodenum;\n"
"#pragma unroll\n"
"	\n"
"	for (i = 0; i < 3; i++)\n"
"	{\n"
"		newnode[counter].p[i][0] = tr_x[i];\n"
"		newnode[counter].p[i][1] = tr_y[i];\n"
"		newnode[counter].p[i][2] = tr_x[i] + tr_w[i];\n"
"		newnode[counter].p[i][3] = tr_y[i] + tr_h[i];\n"
"		newnode[counter].weight[i] = t1.weight[i] * weight_scale;\n"
"	}\n"
"	\n"
"	newnode[counter].left = t1.left;\n"
"	newnode[counter].right = t1.right;\n"
"	newnode[counter].threshold = t1.threshold;\n"
"	newnode[counter].alpha[0] = t1.alpha[0];\n"
"	newnode[counter].alpha[1] = t1.alpha[1];\n"
"}\n"
;
const char *imgproc_bilateral =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Rock Li, Rock.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"//#pragma OPENCL EXTENSION cl_amd_printf :enable\n"
"__kernel\n"
"void bilateral4(__global uchar4 *dst,\n"
"                __global uchar4 *src,\n"
"                int rows,\n"
"                int cols,\n"
"                int channels,\n"
"                int radius,\n"
"                int wholerows,\n"
"                int wholecols,\n"
"                int src_step,\n"
"                int dst_step,\n"
"                int src_offset,\n"
"                int dst_offset,\n"
"                __constant float *sigClr,\n"
"                __constant float *sigSpc)\n"
"{\n"
"	uint lidx = get_local_id(0);\n"
"	uint lidy = get_local_id(1);\n"
"	\n"
"	uint gdx = get_global_id(0);\n"
"	uint gdy = get_global_id(1);\n"
"	\n"
"	uint gidx = gdx >= cols ? cols - 1 : gdx;\n"
"	uint gidy = gdy >= rows ? rows - 1 : gdy;\n"
"	\n"
"	uchar4 p, q, tmp;\n"
"	\n"
"	float4 pf = 0, pq = 0, pd = 0;\n"
"	float wt = 0;\n"
"	\n"
"	int r = radius;\n"
"	int ij = 0;\n"
"	int ct = 0;\n"
"	\n"
"	uint index_src = src_offset / 4 + gidy * src_step / 4 + gidx;\n"
"	uint index_dst = dst_offset / 4 + gidy * dst_step / 4 + gidx;\n"
"	\n"
"	p = src[index_src];\n"
"	\n"
"	uint gx, gy;\n"
"	uint src_index, dst_index;\n"
"	\n"
"	for (int ii = -r; ii < r + 1; ii++)\n"
"	{\n"
"		for (int jj = -r; jj < r + 1; jj++)\n"
"		{\n"
"			ij = ii * ii + jj * jj;\n"
"			\n"
"			if (ij > mul24(radius, radius))\n"
"			{\n"
"				continue;\n"
"			}\n"
"			\n"
"			gx = gidx + jj;\n"
"			gy = gidy + ii;\n"
"			\n"
"			src_index = src_offset / 4 + gy *	 src_step / 4 + gx;\n"
"			q = src[src_index];\n"
"			\n"
"			\n"
"			ct = abs(p.x - q.x) + abs(p.y - q.y) + abs(p.z - q.z);\n"
"			wt = sigClr[ct] * sigSpc[(ii + radius) * (2 * radius + 1) + jj + radius];\n"
"			\n"
"			pf.x += q.x * wt;\n"
"			pf.y += q.y * wt;\n"
"			pf.z += q.z * wt;\n"
"//					pf.w += q.w*wt;\n"
"			pq += wt;\n"
"			\n"
"		}\n"
"	}\n"
"	\n"
"	pd = pf / pq;\n"
"	dst[index_dst] = convert_uchar4_rte(pd);\n"
"}\n"
"__kernel\n"
"void bilateral(__global uchar *dst,\n"
"               __global uchar *src,\n"
"               int rows,\n"
"               int cols,\n"
"               int channels,\n"
"               int radius,\n"
"               int wholerows,\n"
"               int wholecols,\n"
"               int src_step,\n"
"               int dst_step,\n"
"               int src_offset,\n"
"               int dst_offset,\n"
"               __constant float *sigClr,\n"
"               __constant float *sigSpc)\n"
"{\n"
"	uint lidx = get_local_id(0);\n"
"	uint lidy = get_local_id(1);\n"
"	\n"
"	uint gdx = get_global_id(0);\n"
"	uint gdy = get_global_id(1);\n"
"	\n"
"	uint gidx = gdx >= cols ? cols - 1 : gdx;\n"
"	uint gidy = gdy >= rows ? rows - 1 : gdy;\n"
"	\n"
"	uchar p, q, tmp;\n"
"	\n"
"	float pf = 0, pq = 0, wt = 0, pd = 0;\n"
"	\n"
"	int r = radius;\n"
"	int ij = 0;\n"
"	int ct = 0;\n"
"	\n"
"	uint index_src = src_offset + gidy * src_step + gidx;\n"
"	uint index_dst = dst_offset + gidy * dst_step + gidx;\n"
"	\n"
"	p = src[index_src];\n"
"	\n"
"	uint gx, gy;\n"
"	uint src_index, dst_index;\n"
"	\n"
"	for (int ii = -r; ii < r + 1; ii++)\n"
"	{\n"
"		for (int jj = -r; jj < r + 1; jj++)\n"
"		{\n"
"			ij = ii * ii + jj * jj;\n"
"			\n"
"			if (ij > mul24(radius, radius))\n"
"			{\n"
"				continue;\n"
"			}\n"
"			\n"
"			gx = gidx + jj;\n"
"			gy = gidy + ii;\n"
"			\n"
"			\n"
"			src_index = src_offset + gy * src_step + gx;\n"
"			q = src[src_index];\n"
"			\n"
"			ct = abs(p - q);\n"
"			wt = sigClr[ct] * sigSpc[(ii + radius) * (2 * radius + 1) + jj + radius];\n"
"			\n"
"			pf += q * wt;\n"
"			\n"
"			pq += wt;\n"
"		}\n"
"	}\n"
"	\n"
"	pd = pf / pq;\n"
"	dst[index_dst] = convert_uchar_rte(pd);\n"
"	\n"
"}\n"
;
const char *imgproc_calcHarris =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////Macro for border type////////////////////////////////////////////\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#ifdef BORDER_REPLICATE\n"
"//BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (l_edge)   : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (r_edge)-1 : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (t_edge)   :(i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (b_edge)-1 :(addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT\n"
"//BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)-1               : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-1+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)-1 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-1+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT_101\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)                 : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-2+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)                 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-2+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_WRAP\n"
"//BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (i)+(r_edge) : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (i)-(r_edge) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (i)+(b_edge) : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (i)-(b_edge) : (addr))\n"
"#endif\n"
"#define THREADS 256\n"
"#define ELEM(i, l_edge, r_edge, elem1, elem2) (i) >= (l_edge) && (i) < (r_edge) ? (elem1) : (elem2)\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////calcHarris////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void calcHarris(__global const float *Dx, __global const float *Dy, __global float *dst,\n"
"                         int dx_offset, int dx_whole_rows, int dx_whole_cols, int dx_step,\n"
"                         int dy_offset, int dy_whole_rows, int dy_whole_cols, int dy_step,\n"
"                         int dst_offset, int dst_rows, int dst_cols, int dst_step,\n"
"                         float k)\n"
"{\n"
"	int col = get_local_id(0);\n"
"	const int gX = get_group_id(0);\n"
"	const int gY = get_group_id(1);\n"
"	\n"
"	int dx_x_off = (dx_offset % dx_step) >> 2;\n"
"	int dx_y_off = dx_offset / dx_step;\n"
"	int dy_x_off = (dy_offset % dy_step) >> 2;\n"
"	int dy_y_off = dy_offset / dy_step;\n"
"	int dst_x_off = (dst_offset % dst_step) >> 2;\n"
"	int dst_y_off = dst_offset / dst_step;\n"
"	\n"
"	int dx_startX = gX * (THREADS - ksX + 1) - anX + dx_x_off;\n"
"	int dx_startY = (gY << 1) - anY + dx_y_off;\n"
"	int dy_startX = gX * (THREADS - ksX + 1) - anX + dy_x_off;\n"
"	int dy_startY = (gY << 1) - anY + dy_y_off;\n"
"	int dst_startX = gX * (THREADS - ksX + 1) + dst_x_off;\n"
"	int dst_startY = (gY << 1) + dst_y_off;\n"
"	\n"
"	float dx_data[ksY + 1], dy_data[ksY + 1], data[3][ksY + 1];\n"
"	__local float temp[6][THREADS];\n"
"#ifdef BORDER_CONSTANT\n"
"	bool dx_con, dy_con;\n"
"	float dx_s, dy_s;\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		dx_con = dx_startX + col >= 0 && dx_startX + col < dx_whole_cols && dx_startY + i >= 0 && dx_startY + i < dx_whole_rows;\n"
"		dx_s = Dx[(dx_startY + i) * (dx_step >> 2) + (dx_startX + dx_col)];\n"
"		dx_data[i] = dx_con ? dx_s : 0.0;\n"
"		dy_con = dy_startX + col >= 0 && dy_startX + col < dy_whole_cols && dy_startY + i >= 0 && dy_startY + i < dy_whole_rows;\n"
"		dy_s = Dy[(dy_startY + i) * (dy_step >> 2) + (dy_startX + dy_col)];\n"
"		dy_data[i] = dy_con ? dy_s : 0.0;\n"
"		data[0][i] = dx_data[i] * dx_data[i];\n"
"		data[1][i] = dx_data[i] * dy_data[i];\n"
"		data[2][i] = dy_data[i] * dy_data[i];\n"
"	}\n"
"	\n"
"#else\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		int dx_selected_row;\n"
"		int dx_selected_col;\n"
"		dx_selected_row = ADDR_H(dx_startY + i, 0, dx_whole_rows);\n"
"		dx_selected_row = ADDR_B(dx_startY + i, dx_whole_rows, dx_selected_row);\n"
"		dx_selected_col = ADDR_L(dx_startX + col, 0, dx_whole_cols);\n"
"		dx_selected_col = ADDR_R(dx_startX + col, dx_whole_cols, dx_selected_col);\n"
"		dx_data[i] = Dx[dx_selected_row * (dx_step >> 2) + dx_selected_col];\n"
"	\n"
"		int dy_selected_row;\n"
"		int dy_selected_col;\n"
"		dy_selected_row = ADDR_H(dy_startY + i, 0, dy_whole_rows);\n"
"		dy_selected_row = ADDR_B(dy_startY + i, dy_whole_rows, dy_selected_row);\n"
"		dy_selected_col = ADDR_L(dy_startX + col, 0, dy_whole_cols);\n"
"		dy_selected_col = ADDR_R(dy_startX + col, dy_whole_cols, dy_selected_col);\n"
"		dy_data[i] = Dy[dx_selected_row * (dy_step >> 2) + dy_selected_col];\n"
"	\n"
"		data[0][i] = dx_data[i] * dx_data[i];\n"
"		data[1][i] = dx_data[i] * dy_data[i];\n"
"		data[2][i] = dy_data[i] * dy_data[i];\n"
"	}\n"
"	\n"
"#endif\n"
"	float sum0 = 0.0, sum1 = 0.0, sum2 = 0.0;\n"
"	\n"
"	for (int i = 1; i < ksY; i++)\n"
"	{\n"
"		sum0 += (data[0][i]);\n"
"		sum1 += (data[1][i]);\n"
"		sum2 += (data[2][i]);\n"
"	}\n"
"	\n"
"	float sum01, sum02, sum11, sum12, sum21, sum22;\n"
"	sum01 = sum0 + (data[0][0]);\n"
"	sum02 = sum0 + (data[0][ksY]);\n"
"	temp[0][col] = sum01;\n"
"	temp[1][col] = sum02;\n"
"	sum11 = sum1 + (data[1][0]);\n"
"	sum12 = sum1 + (data[1][ksY]);\n"
"	temp[2][col] = sum11;\n"
"	temp[3][col] = sum12;\n"
"	sum21 = sum2 + (data[2][0]);\n"
"	sum22 = sum2 + (data[2][ksY]);\n"
"	temp[4][col] = sum21;\n"
"	temp[5][col] = sum22;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (col < (THREADS - (ksX - 1)))\n"
"	{\n"
"		col += anX;\n"
"		int posX = dst_startX - dst_x_off + col - anX;\n"
"		int posY = (gY << 1);\n"
"		int till = (ksX + 1) % 2;\n"
"		float tmp_sum[6] = { 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0 };\n"
"		\n"
"		for (int k = 0; k < 6; k++)\n"
"			for (int i = -anX; i <= anX - till; i++)\n"
"			{\n"
"				tmp_sum[k] += temp[k][col + i];\n"
"			}\n"
"			\n"
"		if (posX < dst_cols && (posY) < dst_rows)\n"
"		{\n"
"			dst[(dst_startY + 0) * (dst_step >> 2) + dst_startX + col - anX] =\n"
"			    tmp_sum[0] * tmp_sum[4] - tmp_sum[2] * tmp_sum[2] - k * (tmp_sum[0] + tmp_sum[4]) * (tmp_sum[0] + tmp_sum[4]);\n"
"		}\n"
"		\n"
"		if (posX < dst_cols && (posY + 1) < dst_rows)\n"
"		{\n"
"			dst[(dst_startY + 1) * (dst_step >> 2) + dst_startX + col - anX] =\n"
"			    tmp_sum[1] * tmp_sum[5] - tmp_sum[3] * tmp_sum[3] - k * (tmp_sum[1] + tmp_sum[5]) * (tmp_sum[1] + tmp_sum[5]);\n"
"		}\n"
"	}\n"
"}\n"
;
const char *imgproc_calcMinEigenVal =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////Macro for border type////////////////////////////////////////////\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////\n"
"#ifdef BORDER_REPLICATE\n"
"//BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (l_edge)   : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (r_edge)-1 : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (t_edge)   :(i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (b_edge)-1 :(addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT\n"
"//BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)-1               : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-1+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)-1 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-1+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_REFLECT_101\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? -(i)                 : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? -(i)-2+((r_edge)<<1) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? -(i)                 : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? -(i)-2+((b_edge)<<1) : (addr))\n"
"#endif\n"
"#ifdef BORDER_WRAP\n"
"//BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n"
"#define ADDR_L(i, l_edge, r_edge)  ((i) <  (l_edge) ? (i)+(r_edge) : (i))\n"
"#define ADDR_R(i, r_edge, addr)    ((i) >= (r_edge) ? (i)-(r_edge) : (addr))\n"
"#define ADDR_H(i, t_edge, b_edge)  ((i) <  (t_edge) ? (i)+(b_edge) : (i))\n"
"#define ADDR_B(i, b_edge, addr)    ((i) >= (b_edge) ? (i)-(b_edge) : (addr))\n"
"#endif\n"
"#define THREADS 256\n"
"#define ELEM(i, l_edge, r_edge, elem1, elem2) (i) >= (l_edge) && (i) < (r_edge) ? (elem1) : (elem2)\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////////calcHarris////////////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void calcMinEigenVal(__global const float *Dx, __global const float *Dy, __global float *dst,\n"
"                              int dx_offset, int dx_whole_rows, int dx_whole_cols, int dx_step,\n"
"                              int dy_offset, int dy_whole_rows, int dy_whole_cols, int dy_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step,\n"
"                              float k)\n"
"{\n"
"	int col = get_local_id(0);\n"
"	const int gX = get_group_id(0);\n"
"	const int gY = get_group_id(1);\n"
"	\n"
"	int dx_x_off = (dx_offset % dx_step) >> 2;\n"
"	int dx_y_off = dx_offset / dx_step;\n"
"	int dy_x_off = (dy_offset % dy_step) >> 2;\n"
"	int dy_y_off = dy_offset / dy_step;\n"
"	int dst_x_off = (dst_offset % dst_step) >> 2;\n"
"	int dst_y_off = dst_offset / dst_step;\n"
"	\n"
"	int dx_startX = gX * (THREADS - ksX + 1) - anX + dx_x_off;\n"
"	int dx_startY = (gY << 1) - anY + dx_y_off;\n"
"	int dy_startX = gX * (THREADS - ksX + 1) - anX + dy_x_off;\n"
"	int dy_startY = (gY << 1) - anY + dy_y_off;\n"
"	int dst_startX = gX * (THREADS - ksX + 1) + dst_x_off;\n"
"	int dst_startY = (gY << 1) + dst_y_off;\n"
"	\n"
"	float dx_data[ksY + 1], dy_data[ksY + 1], data[3][ksY + 1];\n"
"	__local float temp[6][THREADS];\n"
"#ifdef BORDER_CONSTANT\n"
"	bool dx_con, dy_con;\n"
"	float dx_s, dy_s;\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		dx_con = dx_startX + col >= 0 && dx_startX + col < dx_whole_cols && dx_startY + i >= 0 && dx_startY + i < dx_whole_rows;\n"
"		dx_s = Dx[(dx_startY + i) * (dx_step >> 2) + (dx_startX + dx_col)];\n"
"		dx_data[i] = dx_con ? dx_s : 0.0;\n"
"		dy_con = dy_startX + col >= 0 && dy_startX + col < dy_whole_cols && dy_startY + i >= 0 && dy_startY + i < dy_whole_rows;\n"
"		dy_s = Dy[(dy_startY + i) * (dy_step >> 2) + (dy_startX + dy_col)];\n"
"		dy_data[i] = dy_con ? dy_s : 0.0;\n"
"		data[0][i] = dx_data[i] * dx_data[i];\n"
"		data[1][i] = dx_data[i] * dy_data[i];\n"
"		data[2][i] = dy_data[i] * dy_data[i];\n"
"	}\n"
"	\n"
"#else\n"
"	\n"
"	for (int i = 0; i < ksY + 1; i++)\n"
"	{\n"
"		int dx_selected_row;\n"
"		int dx_selected_col;\n"
"		dx_selected_row = ADDR_H(dx_startY + i, 0, dx_whole_rows);\n"
"		dx_selected_row = ADDR_B(dx_startY + i, dx_whole_rows, dx_selected_row);\n"
"		dx_selected_col = ADDR_L(dx_startX + col, 0, dx_whole_cols);\n"
"		dx_selected_col = ADDR_R(dx_startX + col, dx_whole_cols, dx_selected_col);\n"
"		dx_data[i] = Dx[dx_selected_row * (dx_step >> 2) + dx_selected_col];\n"
"	\n"
"		int dy_selected_row;\n"
"		int dy_selected_col;\n"
"		dy_selected_row = ADDR_H(dy_startY + i, 0, dy_whole_rows);\n"
"		dy_selected_row = ADDR_B(dy_startY + i, dy_whole_rows, dy_selected_row);\n"
"		dy_selected_col = ADDR_L(dy_startX + col, 0, dy_whole_cols);\n"
"		dy_selected_col = ADDR_R(dy_startX + col, dy_whole_cols, dy_selected_col);\n"
"		dy_data[i] = Dy[dx_selected_row * (dy_step >> 2) + dy_selected_col];\n"
"	\n"
"		data[0][i] = dx_data[i] * dx_data[i];\n"
"		data[1][i] = dx_data[i] * dy_data[i];\n"
"		data[2][i] = dy_data[i] * dy_data[i];\n"
"	}\n"
"	\n"
"#endif\n"
"	float sum0 = 0.0, sum1 = 0.0, sum2 = 0.0;\n"
"	\n"
"	for (int i = 1; i < ksY; i++)\n"
"	{\n"
"		sum0 += (data[0][i]);\n"
"		sum1 += (data[1][i]);\n"
"		sum2 += (data[2][i]);\n"
"	}\n"
"	\n"
"	float sum01, sum02, sum11, sum12, sum21, sum22;\n"
"	sum01 = sum0 + (data[0][0]);\n"
"	sum02 = sum0 + (data[0][ksY]);\n"
"	temp[0][col] = sum01;\n"
"	temp[1][col] = sum02;\n"
"	sum11 = sum1 + (data[1][0]);\n"
"	sum12 = sum1 + (data[1][ksY]);\n"
"	temp[2][col] = sum11;\n"
"	temp[3][col] = sum12;\n"
"	sum21 = sum2 + (data[2][0]);\n"
"	sum22 = sum2 + (data[2][ksY]);\n"
"	temp[4][col] = sum21;\n"
"	temp[5][col] = sum22;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (col < (THREADS - (ksX - 1)))\n"
"	{\n"
"		col += anX;\n"
"		int posX = dst_startX - dst_x_off + col - anX;\n"
"		int posY = (gY << 1);\n"
"		int till = (ksX + 1) % 2;\n"
"		float tmp_sum[6] = { 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0 };\n"
"		\n"
"		for (int k = 0; k < 6; k++)\n"
"			for (int i = -anX; i <= anX - till; i++)\n"
"			{\n"
"				tmp_sum[k] += temp[k][col + i];\n"
"			}\n"
"			\n"
"		if (posX < dst_cols && (posY) < dst_rows)\n"
"		{\n"
"			float a = tmp_sum[0] * 0.5f;\n"
"			float b = tmp_sum[2];\n"
"			float c = tmp_sum[4] * 0.5f;\n"
"			dst[(dst_startY + 0) * (dst_step >> 2) + dst_startX + col - anX] = (float)((a + c) - sqrt((a - c) * (a - c) + b * b));\n"
"		}\n"
"		\n"
"		if (posX < dst_cols && (posY + 1) < dst_rows)\n"
"		{\n"
"			float a = tmp_sum[1] * 0.5f;\n"
"			float b = tmp_sum[3];\n"
"			float c = tmp_sum[5] * 0.5f;\n"
"			dst[(dst_startY + 1) * (dst_step >> 2) + dst_startX + col - anX] = (float)((a + c) - sqrt((a - c) * (a - c) + b * b));\n"
"		}\n"
"	}\n"
"}\n"
;
const char *imgproc_copymakeboder =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Zero Lin zero.lin@amd.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#define get(a,b,c) (( b >= top & b < srcRows+top & a >= left & a < srcCols+left )? c : 8)\n"
"__kernel void copyConstBorder_C1_D0(__global uchar *src, __global uchar *dst, int srcOffset, int dstOffset,\n"
"                                    int srcCols, int srcRows, int dstCols, int dstRows,\n"
"                                    int top, int left, uchar nVal, int srcStep, int dstStep)\n"
"{\n"
"	int idx = get_global_id(0);\n"
"	int tpr = (dstCols + 3 + (dstOffset & 3)) >> 2;\n"
"	int dx  = ((idx % (tpr)) << 2) - (dstOffset & 3);\n"
"	int dy = idx / (tpr);\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dstOffset + dy * dstStep + dx);\n"
"	int start = srcOffset + (dy - top) * srcStep + (dx - left);\n"
"	uchar8 s = *((__global uchar8 *)(src + ((start >> 2) << 2)));\n"
"	uchar4 v;\n"
"	\n"
"	uchar sv[9] = {s.s0, s.s1, s.s2, s.s3, s.s4, s.s5, s.s6, s.s7, nVal};\n"
"	\n"
"	int det = start & 3;\n"
"	v.x = sv[get(dx, dy, det)];\n"
"	v.y = sv[get(dx + 1, dy, det + 1)];\n"
"	v.z = sv[get(dx + 2, dy, det + 2)];\n"
"	v.w = sv[get(dx + 3, dy, det + 3)];\n"
"	\n"
"	if (dy < dstRows)\n"
"	{\n"
"		uchar4 res = *d;\n"
"		res.x = (dx >= 0 && dx < dstCols) ? v.x : res.x;\n"
"		res.y = (dx + 1 >= 0 && dx + 1 < dstCols) ? v.y : res.y;\n"
"		res.z = (dx + 2 >= 0 && dx + 2 < dstCols) ? v.z : res.z;\n"
"		res.w = (dx + 3 >= 0 && dx + 3 < dstCols) ? v.w : res.w;\n"
"		\n"
"		*d = res;\n"
"	}\n"
"}\n"
"#undef get(a,b,c)\n"
"#define get(a,b,c,d) (( b >= top & b < srcRows+top & a >= left & a < srcCols+left )? c : d)\n"
"__kernel void copyConstBorder_C1_D4(__global int *src, __global int *dst, int srcOffset, int dstOffset,\n"
"                                    int srcCols, int srcRows, int dstCols, int dstRows,\n"
"                                    int top, int left, int nVal, int srcStep, int dstStep)\n"
"{\n"
"	int idx = get_global_id(0);\n"
"	int tpr = (dstCols + 3) >> 2;\n"
"	int dx  = (idx % (tpr)) << 2;\n"
"	int dy = idx / (tpr);\n"
"	\n"
"	__global int4 *d = (__global int4 *)(dst + dy * dstStep + dx);\n"
"	int4 s = *((__global int4 *)(src + srcOffset + (dy - top) * srcStep + (dx - left)));\n"
"	int4 v;\n"
"	\n"
"	v.x = get(dx, dy, s.x, nVal);\n"
"	v.y = get(dx + 1, dy, s.y, nVal);\n"
"	v.z = get(dx + 2, dy, s.z, nVal);\n"
"	v.w = get(dx + 3, dy, s.w, nVal);\n"
"	\n"
"	if (dy < dstRows)\n"
"	{\n"
"		int4 res = *d;\n"
"		v.y = (dx + 1 < dstCols) ? v.y : res.y;\n"
"		v.z = (dx + 2 < dstCols) ? v.z : res.z;\n"
"		v.w = (dx + 3 < dstCols) ? v.w : res.w;\n"
"		\n"
"		*d = v;\n"
"	}\n"
"}\n"
"#undef get(a,b,c,d)\n"
"#define get(a,b,c) ( a < srcCols+left ? b : c)\n"
"__kernel void copyReplicateBorder_C1_D4(__global int *src, __global int *dst, int srcOffset, int dstOffset,\n"
"                                        int srcCols, int srcRows, int dstCols, int dstRows,\n"
"                                        int top, int left, int nVal, int srcStep, int dstStep)\n"
"{\n"
"	int idx = get_global_id(0);\n"
"	int tpr = (dstCols + 3) >> 2;\n"
"	int dx  = (idx % (tpr)) << 2;\n"
"	int dy = idx / (tpr);\n"
"	\n"
"	__global int4 *d = (__global int4 *)(dst + dstOffset + dy * dstStep + dx);\n"
"	int c = clamp(dx - left, 0, srcCols - 1);\n"
"	int4 s = *((__global int4 *)(src + srcOffset + clamp(dy - top, 0, srcRows - 1) * srcStep + c));\n"
"	int sa[4] = {s.x, s.y, s.z, s.w};\n"
"	int4 v;\n"
"	\n"
"	v.x = get(dx, sa[max(0, (dx - left) - c)], sa[srcCols - 1 - c]);\n"
"	v.y = get(dx + 1, sa[max(0, (dx + 1 - left) - c)], sa[srcCols - 1 - c]);\n"
"	v.z = get(dx + 2, sa[max(0, (dx + 2 - left) - c)], sa[srcCols - 1 - c]);\n"
"	v.w = get(dx + 3, sa[max(0, (dx + 3 - left) - c)], sa[srcCols - 1 - c]);\n"
"	\n"
"	if (dy < dstRows)\n"
"	{\n"
"		int4 res = *d;\n"
"		v.y = (dx + 1 < dstCols) ? v.y : res.y;\n"
"		v.z = (dx + 2 < dstCols) ? v.z : res.z;\n"
"		v.w = (dx + 3 < dstCols) ? v.w : res.w;\n"
"		\n"
"		*d = v;\n"
"	}\n"
"}\n"
"__kernel void copyReplicateBorder_C1_D0(__global uchar *src, __global uchar *dst, int srcOffset, int dstOffset,\n"
"                                        int srcCols, int srcRows, int dstCols, int dstRows,\n"
"                                        int top, int left, uchar nVal, int srcStep, int dstStep)\n"
"{\n"
"	int idx = get_global_id(0);\n"
"	int tpr = (dstCols + 3 + (dstOffset & 3)) >> 2;\n"
"	int dx  = ((idx % (tpr)) << 2) - (dstOffset & 3);\n"
"	int dy = idx / (tpr);\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dstOffset + dy * dstStep + dx);\n"
"	int c = clamp(dx - left, 0, srcCols - 1);\n"
"	int start = srcOffset + clamp(dy - top, 0, srcRows - 1) * srcStep + c;\n"
"	uchar8 s = *((__global uchar8 *)(src + ((start >> 2) << 2)));\n"
"	uchar4 v;\n"
"	\n"
"	uchar sa[8] = {s.s0, s.s1, s.s2, s.s3, s.s4, s.s5, s.s6, s.s7};\n"
"	\n"
"	int det = start & 3;\n"
"	v.x = get(dx, sa[max(0, (dx - left) - c) + det], sa[srcCols - 1 - c + det]);\n"
"	v.y = get(dx + 1, sa[max(0, (dx + 1 - left) - c) + det], sa[srcCols - 1 - c + det]);\n"
"	v.z = get(dx + 2, sa[max(0, (dx + 2 - left) - c) + det], sa[srcCols - 1 - c + det]);\n"
"	v.w = get(dx + 3, sa[max(0, (dx + 3 - left) - c) + det], sa[srcCols - 1 - c + det]);\n"
"	\n"
"	if (dy < dstRows)\n"
"	{\n"
"		uchar4 res = *d;\n"
"		res.x = (dx >= 0 && dx < dstCols) ? v.x : res.x;\n"
"		res.y = (dx + 1 >= 0 && dx + 1 < dstCols) ? v.y : res.y;\n"
"		res.z = (dx + 2 >= 0 && dx + 2 < dstCols) ? v.z : res.z;\n"
"		res.w = (dx + 3 >= 0 && dx + 3 < dstCols) ? v.w : res.w;\n"
"		\n"
"		*d = res;\n"
"	}\n"
"}\n"
"#undef get(a,b,c)\n"
"//BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n"
"#define edge(x,size,rx) rx = abs(x) % ((size<<1)-2); rx = (rx>=size?(size<<1)-2:rx<<1) - rx;\n"
"__kernel void copyReflectBorder_C1_D4(__global int *src, __global int *dst, int srcOffset, int dstOffset,\n"
"                                      int srcCols, int srcRows, int dstCols, int dstRows,\n"
"                                      int top, int left, int nVal, int srcStep, int dstStep)\n"
"{\n"
"	int idx = get_global_id(0);\n"
"	int tpr = (dstCols + 3) >> 2;\n"
"	int dx  = (idx % (tpr)) << 2;\n"
"	int dy = idx / (tpr);\n"
"	\n"
"	__global int4 *d = (__global int4 *)(dst + dstOffset + dy * dstStep + dx);\n"
"	uint4 id;\n"
"	edge(dx - left, srcCols, id.x);\n"
"	edge(dx - left + 1, srcCols, id.x);\n"
"	edge(dx - left + 2, srcCols, id.x);\n"
"	edge(dx - left + 3, srcCols, id.x);\n"
"	\n"
"	\n"
"	\n"
"	int start = min(id.x, id.w);\n"
"	int4 s = *((__global int4 *)(src + srcOffset + clamp(dy - top, 0, srcRows - 1) * srcStep + start));\n"
"	int sa[4] = {s.x, s.y, s.z, s.w};\n"
"	\n"
"	int4 v = (int4)(sa[(id.x - start)], sa[(id.y - start)], sa[(id.z - start)], sa[(id.w - start)]);\n"
"	\n"
"	\n"
"	if (dy < dstRows)\n"
"	{\n"
"		int4 res = *d;\n"
"		v.y = (dx + 1 < dstCols) ? v.y : res.y;\n"
"		v.z = (dx + 2 < dstCols) ? v.z : res.z;\n"
"		v.w = (dx + 3 < dstCols) ? v.w : res.w;\n"
"		\n"
"		*d = v;\n"
"	}\n"
"}\n"
"__kernel void copyReflectBorder_C1_D0(__global uchar *src, __global uchar *dst, int srcOffset, int dstOffset,\n"
"                                      int srcCols, int srcRows, int dstCols, int dstRows,\n"
"                                      int top, int left, uchar nVal, int srcStep, int dstStep)\n"
"{\n"
"	int idx = get_global_id(0);\n"
"	int tpr = (dstCols + 3 + (dstOffset & 3)) >> 2;\n"
"	int dx  = ((idx % (tpr)) << 2) - (dstOffset & 3);\n"
"	int dy = idx / (tpr);\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dstOffset + dy * dstStep + dx);\n"
"	uint4 id;\n"
"	edge(dx - left, srcCols, id.x);\n"
"	edge(dx - left + 1, srcCols, id.x);\n"
"	edge(dx - left + 2, srcCols, id.x);\n"
"	edge(dx - left + 3, srcCols, id.x);\n"
"	\n"
"	int start = min(id.x, id.w) + srcOffset;\n"
"	uchar8 s = *((__global uchar8 *)(src + clamp(dy - top, 0, srcRows - 1) * srcStep + ((start >> 2) << 2)));\n"
"	uchar sa[8] = {s.s0, s.s1, s.s2, s.s3, s.s4, s.s5, s.s6, s.s7};\n"
"	\n"
"	int det = start & 3;\n"
"	uchar4 v = (uchar4)(sa[(id.x - start) + det], sa[(id.y - start) + det], sa[(id.z - start) + det], sa[(id.w - start) + det]);\n"
"	\n"
"	if (dy < dstRows)\n"
"	{\n"
"		uchar4 res = *d;\n"
"		res.x = (dx >= 0 && dx < dstCols) ? v.x : res.x;\n"
"		res.y = (dx + 1 >= 0 && dx + 1 < dstCols) ? v.y : res.y;\n"
"		res.z = (dx + 2 >= 0 && dx + 2 < dstCols) ? v.z : res.z;\n"
"		res.w = (dx + 3 >= 0 && dx + 3 < dstCols) ? v.w : res.w;\n"
"		\n"
"		*d = res;\n"
"	}\n"
"}\n"
"#undef edge(x,size,rx)\n"
;
const char *imgproc_histogram =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#define PARTITAL_HISTGRAM256_COUNT     (256)\n"
"#define HISTOGRAM256_BIN_COUNT         (256)\n"
"#define HISTGRAM256_WORK_GROUP_SIZE     (256)\n"
"#define HISTGRAM256_LOCAL_MEM_SIZE      (HISTOGRAM256_BIN_COUNT)\n"
"__kernel __attribute__((reqd_work_group_size(256, 1, 1)))void calc_sub_hist_D0(__global const uchar4 *src,\n"
"        int src_step,\n"
"        int src_offset,\n"
"        __global int   *buf,\n"
"        int data_count,\n"
"        int cols,\n"
"        int inc_x,\n"
"        int inc_y,\n"
"        int dst_offset)\n"
"{\n"
"	int x  = get_global_id(0);\n"
"	int lx = get_local_id(0);\n"
"	int gx = get_group_id(0);\n"
"	int total_threads = get_global_size(0);\n"
"	src +=  src_offset;\n"
"	__local int s_hist[HISTGRAM256_LOCAL_MEM_SIZE];\n"
"	s_hist[lx] = 0;\n"
"	\n"
"	int pos_y = x / cols;\n"
"	int pos_x = x - mul24(pos_y, cols);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	for (int pos = x; pos < data_count; pos += total_threads)\n"
"	{\n"
"		int4 data = convert_int4(src[mad24(pos_y, src_step, pos_x)]);\n"
"		atomic_inc(s_hist + data.x);\n"
"		atomic_inc(s_hist + data.y);\n"
"		atomic_inc(s_hist + data.z);\n"
"		atomic_inc(s_hist + data.w);\n"
"		\n"
"		pos_x += inc_x;\n"
"		int off = (pos_x >= cols ? -1 : 0);\n"
"		pos_x =  mad24(off, cols, pos_x);\n"
"		pos_y += inc_y - off;\n"
"		\n"
"		//pos_x = pos_x > cols ? pos_x - cols : pos_x;\n"
"		//pos_y = pos_x > cols ? pos_y + 1 : pos_y;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	buf[ mad24(gx, dst_offset, lx)] = s_hist[lx];\n"
"}\n"
"__kernel void __attribute__((reqd_work_group_size(1, 256, 1)))calc_sub_hist2_D0(__global const uchar *src,\n"
"        int src_step,\n"
"        int src_offset,\n"
"        __global int   *buf,\n"
"        int left_col,\n"
"        int cols,\n"
"        int rows,\n"
"        int dst_offset)\n"
"{\n"
"	int gidx = get_global_id(0);\n"
"	int gidy = get_global_id(1);\n"
"	int gx = get_group_id(0);\n"
"	int gy = get_group_id(1);\n"
"	int gnum = get_num_groups(0);\n"
"	int output_row = mad24(gy, gnum, gx);\n"
"	//int lidx = get_local_id(0);\n"
"	int lidy = get_local_id(1);\n"
"	\n"
"	__local int s_hist[HISTGRAM256_LOCAL_MEM_SIZE + 1];\n"
"	s_hist[lidy] = 0;\n"
"	//mem_fence(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	\n"
"	//clamp(gidx,mask,cols-1);\n"
"	gidx = gidx >= left_col ? cols + gidx : gidx;\n"
"	//gidy = gidy >= rows?rows-1:gidy;\n"
"	\n"
"	int src_index = src_offset + mad24(gidy, src_step, gidx);\n"
"	//int dst_index = dst_offset + mad24(gidy,dst_step,gidx);\n"
"	//uchar4 p,q;\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	int p = (int)src[src_index];\n"
"	p = gidy >= rows ? HISTGRAM256_LOCAL_MEM_SIZE : p;\n"
"	atomic_inc(s_hist + p);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	buf[ mad24(output_row, dst_offset, lidy)] += s_hist[lidy];\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(256, 1, 1)))void merge_hist(__global int *buf,\n"
"        __global int *hist,\n"
"        int src_step)\n"
"{\n"
"	int lx = get_local_id(0);\n"
"	int gx = get_group_id(0);\n"
"	\n"
"	int sum = 0;\n"
"	\n"
"	for (int i = lx; i < PARTITAL_HISTGRAM256_COUNT; i += HISTGRAM256_WORK_GROUP_SIZE)\n"
"	{\n"
"		sum += buf[ mad24(i, src_step, gx)];\n"
"	}\n"
"	\n"
"	__local int data[HISTGRAM256_WORK_GROUP_SIZE];\n"
"	data[lx] = sum;\n"
"	\n"
"	for (int stride = HISTGRAM256_WORK_GROUP_SIZE / 2; stride > 0; stride >>= 1)\n"
"	{\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		if (lx < stride)\n"
"		{\n"
"			data[lx] += data[lx + stride];\n"
"		}\n"
"	}\n"
"	\n"
"	if (lx == 0)\n"
"	{\n"
"		hist[gx] = data[0];\n"
"	}\n"
"}\n"
"__kernel __attribute__((reqd_work_group_size(256, 1, 1)))void calLUT(\n"
"    __global uchar *dst,\n"
"    __constant int *hist,\n"
"    float scale)\n"
"{\n"
"	int lid = get_local_id(0);\n"
"	__local int sumhist[HISTOGRAM256_BIN_COUNT];\n"
"	//__local uchar lut[HISTOGRAM256_BIN_COUNT+1];\n"
"	\n"
"	sumhist[lid] = hist[lid];\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (lid == 0)\n"
"	{\n"
"		int sum = 0;\n"
"		\n"
"		for (int i = 0; i < HISTOGRAM256_BIN_COUNT; i++)\n"
"		{\n"
"			sum += sumhist[i];\n"
"			sumhist[i] = sum;\n"
"		}\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	dst[lid] = lid == 0 ? 0 : convert_uchar_sat(convert_float(sumhist[lid]) * scale);\n"
"}\n"
"/*\n"
"///////////////////////////////equalizeHist//////////////////////////////////////////////////\n"
"__kernel __attribute__((reqd_work_group_size(256,1,1)))void equalizeHist(\n"
"							__global uchar * src,\n"
"							__global uchar * dst,\n"
"							__constant int * hist,\n"
"							int srcstep,\n"
"							int srcoffset,\n"
"							int dststep,\n"
"							int dstoffset,\n"
"							int width,\n"
"							int height,\n"
"							float scale,\n"
"							int inc_x,\n"
"							int inc_y)\n"
"{\n"
"	int gidx = get_global_id(0);\n"
"	int lid = get_local_id(0);\n"
"	int glb_size = get_global_size(0);\n"
"	src+=srcoffset;\n"
"	dst+=dstoffset;\n"
"	__local int sumhist[HISTOGRAM256_BIN_COUNT];\n"
"	__local uchar lut[HISTOGRAM256_BIN_COUNT+1];\n"
"	sumhist[lid]=hist[lid];\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	if(lid==0)\n"
"	{\n"
"		int sum = 0;\n"
"		for(int i=0;i<HISTOGRAM256_BIN_COUNT;i++)\n"
"		{\n"
"			sum+=sumhist[i];\n"
"			sumhist[i]=sum;\n"
"		}\n"
"	}\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	lut[lid]= convert_uchar_sat(convert_float(sumhist[lid])*scale);\n"
"	lut[0]=0;\n"
"    int pos_y = gidx / width;\n"
"    int pos_x = gidx - mul24(pos_y, width);\n"
"    for(int pos = gidx; pos < mul24(width,height); pos += glb_size)\n"
"	{\n"
"		int inaddr = mad24(pos_y,srcstep,pos_x);\n"
"		int outaddr = mad24(pos_y,dststep,pos_x);\n"
"		dst[outaddr] = lut[src[inaddr]];\n"
"		pos_x +=inc_x;\n"
"		int off = (pos_x >= width ? -1 : 0);\n"
"		pos_x =  mad24(off,width,pos_x);\n"
"		pos_y += inc_y - off;\n"
"	}\n"
"}\n"
"*/\n"
;
const char *imgproc_integral =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#define LSIZE 256\n"
"#define LSIZE_1 255\n"
"#define LSIZE_2 254\n"
"#define HF_LSIZE 128\n"
"#define LOG_LSIZE 8\n"
"#define LOG_NUM_BANKS 5\n"
"#define NUM_BANKS 32\n"
"#define GET_CONFLICT_OFFSET(lid) ((lid) >> LOG_NUM_BANKS)\n"
"kernel void integral_cols(__global uchar4 *src, __global int *sum , __global float *sqsum,\n"
"                          int src_offset, int pre_invalid, int rows, int cols, int src_step, int dst_step)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	int4 src_t[2], sum_t[2];\n"
"	float4 sqsum_t[2];\n"
"	__local int4 lm_sum[2][LSIZE + LOG_LSIZE];\n"
"	__local float4 lm_sqsum[2][LSIZE + LOG_LSIZE];\n"
"	__local int *sum_p;\n"
"	__local float *sqsum_p;\n"
"	src_step = src_step >> 2;\n"
"	gid = gid << 1;\n"
"	\n"
"	for (int i = 0; i < rows; i = i + LSIZE_1)\n"
"	{\n"
"		src_t[0] = (i + lid < rows ? convert_int4(src[src_offset + (lid + i) * src_step + gid]) : 0);\n"
"		src_t[1] = (i + lid < rows ? convert_int4(src[src_offset + (lid + i) * src_step + gid + 1]) : 0);\n"
"		\n"
"		sum_t[0] = (i == 0 ? 0 : lm_sum[0][LSIZE_2 + LOG_LSIZE]);\n"
"		sqsum_t[0] = (i == 0 ? 0 : lm_sqsum[0][LSIZE_2 + LOG_LSIZE]);\n"
"		sum_t[1] = (i == 0 ? 0 : lm_sum[1][LSIZE_2 + LOG_LSIZE]);\n"
"		sqsum_t[1] = (i == 0 ? 0 : lm_sqsum[1][LSIZE_2 + LOG_LSIZE]);\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		int bf_loc = lid + GET_CONFLICT_OFFSET(lid);\n"
"		lm_sum[0][bf_loc] = src_t[0];\n"
"		lm_sqsum[0][bf_loc] = convert_float4(src_t[0] * src_t[0]);\n"
"		\n"
"		lm_sum[1][bf_loc] = src_t[1];\n"
"		lm_sqsum[1][bf_loc] = convert_float4(src_t[1] * src_t[1]);\n"
"		\n"
"		int offset = 1;\n"
"		\n"
"		for (int d = LSIZE >> 1 ;  d > 0; d >>= 1)\n"
"		{\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			int ai = offset * (((lid & 127) << 1) + 1) - 1, bi = ai + offset;\n"
"			ai += GET_CONFLICT_OFFSET(ai);\n"
"			bi += GET_CONFLICT_OFFSET(bi);\n"
"			\n"
"			if ((lid & 127) < d)\n"
"			{\n"
"				lm_sum[lid >> 7][bi]  +=  lm_sum[lid >> 7][ai];\n"
"				lm_sqsum[lid >> 7][bi]  +=  lm_sqsum[lid >> 7][ai];\n"
"			}\n"
"			\n"
"			offset <<= 1;\n"
"		}\n"
"		\n"
"		if (lid < 2)\n"
"		{\n"
"			lm_sum[lid][LSIZE_2 + LOG_LSIZE] = 0;\n"
"			lm_sqsum[lid][LSIZE_2 + LOG_LSIZE] = 0;\n"
"		}\n"
"		\n"
"		for (int d = 1;  d < LSIZE; d <<= 1)\n"
"		{\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			offset >>= 1;\n"
"			int ai = offset * (((lid & 127) << 1) + 1) - 1, bi = ai + offset;\n"
"			ai += GET_CONFLICT_OFFSET(ai);\n"
"			bi += GET_CONFLICT_OFFSET(bi);\n"
"			\n"
"			if ((lid & 127) < d)\n"
"			{\n"
"				lm_sum[lid >> 7][bi] += lm_sum[lid >> 7][ai];\n"
"				lm_sum[lid >> 7][ai] = lm_sum[lid >> 7][bi] - lm_sum[lid >> 7][ai];\n"
"				\n"
"				lm_sqsum[lid >> 7][bi] += lm_sqsum[lid >> 7][ai];\n"
"				lm_sqsum[lid >> 7][ai] = lm_sqsum[lid >> 7][bi] - lm_sqsum[lid >> 7][ai];\n"
"			}\n"
"		}\n"
"		\n"
"		if (lid > 0 & (i + lid) <= rows)\n"
"		{\n"
"			int loc_s0 = gid * dst_step + i + lid - 1 - pre_invalid * dst_step / 4, loc_s1 = loc_s0 + dst_step ;\n"
"			lm_sum[0][bf_loc] += sum_t[0];\n"
"			lm_sum[1][bf_loc] += sum_t[1];\n"
"			lm_sqsum[0][bf_loc] += sqsum_t[0];\n"
"			lm_sqsum[1][bf_loc] += sqsum_t[1];\n"
"			sum_p = (__local int *)(&(lm_sum[0][bf_loc]));\n"
"			sqsum_p = (__local float *)(&(lm_sqsum[0][bf_loc]));\n"
"			\n"
"			for (int k = 0; k < 4; k++)\n"
"			{\n"
"				if (gid * 4 + k >= cols + pre_invalid || gid * 4 + k < pre_invalid)\n"
"				{\n"
"					continue;\n"
"				}\n"
"				\n"
"				sum[loc_s0 + k * dst_step / 4] = sum_p[k];\n"
"				sqsum[loc_s0 + k * dst_step / 4] = sqsum_p[k];\n"
"			}\n"
"			\n"
"			sum_p = (__local int *)(&(lm_sum[1][bf_loc]));\n"
"			sqsum_p = (__local float *)(&(lm_sqsum[1][bf_loc]));\n"
"			\n"
"			for (int k = 0; k < 4; k++)\n"
"			{\n"
"				if (gid * 4 + k + 4 >= cols + pre_invalid)\n"
"				{\n"
"					break;\n"
"				}\n"
"				\n"
"				sum[loc_s1 + k * dst_step / 4] = sum_p[k];\n"
"				sqsum[loc_s1 + k * dst_step / 4] = sqsum_p[k];\n"
"			}\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"}\n"
"kernel void integral_rows(__global int4 *srcsum, __global float4 *srcsqsum, __global int *sum ,\n"
"                          __global float *sqsum, int rows, int cols, int src_step, int sum_step,\n"
"                          int sqsum_step, int sum_offset, int sqsum_offset)\n"
"{\n"
"	unsigned int lid = get_local_id(0);\n"
"	unsigned int gid = get_group_id(0);\n"
"	int4 src_t[2], sum_t[2];\n"
"	float4 sqsrc_t[2], sqsum_t[2];\n"
"	__local int4 lm_sum[2][LSIZE + LOG_LSIZE];\n"
"	__local float4 lm_sqsum[2][LSIZE + LOG_LSIZE];\n"
"	__local int *sum_p;\n"
"	__local float *sqsum_p;\n"
"	src_step = src_step >> 4;\n"
"	\n"
"	for (int i = 0; i < rows; i = i + LSIZE_1)\n"
"	{\n"
"		src_t[0] = i + lid < rows ? srcsum[(lid + i) * src_step + gid * 2] : 0;\n"
"		sqsrc_t[0] = i + lid < rows ? srcsqsum[(lid + i) * src_step + gid * 2] : 0;\n"
"		src_t[1] = i + lid < rows ? srcsum[(lid + i) * src_step + gid * 2 + 1] : 0;\n"
"		sqsrc_t[1] = i + lid < rows ? srcsqsum[(lid + i) * src_step + gid * 2 + 1] : 0;\n"
"		\n"
"		sum_t[0] = (i == 0 ? 0 : lm_sum[0][LSIZE_2 + LOG_LSIZE]);\n"
"		sqsum_t[0] = (i == 0 ? 0 : lm_sqsum[0][LSIZE_2 + LOG_LSIZE]);\n"
"		sum_t[1] = (i == 0 ? 0 : lm_sum[1][LSIZE_2 + LOG_LSIZE]);\n"
"		sqsum_t[1] = (i == 0 ? 0 : lm_sqsum[1][LSIZE_2 + LOG_LSIZE]);\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		int bf_loc = lid + GET_CONFLICT_OFFSET(lid);\n"
"		lm_sum[0][bf_loc] = src_t[0];\n"
"		lm_sqsum[0][bf_loc] = sqsrc_t[0];\n"
"		\n"
"		lm_sum[1][bf_loc] = src_t[1];\n"
"		lm_sqsum[1][bf_loc] = sqsrc_t[1];\n"
"		\n"
"		int offset = 1;\n"
"		\n"
"		for (int d = LSIZE >> 1 ;  d > 0; d >>= 1)\n"
"		{\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			int ai = offset * (((lid & 127) << 1) + 1) - 1, bi = ai + offset;\n"
"			ai += GET_CONFLICT_OFFSET(ai);\n"
"			bi += GET_CONFLICT_OFFSET(bi);\n"
"			\n"
"			if ((lid & 127) < d)\n"
"			{\n"
"				lm_sum[lid >> 7][bi]  +=  lm_sum[lid >> 7][ai];\n"
"				lm_sqsum[lid >> 7][bi]  +=  lm_sqsum[lid >> 7][ai];\n"
"			}\n"
"			\n"
"			offset <<= 1;\n"
"		}\n"
"		\n"
"		if (lid < 2)\n"
"		{\n"
"			lm_sum[lid][LSIZE_2 + LOG_LSIZE] = 0;\n"
"			lm_sqsum[lid][LSIZE_2 + LOG_LSIZE] = 0;\n"
"		}\n"
"		\n"
"		for (int d = 1;  d < LSIZE; d <<= 1)\n"
"		{\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			offset >>= 1;\n"
"			int ai = offset * (((lid & 127) << 1) + 1) - 1, bi = ai + offset;\n"
"			ai += GET_CONFLICT_OFFSET(ai);\n"
"			bi += GET_CONFLICT_OFFSET(bi);\n"
"			\n"
"			if ((lid & 127) < d)\n"
"			{\n"
"				lm_sum[lid >> 7][bi] += lm_sum[lid >> 7][ai];\n"
"				lm_sum[lid >> 7][ai] = lm_sum[lid >> 7][bi] - lm_sum[lid >> 7][ai];\n"
"				\n"
"				lm_sqsum[lid >> 7][bi] += lm_sqsum[lid >> 7][ai];\n"
"				lm_sqsum[lid >> 7][ai] = lm_sqsum[lid >> 7][bi] - lm_sqsum[lid >> 7][ai];\n"
"			}\n"
"		}\n"
"		\n"
"		if (gid == 0 && (i + lid) <= rows)\n"
"		{\n"
"			sum[sum_offset + i + lid] = 0;\n"
"			sqsum[sqsum_offset + i + lid] = 0;\n"
"		}\n"
"		\n"
"		if (i + lid == 0)\n"
"		{\n"
"			int loc0 = gid * 2 * sum_step;\n"
"			int loc1 = gid * 2 * sqsum_step;\n"
"			\n"
"			for (int k = 1; k <= 8; k++)\n"
"			{\n"
"				if (gid * 8 + k > cols)\n"
"				{\n"
"					break;\n"
"				}\n"
"				\n"
"				sum[sum_offset + loc0 + k * sum_step / 4] = 0;\n"
"				sqsum[sqsum_offset + loc1 + k * sqsum_step / 4] = 0;\n"
"			}\n"
"		}\n"
"		\n"
"		if (lid > 0 & (i + lid) <= rows)\n"
"		{\n"
"			int loc_s0 = sum_offset + gid * 2 * sum_step + sum_step / 4 + i + lid, loc_s1 = loc_s0 + sum_step ;\n"
"			int loc_sq0 = sqsum_offset + gid * 2 * sqsum_step + sqsum_step / 4 + i + lid, loc_sq1 = loc_sq0 + sqsum_step ;\n"
"			lm_sum[0][bf_loc] += sum_t[0];\n"
"			lm_sum[1][bf_loc] += sum_t[1];\n"
"			lm_sqsum[0][bf_loc] += sqsum_t[0];\n"
"			lm_sqsum[1][bf_loc] += sqsum_t[1];\n"
"			sum_p = (__local int *)(&(lm_sum[0][bf_loc]));\n"
"			sqsum_p = (__local float *)(&(lm_sqsum[0][bf_loc]));\n"
"			\n"
"			for (int k = 0; k < 4; k++)\n"
"			{\n"
"				if (gid * 8 + k >= cols)\n"
"				{\n"
"					break;\n"
"				}\n"
"				\n"
"				sum[loc_s0 + k * sum_step / 4] = sum_p[k];\n"
"				sqsum[loc_sq0 + k * sqsum_step / 4] = sqsum_p[k];\n"
"			}\n"
"			\n"
"			sum_p = (__local int *)(&(lm_sum[1][bf_loc]));\n"
"			sqsum_p = (__local float *)(&(lm_sqsum[1][bf_loc]));\n"
"			\n"
"			for (int k = 0; k < 4; k++)\n"
"			{\n"
"				if (gid * 8 + 4 + k >= cols)\n"
"				{\n"
"					break;\n"
"				}\n"
"				\n"
"				sum[loc_s1 + k * sum_step / 4] = sum_p[k];\n"
"				sqsum[loc_sq1 + k * sqsum_step / 4] = sqsum_p[k];\n"
"			}\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"	}\n"
"}\n"
;
const char *imgproc_median =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Zero Lin, zero.lin@amd.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"/*\n"
"__kernel void medianFilter_C1(__global uchar * src, __global uchar * dst,  int srcOffset, int dstOffset, int cols,\n"
"                                int rows, int srcStep, int dstStep, int m)\n"
"{\n"
"	int dx = get_global_id(0)-(m>>1);\n"
"    int dy = get_global_id(1)-(m>>1);\n"
"	short histom[256];\n"
"	for(int i=0;i<256;++i)\n"
"		histom[i]=0;\n"
"	for(int i=0;i<m;++i)\n"
"	{\n"
"		__global uchar * data = src + srcOffset + mul24(srcStep,clamp(dy + (i), 0, rows-1));\n"
"		for(int j=dx;j<dx+m;++j)\n"
"		{\n"
"			histom[data[clamp(j, 0, cols-1)]]++;\n"
"		}\n"
"	}\n"
"	int now=0;\n"
"	int goal=(m*m+1)>>1;\n"
"	int v;\n"
"	for(int i=0;i<256;++i)\n"
"	{\n"
"		v=(now<goal?i:v);\n"
"		now+=histom[i];\n"
"	}\n"
"	if(dy<rows && dx<cols)\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)]=v;\n"
"}\n"
"*/\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter3_C4_D0(__global uchar4 *src, __global uchar4 *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local uchar4 data[18][18];\n"
"	__global uchar4 *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 1;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 1;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 9 * 18 - 1);\n"
"	\n"
"	int dr = id / 18;\n"
"	int dc = id % 18;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 9, 0, rows - 1);\n"
"	data[dr + 9][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	uchar4 p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2];\n"
"	uchar4 p3 = data[y + 1][x], p4 = data[y + 1][x + 1], p5 = data[y + 1][x + 2];\n"
"	uchar4 p6 = data[y + 2][x], p7 = data[y + 2][x + 1], p8 = data[y + 2][x + 2];\n"
"	uchar4 mid;\n"
"	\n"
"	op(p1, p2); op(p4, p5); op(p7, p8); op(p0, p1);\n"
"	op(p3, p4); op(p6, p7); op(p1, p2); op(p4, p5);\n"
"	op(p7, p8); op(p0, p3); op(p5, p8); op(p4, p7);\n"
"	op(p3, p6); op(p1, p4); op(p2, p5); op(p4, p7);\n"
"	op(p4, p2); op(p6, p4); op(p4, p2);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p4;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter3_C1_D0(__global uchar *src, __global uchar *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local uchar data[18][18];\n"
"	__global uchar *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 1;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 1;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 9 * 18 - 1);\n"
"	\n"
"	int dr = id / 18;\n"
"	int dc = id % 18;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 9, 0, rows - 1);\n"
"	data[dr + 9][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	uchar p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2];\n"
"	uchar p3 = data[y + 1][x], p4 = data[y + 1][x + 1], p5 = data[y + 1][x + 2];\n"
"	uchar p6 = data[y + 2][x], p7 = data[y + 2][x + 1], p8 = data[y + 2][x + 2];\n"
"	uchar mid;\n"
"	\n"
"	op(p1, p2); op(p4, p5); op(p7, p8); op(p0, p1);\n"
"	op(p3, p4); op(p6, p7); op(p1, p2); op(p4, p5);\n"
"	op(p7, p8); op(p0, p3); op(p5, p8); op(p4, p7);\n"
"	op(p3, p6); op(p1, p4); op(p2, p5); op(p4, p7);\n"
"	op(p4, p2); op(p6, p4); op(p4, p2);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p4;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter3_C1_D5(__global float *src, __global float *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local float data[18][18];\n"
"	__global float *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 1;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 1;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 9 * 18 - 1);\n"
"	\n"
"	int dr = id / 18;\n"
"	int dc = id % 18;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 9, 0, rows - 1);\n"
"	data[dr + 9][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	float p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2];\n"
"	float p3 = data[y + 1][x], p4 = data[y + 1][x + 1], p5 = data[y + 1][x + 2];\n"
"	float p6 = data[y + 2][x], p7 = data[y + 2][x + 1], p8 = data[y + 2][x + 2];\n"
"	float mid;\n"
"	\n"
"	op(p1, p2); op(p4, p5); op(p7, p8); op(p0, p1);\n"
"	op(p3, p4); op(p6, p7); op(p1, p2); op(p4, p5);\n"
"	op(p7, p8); op(p0, p3); op(p5, p8); op(p4, p7);\n"
"	op(p3, p6); op(p1, p4); op(p2, p5); op(p4, p7);\n"
"	op(p4, p2); op(p6, p4); op(p4, p2);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p4;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter3_C4_D5(__global float4 *src, __global float4 *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local float4 data[18][18];\n"
"	__global float4 *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 1;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 1;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 9 * 18 - 1);\n"
"	\n"
"	int dr = id / 18;\n"
"	int dc = id % 18;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 9, 0, rows - 1);\n"
"	data[dr + 9][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	float4 p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2];\n"
"	float4 p3 = data[y + 1][x], p4 = data[y + 1][x + 1], p5 = data[y + 1][x + 2];\n"
"	float4 p6 = data[y + 2][x], p7 = data[y + 2][x + 1], p8 = data[y + 2][x + 2];\n"
"	float4 mid;\n"
"	\n"
"	op(p1, p2); op(p4, p5); op(p7, p8); op(p0, p1);\n"
"	op(p3, p4); op(p6, p7); op(p1, p2); op(p4, p5);\n"
"	op(p7, p8); op(p0, p3); op(p5, p8); op(p4, p7);\n"
"	op(p3, p6); op(p1, p4); op(p2, p5); op(p4, p7);\n"
"	op(p4, p2); op(p6, p4); op(p4, p2);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p4;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter5_C4_D0(__global uchar4 *src, __global uchar4 *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local uchar4 data[20][20];\n"
"	__global uchar4 *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 2;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 2;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 10 * 20 - 1);\n"
"	\n"
"	int dr = id / 20;\n"
"	int dc = id % 20;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 10, 0, rows - 1);\n"
"	data[dr + 10][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	uchar4 p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2], p3 = data[y][x + 3], p4 = data[y][x + 4];\n"
"	uchar4 p5 = data[y + 1][x], p6 = data[y + 1][x + 1], p7 = data[y + 1][x + 2], p8 = data[y + 1][x + 3], p9 = data[y + 1][x + 4];\n"
"	uchar4 p10 = data[y + 2][x], p11 = data[y + 2][x + 1], p12 = data[y + 2][x + 2], p13 = data[y + 2][x + 3], p14 = data[y + 2][x + 4];\n"
"	uchar4 p15 = data[y + 3][x], p16 = data[y + 3][x + 1], p17 = data[y + 3][x + 2], p18 = data[y + 3][x + 3], p19 = data[y + 3][x + 4];\n"
"	uchar4 p20 = data[y + 4][x], p21 = data[y + 4][x + 1], p22 = data[y + 4][x + 2], p23 = data[y + 4][x + 3], p24 = data[y + 4][x + 4];\n"
"	uchar4 mid;\n"
"	\n"
"	op(p1, p2); op(p0, p1); op(p1, p2); op(p4, p5); op(p3, p4);\n"
"	op(p4, p5); op(p0, p3); op(p2, p5); op(p2, p3); op(p1, p4);\n"
"	op(p1, p2); op(p3, p4); op(p7, p8); op(p6, p7); op(p7, p8);\n"
"	op(p10, p11); op(p9, p10); op(p10, p11); op(p6, p9); op(p8, p11);\n"
"	op(p8, p9); op(p7, p10); op(p7, p8); op(p9, p10); op(p0, p6);\n"
"	op(p4, p10); op(p4, p6); op(p2, p8); op(p2, p4); op(p6, p8);\n"
"	op(p1, p7); op(p5, p11); op(p5, p7); op(p3, p9); op(p3, p5);\n"
"	op(p7, p9); op(p1, p2); op(p3, p4); op(p5, p6); op(p7, p8);\n"
"	op(p9, p10); op(p13, p14); op(p12, p13); op(p13, p14); op(p16, p17);\n"
"	op(p15, p16); op(p16, p17); op(p12, p15); op(p14, p17); op(p14, p15);\n"
"	op(p13, p16); op(p13, p14); op(p15, p16); op(p19, p20); op(p18, p19);\n"
"	op(p19, p20); op(p21, p22); op(p23, p24); op(p21, p23); op(p22, p24);\n"
"	op(p22, p23); op(p18, p21); op(p20, p23); op(p20, p21); op(p19, p22);\n"
"	op(p22, p24); op(p19, p20); op(p21, p22); op(p23, p24); op(p12, p18);\n"
"	op(p16, p22); op(p16, p18); op(p14, p20); op(p20, p24); op(p14, p16);\n"
"	op(p18, p20); op(p22, p24); op(p13, p19); op(p17, p23); op(p17, p19);\n"
"	op(p15, p21); op(p15, p17); op(p19, p21); op(p13, p14); op(p15, p16);\n"
"	op(p17, p18); op(p19, p20); op(p21, p22); op(p23, p24); op(p0, p12);\n"
"	op(p8, p20); op(p8, p12); op(p4, p16); op(p16, p24); op(p12, p16);\n"
"	op(p2, p14); op(p10, p22); op(p10, p14); op(p6, p18); op(p6, p10);\n"
"	op(p10, p12); op(p1, p13); op(p9, p21); op(p9, p13); op(p5, p17);\n"
"	op(p13, p17); op(p3, p15); op(p11, p23); op(p11, p15); op(p7, p19);\n"
"	op(p7, p11); op(p11, p13); op(p11, p12);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p12;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter5_C1_D0(__global uchar *src, __global uchar *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local uchar data[20][20];\n"
"	__global uchar *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 2;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 2;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 10 * 20 - 1);\n"
"	\n"
"	int dr = id / 20;\n"
"	int dc = id % 20;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 10, 0, rows - 1);\n"
"	data[dr + 10][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	uchar p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2], p3 = data[y][x + 3], p4 = data[y][x + 4];\n"
"	uchar p5 = data[y + 1][x], p6 = data[y + 1][x + 1], p7 = data[y + 1][x + 2], p8 = data[y + 1][x + 3], p9 = data[y + 1][x + 4];\n"
"	uchar p10 = data[y + 2][x], p11 = data[y + 2][x + 1], p12 = data[y + 2][x + 2], p13 = data[y + 2][x + 3], p14 = data[y + 2][x + 4];\n"
"	uchar p15 = data[y + 3][x], p16 = data[y + 3][x + 1], p17 = data[y + 3][x + 2], p18 = data[y + 3][x + 3], p19 = data[y + 3][x + 4];\n"
"	uchar p20 = data[y + 4][x], p21 = data[y + 4][x + 1], p22 = data[y + 4][x + 2], p23 = data[y + 4][x + 3], p24 = data[y + 4][x + 4];\n"
"	uchar mid;\n"
"	\n"
"	op(p1, p2); op(p0, p1); op(p1, p2); op(p4, p5); op(p3, p4);\n"
"	op(p4, p5); op(p0, p3); op(p2, p5); op(p2, p3); op(p1, p4);\n"
"	op(p1, p2); op(p3, p4); op(p7, p8); op(p6, p7); op(p7, p8);\n"
"	op(p10, p11); op(p9, p10); op(p10, p11); op(p6, p9); op(p8, p11);\n"
"	op(p8, p9); op(p7, p10); op(p7, p8); op(p9, p10); op(p0, p6);\n"
"	op(p4, p10); op(p4, p6); op(p2, p8); op(p2, p4); op(p6, p8);\n"
"	op(p1, p7); op(p5, p11); op(p5, p7); op(p3, p9); op(p3, p5);\n"
"	op(p7, p9); op(p1, p2); op(p3, p4); op(p5, p6); op(p7, p8);\n"
"	op(p9, p10); op(p13, p14); op(p12, p13); op(p13, p14); op(p16, p17);\n"
"	op(p15, p16); op(p16, p17); op(p12, p15); op(p14, p17); op(p14, p15);\n"
"	op(p13, p16); op(p13, p14); op(p15, p16); op(p19, p20); op(p18, p19);\n"
"	op(p19, p20); op(p21, p22); op(p23, p24); op(p21, p23); op(p22, p24);\n"
"	op(p22, p23); op(p18, p21); op(p20, p23); op(p20, p21); op(p19, p22);\n"
"	op(p22, p24); op(p19, p20); op(p21, p22); op(p23, p24); op(p12, p18);\n"
"	op(p16, p22); op(p16, p18); op(p14, p20); op(p20, p24); op(p14, p16);\n"
"	op(p18, p20); op(p22, p24); op(p13, p19); op(p17, p23); op(p17, p19);\n"
"	op(p15, p21); op(p15, p17); op(p19, p21); op(p13, p14); op(p15, p16);\n"
"	op(p17, p18); op(p19, p20); op(p21, p22); op(p23, p24); op(p0, p12);\n"
"	op(p8, p20); op(p8, p12); op(p4, p16); op(p16, p24); op(p12, p16);\n"
"	op(p2, p14); op(p10, p22); op(p10, p14); op(p6, p18); op(p6, p10);\n"
"	op(p10, p12); op(p1, p13); op(p9, p21); op(p9, p13); op(p5, p17);\n"
"	op(p13, p17); op(p3, p15); op(p11, p23); op(p11, p15); op(p7, p19);\n"
"	op(p7, p11); op(p11, p13); op(p11, p12);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p12;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter5_C4_D5(__global float4 *src, __global float4 *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local float4 data[20][20];\n"
"	__global float4 *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 2;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 2;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 10 * 20 - 1);\n"
"	\n"
"	int dr = id / 20;\n"
"	int dc = id % 20;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 10, 0, rows - 1);\n"
"	data[dr + 10][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	float4 p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2], p3 = data[y][x + 3], p4 = data[y][x + 4];\n"
"	float4 p5 = data[y + 1][x], p6 = data[y + 1][x + 1], p7 = data[y + 1][x + 2], p8 = data[y + 1][x + 3], p9 = data[y + 1][x + 4];\n"
"	float4 p10 = data[y + 2][x], p11 = data[y + 2][x + 1], p12 = data[y + 2][x + 2], p13 = data[y + 2][x + 3], p14 = data[y + 2][x + 4];\n"
"	float4 p15 = data[y + 3][x], p16 = data[y + 3][x + 1], p17 = data[y + 3][x + 2], p18 = data[y + 3][x + 3], p19 = data[y + 3][x + 4];\n"
"	float4 p20 = data[y + 4][x], p21 = data[y + 4][x + 1], p22 = data[y + 4][x + 2], p23 = data[y + 4][x + 3], p24 = data[y + 4][x + 4];\n"
"	float4 mid;\n"
"	\n"
"	op(p1, p2); op(p0, p1); op(p1, p2); op(p4, p5); op(p3, p4);\n"
"	op(p4, p5); op(p0, p3); op(p2, p5); op(p2, p3); op(p1, p4);\n"
"	op(p1, p2); op(p3, p4); op(p7, p8); op(p6, p7); op(p7, p8);\n"
"	op(p10, p11); op(p9, p10); op(p10, p11); op(p6, p9); op(p8, p11);\n"
"	op(p8, p9); op(p7, p10); op(p7, p8); op(p9, p10); op(p0, p6);\n"
"	op(p4, p10); op(p4, p6); op(p2, p8); op(p2, p4); op(p6, p8);\n"
"	op(p1, p7); op(p5, p11); op(p5, p7); op(p3, p9); op(p3, p5);\n"
"	op(p7, p9); op(p1, p2); op(p3, p4); op(p5, p6); op(p7, p8);\n"
"	op(p9, p10); op(p13, p14); op(p12, p13); op(p13, p14); op(p16, p17);\n"
"	op(p15, p16); op(p16, p17); op(p12, p15); op(p14, p17); op(p14, p15);\n"
"	op(p13, p16); op(p13, p14); op(p15, p16); op(p19, p20); op(p18, p19);\n"
"	op(p19, p20); op(p21, p22); op(p23, p24); op(p21, p23); op(p22, p24);\n"
"	op(p22, p23); op(p18, p21); op(p20, p23); op(p20, p21); op(p19, p22);\n"
"	op(p22, p24); op(p19, p20); op(p21, p22); op(p23, p24); op(p12, p18);\n"
"	op(p16, p22); op(p16, p18); op(p14, p20); op(p20, p24); op(p14, p16);\n"
"	op(p18, p20); op(p22, p24); op(p13, p19); op(p17, p23); op(p17, p19);\n"
"	op(p15, p21); op(p15, p17); op(p19, p21); op(p13, p14); op(p15, p16);\n"
"	op(p17, p18); op(p19, p20); op(p21, p22); op(p23, p24); op(p0, p12);\n"
"	op(p8, p20); op(p8, p12); op(p4, p16); op(p16, p24); op(p12, p16);\n"
"	op(p2, p14); op(p10, p22); op(p10, p14); op(p6, p18); op(p6, p10);\n"
"	op(p10, p12); op(p1, p13); op(p9, p21); op(p9, p13); op(p5, p17);\n"
"	op(p13, p17); op(p3, p15); op(p11, p23); op(p11, p15); op(p7, p19);\n"
"	op(p7, p11); op(p11, p13); op(p11, p12);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p12;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
"#define op(a,b) {mid=a; a=min(a,b); b=max(mid,b);}\n"
"__kernel void medianFilter5_C1_D5(__global float *src, __global float *dst,  int srcOffset, int dstOffset, int cols,\n"
"                                  int rows, int srcStep, int dstStep)\n"
"{\n"
"	__local float data[20][20];\n"
"	__global float *source = src + srcOffset;\n"
"	\n"
"	int dx = get_global_id(0) - get_local_id(0) - 2;\n"
"	int dy = get_global_id(1) - get_local_id(1) - 2;\n"
"	\n"
"	const int id = min((int)(get_local_id(0) * 16 + get_local_id(1)), 10 * 20 - 1);\n"
"	\n"
"	int dr = id / 20;\n"
"	int dc = id % 20;\n"
"	int r = clamp(dy + dr, 0, rows - 1);\n"
"	int c = clamp(dx + dc, 0, cols - 1);\n"
"	\n"
"	data[dr][dc] = source[r * srcStep + c];\n"
"	r = clamp(dy + dr + 10, 0, rows - 1);\n"
"	data[dr + 10][dc] = source[r * srcStep + c];\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int y = get_local_id(1);\n"
"	float p0 = data[y][x], p1 = data[y][x + 1], p2 = data[y][x + 2], p3 = data[y][x + 3], p4 = data[y][x + 4];\n"
"	float p5 = data[y + 1][x], p6 = data[y + 1][x + 1], p7 = data[y + 1][x + 2], p8 = data[y + 1][x + 3], p9 = data[y + 1][x + 4];\n"
"	float p10 = data[y + 2][x], p11 = data[y + 2][x + 1], p12 = data[y + 2][x + 2], p13 = data[y + 2][x + 3], p14 = data[y + 2][x + 4];\n"
"	float p15 = data[y + 3][x], p16 = data[y + 3][x + 1], p17 = data[y + 3][x + 2], p18 = data[y + 3][x + 3], p19 = data[y + 3][x + 4];\n"
"	float p20 = data[y + 4][x], p21 = data[y + 4][x + 1], p22 = data[y + 4][x + 2], p23 = data[y + 4][x + 3], p24 = data[y + 4][x + 4];\n"
"	float mid;\n"
"	\n"
"	op(p1, p2); op(p0, p1); op(p1, p2); op(p4, p5); op(p3, p4);\n"
"	op(p4, p5); op(p0, p3); op(p2, p5); op(p2, p3); op(p1, p4);\n"
"	op(p1, p2); op(p3, p4); op(p7, p8); op(p6, p7); op(p7, p8);\n"
"	op(p10, p11); op(p9, p10); op(p10, p11); op(p6, p9); op(p8, p11);\n"
"	op(p8, p9); op(p7, p10); op(p7, p8); op(p9, p10); op(p0, p6);\n"
"	op(p4, p10); op(p4, p6); op(p2, p8); op(p2, p4); op(p6, p8);\n"
"	op(p1, p7); op(p5, p11); op(p5, p7); op(p3, p9); op(p3, p5);\n"
"	op(p7, p9); op(p1, p2); op(p3, p4); op(p5, p6); op(p7, p8);\n"
"	op(p9, p10); op(p13, p14); op(p12, p13); op(p13, p14); op(p16, p17);\n"
"	op(p15, p16); op(p16, p17); op(p12, p15); op(p14, p17); op(p14, p15);\n"
"	op(p13, p16); op(p13, p14); op(p15, p16); op(p19, p20); op(p18, p19);\n"
"	op(p19, p20); op(p21, p22); op(p23, p24); op(p21, p23); op(p22, p24);\n"
"	op(p22, p23); op(p18, p21); op(p20, p23); op(p20, p21); op(p19, p22);\n"
"	op(p22, p24); op(p19, p20); op(p21, p22); op(p23, p24); op(p12, p18);\n"
"	op(p16, p22); op(p16, p18); op(p14, p20); op(p20, p24); op(p14, p16);\n"
"	op(p18, p20); op(p22, p24); op(p13, p19); op(p17, p23); op(p17, p19);\n"
"	op(p15, p21); op(p15, p17); op(p19, p21); op(p13, p14); op(p15, p16);\n"
"	op(p17, p18); op(p19, p20); op(p21, p22); op(p23, p24); op(p0, p12);\n"
"	op(p8, p20); op(p8, p12); op(p4, p16); op(p16, p24); op(p12, p16);\n"
"	op(p2, p14); op(p10, p22); op(p10, p14); op(p6, p18); op(p6, p10);\n"
"	op(p10, p12); op(p1, p13); op(p9, p21); op(p9, p13); op(p5, p17);\n"
"	op(p13, p17); op(p3, p15); op(p11, p23); op(p11, p15); op(p7, p19);\n"
"	op(p7, p11); op(p11, p13); op(p11, p12);\n"
"	\n"
"	if (get_global_id(1) < rows && get_global_id(0) < cols)\n"
"	{\n"
"		dst[dstOffset + get_global_id(1)*dstStep + get_global_id(0)] = p12;\n"
"	}\n"
"}\n"
"#undef op(a,b)\n"
;
const char *imgproc_resize =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zhang Ying, zhangying913@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"// resize kernel\n"
"// Currently, CV_8UC1  CV_8UC4  CV_32FC1 and CV_32FC4are supported.\n"
"// We shall support other types later if necessary.\n"
"#if defined DOUBLE_SUPPORT\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"typedef double F ;\n"
"#else\n"
"typedef float F;\n"
"#endif\n"
"inline int getPoint(__global unsigned char const *data, int offset, int x, int y, int step)\n"
"{\n"
"	return (data[offset + y * step + x]);\n"
"}\n"
"inline uint4 getPoint_8uc4(__global uchar4 *data, int offset, int x, int y, int step)\n"
"{\n"
"	return convert_uint4(data[(offset >> 2) + y * (step >> 2) + x]);\n"
"}\n"
"inline float getPoint_32fc1(__global float *data, int offset, int x, int y, int step)\n"
"{\n"
"	return data[(offset >> 2) + y * (step >> 2) + x];\n"
"}\n"
"inline float4 getPoint_32fc4(__global float4 *data, int offset, int x, int y, int step)\n"
"{\n"
"	return data[(offset >> 4) + y * (step >> 4) + x];\n"
"}\n"
"#define INTER_RESIZE_COEF_BITS 11\n"
"#define INTER_RESIZE_COEF_SCALE (1 << INTER_RESIZE_COEF_BITS)\n"
"#define CAST_BITS (INTER_RESIZE_COEF_BITS << 1)\n"
"#define CAST_SCALE (1.0f/(1<<CAST_BITS))\n"
"#define INC(x,l) ((x+1) >= (l) ? (x):((x)+1))\n"
"__kernel void resizeLN_C1_D0(__global unsigned char *dst, __global unsigned char const *restrict src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, float ifx, float ify)\n"
"{\n"
"	int gx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	float4  sx, u, xf;\n"
"	int4 x, DX;\n"
"	gx = (gx << 2) - (dst_offset & 3);\n"
"	DX = (int4)(gx, gx + 1, gx + 2, gx + 3);\n"
"	sx = (convert_float4(DX) + 0.5f) * ifx - 0.5f;\n"
"	xf = floor(sx);\n"
"	x = convert_int4(xf);\n"
"	u = sx - xf;\n"
"	float sy = ((dy + 0.5f) * ify - 0.5f);\n"
"	int y = floor(sy);\n"
"	float v = sy - y;\n"
"	\n"
"	u = x < 0 ? 0 : u;\n"
"	u = (x >= src_cols) ? 0 : u;\n"
"	x = x < 0 ? 0 : x;\n"
"	x = (x >= src_cols) ? src_cols - 1 : x;\n"
"	\n"
"	y < 0 ? y = 0, v = 0 : y;\n"
"	y >= src_rows ? y = src_rows - 1, v = 0 : y;\n"
"	\n"
"	int4 U, U1;\n"
"	int V, V1;\n"
"	float4 utmp1, utmp2;\n"
"	float vtmp;\n"
"	float4 scale_vec = INTER_RESIZE_COEF_SCALE;\n"
"	utmp1 = u * scale_vec;\n"
"	utmp2 = scale_vec - utmp1;\n"
"	U = convert_int4(rint(utmp1));\n"
"	U1 = convert_int4(rint(utmp2));\n"
"	vtmp = v * INTER_RESIZE_COEF_SCALE;\n"
"	V = rint(vtmp);\n"
"	V1 = rint(INTER_RESIZE_COEF_SCALE - vtmp);\n"
"	\n"
"	int y_ = INC(y, src_rows);\n"
"	int4 x_;\n"
"	x_ = ((x + 1 >= src_cols) != 0) ? x : x + 1;\n"
"	\n"
"	int4 val1, val2, val;\n"
"	int4 sdata1, sdata2, sdata3, sdata4;\n"
"	\n"
"	int4 pos1 = src_offset + y * src_step + x;\n"
"	int4 pos2 = src_offset + y * src_step + x_;\n"
"	int4 pos3 = src_offset + y_ * src_step + x;\n"
"	int4 pos4 = src_offset + y_ * src_step + x_;\n"
"	\n"
"	sdata1.s0 = src[pos1.s0];\n"
"	sdata1.s1 = src[pos1.s1];\n"
"	sdata1.s2 = src[pos1.s2];\n"
"	sdata1.s3 = src[pos1.s3];\n"
"	\n"
"	sdata2.s0 = src[pos2.s0];\n"
"	sdata2.s1 = src[pos2.s1];\n"
"	sdata2.s2 = src[pos2.s2];\n"
"	sdata2.s3 = src[pos2.s3];\n"
"	\n"
"	sdata3.s0 = src[pos3.s0];\n"
"	sdata3.s1 = src[pos3.s1];\n"
"	sdata3.s2 = src[pos3.s2];\n"
"	sdata3.s3 = src[pos3.s3];\n"
"	\n"
"	sdata4.s0 = src[pos4.s0];\n"
"	sdata4.s1 = src[pos4.s1];\n"
"	sdata4.s2 = src[pos4.s2];\n"
"	sdata4.s3 = src[pos4.s3];\n"
"	\n"
"	val1 = U1 * sdata1 + U * sdata2;\n"
"	val2 = U1 * sdata3 + U * sdata4;\n"
"	val = V1 * val1 + V * val2;\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dst_offset + dy * dst_step + gx);\n"
"	uchar4 dVal = *d;\n"
"	int4 con = (DX >= 0 && DX < dst_cols && dy >= 0 && dy < dst_rows);\n"
"	val = ((val + (1 << (CAST_BITS - 1))) >> CAST_BITS);\n"
"	*d = convert_uchar4(con != 0) ? convert_uchar4_sat(val) : dVal;\n"
"	\n"
"}\n"
"__kernel void resizeLN_C4_D0(__global uchar4 *dst, __global uchar4 *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, float ifx, float ify)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	float sx = ((dx + 0.5f) * ifx - 0.5f), sy = ((dy + 0.5f) * ify - 0.5f);\n"
"	int x = floor(sx), y = floor(sy);\n"
"	float u = sx - x, v = sy - y;\n"
"	\n"
"	x < 0 ? x = 0, u = 0 : x, u;\n"
"	x >= src_cols ? x = src_cols - 1, u = 0 : x, u;\n"
"	y < 0 ? y = 0, v = 0 : y, v;\n"
"	y >= src_rows ? y = src_rows - 1, v = 0 : y, v;\n"
"	\n"
"	u = u * INTER_RESIZE_COEF_SCALE;\n"
"	v = v * INTER_RESIZE_COEF_SCALE;\n"
"	\n"
"	int U = rint(u);\n"
"	int V = rint(v);\n"
"	int U1 = rint(INTER_RESIZE_COEF_SCALE - u);\n"
"	int V1 = rint(INTER_RESIZE_COEF_SCALE - v);\n"
"	\n"
"	int y_ = INC(y, src_rows);\n"
"	int x_ = INC(x, src_cols);\n"
"	\n"
"	uint4 val = U1 * V1 *  getPoint_8uc4(src, src_offset, x, y, src_step) +\n"
"	            U1 * V  *  getPoint_8uc4(src, src_offset, x, y_, src_step) +\n"
"	            U * V1 *  getPoint_8uc4(src, src_offset, x_, y, src_step) +\n"
"	            U * V  *  getPoint_8uc4(src, src_offset, x_, y_, src_step);\n"
"	            \n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * (dst_step >> 2) + dx] = convert_uchar4((val + (1 << (CAST_BITS - 1))) >> CAST_BITS);\n"
"	}\n"
"}\n"
"__kernel void resizeLN_C1_D5(__global float *dst, __global float *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, float ifx, float ify)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	float sx = ((dx + 0.5f) * ifx - 0.5f), sy = ((dy + 0.5f) * ify - 0.5f);\n"
"	int x = floor(sx), y = floor(sy);\n"
"	float u = sx - x, v = sy - y;\n"
"	\n"
"	x < 0 ? x = 0, u = 0 : x, u;\n"
"	x >= src_cols ? x = src_cols - 1, u = 0 : x, u;\n"
"	y < 0 ? y = 0, v = 0 : y, v;\n"
"	y >= src_rows ? y = src_rows - 1, v = 0 : y, v;\n"
"	\n"
"	int y_ = INC(y, src_rows);\n"
"	int x_ = INC(x, src_cols);\n"
"	\n"
"	float val1 = (1.0f - u) *  getPoint_32fc1(src, src_offset, x, y, src_step) +\n"
"	             u  *  getPoint_32fc1(src, src_offset, x_, y, src_step) ;\n"
"	float val2 = (1.0f - u) *  getPoint_32fc1(src, src_offset, x, y_, src_step) +\n"
"	             u *  getPoint_32fc1(src, src_offset, x_, y_, src_step);\n"
"	float val = (1.0f - v) * val1 + v * val2;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * (dst_step >> 2) + dx] = val;\n"
"	}\n"
"}\n"
"__kernel void resizeLN_C4_D5(__global float4 *dst, __global float4 *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, float ifx, float ify)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	float sx = ((dx + 0.5f) * ifx - 0.5f), sy = ((dy + 0.5f) * ify - 0.5f);\n"
"	int x = floor(sx), y = floor(sy);\n"
"	float u = sx - x, v = sy - y;\n"
"	\n"
"	x < 0 ? x = 0, u = 0 : x;\n"
"	x >= src_cols ? x = src_cols - 1, u = 0 : x;\n"
"	y < 0 ? y = 0, v = 0 : y;\n"
"	y >= src_rows ? y = src_rows - 1, v = 0 : y;\n"
"	\n"
"	int y_ = INC(y, src_rows);\n"
"	int x_ = INC(x, src_cols);\n"
"	\n"
"	float4 s_data1, s_data2, s_data3, s_data4;\n"
"	src_offset = (src_offset >> 4);\n"
"	src_step = (src_step >> 4);\n"
"	s_data1 = src[src_offset + y * src_step + x];\n"
"	s_data2 = src[src_offset + y * src_step + x_];\n"
"	s_data3 = src[src_offset + y_ * src_step + x];\n"
"	s_data4 = src[src_offset + y_ * src_step + x_];\n"
"	s_data1 = (1.0f - u) * s_data1 + u * s_data2;\n"
"	s_data2 = (1.0f - u) * s_data3 + u * s_data4;\n"
"	s_data3 = (1.0f - v) * s_data1 + v * s_data2;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 4) + dy * (dst_step >> 4) + dx] = s_data3;\n"
"	}\n"
"}\n"
"__kernel void resizeNN_C1_D0(__global uchar *dst, __global uchar *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, F ifx, F ify)\n"
"{\n"
"	int gx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	gx = (gx << 2) - (dst_offset & 3);\n"
"	int4 GX = (int4)(gx, gx + 1, gx + 2, gx + 3);\n"
"	\n"
"	int4 sx;\n"
"	int sy;\n"
"	F ss1 = gx * ifx;\n"
"	F ss2 = (gx + 1) * ifx;\n"
"	F ss3 = (gx + 2) * ifx;\n"
"	F ss4 = (gx + 3) * ifx;\n"
"	F s5 = dy * ify;\n"
"	sx.s0 = min((int)floor(ss1), src_cols - 1);\n"
"	sx.s1 = min((int)floor(ss2), src_cols - 1);\n"
"	sx.s2 = min((int)floor(ss3), src_cols - 1);\n"
"	sx.s3 = min((int)floor(ss4), src_cols - 1);\n"
"	sy = min((int)floor(s5), src_rows - 1);\n"
"	\n"
"	uchar4 val;\n"
"	int4 pos = src_offset + sy * src_step + sx;\n"
"	val.s0 = src[pos.s0];\n"
"	val.s1 = src[pos.s1];\n"
"	val.s2 = src[pos.s2];\n"
"	val.s3 = src[pos.s3];\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dst_offset + dy * dst_step + gx);\n"
"	uchar4 dVal = *d;\n"
"	int4 con = (GX >= 0 && GX < dst_cols && dy >= 0 && dy < dst_rows);\n"
"	val = (convert_uchar4(con) != 0) ? val : dVal;\n"
"	\n"
"	*d = val;\n"
"}\n"
"__kernel void resizeNN_C4_D0(__global uchar4 *dst, __global uchar4 *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, F ifx, F ify)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	F s1 = dx * ifx;\n"
"	F s2 = dy * ify;\n"
"	int sx = fmin((float)floor(s1), (float)src_cols - 1);\n"
"	int sy = fmin((float)floor(s2), (float)src_rows - 1);\n"
"	int dpos = (dst_offset >> 2) + dy * (dst_step >> 2) + dx;\n"
"	int spos = (src_offset >> 2) + sy * (src_step >> 2) + sx;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[dpos] = src[spos];\n"
"	}\n"
"	\n"
"}\n"
"__kernel void resizeNN_C1_D5(__global float *dst, __global float *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, F ifx, F ify)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	F s1 = dx * ifx;\n"
"	F s2 = dy * ify;\n"
"	int sx = fmin((float)floor(s1), (float)src_cols - 1);\n"
"	int sy = fmin((float)floor(s2), (float)src_rows - 1);\n"
"	int dpos = (dst_offset >> 2) + dy * (dst_step >> 2) + dx;\n"
"	int spos = (src_offset >> 2) + sy * (src_step >> 2) + sx;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[dpos] = src[spos];\n"
"	}\n"
"	\n"
"}\n"
"__kernel void resizeNN_C4_D5(__global float4 *dst, __global float4 *src,\n"
"                             int dst_offset, int src_offset, int dst_step, int src_step,\n"
"                             int src_cols, int src_rows, int dst_cols, int dst_rows, F ifx, F ify)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	F s1 = dx * ifx;\n"
"	F s2 = dy * ify;\n"
"	int s_col = floor(s1);\n"
"	int s_row = floor(s2);\n"
"	int sx = min(s_col, src_cols - 1);\n"
"	int sy = min(s_row, src_rows - 1);\n"
"	int dpos = (dst_offset >> 4) + dy * (dst_step >> 4) + dx;\n"
"	int spos = (src_offset >> 4) + sy * (src_step >> 4) + sx;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[dpos] = src[spos];\n"
"	}\n"
"	\n"
"}\n"
;
const char *imgproc_threshold =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zhang Ying, zhangying913@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"// threshold type:\n"
"// enum { THRESH_BINARY=0, THRESH_BINARY_INV=1, THRESH_TRUNC=2, THRESH_TOZERO=3,\n"
"//       THRESH_TOZERO_INV=4, THRESH_MASK=7, THRESH_OTSU=8 };\n"
"__kernel void threshold_C1_D0(__global const uchar *restrict src, __global uchar *dst,\n"
"                              int src_offset, int src_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step,\n"
"                              uchar thresh, uchar max_val, int thresh_type\n"
"                             )\n"
"{\n"
"	int gx = get_global_id(0);\n"
"	const int gy = get_global_id(1);\n"
"	\n"
"	int offset = (dst_offset & 15);\n"
"	src_offset -= offset;\n"
"	\n"
"	int dstart = (gx << 4) - offset;\n"
"	\n"
"	if (dstart < dst_cols && gy < dst_rows)\n"
"	{\n"
"		uchar16 sdata = vload16(gx, src + src_offset + gy * src_step);\n"
"		uchar16 ddata;\n"
"		uchar16 zero = 0;\n"
"		\n"
"		switch (thresh_type)\n"
"		{\n"
"			case 0:\n"
"				ddata = ((sdata > thresh)) ? max_val : 0;\n"
"				break;\n"
"			case 1:\n"
"				ddata = ((sdata > thresh)) ? zero  : max_val;\n"
"				break;\n"
"			case 2:\n"
"				ddata = ((sdata > thresh)) ? thresh : sdata;\n"
"				break;\n"
"			case 3:\n"
"				ddata = ((sdata > thresh)) ? sdata : 0;\n"
"				break;\n"
"			case 4:\n"
"				ddata = ((sdata > thresh)) ? 0 : sdata;\n"
"				break;\n"
"			default:\n"
"				ddata = sdata;\n"
"		}\n"
"		\n"
"		int16 dpos = (int16)(dstart, dstart + 1, dstart + 2, dstart + 3, dstart + 4, dstart + 5, dstart + 6, dstart + 7, dstart + 8,\n"
"		                     dstart + 9, dstart + 10, dstart + 11, dstart + 12, dstart + 13, dstart + 14, dstart + 15);\n"
"		uchar16 dVal = *(__global uchar16 *)(dst + dst_offset + gy * dst_step + dstart);\n"
"		int16 con = dpos >= 0 && dpos < dst_cols;\n"
"		ddata = convert_uchar16(con != 0) ? ddata : dVal;\n"
"		\n"
"		if (dstart < dst_cols)\n"
"		{\n"
"			*(__global uchar16 *)(dst + dst_offset + gy * dst_step + dstart) = ddata;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void threshold_C1_D5(__global const float *restrict src, __global float *dst,\n"
"                              int src_offset, int src_step,\n"
"                              int dst_offset, int dst_rows, int dst_cols, int dst_step,\n"
"                              float thresh, float max_val, int thresh_type\n"
"                             )\n"
"{\n"
"	const int gx = get_global_id(0);\n"
"	const int gy = get_global_id(1);\n"
"	\n"
"	int offset = (dst_offset & 3);\n"
"	src_offset -= offset;\n"
"	\n"
"	int dstart = (gx << 2) - offset;\n"
"	\n"
"	if (dstart < dst_cols && gy < dst_rows)\n"
"	{\n"
"		float4 sdata = vload4(gx, src + src_offset + gy * src_step);\n"
"		float4 ddata;\n"
"		float4 zero = 0;\n"
"		\n"
"		switch (thresh_type)\n"
"		{\n"
"			case 0:\n"
"				ddata = sdata > thresh ? max_val : 0;\n"
"				break;\n"
"			case 1:\n"
"				ddata = sdata > thresh ? zero : max_val;\n"
"				break;\n"
"			case 2:\n"
"				ddata = sdata > thresh ? thresh : sdata;\n"
"				break;\n"
"			case 3:\n"
"				ddata = sdata > thresh ? sdata : 0;\n"
"				break;\n"
"			case 4:\n"
"				ddata = sdata > thresh ? 0 : sdata;\n"
"				break;\n"
"			default:\n"
"				ddata = sdata;\n"
"		}\n"
"		\n"
"		int4 dpos = (int4)(dstart, dstart + 1, dstart + 2, dstart + 3);\n"
"		float4 dVal = *(__global float4 *)(dst + dst_offset + gy * dst_step + dstart);\n"
"		int4 con = dpos >= 0 && dpos < dst_cols;\n"
"		ddata = convert_float4(con) != 0 ? ddata : dVal;\n"
"		\n"
"		if (dstart < dst_cols)\n"
"		{\n"
"			*(__global float4 *)(dst + dst_offset + gy * dst_step + dstart) = ddata;\n"
"		}\n"
"	}\n"
"}\n"
;
const char *imgproc_warpAffine =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zhang Ying, zhangying913@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"//warpAffine kernel\n"
"//support data types: CV_8UC1, CV_8UC4, CV_32FC1, CV_32FC4, and three interpolation methods: NN, Linear, Cubic.\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"#define F double\n"
"#define INTER_BITS 5\n"
"#define INTER_TAB_SIZE (1 << INTER_BITS)\n"
"#define INTER_SCALE 1.f/INTER_TAB_SIZE\n"
"#define AB_BITS max(10, (int)INTER_BITS)\n"
"#define AB_SCALE (1 << AB_BITS)\n"
"#define INTER_REMAP_COEF_BITS 15\n"
"#define INTER_REMAP_COEF_SCALE (1 << INTER_REMAP_COEF_BITS)\n"
"inline void interpolateCubic(float x, float *coeffs)\n"
"{\n"
"	const float A = -0.75f;\n"
"	\n"
"	coeffs[0] = ((A * (x + 1.f) - 5.0f * A) * (x + 1.f) + 8.0f * A) * (x + 1.f) - 4.0f * A;\n"
"	coeffs[1] = ((A + 2.f) * x - (A + 3.f)) * x * x + 1.f;\n"
"	coeffs[2] = ((A + 2.f) * (1.f - x) - (A + 3.f)) * (1.f - x) * (1.f - x) + 1.f;\n"
"	coeffs[3] = 1.f - coeffs[0] - coeffs[1] - coeffs[2];\n"
"}\n"
"/**********************************************8UC1*********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpAffineNN_C1_D0(__global uchar const *restrict src, __global uchar *dst, int src_cols, int src_rows,\n"
"                                 int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                 int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	dx = (dx << 2) - (dst_offset & 3);\n"
"	\n"
"	int round_delta = (AB_SCALE >> 1);\n"
"	\n"
"	int4 X, Y;\n"
"	int4 sx, sy;\n"
"	int4 DX = (int4)(dx, dx + 1, dx + 2, dx + 3);\n"
"	DX = (DX << AB_BITS);\n"
"	double4 M0DX, M3DX;\n"
"	M0DX = M[0] * convert_double4(DX);\n"
"	M3DX = M[3] * convert_double4(DX);\n"
"	X = convert_int4(rint(M0DX));\n"
"	Y = convert_int4(rint(M3DX));\n"
"	int tmp1, tmp2;\n"
"	tmp1 = rint((M[1] * dy + M[2]) * AB_SCALE);\n"
"	tmp2 = rint((M[4] * dy + M[5]) * AB_SCALE);\n"
"	\n"
"	X += tmp1 + round_delta;\n"
"	Y += tmp2 + round_delta;\n"
"	\n"
"	sx = convert_int4(convert_short4(X >> AB_BITS));\n"
"	sy = convert_int4(convert_short4(Y >> AB_BITS));\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dst_offset + dy * dstStep + dx);\n"
"	uchar4 dval = *d;\n"
"	DX = (int4)(dx, dx + 1, dx + 2, dx + 3);\n"
"	int4 dcon = DX >= 0 && DX < dst_cols && dy >= 0 && dy < dst_rows;\n"
"	int4 scon = sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows;\n"
"	int4 spos = src_offset + sy * srcStep + sx;\n"
"	uchar4 sval;\n"
"	sval.s0 = scon.s0 ? src[spos.s0] : 0;\n"
"	sval.s1 = scon.s1 ? src[spos.s1] : 0;\n"
"	sval.s2 = scon.s2 ? src[spos.s2] : 0;\n"
"	sval.s3 = scon.s3 ? src[spos.s3] : 0;\n"
"	dval = convert_uchar4(dcon != 0) ? sval : dval;\n"
"	*d = dval;\n"
"}\n"
"__kernel void warpAffineLinear_C1_D0(__global const uchar *restrict src, __global uchar *dst, int src_cols, int src_rows,\n"
"                                     int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                     int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	dx = (dx << 2) - (dst_offset & 3);\n"
"	\n"
"	int round_delta = ((AB_SCALE >> INTER_BITS) >> 1);\n"
"	\n"
"	int4 X, Y;\n"
"	short4  ax, ay;\n"
"	int4 sx, sy;\n"
"	int4 DX = (int4)(dx, dx + 1, dx + 2, dx + 3);\n"
"	DX = (DX << AB_BITS);\n"
"	double4 M0DX, M3DX;\n"
"	M0DX = M[0] * convert_double4(DX);\n"
"	M3DX = M[3] * convert_double4(DX);\n"
"	X = convert_int4(rint(M0DX));\n"
"	Y = convert_int4(rint(M3DX));\n"
"	\n"
"	int tmp1, tmp2;\n"
"	tmp1 = rint((M[1] * dy + M[2]) * AB_SCALE);\n"
"	tmp2 = rint((M[4] * dy + M[5]) * AB_SCALE);\n"
"	\n"
"	X += tmp1 + round_delta;\n"
"	Y += tmp2 + round_delta;\n"
"	\n"
"	X = X >> (AB_BITS - INTER_BITS);\n"
"	Y = Y >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	sx = convert_int4(convert_short4(X >> INTER_BITS));\n"
"	sy = convert_int4(convert_short4(Y >> INTER_BITS));\n"
"	ax = convert_short4(X & (INTER_TAB_SIZE - 1));\n"
"	ay = convert_short4(Y & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar4 v0, v1, v2, v3;\n"
"	int4 scon0, scon1, scon2, scon3;\n"
"	int4 spos0, spos1, spos2, spos3;\n"
"	\n"
"	scon0 = (sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows);\n"
"	scon1 = (sx + 1 >= 0 && sx + 1 < src_cols && sy >= 0 && sy < src_rows);\n"
"	scon2 = (sx >= 0 && sx < src_cols && sy + 1 >= 0 && sy + 1 < src_rows);\n"
"	scon3 = (sx + 1 >= 0 && sx + 1 < src_cols && sy + 1 >= 0 && sy + 1 < src_rows);\n"
"	spos0 = src_offset + sy * srcStep + sx;\n"
"	spos1 = src_offset + sy * srcStep + sx + 1;\n"
"	spos2 = src_offset + (sy + 1) * srcStep + sx;\n"
"	spos3 = src_offset + (sy + 1) * srcStep + sx + 1;\n"
"	\n"
"	v0.s0 = scon0.s0 ? src[spos0.s0] : 0;\n"
"	v1.s0 = scon1.s0 ? src[spos1.s0] : 0;\n"
"	v2.s0 = scon2.s0 ? src[spos2.s0] : 0;\n"
"	v3.s0 = scon3.s0 ? src[spos3.s0] : 0;\n"
"	\n"
"	v0.s1 = scon0.s1 ? src[spos0.s1] : 0;\n"
"	v1.s1 = scon1.s1 ? src[spos1.s1] : 0;\n"
"	v2.s1 = scon2.s1 ? src[spos2.s1] : 0;\n"
"	v3.s1 = scon3.s1 ? src[spos3.s1] : 0;\n"
"	\n"
"	v0.s2 = scon0.s2 ? src[spos0.s2] : 0;\n"
"	v1.s2 = scon1.s2 ? src[spos1.s2] : 0;\n"
"	v2.s2 = scon2.s2 ? src[spos2.s2] : 0;\n"
"	v3.s2 = scon3.s2 ? src[spos3.s2] : 0;\n"
"	\n"
"	v0.s3 = scon0.s3 ? src[spos0.s3] : 0;\n"
"	v1.s3 = scon1.s3 ? src[spos1.s3] : 0;\n"
"	v2.s3 = scon2.s3 ? src[spos2.s3] : 0;\n"
"	v3.s3 = scon3.s3 ? src[spos3.s3] : 0;\n"
"	\n"
"	short4 itab0, itab1, itab2, itab3;\n"
"	float4 taby, tabx;\n"
"	taby = INTER_SCALE * convert_float4(ay);\n"
"	tabx = INTER_SCALE * convert_float4(ax);\n"
"	\n"
"	itab0 = convert_short4_sat(((1.0f - taby) * (1.0f - tabx) * INTER_REMAP_COEF_SCALE));\n"
"	itab1 = convert_short4_sat(((1.0f - taby) * tabx * INTER_REMAP_COEF_SCALE));\n"
"	itab2 = convert_short4_sat((taby * (1.0f - tabx) * INTER_REMAP_COEF_SCALE));\n"
"	itab3 = convert_short4_sat((taby * tabx * INTER_REMAP_COEF_SCALE));\n"
"	\n"
"	\n"
"	int4 val;\n"
"	uchar4 tval;\n"
"	val = convert_int4(v0) * convert_int4(itab0) + convert_int4(v1) * convert_int4(itab1)\n"
"	      + convert_int4(v2) * convert_int4(itab2) + convert_int4(v3) * convert_int4(itab3);\n"
"	tval = convert_uchar4_sat((val + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dst_offset + dy * dstStep + dx);\n"
"	uchar4 dval = *d;\n"
"	DX = (int4)(dx, dx + 1, dx + 2, dx + 3);\n"
"	int4 dcon = DX >= 0 && DX < dst_cols && dy >= 0 && dy < dst_rows;\n"
"	dval = convert_uchar4(dcon != 0) ? tval : dval;\n"
"	*d = dval;\n"
"	\n"
"}\n"
"__kernel void warpAffineCubic_C1_D0(__global uchar *src, __global uchar *dst, int src_cols, int src_rows,\n"
"                                    int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                    int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = ((AB_SCALE >> INTER_BITS) >> 1);\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar v[16];\n"
"	int i, j;\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4;  j++)\n"
"		{\n"
"			v[i * 4 + j] = (sx + j >= 0 && sx + j < src_cols && sy + i >= 0 && sy + i < src_rows) ? src[src_offset + (sy + i) * srcStep + (sx + j)] : 0;\n"
"		}\n"
"		\n"
"	short itab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	int isum = 0;\n"
"	\n"
"#pragma unroll 16\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		double v = tab1y[(i >> 2)] * tab1x[(i & 3)];\n"
"		isum += itab[i] = convert_short_sat(rint(v * INTER_REMAP_COEF_SCALE));\n"
"	}\n"
"	\n"
"	if (isum != INTER_REMAP_COEF_SCALE)\n"
"	{\n"
"		int k1, k2;\n"
"		int diff = isum - INTER_REMAP_COEF_SCALE;\n"
"		int Mk1 = 2, Mk2 = 2, mk1 = 2, mk2 = 2;\n"
"		\n"
"		for (k1 = 2; k1 < 4; k1++)\n"
"			for (k2 = 2; k2 < 4; k2++)\n"
"			{\n"
"				if (itab[(k1 << 2) + k2] < itab[(mk1 << 2) + mk2])\n"
"				{\n"
"					mk1 = k1, mk2 = k2;\n"
"				}\n"
"				else if (itab[(k1 << 2) + k2] > itab[(Mk1 << 2) + Mk2])\n"
"				{\n"
"					Mk1 = k1, Mk2 = k2;\n"
"				}\n"
"			}\n"
"			\n"
"		diff < 0 ? (itab[(Mk1 << 2) + Mk2] = (short)(itab[(Mk1 << 2) + Mk2] - diff)) : (itab[(mk1 << 2) + mk2] = (short)(itab[(mk1 << 2) + mk2] - diff));\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		int sum = 0;\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += v[i] * itab[i] ;\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = convert_uchar_sat((sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"/**********************************************8UC4*********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpAffineNN_C4_D0(__global uchar4 const *restrict src, __global uchar4 *dst, int src_cols, int src_rows,\n"
"                                 int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                 int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = (AB_SCALE >> 1);\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	int sx0 = (short)(X0 >> AB_BITS);\n"
"	int sy0 = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * (dstStep >> 2) + dx] = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[(src_offset >> 2) + sy0 * (srcStep >> 2) + sx0] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffineLinear_C4_D0(__global uchar4 const *restrict src, __global uchar4 *dst, int src_cols, int src_rows,\n"
"                                     int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                     int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	srcStep = (srcStep >> 2);\n"
"	\n"
"	int tmp = (dx << AB_BITS);\n"
"	int X0 = rint(M[0] * tmp);\n"
"	int Y0 = rint(M[3] * tmp);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	X0 = X0 >> (AB_BITS - INTER_BITS);\n"
"	Y0 = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx0 = (short)(X0 >> INTER_BITS);\n"
"	short sy0 = (short)(Y0 >> INTER_BITS);\n"
"	short ax0 = (short)(X0 & (INTER_TAB_SIZE - 1));\n"
"	short ay0 = (short)(Y0 & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	int4 v0, v1, v2, v3;\n"
"	\n"
"	v0 = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? convert_int4(src[src_offset + sy0 * srcStep + sx0]) : 0;\n"
"	v1 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 >= 0 && sy0 < src_rows) ? convert_int4(src[src_offset + sy0 * srcStep + sx0 + 1]) : 0;\n"
"	v2 = (sx0 >= 0 && sx0 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? convert_int4(src[src_offset + (sy0 + 1) * srcStep + sx0]) : 0;\n"
"	v3 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? convert_int4(src[src_offset + (sy0 + 1) * srcStep + sx0 + 1]) : 0;\n"
"	\n"
"	int itab0, itab1, itab2, itab3;\n"
"	float taby, tabx;\n"
"	taby = 1.f / INTER_TAB_SIZE * ay0;\n"
"	tabx = 1.f / INTER_TAB_SIZE * ax0;\n"
"	\n"
"	itab0 = convert_short_sat(rint((1.0f - taby) * (1.0f - tabx) * INTER_REMAP_COEF_SCALE));\n"
"	itab1 = convert_short_sat(rint((1.0f - taby) * tabx * INTER_REMAP_COEF_SCALE));\n"
"	itab2 = convert_short_sat(rint(taby * (1.0f - tabx) * INTER_REMAP_COEF_SCALE));\n"
"	itab3 = convert_short_sat(rint(taby * tabx * INTER_REMAP_COEF_SCALE));\n"
"	\n"
"	int4 val;\n"
"	val = v0 * itab0 +  v1 * itab1 + v2 * itab2 + v3 * itab3;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * (dstStep >> 2) + dx] =  convert_uchar4_sat((val + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"__kernel void warpAffineCubic_C4_D0(__global uchar4 const *restrict src, __global uchar4 *dst, int src_cols, int src_rows,\n"
"                                    int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                    int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = ((AB_SCALE >> INTER_BITS) >> 1);\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	srcStep = (srcStep >> 2);\n"
"	dst_offset = (dst_offset >> 2);\n"
"	dstStep = (dstStep >> 2);\n"
"	\n"
"	int tmp = (dx << AB_BITS);\n"
"	int X0 = rint(M[0] * tmp);\n"
"	int Y0 = rint(M[3] * tmp);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	X0 = X0 >> (AB_BITS - INTER_BITS);\n"
"	Y0 = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	int sx = (short)(X0 >> INTER_BITS) - 1;\n"
"	int sy = (short)(Y0 >> INTER_BITS) - 1;\n"
"	int ay = (short)(Y0 & (INTER_TAB_SIZE - 1));\n"
"	int ax = (short)(X0 & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar4 v[16];\n"
"	int i, j;\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			v[i * 4 + j] = (sx + j >= 0 && sx + j < src_cols && sy + i >= 0 && sy + i < src_rows) ? (src[src_offset + (sy + i) * srcStep + (sx + j)])  : 0;\n"
"		}\n"
"		\n"
"	int itab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = INTER_SCALE * ay;\n"
"	axx = INTER_SCALE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	int isum = 0;\n"
"	\n"
"#pragma unroll 16\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		float tmp;\n"
"		tmp = tab1y[(i >> 2)] * tab1x[(i & 3)] * INTER_REMAP_COEF_SCALE;\n"
"		itab[i] = rint(tmp);\n"
"		isum += itab[i];\n"
"	}\n"
"	\n"
"	if (isum != INTER_REMAP_COEF_SCALE)\n"
"	{\n"
"		int k1, k2;\n"
"		int diff = isum - INTER_REMAP_COEF_SCALE;\n"
"		int Mk1 = 2, Mk2 = 2, mk1 = 2, mk2 = 2;\n"
"		\n"
"		for (k1 = 2; k1 < 4; k1++)\n"
"			for (k2 = 2; k2 < 4; k2++)\n"
"			{\n"
"			\n"
"				if (itab[(k1 << 2) + k2] < itab[(mk1 << 2) + mk2])\n"
"				{\n"
"					mk1 = k1, mk2 = k2;\n"
"				}\n"
"				else if (itab[(k1 << 2) + k2] > itab[(Mk1 << 2) + Mk2])\n"
"				{\n"
"					Mk1 = k1, Mk2 = k2;\n"
"				}\n"
"			}\n"
"			\n"
"		diff < 0 ? (itab[(Mk1 << 2) + Mk2] = (short)(itab[(Mk1 << 2) + Mk2] - diff)) : (itab[(mk1 << 2) + mk2] = (short)(itab[(mk1 << 2) + mk2] - diff));\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		int4 sum = 0;\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += convert_int4(v[i]) * itab[i];\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = convert_uchar4_sat((sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"/**********************************************32FC1********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpAffineNN_C1_D5(__global float *src, __global float *dst, int src_cols, int src_rows,\n"
"                                 int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                 int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / 2;\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	short sx0 = (short)(X0 >> AB_BITS);\n"
"	short sy0 = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * dstStep + dx] = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[(src_offset >> 2) + sy0 * srcStep + sx0] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffineLinear_C1_D5(__global float *src, __global float *dst, int src_cols, int src_rows,\n"
"                                     int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                     int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	X0 = X0 >> (AB_BITS - INTER_BITS);\n"
"	Y0 = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx0 = (short)(X0 >> INTER_BITS);\n"
"	short sy0 = (short)(Y0 >> INTER_BITS);\n"
"	short ax0 = (short)(X0 & (INTER_TAB_SIZE - 1));\n"
"	short ay0 = (short)(Y0 & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v0, v1, v2, v3;\n"
"	\n"
"	v0 = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[src_offset + sy0 * srcStep + sx0] : 0;\n"
"	v1 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[src_offset + sy0 * srcStep + sx0 + 1] : 0;\n"
"	v2 = (sx0 >= 0 && sx0 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? src[src_offset + (sy0 + 1) * srcStep + sx0] : 0;\n"
"	v3 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? src[src_offset + (sy0 + 1) * srcStep + sx0 + 1] : 0;\n"
"	\n"
"	float tab[4];\n"
"	float taby[2], tabx[2];\n"
"	taby[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay0;\n"
"	taby[1] = 1.f / INTER_TAB_SIZE * ay0;\n"
"	tabx[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax0;\n"
"	tabx[1] = 1.f / INTER_TAB_SIZE * ax0;\n"
"	\n"
"	tab[0] = taby[0] * tabx[0];\n"
"	tab[1] = taby[0] * tabx[1];\n"
"	tab[2] = taby[1] * tabx[0];\n"
"	tab[3] = taby[1] * tabx[1];\n"
"	\n"
"	float sum = 0;\n"
"	sum += v0 * tab[0] +  v1 * tab[1] +  v2 * tab[2] +  v3 * tab[3];\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * dstStep + dx] = sum;\n"
"	}\n"
"}\n"
"__kernel void warpAffineCubic_C1_D5(__global float *src, __global float *dst, int src_cols, int src_rows,\n"
"                                    int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                    int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	dst_offset = (dst_offset >> 2);\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	X0 = X0 >> (AB_BITS - INTER_BITS);\n"
"	Y0 = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X0 >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y0 >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y0 & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X0 & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v[16];\n"
"	int i;\n"
"	\n"
"	for (i = 0; i < 16;  i++)\n"
"	{\n"
"		v[i] = (sx + (i & 3) >= 0 && sx + (i & 3) < src_cols && sy + (i >> 2) >= 0 && sy + (i >> 2) < src_rows) ? src[src_offset + (sy + (i >> 2)) * srcStep + (sx + (i & 3))] : 0;\n"
"	}\n"
"	\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		tab[i] = tab1y[(i >> 2)] * tab1x[(i & 3)];\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		float sum = 0;\n"
"#pragma unroll 4\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += v[i] * tab[i];\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = sum;\n"
"		\n"
"	}\n"
"}\n"
"/**********************************************32FC4********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpAffineNN_C4_D5(__global float4 *src, __global float4 *dst, int src_cols, int src_rows,\n"
"                                 int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                 int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / 2;\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	short sx0 = (short)(X0 >> AB_BITS);\n"
"	short sy0 = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 4) + dy * (dstStep >> 2) + dx] = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[(src_offset >> 4) + sy0 * (srcStep >> 2) + sx0] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffineLinear_C4_D5(__global float4 *src, __global float4 *dst, int src_cols, int src_rows,\n"
"                                     int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                     int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	src_offset = (src_offset >> 4);\n"
"	dst_offset = (dst_offset >> 4);\n"
"	srcStep = (srcStep >> 2);\n"
"	dstStep = (dstStep >> 2);\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	X0 = X0 >> (AB_BITS - INTER_BITS);\n"
"	Y0 = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx0 = (short)(X0 >> INTER_BITS);\n"
"	short sy0 = (short)(Y0 >> INTER_BITS);\n"
"	short ax0 = (short)(X0 & (INTER_TAB_SIZE - 1));\n"
"	short ay0 = (short)(Y0 & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float4 v0, v1, v2, v3;\n"
"	\n"
"	v0 = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[src_offset + sy0 * srcStep + sx0] : 0;\n"
"	v1 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[src_offset + sy0 * srcStep + sx0 + 1] : 0;\n"
"	v2 = (sx0 >= 0 && sx0 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? src[src_offset + (sy0 + 1) * srcStep + sx0] : 0;\n"
"	v3 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? src[src_offset + (sy0 + 1) * srcStep + sx0 + 1] : 0;\n"
"	\n"
"	float tab[4];\n"
"	float taby[2], tabx[2];\n"
"	taby[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay0;\n"
"	taby[1] = 1.f / INTER_TAB_SIZE * ay0;\n"
"	tabx[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax0;\n"
"	tabx[1] = 1.f / INTER_TAB_SIZE * ax0;\n"
"	\n"
"	tab[0] = taby[0] * tabx[0];\n"
"	tab[1] = taby[0] * tabx[1];\n"
"	tab[2] = taby[1] * tabx[0];\n"
"	tab[3] = taby[1] * tabx[1];\n"
"	\n"
"	float4 sum = 0;\n"
"	sum += v0 * tab[0] +  v1 * tab[1] +  v2 * tab[2] +  v3 * tab[3];\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[dst_offset + dy * dstStep + dx] = sum;\n"
"	}\n"
"}\n"
"__kernel void warpAffineCubic_C4_D5(__global float4 *src, __global float4 *dst, int src_cols, int src_rows,\n"
"                                    int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                    int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	src_offset = (src_offset >> 4);\n"
"	dst_offset = (dst_offset >> 4);\n"
"	srcStep = (srcStep >> 2);\n"
"	dstStep = (dstStep >> 2);\n"
"	\n"
"	int X0 = rint(M[0] * dx * AB_SCALE);\n"
"	int Y0 = rint(M[3] * dx * AB_SCALE);\n"
"	X0 += rint((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += rint((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	X0 = X0 >> (AB_BITS - INTER_BITS);\n"
"	Y0 = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X0 >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y0 >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y0 & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X0 & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float4 v[16];\n"
"	int i;\n"
"	\n"
"	for (i = 0; i < 16;  i++)\n"
"	{\n"
"		v[i] = (sx + (i & 3) >= 0 && sx + (i & 3) < src_cols && sy + (i >> 2) >= 0 && sy + (i >> 2) < src_rows) ? src[src_offset + (sy + (i >> 2)) * srcStep + (sx + (i & 3))] : 0;\n"
"	}\n"
"	\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		tab[i] = tab1y[(i >> 2)] * tab1x[(i & 3)];\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		float4 sum = 0;\n"
"#pragma unroll 4\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += v[i] * tab[i];\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = sum;\n"
"		\n"
"	}\n"
"}\n"
;
const char *imgproc_warpPerspective =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Zhang Ying, zhangying913@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"//wrapPerspective kernel\n"
"//support data types: CV_8UC1, CV_8UC4, CV_32FC1, CV_32FC4, and three interpolation methods: NN, Linear, Cubic.\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"typedef double F;\n"
"#define INTER_BITS 5\n"
"#define INTER_TAB_SIZE (1 << INTER_BITS)\n"
"#define INTER_SCALE 1.f/INTER_TAB_SIZE\n"
"#define AB_BITS max(10, (int)INTER_BITS)\n"
"#define AB_SCALE (1 << AB_BITS)\n"
"#define INTER_REMAP_COEF_BITS 15\n"
"#define INTER_REMAP_COEF_SCALE (1 << INTER_REMAP_COEF_BITS)\n"
"inline void interpolateCubic(float x, float *coeffs)\n"
"{\n"
"	const float A = -0.75f;\n"
"	\n"
"	coeffs[0] = ((A * (x + 1.f) - 5.0f * A) * (x + 1.f) + 8.0f * A) * (x + 1.f) - 4.0f * A;\n"
"	coeffs[1] = ((A + 2.f) * x - (A + 3.f)) * x * x + 1.f;\n"
"	coeffs[2] = ((A + 2.f) * (1.f - x) - (A + 3.f)) * (1.f - x) * (1.f - x) + 1.f;\n"
"	coeffs[3] = 1.f - coeffs[0] - coeffs[1] - coeffs[2];\n"
"}\n"
"/**********************************************8UC1*********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpPerspectiveNN_C1_D0(__global uchar const *restrict src, __global uchar *dst, int src_cols, int src_rows,\n"
"                                      int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                      int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	dx = (dx << 2) - (dst_offset & 3);\n"
"	\n"
"	double4 DX = (double4)(dx, dx + 1, dx + 2, dx + 3);\n"
"	double4 X0 = M[0] * DX + M[1] * dy + M[2];\n"
"	double4 Y0 = M[3] * DX + M[4] * dy + M[5];\n"
"	double4 W = M[6] * DX + M[7] * dy + M[8];\n"
"	W = (W != 0) ? 1. / W : 0;\n"
"	short4 X = convert_short4(rint(X0 * W));\n"
"	short4 Y = convert_short4(rint(Y0 * W));\n"
"	int4 sx = convert_int4(X);\n"
"	int4 sy = convert_int4(Y);\n"
"	\n"
"	int4 DXD = (int4)(dx, dx + 1, dx + 2, dx + 3);\n"
"	__global uchar4 *d = (__global uchar4 *)(dst + dst_offset + dy * dstStep + dx);\n"
"	uchar4 dval = *d;\n"
"	int4 dcon = DXD >= 0 && DXD < dst_cols && dy >= 0 && dy < dst_rows;\n"
"	int4 scon = sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows;\n"
"	int4 spos = src_offset + sy * srcStep + sx;\n"
"	uchar4 sval;\n"
"	sval.s0 = scon.s0 ? src[spos.s0] : 0;\n"
"	sval.s1 = scon.s1 ? src[spos.s1] : 0;\n"
"	sval.s2 = scon.s2 ? src[spos.s2] : 0;\n"
"	sval.s3 = scon.s3 ? src[spos.s3] : 0;\n"
"	dval = convert_uchar4(dcon != 0) ? sval : dval;\n"
"	*d = dval;\n"
"	\n"
"}\n"
"__kernel void warpPerspectiveLinear_C1_D0(__global const uchar *restrict src, __global uchar *dst,\n"
"        int src_cols, int src_rows, int dst_cols, int dst_rows, int srcStep,\n"
"        int dstStep, int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	F X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	F Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	F W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	int sx = (short)(X >> INTER_BITS);\n"
"	int sy = (short)(Y >> INTER_BITS);\n"
"	int ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	int ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar v[4];\n"
"	int i;\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"	{\n"
"		v[i] = (sx + (i & 1) >= 0 && sx + (i & 1) < src_cols && sy + (i >> 1) >= 0 && sy + (i >> 1) < src_rows) ? src[src_offset + (sy + (i >> 1)) * srcStep + (sx + (i & 1))] : 0;\n"
"	}\n"
"	\n"
"	short itab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"	{\n"
"		float v = tab1y[(i >> 1)] * tab1x[(i & 1)];\n"
"		itab[i] = convert_short_sat(rint(v * INTER_REMAP_COEF_SCALE));\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		int sum = 0;\n"
"		\n"
"		for (i = 0; i < 4; i++)\n"
"		{\n"
"			sum += v[i] * itab[i] ;\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = convert_uchar_sat((sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveCubic_C1_D0(__global uchar *src, __global uchar *dst, int src_cols, int src_rows,\n"
"        int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"        int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	F X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	F Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	F W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar v[16];\n"
"	int i, j;\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4;  j++)\n"
"		{\n"
"			v[i * 4 + j] = (sx + j >= 0 && sx + j < src_cols && sy + i >= 0 && sy + i < src_rows) ? src[src_offset + (sy + i) * srcStep + (sx + j)] : 0;\n"
"		}\n"
"		\n"
"	short itab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	int isum = 0;\n"
"#pragma unroll 16\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		double v = tab1y[(i >> 2)] * tab1x[(i & 3)];\n"
"		isum += itab[i] = convert_short_sat(rint(v * INTER_REMAP_COEF_SCALE));\n"
"	}\n"
"	\n"
"	if (isum != INTER_REMAP_COEF_SCALE)\n"
"	{\n"
"		int k1, k2;\n"
"		int diff = isum - INTER_REMAP_COEF_SCALE;\n"
"		int Mk1 = 2, Mk2 = 2, mk1 = 2, mk2 = 2;\n"
"		\n"
"		for (k1 = 2; k1 < 4; k1++)\n"
"			for (k2 = 2; k2 < 4; k2++)\n"
"			{\n"
"				if (itab[(k1 << 2) + k2] < itab[(mk1 << 2) + mk2])\n"
"				{\n"
"					mk1 = k1, mk2 = k2;\n"
"				}\n"
"				else if (itab[(k1 << 2) + k2] > itab[(Mk1 << 2) + Mk2])\n"
"				{\n"
"					Mk1 = k1, Mk2 = k2;\n"
"				}\n"
"			}\n"
"			\n"
"		diff < 0 ? (itab[(Mk1 << 2) + Mk2] = (short)(itab[(Mk1 << 2) + Mk2] - diff)) : (itab[(mk1 << 2) + mk2] = (short)(itab[(mk1 << 2) + mk2] - diff));\n"
"	}\n"
"	\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		int sum = 0;\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += v[i] * itab[i] ;\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = convert_uchar_sat((sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"/**********************************************8UC4*********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpPerspectiveNN_C4_D0(__global uchar4 const *restrict src, __global uchar4 *dst,\n"
"                                      int src_cols, int src_rows, int dst_cols, int dst_rows, int srcStep,\n"
"                                      int dstStep, int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * (dstStep >> 2) + dx] = (sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows) ? src[(src_offset >> 2) + sy * (srcStep >> 2) + sx] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveLinear_C4_D0(__global uchar4 const *restrict src, __global uchar4 *dst,\n"
"        int src_cols, int src_rows, int dst_cols, int dst_rows, int srcStep,\n"
"        int dstStep, int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	srcStep = (srcStep >> 2);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	\n"
"	int4 v0, v1, v2, v3;\n"
"	\n"
"	v0 = (sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows) ? convert_int4(src[src_offset + sy * srcStep + sx]) : 0;\n"
"	v1 = (sx + 1 >= 0 && sx + 1 < src_cols && sy >= 0 && sy < src_rows) ? convert_int4(src[src_offset + sy * srcStep + sx + 1]) : 0;\n"
"	v2 = (sx >= 0 && sx < src_cols && sy + 1 >= 0 && sy + 1 < src_rows) ? convert_int4(src[src_offset + (sy + 1) * srcStep + sx]) : 0;\n"
"	v3 = (sx + 1 >= 0 && sx + 1 < src_cols && sy + 1 >= 0 && sy + 1 < src_rows) ? convert_int4(src[src_offset + (sy + 1) * srcStep + sx + 1]) : 0;\n"
"	\n"
"	int itab0, itab1, itab2, itab3;\n"
"	float taby, tabx;\n"
"	taby = 1.f / INTER_TAB_SIZE * ay;\n"
"	tabx = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	itab0 = convert_short_sat(rint((1.0f - taby) * (1.0f - tabx) * INTER_REMAP_COEF_SCALE));\n"
"	itab1 = convert_short_sat(rint((1.0f - taby) * tabx * INTER_REMAP_COEF_SCALE));\n"
"	itab2 = convert_short_sat(rint(taby * (1.0f - tabx) * INTER_REMAP_COEF_SCALE));\n"
"	itab3 = convert_short_sat(rint(taby * tabx * INTER_REMAP_COEF_SCALE));\n"
"	\n"
"	int4 val;\n"
"	val = v0 * itab0 +  v1 * itab1 + v2 * itab2 + v3 * itab3;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * (dstStep >> 2) + dx] =  convert_uchar4_sat((val + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveCubic_C4_D0(__global uchar4 const *restrict src, __global uchar4 *dst,\n"
"        int src_cols, int src_rows, int dst_cols, int dst_rows, int srcStep,\n"
"        int dstStep, int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	srcStep = (srcStep >> 2);\n"
"	dst_offset = (dst_offset >> 2);\n"
"	dstStep = (dstStep >> 2);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar4 v[16];\n"
"	int i, j;\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			v[i * 4 + j] = (sx + j >= 0 && sx + j < src_cols && sy + i >= 0 && sy + i < src_rows) ? (src[src_offset + (sy + i) * srcStep + (sx + j)])  : 0;\n"
"		}\n"
"		\n"
"	int itab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = INTER_SCALE * ay;\n"
"	axx = INTER_SCALE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	int isum = 0;\n"
"	\n"
"#pragma unroll 16\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		float tmp;\n"
"		tmp = tab1y[(i >> 2)] * tab1x[(i & 3)] * INTER_REMAP_COEF_SCALE;\n"
"		itab[i] = rint(tmp);\n"
"		isum += itab[i];\n"
"	}\n"
"	\n"
"	if (isum != INTER_REMAP_COEF_SCALE)\n"
"	{\n"
"		int k1, k2;\n"
"		int diff = isum - INTER_REMAP_COEF_SCALE;\n"
"		int Mk1 = 2, Mk2 = 2, mk1 = 2, mk2 = 2;\n"
"		\n"
"		for (k1 = 2; k1 < 4; k1++)\n"
"			for (k2 = 2; k2 < 4; k2++)\n"
"			{\n"
"			\n"
"				if (itab[(k1 << 2) + k2] < itab[(mk1 << 2) + mk2])\n"
"				{\n"
"					mk1 = k1, mk2 = k2;\n"
"				}\n"
"				else if (itab[(k1 << 2) + k2] > itab[(Mk1 << 2) + Mk2])\n"
"				{\n"
"					Mk1 = k1, Mk2 = k2;\n"
"				}\n"
"			}\n"
"			\n"
"		diff < 0 ? (itab[(Mk1 << 2) + Mk2] = (short)(itab[(Mk1 << 2) + Mk2] - diff)) : (itab[(mk1 << 2) + mk2] = (short)(itab[(mk1 << 2) + mk2] - diff));\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		int4 sum = 0;\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += convert_int4(v[i]) * itab[i];\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = convert_uchar4_sat((sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"	}\n"
"}\n"
"/**********************************************32FC1********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpPerspectiveNN_C1_D5(__global float *src, __global float *dst, int src_cols, int src_rows,\n"
"                                      int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                      int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * dstStep + dx] = (sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows) ? src[(src_offset >> 2) + sy * srcStep + sx] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveLinear_C1_D5(__global float *src, __global float *dst, int src_cols, int src_rows,\n"
"        int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"        int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v0, v1, v2, v3;\n"
"	\n"
"	v0 = (sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows) ? src[src_offset + sy * srcStep + sx] : 0;\n"
"	v1 = (sx + 1 >= 0 && sx + 1 < src_cols && sy >= 0 && sy < src_rows) ? src[src_offset + sy * srcStep + sx + 1] : 0;\n"
"	v2 = (sx >= 0 && sx < src_cols && sy + 1 >= 0 && sy + 1 < src_rows) ? src[src_offset + (sy + 1) * srcStep + sx] : 0;\n"
"	v3 = (sx + 1 >= 0 && sx + 1 < src_cols && sy + 1 >= 0 && sy + 1 < src_rows) ? src[src_offset + (sy + 1) * srcStep + sx + 1] : 0;\n"
"	\n"
"	float tab[4];\n"
"	float taby[2], tabx[2];\n"
"	taby[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	taby[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tabx[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tabx[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	tab[0] = taby[0] * tabx[0];\n"
"	tab[1] = taby[0] * tabx[1];\n"
"	tab[2] = taby[1] * tabx[0];\n"
"	tab[3] = taby[1] * tabx[1];\n"
"	\n"
"	float sum = 0;\n"
"	sum += v0 * tab[0] +  v1 * tab[1] +  v2 * tab[2] +  v3 * tab[3];\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 2) + dy * dstStep + dx] = sum;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveCubic_C1_D5(__global float *src, __global float *dst, int src_cols, int src_rows,\n"
"        int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"        int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	src_offset = (src_offset >> 2);\n"
"	dst_offset = (dst_offset >> 2);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v[16];\n"
"	int i;\n"
"	\n"
"	for (i = 0; i < 16;  i++)\n"
"	{\n"
"		v[i] = (sx + (i & 3) >= 0 && sx + (i & 3) < src_cols && sy + (i >> 2) >= 0 && sy + (i >> 2) < src_rows) ? src[src_offset + (sy + (i >> 2)) * srcStep + (sx + (i & 3))] : 0;\n"
"	}\n"
"	\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		tab[i] = tab1y[(i >> 2)] * tab1x[(i & 3)];\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		float sum = 0;\n"
"#pragma unroll 4\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += v[i] * tab[i];\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = sum;\n"
"		\n"
"	}\n"
"}\n"
"/**********************************************32FC4********************************************\n"
"***********************************************************************************************/\n"
"__kernel void warpPerspectiveNN_C4_D5(__global float4 *src, __global float4 *dst, int src_cols, int src_rows,\n"
"                                      int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"                                      int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[(dst_offset >> 4) + dy * (dstStep >> 2) + dx] = (sx >= 0 && sx < src_cols && sy >= 0 && sy < src_rows) ? src[(src_offset >> 4) + sy * (srcStep >> 2) + sx] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveLinear_C4_D5(__global float4 *src, __global float4 *dst, int src_cols, int src_rows,\n"
"        int dst_cols, int dst_rows, int srcStep, int dstStep,\n"
"        int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	src_offset = (src_offset >> 4);\n"
"	dst_offset = (dst_offset >> 4);\n"
"	srcStep = (srcStep >> 2);\n"
"	dstStep = (dstStep >> 2);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx0 = (short)(X >> INTER_BITS);\n"
"	short sy0 = (short)(Y >> INTER_BITS);\n"
"	short ay0 = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax0 = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	\n"
"	float4 v0, v1, v2, v3;\n"
"	\n"
"	v0 = (sx0 >= 0 && sx0 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[src_offset + sy0 * srcStep + sx0] : 0;\n"
"	v1 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 >= 0 && sy0 < src_rows) ? src[src_offset + sy0 * srcStep + sx0 + 1] : 0;\n"
"	v2 = (sx0 >= 0 && sx0 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? src[src_offset + (sy0 + 1) * srcStep + sx0] : 0;\n"
"	v3 = (sx0 + 1 >= 0 && sx0 + 1 < src_cols && sy0 + 1 >= 0 && sy0 + 1 < src_rows) ? src[src_offset + (sy0 + 1) * srcStep + sx0 + 1] : 0;\n"
"	\n"
"	float tab[4];\n"
"	float taby[2], tabx[2];\n"
"	taby[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay0;\n"
"	taby[1] = 1.f / INTER_TAB_SIZE * ay0;\n"
"	tabx[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax0;\n"
"	tabx[1] = 1.f / INTER_TAB_SIZE * ax0;\n"
"	\n"
"	tab[0] = taby[0] * tabx[0];\n"
"	tab[1] = taby[0] * tabx[1];\n"
"	tab[2] = taby[1] * tabx[0];\n"
"	tab[3] = taby[1] * tabx[1];\n"
"	\n"
"	float4 sum = 0;\n"
"	sum += v0 * tab[0] +  v1 * tab[1] +  v2 * tab[2] +  v3 * tab[3];\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		dst[dst_offset + dy * dstStep + dx] = sum;\n"
"	}\n"
"}\n"
"__kernel void warpPerspectiveCubic_C4_D5(__global float4 *src, __global float4 *dst,\n"
"        int src_cols, int src_rows, int dst_cols, int dst_rows, int srcStep,\n"
"        int dstStep, int src_offset, int dst_offset,  __constant F *M)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	src_offset = (src_offset >> 4);\n"
"	dst_offset = (dst_offset >> 4);\n"
"	srcStep = (srcStep >> 2);\n"
"	dstStep = (dstStep >> 2);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = rint(X0 * W);\n"
"	int Y = rint(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	\n"
"	float4 v[16];\n"
"	int i;\n"
"	\n"
"	for (i = 0; i < 16;  i++)\n"
"	{\n"
"		v[i] = (sx + (i & 3) >= 0 && sx + (i & 3) < src_cols && sy + (i >> 2) >= 0 && sy + (i >> 2) < src_rows) ? src[src_offset + (sy + (i >> 2)) * srcStep + (sx + (i & 3))] : 0;\n"
"	}\n"
"	\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"#pragma unroll 4\n"
"	\n"
"	for (i = 0; i < 16; i++)\n"
"	{\n"
"		tab[i] = tab1y[(i >> 2)] * tab1x[(i & 3)];\n"
"	}\n"
"	\n"
"	if (dx >= 0 && dx < dst_cols && dy >= 0 && dy < dst_rows)\n"
"	{\n"
"		float4 sum = 0;\n"
"#pragma unroll 4\n"
"		\n"
"		for (i = 0; i < 16; i++)\n"
"		{\n"
"			sum += v[i] * tab[i];\n"
"		}\n"
"		\n"
"		dst[dst_offset + dy * dstStep + dx] = sum;\n"
"		\n"
"	}\n"
"}\n"
;
const char *img_proc =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined DOUBLE_SUPPORT\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"//wrapAffine kernel\n"
"//support four data types: CV_8U, CV_16U, CV_32S, CV_32F, and three interpolation methods: NN, Linear, Cubic.\n"
"#define INTER_BITS 5\n"
"#define INTER_TAB_SIZE (1 << INTER_BITS)\n"
"#define AB_BITS max(10, (int)INTER_BITS)\n"
"#define AB_SCALE (1 << AB_BITS)\n"
"#define INTER_REMAP_COEF_BITS 15\n"
"#define INTER_REMAP_COEF_SCALE (1 << INTER_REMAP_COEF_BITS)\n"
"//this round operation is to approximate CPU's saturate_cast<int>\n"
"int round2_int(double v)\n"
"{\n"
"	int v1 = (int)v;\n"
"	\n"
"	if (((v - v1) == 0.5 || (v1 - v) == 0.5) && (v1 % 2) == 0)\n"
"	{\n"
"		return v1;\n"
"	}\n"
"	else\n"
"	{\n"
"		return convert_int_sat(v + (v >= 0 ? 0.5 : -0.5));\n"
"	}\n"
"}\n"
"inline void interpolateCubic(float x, float *coeffs)\n"
"{\n"
"	const float A = -0.75f;\n"
"	\n"
"	coeffs[0] = ((A * (x + 1) - 5 * A) * (x + 1) + 8 * A) * (x + 1) - 4 * A;\n"
"	coeffs[1] = ((A + 2) * x - (A + 3)) * x * x + 1;\n"
"	coeffs[2] = ((A + 2) * (1 - x) - (A + 3)) * (1 - x) * (1 - x) + 1;\n"
"	coeffs[3] = 1.f - coeffs[0] - coeffs[1] - coeffs[2];\n"
"}\n"
"__kernel void warpAffine_8u_NN(__global uchar *src, __global uchar *dst, int cols, int rows,  int cn,\n"
"                               int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	short sx = (short)(X0 >> AB_BITS);\n"
"	short sy = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffine_8u_Linear(__global uchar *src, __global uchar *dst, int cols, int rows,  int cn,\n"
"                                   int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	int v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	short itab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			float v = tab1y[i] * tab1x[j];\n"
"			itab[i * 2 + j] = convert_short_sat(round2_int(v * INTER_REMAP_COEF_SCALE));\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		int sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * itab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_uchar_sat(((int)sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_8u_Cubic(__global uchar *src, __global uchar *dst, int cols, int rows,  int cn,\n"
"                                  int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	short itab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	int isum = 0;\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			double v = tab1y[i] * tab1x[j];\n"
"			isum += itab[i * 4 + j] = convert_short_sat(round2_int(v * INTER_REMAP_COEF_SCALE));\n"
"		}\n"
"	}\n"
"	\n"
"	if (isum != INTER_REMAP_COEF_SCALE)\n"
"	{\n"
"		int k1, k2, ksize = 4;\n"
"		int diff = isum - INTER_REMAP_COEF_SCALE;\n"
"		int ksize2 = ksize / 2, Mk1 = ksize2, Mk2 = ksize2, mk1 = ksize2, mk2 = ksize2;\n"
"		\n"
"		for (k1 = ksize2; k1 < ksize2 + 2; k1++)\n"
"			for (k2 = ksize2; k2 < ksize2 + 2; k2++)\n"
"			{\n"
"				if (itab[k1 * ksize + k2] < itab[mk1 * ksize + mk2])\n"
"				{\n"
"					mk1 = k1, mk2 = k2;\n"
"				}\n"
"				else if (itab[k1 * ksize + k2] > itab[Mk1 * ksize + Mk2])\n"
"				{\n"
"					Mk1 = k1, Mk2 = k2;\n"
"				}\n"
"			}\n"
"			\n"
"		if (diff < 0)\n"
"		{\n"
"			itab[Mk1 * ksize + Mk2] = (short)(itab[Mk1 * ksize + Mk2] - diff);\n"
"		}\n"
"		else\n"
"		{\n"
"			itab[mk1 * ksize + mk2] = (short)(itab[mk1 * ksize + mk2] - diff);\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		int sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * itab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_uchar_sat((int)(sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_16u_NN(__global ushort *src, __global ushort *dst, int cols, int rows,  int cn,\n"
"                                int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	short sx = (short)(X0 >> AB_BITS);\n"
"	short sy = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffine_16u_Linear(__global ushort *src, __global ushort *dst, int cols, int rows,  int cn,\n"
"                                    int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	ushort v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			tab[i * 2 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_ushort_sat(round2_int(sum)) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_16u_Cubic(__global ushort *src, __global ushort *dst, int cols, int rows,  int cn,\n"
"                                   int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	ushort v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			tab[i * 4 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	int width = cols - 3 > 0 ? cols - 3 : 0;\n"
"	int height = rows - 3 > 0 ? rows - 3 : 0;\n"
"	\n"
"	if ((unsigned)sx < width && (unsigned)sy < height)\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * 4 * cn + c] * tab[i * 4] + v[i * 4 * cn + c + 1] * tab[i * 4 + 1]\n"
"				       + v[i * 4 * cn + c + 2] * tab[i * 4 + 2] + v[i * 4 * cn + c + 3] * tab[i * 4 + 3];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_ushort_sat(round2_int(sum));\n"
"		}\n"
"	}\n"
"	else if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_ushort_sat(round2_int(sum));\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_32s_NN(__global int *src, __global int *dst, int cols, int rows,  int cn,\n"
"                                int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	short sx = (short)(X0 >> AB_BITS);\n"
"	short sy = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffine_32s_Linear(__global int *src, __global int *dst, int cols, int rows,  int cn,\n"
"                                    int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	int v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			tab[i * 2 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_int_sat(round2_int(sum)) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_32s_Cubic(__global int *src, __global int *dst, int cols, int rows,  int cn,\n"
"                                   int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	int v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			tab[i * 4 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_int_sat(round2_int(sum));\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_32f_NN(__global float *src, __global float *dst, int cols, int rows,  int cn,\n"
"                                int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	\n"
"	short sx = (short)(X0 >> AB_BITS);\n"
"	short sy = (short)(Y0 >> AB_BITS);\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpAffine_32f_Linear(__global float *src, __global float *dst, int cols, int rows,  int cn,\n"
"                                    int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			tab[i * 2 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = sum ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpAffine_32f_Cubic(__global float *src, __global float *dst, int cols, int rows,  int cn,\n"
"                                   int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	int round_delta = AB_SCALE / INTER_TAB_SIZE / 2;\n"
"	\n"
"	int X0 = round2_int(M[0] * dx * AB_SCALE);\n"
"	int Y0 = round2_int(M[3] * dx * AB_SCALE);\n"
"	X0 += round2_int((M[1] * dy + M[2]) * AB_SCALE) + round_delta;\n"
"	Y0 += round2_int((M[4] * dy + M[5]) * AB_SCALE) + round_delta;\n"
"	int X = X0 >> (AB_BITS - INTER_BITS);\n"
"	int Y = Y0 >> (AB_BITS - INTER_BITS);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			tab[i * 4 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	int width = cols - 3 > 0 ? cols - 3 : 0;\n"
"	int height = rows - 3 > 0 ? rows - 3 : 0;\n"
"	\n"
"	if ((unsigned)sx < width && (unsigned)sy < height)\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * 4 * cn + c] * tab[i * 4] + v[i * 4 * cn + c + 1] * tab[i * 4 + 1]\n"
"				       + v[i * 4 * cn + c + 2] * tab[i * 4 + 2] + v[i * 4 * cn + c + 3] * tab[i * 4 + 3];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = sum;\n"
"		}\n"
"	}\n"
"	else if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = sum;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_8u_NN(__global uchar *src, __global uchar *dst, int cols, int rows,  int cn,\n"
"                                    int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_8u_Linear(__global uchar *src, __global uchar *dst, int cols, int rows,  int cn,\n"
"                                        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	short itab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			float v = tab1y[i] * tab1x[j];\n"
"			itab[i * 2 + j] = convert_short_sat(round2_int(v * INTER_REMAP_COEF_SCALE));\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		int sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * itab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_uchar_sat(round2_int(sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_8u_Cubic(__global uchar *src, __global uchar *dst, int cols, int rows,  int cn,\n"
"                                       int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	uchar v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	short itab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	int isum = 0;\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			double v = tab1y[i] * tab1x[j];\n"
"			isum += itab[i * 4 + j] = convert_short_sat(round2_int(v * INTER_REMAP_COEF_SCALE));\n"
"		}\n"
"	}\n"
"	\n"
"	if (isum != INTER_REMAP_COEF_SCALE)\n"
"	{\n"
"		int k1, k2, ksize = 4;\n"
"		int diff = isum - INTER_REMAP_COEF_SCALE;\n"
"		int ksize2 = ksize / 2, Mk1 = ksize2, Mk2 = ksize2, mk1 = ksize2, mk2 = ksize2;\n"
"		\n"
"		for (k1 = ksize2; k1 < ksize2 + 2; k1++)\n"
"			for (k2 = ksize2; k2 < ksize2 + 2; k2++)\n"
"			{\n"
"				if (itab[k1 * ksize + k2] < itab[mk1 * ksize + mk2])\n"
"				{\n"
"					mk1 = k1, mk2 = k2;\n"
"				}\n"
"				else if (itab[k1 * ksize + k2] > itab[Mk1 * ksize + Mk2])\n"
"				{\n"
"					Mk1 = k1, Mk2 = k2;\n"
"				}\n"
"			}\n"
"			\n"
"		if (diff < 0)\n"
"		{\n"
"			itab[Mk1 * ksize + Mk2] = (short)(itab[Mk1 * ksize + Mk2] - diff);\n"
"		}\n"
"		else\n"
"		{\n"
"			itab[mk1 * ksize + mk2] = (short)(itab[mk1 * ksize + mk2] - diff);\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		int sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * itab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_uchar_sat(round2_int(sum + (1 << (INTER_REMAP_COEF_BITS - 1))) >> INTER_REMAP_COEF_BITS) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_16u_NN(__global ushort *src, __global ushort *dst, int cols, int rows,  int cn,\n"
"                                     int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_16u_Linear(__global ushort *src, __global ushort *dst, int cols, int rows,  int cn,\n"
"        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	ushort v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			tab[i * 2 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_ushort_sat(round2_int(sum)) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_16u_Cubic(__global ushort *src, __global ushort *dst, int cols, int rows,  int cn,\n"
"                                        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	ushort v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			tab[i * 4 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	int width = cols - 3 > 0 ? cols - 3 : 0;\n"
"	int height = rows - 3 > 0 ? rows - 3 : 0;\n"
"	\n"
"	if ((unsigned)sx < width && (unsigned)sy < height)\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * 4 * cn + c] * tab[i * 4] + v[i * 4 * cn + c + 1] * tab[i * 4 + 1]\n"
"				       + v[i * 4 * cn + c + 2] * tab[i * 4 + 2] + v[i * 4 * cn + c + 3] * tab[i * 4 + 3];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_ushort_sat(round2_int(sum));\n"
"		}\n"
"	}\n"
"	else if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_ushort_sat(round2_int(sum));\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_32s_NN(__global int *src, __global int *dst, int cols, int rows,  int cn,\n"
"                                     int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_32s_Linear(__global int *src, __global int *dst, int cols, int rows,  int cn,\n"
"        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	int v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			tab[i * 2 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_int_sat(round2_int(sum)) ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_32s_Cubic(__global int *src, __global int *dst, int cols, int rows,  int cn,\n"
"                                        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	int v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			tab[i * 4 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = convert_int_sat(round2_int(sum));\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_32f_NN(__global float *src, __global float *dst, int cols, int rows,  int cn,\n"
"                                     int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? 1. / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	short sx = (short)X;\n"
"	short sy = (short)Y;\n"
"	\n"
"	for (int c = 0; c < cn; c++)\n"
"	{\n"
"		dst[dy * dstStep + dx * cn + c] = (sx >= 0 && sx < cols && sy >= 0 && sy < rows) ? src[sy * srcStep + sx * cn + c] : 0;\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_32f_Linear(__global float *src, __global float *dst, int cols, int rows,  int cn,\n"
"        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS);\n"
"	short sy = (short)(Y >> INTER_BITS);\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v[16];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 2;  i++)\n"
"		for (j = 0; j < 2; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 2 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[4];\n"
"	float tab1y[2], tab1x[2];\n"
"	tab1y[0] = 1.0 - 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1y[1] = 1.f / INTER_TAB_SIZE * ay;\n"
"	tab1x[0] = 1.0 - 1.f / INTER_TAB_SIZE * ax;\n"
"	tab1x[1] = 1.f / INTER_TAB_SIZE * ax;\n"
"	\n"
"	for (i = 0; i < 2; i++)\n"
"	{\n"
"		for (j = 0; j < 2; j++)\n"
"		{\n"
"			tab[i * 2 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	if (sx + 1 < 0 || sx >= cols || sy + 1 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i] ;\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = sum ;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void warpPerspective_32f_Cubic(__global float *src, __global float *dst, int cols, int rows,  int cn,\n"
"                                        int srcStep, int dstStep, __global double *M, int interpolation)\n"
"{\n"
"	int dx = get_global_id(0);\n"
"	int dy = get_global_id(1);\n"
"	\n"
"	double X0 = M[0] * dx + M[1] * dy + M[2];\n"
"	double Y0 = M[3] * dx + M[4] * dy + M[5];\n"
"	double W = M[6] * dx + M[7] * dy + M[8];\n"
"	W = W ? INTER_TAB_SIZE / W : 0;\n"
"	int X = round2_int(X0 * W);\n"
"	int Y = round2_int(Y0 * W);\n"
"	\n"
"	short sx = (short)(X >> INTER_BITS) - 1;\n"
"	short sy = (short)(Y >> INTER_BITS) - 1;\n"
"	short ay = (short)(Y & (INTER_TAB_SIZE - 1));\n"
"	short ax = (short)(X & (INTER_TAB_SIZE - 1));\n"
"	\n"
"	float v[64];\n"
"	int i, j, c;\n"
"	\n"
"	for (i = 0; i < 4;  i++)\n"
"		for (j = 0; j < 4; j++)\n"
"			for (c = 0; c < cn; c++)\n"
"			{\n"
"				v[i * 4 * cn + j * cn + c] = (sx + j >= 0 && sx + j < cols && sy + i >= 0 && sy + i < rows) ? src[(sy + i) * srcStep + (sx + j) * cn + c] : 0;\n"
"			}\n"
"			\n"
"	float tab[16];\n"
"	float tab1y[4], tab1x[4];\n"
"	float axx, ayy;\n"
"	\n"
"	ayy = 1.f / INTER_TAB_SIZE * ay;\n"
"	axx = 1.f / INTER_TAB_SIZE * ax;\n"
"	interpolateCubic(ayy, tab1y);\n"
"	interpolateCubic(axx, tab1x);\n"
"	\n"
"	for (i = 0; i < 4; i++)\n"
"	{\n"
"		for (j = 0; j < 4; j++)\n"
"		{\n"
"			tab[i * 4 + j] = tab1y[i] * tab1x[j];\n"
"		}\n"
"	}\n"
"	\n"
"	int width = cols - 3 > 0 ? cols - 3 : 0;\n"
"	int height = rows - 3 > 0 ? rows - 3 : 0;\n"
"	\n"
"	if ((unsigned)sx < width && (unsigned)sy < height)\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 4; i++)\n"
"			{\n"
"				sum += v[i * 4 * cn + c] * tab[i * 4] + v[i * 4 * cn + c + 1] * tab[i * 4 + 1]\n"
"				       + v[i * 4 * cn + c + 2] * tab[i * 4 + 2] + v[i * 4 * cn + c + 3] * tab[i * 4 + 3];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = sum;\n"
"		}\n"
"	}\n"
"	else if (sx + 4 < 0 || sx >= cols || sy + 4 < 0 || sy >= rows)\n"
"	{\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			dst[dy * dstStep + dx * cn + c] = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		float sum;\n"
"		\n"
"		for (c = 0; c < cn; c++)\n"
"		{\n"
"			sum = 0;\n"
"			\n"
"			for (i = 0; i < 16; i++)\n"
"			{\n"
"				sum += v[i * cn + c] * tab[i];\n"
"			}\n"
"			\n"
"			dst[dy * dstStep + dx * cn + c] = sum;\n"
"		}\n"
"	}\n"
"}\n"
"#endif\n"
;
const char *meanShift =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Shengen Yan,yanshengen@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"short2 do_mean_shift(int x0, int y0, __global unsigned char *out, int out_step,\n"
"                     __global unsigned char *in, int in_step, int cols, int rows,\n"
"                     int sp, int sr, int maxIter, float eps)\n"
"{\n"
"	int isr2 = sr * sr;\n"
"	int idx = y0 * in_step + x0 * 4;\n"
"	uchar4 c = (uchar4)(in[idx], in[idx + 1], in[idx + 2], in[idx + 3]);\n"
"	\n"
"	// iterate meanshift procedure\n"
"	for (int iter = 0; iter < maxIter; iter++)\n"
"	{\n"
"		int count = 0;\n"
"		int s0 = 0, s1 = 0, s2 = 0, sx = 0, sy = 0;\n"
"		float icount;\n"
"		\n"
"		//mean shift: process pixels in window (p-sigmaSp)x(p+sigmaSp)\n"
"		int minx = x0 - sp;\n"
"		int miny = y0 - sp;\n"
"		int maxx = x0 + sp;\n"
"		int maxy = y0 + sp;\n"
"		\n"
"		//deal with the image boundary\n"
"		if (minx < 0)\n"
"		{\n"
"			minx = 0;\n"
"		}\n"
"		\n"
"		if (miny < 0)\n"
"		{\n"
"			miny = 0;\n"
"		}\n"
"		\n"
"		if (maxx >= cols)\n"
"		{\n"
"			maxx = cols - 1;\n"
"		}\n"
"		\n"
"		if (maxy >= rows)\n"
"		{\n"
"			maxy = rows - 1;\n"
"		}\n"
"		\n"
"		for (int y = miny; y <= maxy; y++)\n"
"		{\n"
"			int rowCount = 0;\n"
"			\n"
"			for (int x = minx; x <= maxx; x++)\n"
"			{\n"
"				//uchar4 t = tex2D( tex_meanshift, x, y );\n"
"				int idx = y * in_step + x * 4;\n"
"				uchar4 t = (uchar4)(in[idx], in[idx + 1], in[idx + 2], in[idx + 3]);\n"
"				\n"
"				int norm2 = (t.x - c.x) * (t.x - c.x) + (t.y - c.y) * (t.y - c.y) + (t.z - c.z) * (t.z - c.z);\n"
"				\n"
"				if (norm2 <= isr2)\n"
"				{\n"
"					s0 += t.x; s1 += t.y; s2 += t.z;\n"
"					sx += x; rowCount++;\n"
"				}\n"
"			}\n"
"			\n"
"			count += rowCount;\n"
"			sy += y * rowCount;\n"
"		}\n"
"		\n"
"		if (count == 0)\n"
"		{\n"
"			break;\n"
"		}\n"
"		\n"
"		icount = 1.f / count;\n"
"		int x1 = convert_int_rtz(sx * icount);\n"
"		int y1 = convert_int_rtz(sy * icount);\n"
"		s0 = convert_int_rtz(s0 * icount);\n"
"		s1 = convert_int_rtz(s1 * icount);\n"
"		s2 = convert_int_rtz(s2 * icount);\n"
"		\n"
"		int norm2 = (s0 - c.x) * (s0 - c.x) + (s1 - c.y) * (s1 - c.y) + (s2 - c.z) * (s2 - c.z);\n"
"		\n"
"		bool stopFlag = (x0 == x1 && y0 == y1) || (abs(x1 - x0) + abs(y1 - y0) + norm2 <= eps);\n"
"		\n"
"		x0 = x1; y0 = y1;\n"
"		c.x = s0; c.y = s1; c.z = s2;\n"
"		\n"
"		if (stopFlag)\n"
"		{\n"
"			break;\n"
"		}\n"
"	}\n"
"	\n"
"	int base = get_global_id(1) * out_step + get_global_id(0) * 4;\n"
"	//FIXME!!! It seems OpenCL does not support complex pointer arithmetic.\n"
"	//FIXME!!! As a result, we have to do it in a tedious way as follows:\n"
"	//*(uchar4*)(out + base) = c;\n"
"	out[base] = c.x;\n"
"	out[base + 1] = c.y;\n"
"	out[base + 2] = c.z;\n"
"	out[base + 3] = c.w;\n"
"	\n"
"	return (short2)((short)x0, (short)y0);\n"
"}\n"
"__kernel void meanshift_kernel(__global unsigned char *out, int out_step,\n"
"                               __global unsigned char *in, int in_step,\n"
"                               int cols, int rows, int sp, int sr, int maxIter, float eps)\n"
"{\n"
"	int x0 = get_global_id(0);\n"
"	int y0 = get_global_id(1);\n"
"	\n"
"	if (x0 < cols && y0 < rows)\n"
"	{\n"
"		do_mean_shift(x0, y0, out, out_step, in, in_step, cols, rows, sp, sr, maxIter, eps);\n"
"	}\n"
"}\n"
"__kernel void meanshiftproc_kernel(__global unsigned char *in, __global unsigned char *outr,\n"
"                                   __global short2 *outsp, int instep, int outrstep,\n"
"                                   int outspstep, int cols, int rows,\n"
"                                   int sp, int sr, int maxIter, float eps)\n"
"{\n"
"	int x0 = get_global_id(0);\n"
"	int y0 = get_global_id(1);\n"
"	\n"
"	if (x0 < cols && y0 < rows)\n"
"	{\n"
"		//int basesp = (blockIdx.y * blockDim.y + threadIdx.y) * outspstep + (blockIdx.x * blockDim.x + threadIdx.x) * 2 * sizeof(short);\n"
"		//*(short2*)(outsp + basesp) = do_mean_shift(x0, y0, outr, outrstep, cols, rows, sp, sr, maxIter, eps);\n"
"		// we have ensured before that ((outspstep & 0x11)==0).\n"
"		int basesp = y0 * (outspstep >> 2) + x0;\n"
"		outsp[basesp] = do_mean_shift(x0, y0, outr, outrstep, in, instep, cols, rows, sp, sr, maxIter, eps);\n"
"	}\n"
"}\n"
;
const char *merge_mat =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"///////////////////////////////////////////////////////////////////////////////////////////////\n"
"//////////////////////////////////optimized code using vector roi//////////////////////////\n"
"////////////vector fuction name format: merge_vector_C(channels number)D_(data type depth)//////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void merge_vector_C2_D0(__global uchar *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global uchar *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global uchar *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align  ((dst_offset & 3) >> 1)\n"
"		int src0_index = mad24(y, src0_step, src0_offset + x - dst_align);\n"
"		int src1_index = mad24(y, src1_step, src1_offset + x - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		__global uchar4 *dst  = (__global uchar4 *)(mat_dst + dst_index);\n"
"		__global uchar   *src0 = mat_src0 + src0_index;\n"
"		__global uchar   *src1 = src0     + 1;\n"
"		__global uchar   *src2 = mat_src1 + src1_index;\n"
"		__global uchar   *src3 = src2     + 1;\n"
"		\n"
"		uchar4 dst_data = *dst;\n"
"		uchar  data_0   = *(src0);\n"
"		uchar  data_1   = *(src1);\n"
"		uchar  data_2   = *(src2);\n"
"		uchar  data_3   = *(src3);\n"
"		\n"
"		uchar4 tmp_data = (uchar4)(data_0, data_2, data_1, data_3);\n"
"		\n"
"		tmp_data.xy = dst_index + 0 >= dst_start ? tmp_data.xy : dst_data.xy;\n"
"		tmp_data.zw = dst_index + 2 <  dst_end   ? tmp_data.zw : dst_data.zw;\n"
"		\n"
"		*dst = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D1(__global char *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global char *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global char *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst_align  ((dst_offset & 3) >> 1)\n"
"		int src0_index = mad24(y, src0_step, src0_offset + x - dst_align);\n"
"		int src1_index = mad24(y, src1_step, src1_offset + x - dst_align);\n"
"		\n"
"		int dst_start  = mad24(y, dst_step, dst_offset);\n"
"		int dst_end    = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index  = mad24(y, dst_step, dst_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		__global char4 *dst  = (__global char4 *)(mat_dst + dst_index);\n"
"		__global char   *src0 = mat_src0 + src0_index;\n"
"		__global char   *src1 = src0     + 1;\n"
"		__global char   *src2 = mat_src1 + src1_index;\n"
"		__global char   *src3 = src2     + 1;\n"
"		\n"
"		char4 dst_data = *dst;\n"
"		char  data_0   = *(src0);\n"
"		char  data_1   = *(src1);\n"
"		char  data_2   = *(src2);\n"
"		char  data_3   = *(src3);\n"
"		\n"
"		char4 tmp_data = (char4)(data_0, data_2, data_1, data_3);\n"
"		\n"
"		tmp_data.xy = dst_index + 0 >= dst_start ? tmp_data.xy : dst_data.xy;\n"
"		tmp_data.zw = dst_index + 2 <  dst_end   ? tmp_data.zw : dst_data.zw;\n"
"		\n"
"		*dst = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D2(__global ushort *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global ushort *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global ushort *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		__global ushort  *src0 = (__global ushort *)((__global uchar *)mat_src0 + src0_index + (x << 1));\n"
"		__global ushort  *src1 = (__global ushort *)((__global uchar *)mat_src1 + src1_index + (x << 1));\n"
"		__global ushort2 *dist = (__global ushort2 *)((__global uchar *)mat_dst  + dst_index  + (x << 2));\n"
"		\n"
"		ushort  src0_data = *src0;\n"
"		ushort  src1_data = *src1;\n"
"		\n"
"		*dist = (ushort2)(src0_data, src1_data);\n"
"		\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D3(__global short *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global short *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global short *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		__global short  *src0 = (__global short *)((__global uchar *)mat_src0 + src0_index + (x << 1));\n"
"		__global short  *src1 = (__global short *)((__global uchar *)mat_src1 + src1_index + (x << 1));\n"
"		__global short2 *dist = (__global short2 *)((__global uchar *)mat_dst  + dst_index   + (x << 2));\n"
"		\n"
"		short  src0_data = *src0;\n"
"		short  src1_data = *src1;\n"
"		\n"
"		*dist = (short2)(src0_data, src1_data);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D4(__global int *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global int *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global int *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		int src0 = *((__global int *)((__global uchar *)mat_src0 + src0_index + (x << 2)));\n"
"		int src1 = *((__global int *)((__global uchar *)mat_src1 + src1_index + (x << 2)));\n"
"		\n"
"		*((__global int2 *)((__global uchar *)mat_dst  + dst_index + (x << 4))) = (int2)(src0, src1);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D5(__global float *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global float *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global float *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		float src0 = *((__global float *)((__global uchar *)mat_src0 + src0_index + (x << 2)));\n"
"		float src1 = *((__global float *)((__global uchar *)mat_src1 + src1_index + (x << 2)));\n"
"		\n"
"		*((__global float2 *)((__global uchar *)mat_dst  + dst_index + (x << 4))) = (float2)(src0, src1);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D6(__global double *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global double *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global double *mat_src1, int src1_step, int src1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		double src0 = *((__global double *)((__global uchar *)mat_src0 + src0_index + (x << 3)));\n"
"		double src1 = *((__global double *)((__global uchar *)mat_src1 + src1_index + (x << 3)));\n"
"		\n"
"		*((__global double2 *)((__global uchar *)mat_dst  + dst_index + (x << 4))) = (double2)(src0, src1);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D0(__global uchar *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global uchar *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global uchar *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global uchar *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"		int src0_index = mad24(y, src0_step, x + src0_offset - offset_cols);\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - offset_cols);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - offset_cols);\n"
"		\n"
"		int dst_start = mad24(y, dst_step, dst_offset);\n"
"		int dst_end   = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index = mad24(y, dst_step, dst_offset + 3 * x - offset_cols * 3);\n"
"		\n"
"		uchar data0_0 = *(mat_src0 + src0_index + 0);\n"
"		uchar data0_1 = *(mat_src0 + src0_index + 1);\n"
"		uchar data0_2 = *(mat_src0 + src0_index + 2);\n"
"		uchar data0_3 = *(mat_src0 + src0_index + 3);\n"
"		\n"
"		uchar data1_0 = *(mat_src1 + src1_index + 0);\n"
"		uchar data1_1 = *(mat_src1 + src1_index + 1);\n"
"		uchar data1_2 = *(mat_src1 + src1_index + 2);\n"
"		uchar data1_3 = *(mat_src1 + src1_index + 3);\n"
"		\n"
"		uchar data2_0 = *(mat_src2 + src2_index + 0);\n"
"		uchar data2_1 = *(mat_src2 + src2_index + 1);\n"
"		uchar data2_2 = *(mat_src2 + src2_index + 2);\n"
"		uchar data2_3 = *(mat_src2 + src2_index + 3);\n"
"		\n"
"		uchar4 tmp_data0 = (uchar4)(data0_0, data1_0, data2_0, data0_1);\n"
"		uchar4 tmp_data1 = (uchar4)(data1_1, data2_1, data0_2, data1_2);\n"
"		uchar4 tmp_data2 = (uchar4)(data2_2, data0_3, data1_3, data2_3);\n"
"		\n"
"		uchar4 dst_data0 = *((__global uchar4 *)(mat_dst + dst_index + 0));\n"
"		uchar4 dst_data1 = *((__global uchar4 *)(mat_dst + dst_index + 4));\n"
"		uchar4 dst_data2 = *((__global uchar4 *)(mat_dst + dst_index + 8));\n"
"		\n"
"		tmp_data0.x = ((dst_index + 0  >= dst_start) && (dst_index + 0  < dst_end)) ? tmp_data0.x : dst_data0.x;\n"
"		tmp_data0.y = ((dst_index + 1  >= dst_start) && (dst_index + 1  < dst_end)) ? tmp_data0.y : dst_data0.y;\n"
"		tmp_data0.z = ((dst_index + 2  >= dst_start) && (dst_index + 2  < dst_end)) ? tmp_data0.z : dst_data0.z;\n"
"		tmp_data0.w = ((dst_index + 3  >= dst_start) && (dst_index + 3  < dst_end)) ? tmp_data0.w : dst_data0.w;\n"
"		\n"
"		tmp_data1.x = ((dst_index + 4  >= dst_start) && (dst_index + 4  < dst_end)) ? tmp_data1.x : dst_data1.x;\n"
"		tmp_data1.y = ((dst_index + 5  >= dst_start) && (dst_index + 5  < dst_end)) ? tmp_data1.y : dst_data1.y;\n"
"		tmp_data1.z = ((dst_index + 6  >= dst_start) && (dst_index + 6  < dst_end)) ? tmp_data1.z : dst_data1.z;\n"
"		tmp_data1.w = ((dst_index + 7  >= dst_start) && (dst_index + 7  < dst_end)) ? tmp_data1.w : dst_data1.w;\n"
"		\n"
"		tmp_data2.x = ((dst_index + 8  >= dst_start) && (dst_index + 8  < dst_end)) ? tmp_data2.x : dst_data2.x;\n"
"		tmp_data2.y = ((dst_index + 9  >= dst_start) && (dst_index + 9  < dst_end)) ? tmp_data2.y : dst_data2.y;\n"
"		tmp_data2.z = ((dst_index + 10 >= dst_start) && (dst_index + 10 < dst_end)) ? tmp_data2.z : dst_data2.z;\n"
"		tmp_data2.w = ((dst_index + 11 >= dst_start) && (dst_index + 11 < dst_end)) ? tmp_data2.w : dst_data2.w;\n"
"		\n"
"		*((__global uchar4 *)(mat_dst + dst_index + 0)) = tmp_data0;\n"
"		*((__global uchar4 *)(mat_dst + dst_index + 4)) = tmp_data1;\n"
"		*((__global uchar4 *)(mat_dst + dst_index + 8)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D1(__global char *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global char *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global char *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global char *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"		int src0_index = mad24(y, src0_step, x + src0_offset - offset_cols);\n"
"		int src1_index = mad24(y, src1_step, x + src1_offset - offset_cols);\n"
"		int src2_index = mad24(y, src2_step, x + src2_offset - offset_cols);\n"
"		\n"
"		int dst_start = mad24(y, dst_step, dst_offset);\n"
"		int dst_end   = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index = mad24(y, dst_step, dst_offset + 3 * x - offset_cols * 3);\n"
"		\n"
"		char data0_0 = *(mat_src0 + src0_index + 0);\n"
"		char data0_1 = *(mat_src0 + src0_index + 1);\n"
"		char data0_2 = *(mat_src0 + src0_index + 2);\n"
"		char data0_3 = *(mat_src0 + src0_index + 3);\n"
"		\n"
"		char data1_0 = *(mat_src1 + src1_index + 0);\n"
"		char data1_1 = *(mat_src1 + src1_index + 1);\n"
"		char data1_2 = *(mat_src1 + src1_index + 2);\n"
"		char data1_3 = *(mat_src1 + src1_index + 3);\n"
"		\n"
"		char data2_0 = *(mat_src2 + src2_index + 0);\n"
"		char data2_1 = *(mat_src2 + src2_index + 1);\n"
"		char data2_2 = *(mat_src2 + src2_index + 2);\n"
"		char data2_3 = *(mat_src2 + src2_index + 3);\n"
"		\n"
"		char4 tmp_data0 = (char4)(data0_0, data1_0, data2_0, data0_1);\n"
"		char4 tmp_data1 = (char4)(data1_1, data2_1, data0_2, data1_2);\n"
"		char4 tmp_data2 = (char4)(data2_2, data0_3, data1_3, data2_3);\n"
"		\n"
"		char4 dst_data0 = *((__global char4 *)(mat_dst + dst_index + 0));\n"
"		char4 dst_data1 = *((__global char4 *)(mat_dst + dst_index + 4));\n"
"		char4 dst_data2 = *((__global char4 *)(mat_dst + dst_index + 8));\n"
"		\n"
"		tmp_data0.x = ((dst_index + 0  >= dst_start) && (dst_index + 0  < dst_end)) ? tmp_data0.x : dst_data0.x;\n"
"		tmp_data0.y = ((dst_index + 1  >= dst_start) && (dst_index + 1  < dst_end)) ? tmp_data0.y : dst_data0.y;\n"
"		tmp_data0.z = ((dst_index + 2  >= dst_start) && (dst_index + 2  < dst_end)) ? tmp_data0.z : dst_data0.z;\n"
"		tmp_data0.w = ((dst_index + 3  >= dst_start) && (dst_index + 3  < dst_end)) ? tmp_data0.w : dst_data0.w;\n"
"		\n"
"		tmp_data1.x = ((dst_index + 4  >= dst_start) && (dst_index + 4  < dst_end)) ? tmp_data1.x : dst_data1.x;\n"
"		tmp_data1.y = ((dst_index + 5  >= dst_start) && (dst_index + 5  < dst_end)) ? tmp_data1.y : dst_data1.y;\n"
"		tmp_data1.z = ((dst_index + 6  >= dst_start) && (dst_index + 6  < dst_end)) ? tmp_data1.z : dst_data1.z;\n"
"		tmp_data1.w = ((dst_index + 7  >= dst_start) && (dst_index + 7  < dst_end)) ? tmp_data1.w : dst_data1.w;\n"
"		\n"
"		tmp_data2.x = ((dst_index + 8  >= dst_start) && (dst_index + 8  < dst_end)) ? tmp_data2.x : dst_data2.x;\n"
"		tmp_data2.y = ((dst_index + 9  >= dst_start) && (dst_index + 9  < dst_end)) ? tmp_data2.y : dst_data2.y;\n"
"		tmp_data2.z = ((dst_index + 10 >= dst_start) && (dst_index + 10 < dst_end)) ? tmp_data2.z : dst_data2.z;\n"
"		tmp_data2.w = ((dst_index + 11 >= dst_start) && (dst_index + 11 < dst_end)) ? tmp_data2.w : dst_data2.w;\n"
"		\n"
"		*((__global char4 *)(mat_dst + dst_index + 0)) = tmp_data0;\n"
"		*((__global char4 *)(mat_dst + dst_index + 4)) = tmp_data1;\n"
"		*((__global char4 *)(mat_dst + dst_index + 8)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D2(__global ushort *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global ushort *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global ushort *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global ushort *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"		int src0_index = mad24(y, src0_step, (x << 1) + src0_offset - offset_cols);\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - offset_cols);\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - offset_cols);\n"
"		\n"
"		int dst_start = mad24(y, dst_step, dst_offset);\n"
"		int dst_end   = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index = mad24(y, dst_step, dst_offset + 6 * x - offset_cols * 6);\n"
"		\n"
"		ushort data0_0 = *((__global ushort *)((__global char *)mat_src0 + src0_index + 0));\n"
"		ushort data0_1 = *((__global ushort *)((__global char *)mat_src0 + src0_index + 2));\n"
"		\n"
"		ushort data1_0 = *((__global ushort *)((__global char *)mat_src1 + src1_index + 0));\n"
"		ushort data1_1 = *((__global ushort *)((__global char *)mat_src1 + src1_index + 2));\n"
"		\n"
"		ushort data2_0 = *((__global ushort *)((__global char *)mat_src2 + src2_index + 0));\n"
"		ushort data2_1 = *((__global ushort *)((__global char *)mat_src2 + src2_index + 2));\n"
"		\n"
"		ushort2 tmp_data0 = (ushort2)(data0_0, data1_0);\n"
"		ushort2 tmp_data1 = (ushort2)(data2_0, data0_1);\n"
"		ushort2 tmp_data2 = (ushort2)(data1_1, data2_1);\n"
"		\n"
"		ushort2 dst_data0 = *((__global ushort2 *)((__global char *)mat_dst + dst_index + 0));\n"
"		ushort2 dst_data1 = *((__global ushort2 *)((__global char *)mat_dst + dst_index + 4));\n"
"		ushort2 dst_data2 = *((__global ushort2 *)((__global char *)mat_dst + dst_index + 8));\n"
"		\n"
"		tmp_data0.x = ((dst_index + 0  >= dst_start) && (dst_index + 0  < dst_end)) ? tmp_data0.x : dst_data0.x;\n"
"		tmp_data0.y = ((dst_index + 2  >= dst_start) && (dst_index + 2  < dst_end)) ? tmp_data0.y : dst_data0.y;\n"
"		\n"
"		tmp_data1.x = ((dst_index + 4  >= dst_start) && (dst_index + 4  < dst_end)) ? tmp_data1.x : dst_data1.x;\n"
"		tmp_data1.y = ((dst_index + 6  >= dst_start) && (dst_index + 6  < dst_end)) ? tmp_data1.y : dst_data1.y;\n"
"		\n"
"		tmp_data2.x = ((dst_index + 8  >= dst_start) && (dst_index + 8  < dst_end)) ? tmp_data2.x : dst_data2.x;\n"
"		tmp_data2.y = ((dst_index + 10 >= dst_start) && (dst_index + 10 < dst_end)) ? tmp_data2.y : dst_data2.y;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)mat_dst + dst_index + 0)) = tmp_data0;\n"
"		*((__global ushort2 *)((__global char *)mat_dst + dst_index + 4)) = tmp_data1;\n"
"		*((__global ushort2 *)((__global char *)mat_dst + dst_index + 8)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D3(__global short *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global short *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global short *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global short *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"		int src0_index = mad24(y, src0_step, (x << 1) + src0_offset - offset_cols);\n"
"		int src1_index = mad24(y, src1_step, (x << 1) + src1_offset - offset_cols);\n"
"		int src2_index = mad24(y, src2_step, (x << 1) + src2_offset - offset_cols);\n"
"		\n"
"		int dst_start = mad24(y, dst_step, dst_offset);\n"
"		int dst_end   = mad24(y, dst_step, dst_offset + dst_step1);\n"
"		int dst_index = mad24(y, dst_step, dst_offset + 6 * x - offset_cols * 6);\n"
"		\n"
"		short data0_0 = *((__global short *)((__global char *)mat_src0 + src0_index + 0));\n"
"		short data0_1 = *((__global short *)((__global char *)mat_src0 + src0_index + 2));\n"
"		\n"
"		short data1_0 = *((__global short *)((__global char *)mat_src1 + src1_index + 0));\n"
"		short data1_1 = *((__global short *)((__global char *)mat_src1 + src1_index + 2));\n"
"		\n"
"		short data2_0 = *((__global short *)((__global char *)mat_src2 + src2_index + 0));\n"
"		short data2_1 = *((__global short *)((__global char *)mat_src2 + src2_index + 2));\n"
"		\n"
"		short2 tmp_data0 = (short2)(data0_0, data1_0);\n"
"		short2 tmp_data1 = (short2)(data2_0, data0_1);\n"
"		short2 tmp_data2 = (short2)(data1_1, data2_1);\n"
"		\n"
"		short2 dst_data0 = *((__global short2 *)((__global char *)mat_dst + dst_index + 0));\n"
"		short2 dst_data1 = *((__global short2 *)((__global char *)mat_dst + dst_index + 4));\n"
"		short2 dst_data2 = *((__global short2 *)((__global char *)mat_dst + dst_index + 8));\n"
"		\n"
"		tmp_data0.x = ((dst_index + 0  >= dst_start) && (dst_index + 0  < dst_end)) ? tmp_data0.x : dst_data0.x;\n"
"		tmp_data0.y = ((dst_index + 2  >= dst_start) && (dst_index + 2  < dst_end)) ? tmp_data0.y : dst_data0.y;\n"
"		\n"
"		tmp_data1.x = ((dst_index + 4  >= dst_start) && (dst_index + 4  < dst_end)) ? tmp_data1.x : dst_data1.x;\n"
"		tmp_data1.y = ((dst_index + 6  >= dst_start) && (dst_index + 6  < dst_end)) ? tmp_data1.y : dst_data1.y;\n"
"		\n"
"		tmp_data2.x = ((dst_index + 8  >= dst_start) && (dst_index + 8  < dst_end)) ? tmp_data2.x : dst_data2.x;\n"
"		tmp_data2.y = ((dst_index + 10 >= dst_start) && (dst_index + 10 < dst_end)) ? tmp_data2.y : dst_data2.y;\n"
"		\n"
"		*((__global short2 *)((__global char *)mat_dst + dst_index + 0)) = tmp_data0;\n"
"		*((__global short2 *)((__global char *)mat_dst + dst_index + 4)) = tmp_data1;\n"
"		*((__global short2 *)((__global char *)mat_dst + dst_index + 8)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D4(__global int *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global int *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global int *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global int *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		__global int *src0 = (__global int *)((__global uchar *)mat_src0 + src0_index + (x << 2));\n"
"		__global int *src1 = (__global int *)((__global uchar *)mat_src1 + src1_index + (x << 2));\n"
"		__global int *src2 = (__global int *)((__global uchar *)mat_src2 + src2_index + (x << 2));\n"
"		\n"
"		__global int *dist0 = (__global int *)((__global uchar *)mat_dst  + dst_index  + 3 * (x << 2));\n"
"		__global int *dist1 = dist0 + 1;\n"
"		__global int *dist2 = dist0 + 2;\n"
"		\n"
"		int  src0_data = *src0;\n"
"		int  src1_data = *src1;\n"
"		int  src2_data = *src2;\n"
"		\n"
"		*dist0 = src0_data;\n"
"		*dist1 = src1_data;\n"
"		*dist2 = src2_data;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D5(__global float *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global float *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global float *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global float *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		__global float *src0 = (__global float *)((__global uchar *)mat_src0 + src0_index + (x << 2));\n"
"		__global float *src1 = (__global float *)((__global uchar *)mat_src1 + src1_index + (x << 2));\n"
"		__global float *src2 = (__global float *)((__global uchar *)mat_src2 + src2_index + (x << 2));\n"
"		\n"
"		__global float *dist0 = (__global float *)((__global uchar *)mat_dst  + dst_index  + 3 * (x << 2));\n"
"		__global float *dist1 = dist0 + 1;\n"
"		__global float *dist2 = dist0 + 2;\n"
"		\n"
"		float  src0_data = *src0;\n"
"		float  src1_data = *src1;\n"
"		float  src2_data = *src2;\n"
"		\n"
"		*dist0 = src0_data;\n"
"		*dist1 = src1_data;\n"
"		*dist2 = src2_data;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D6(__global double *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global double *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global double *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global double *mat_src2, int src2_step, int src2_offset, int offset_cols,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		__global double *src0 = (__global double *)((__global uchar *)mat_src0 + src0_index + (x << 3));\n"
"		__global double *src1 = (__global double *)((__global uchar *)mat_src1 + src1_index + (x << 3));\n"
"		__global double *src2 = (__global double *)((__global uchar *)mat_src2 + src2_index + (x << 3));\n"
"		\n"
"		__global double *dist0 = (__global double *)((__global uchar *)mat_dst  + dst_index  + 3 * (x << 3));\n"
"		__global double *dist1 = dist0 + 1;\n"
"		__global double *dist2 = dist0 + 2;\n"
"		\n"
"		double  src0_data = *src0;\n"
"		double  src1_data = *src1;\n"
"		double  src2_data = *src2;\n"
"		\n"
"		*dist0 = src0_data;\n"
"		*dist1 = src1_data;\n"
"		*dist2 = src2_data;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D0(__global uchar *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global uchar *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global uchar *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global uchar *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global uchar *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		uchar src0 = *(mat_src0 + src0_index + x);\n"
"		uchar src1 = *(mat_src1 + src1_index + x);\n"
"		uchar src2 = *(mat_src2 + src2_index + x);\n"
"		uchar src3 = *(mat_src3 + src3_index + x);\n"
"		\n"
"		*((__global uchar4 *)(mat_dst  + dst_index + (x << 2))) = (uchar4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D1(__global char *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global char *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global char *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global char *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global char *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		char src0 = *(mat_src0 + src0_index + x);\n"
"		char src1 = *(mat_src1 + src1_index + x);\n"
"		char src2 = *(mat_src2 + src2_index + x);\n"
"		char src3 = *(mat_src3 + src3_index + x);\n"
"		\n"
"		*((__global char4 *)(mat_dst  + dst_index + (x << 2))) = (char4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D2(__global ushort *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global ushort *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global ushort *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global ushort *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global ushort *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		ushort src0 = *((__global ushort *)((__global uchar *)mat_src0 + src0_index + (x << 1)));\n"
"		ushort src1 = *((__global ushort *)((__global uchar *)mat_src1 + src1_index + (x << 1)));\n"
"		ushort src2 = *((__global ushort *)((__global uchar *)mat_src2 + src2_index + (x << 1)));\n"
"		ushort src3 = *((__global ushort *)((__global uchar *)mat_src3 + src3_index + (x << 1)));\n"
"		\n"
"		*((__global ushort4 *)((__global uchar *)mat_dst  + dst_index + (x << 3))) = (ushort4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D3(__global short *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global short *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global short *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global short *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global short *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		short src0 = *((__global short *)((__global uchar *)mat_src0 + src0_index + (x << 1)));\n"
"		short src1 = *((__global short *)((__global uchar *)mat_src1 + src1_index + (x << 1)));\n"
"		short src2 = *((__global short *)((__global uchar *)mat_src2 + src2_index + (x << 1)));\n"
"		short src3 = *((__global short *)((__global uchar *)mat_src3 + src3_index + (x << 1)));\n"
"		\n"
"		*((__global short4 *)((__global uchar *)mat_dst  + dst_index + (x << 3))) = (short4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D4(__global int *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global int *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global int *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global int *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global int *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		int src0 = *((__global int *)((__global uchar *)mat_src0 + src0_index + (x << 2)));\n"
"		int src1 = *((__global int *)((__global uchar *)mat_src1 + src1_index + (x << 2)));\n"
"		int src2 = *((__global int *)((__global uchar *)mat_src2 + src2_index + (x << 2)));\n"
"		int src3 = *((__global int *)((__global uchar *)mat_src3 + src3_index + (x << 2)));\n"
"		\n"
"		*((__global int4 *)((__global uchar *)mat_dst  + dst_index + (x << 4))) = (int4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D5(__global float *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global float *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global float *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global float *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global float *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		float src0 = *((__global float *)((__global uchar *)mat_src0 + src0_index + (x << 2)));\n"
"		float src1 = *((__global float *)((__global uchar *)mat_src1 + src1_index + (x << 2)));\n"
"		float src2 = *((__global float *)((__global uchar *)mat_src2 + src2_index + (x << 2)));\n"
"		float src3 = *((__global float *)((__global uchar *)mat_src3 + src3_index + (x << 2)));\n"
"		\n"
"		*((__global float4 *)((__global uchar *)mat_dst  + dst_index + (x << 4))) = (float4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D6(__global double *mat_dst,  int dst_step,  int dst_offset,\n"
"                                 __global double *mat_src0, int src0_step, int src0_offset,\n"
"                                 __global double *mat_src1, int src1_step, int src1_offset,\n"
"                                 __global double *mat_src2, int src2_step, int src2_offset,\n"
"                                 __global double *mat_src3, int src3_step, int src3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		int src0_index = mad24(y, src0_step, src0_offset);\n"
"		int src1_index = mad24(y, src1_step, src1_offset);\n"
"		int src2_index = mad24(y, src2_step, src2_offset);\n"
"		int src3_index = mad24(y, src3_step, src3_offset);\n"
"		int dst_index  = mad24(y, dst_step , dst_offset);\n"
"		\n"
"		double src0 = *((__global double *)((__global uchar *)mat_src0 + src0_index + (x << 3)));\n"
"		double src1 = *((__global double *)((__global uchar *)mat_src1 + src1_index + (x << 3)));\n"
"		double src2 = *((__global double *)((__global uchar *)mat_src2 + src2_index + (x << 3)));\n"
"		double src3 = *((__global double *)((__global uchar *)mat_src3 + src3_index + (x << 3)));\n"
"		\n"
"		*((__global double4 *)((__global uchar *)mat_dst  + dst_index + (x << 5))) = (double4)(src0, src1, src2, src3);\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////\n"
"//////////////////////////////////optimized code using vector  no roi//////////////////////////\n"
"////////////vector fuction name format: merge_vector_C(channels number)D_(data type depth)//////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void merge_vector_C2_D0_1(int rows, int cols,\n"
"                                   __global uchar *mat_dst,  int dst_step,\n"
"                                   __global uchar *mat_src0, int src0_step,\n"
"                                   __global uchar *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global uchar4  *src0_y = (__global uchar4 *)(mat_src0 + y * src0_step);\n"
"		__global uchar4  *src1_y = (__global uchar4 *)(mat_src1 + y * src1_step);\n"
"		__global uchar8 *dst_y  = (__global uchar8 *)(mat_dst  + y * dst_step);\n"
"		\n"
"		uchar4 value1 = src0_y[x];\n"
"		uchar4 value2 = src1_y[x];\n"
"		\n"
"		uchar8 value;\n"
"		value.even = value1;\n"
"		value.odd = value2;\n"
"		\n"
"		dst_y[x] = value;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D1_1(int rows, int cols,\n"
"                                   __global char *mat_dst,  int dst_step,\n"
"                                   __global char *mat_src0, int src0_step,\n"
"                                   __global char *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global char4  *src0_y = (__global char4 *)(mat_src0 + y * src0_step);\n"
"		__global char4  *src1_y = (__global char4 *)(mat_src1 + y * src1_step);\n"
"		__global char8 *dst_y  = (__global char8 *)(mat_dst  + y * dst_step);\n"
"		\n"
"		char4 value1 = src0_y[x];\n"
"		char4 value2 = src1_y[x];\n"
"		\n"
"		char8 value;\n"
"		value.even = value1;\n"
"		value.odd = value2;\n"
"		\n"
"		dst_y[x] = value;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D2_1(int rows, int cols,\n"
"                                   __global ushort *mat_dst,  int dst_step,\n"
"                                   __global ushort *mat_src0, int src0_step,\n"
"                                   __global ushort *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global ushort2  *src0_y = (__global ushort2 *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global ushort2  *src1_y = (__global ushort2 *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global ushort4  *dst_y  = (__global ushort4 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		ushort2 value1 = src0_y[x];\n"
"		ushort2 value2 = src1_y[x];\n"
"		\n"
"		ushort4 value;\n"
"		value.even = value1;\n"
"		value.odd = value2;\n"
"		\n"
"		dst_y[x] = value;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D3_1(int rows, int cols,\n"
"                                   __global short *mat_dst,  int dst_step,\n"
"                                   __global short *mat_src0, int src0_step,\n"
"                                   __global short *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global short2  *src0_y = (__global short2 *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global short2  *src1_y = (__global short2 *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global short4 *dst_y   = (__global short4 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		short2 value1 = src0_y[x];\n"
"		short2 value2 = src1_y[x];\n"
"		\n"
"		short4 value;\n"
"		value.even = value1;\n"
"		value.odd = value2;\n"
"		\n"
"		dst_y[x] = value;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D4_1(int rows, int cols,\n"
"                                   __global int *mat_dst,  int dst_step,\n"
"                                   __global int *mat_src0, int src0_step,\n"
"                                   __global int *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global int  *src0_y = (__global int *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global int  *src1_y = (__global int *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global int2  *dst_y  = (__global int2 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		int value1 = src0_y[x];\n"
"		int value2 = src1_y[x];\n"
"		\n"
"		int2 value;\n"
"		value.even = value1;\n"
"		value.odd = value2;\n"
"		\n"
"		dst_y[x] = value;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D5_1(int rows, int cols,\n"
"                                   __global float *mat_dst,  int dst_step,\n"
"                                   __global float *mat_src0, int src0_step,\n"
"                                   __global float *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global float  *src0_y = (__global float *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global float  *src1_y = (__global float *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global float2  *dst_y  = (__global float2 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		float value1 = src0_y[x];\n"
"		float value2 = src1_y[x];\n"
"		\n"
"		dst_y[x] = (float2)(value1, value2);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C2_D6_1(int rows, int cols,\n"
"                                   __global double *mat_dst,  int dst_step,\n"
"                                   __global double *mat_src0, int src0_step,\n"
"                                   __global double *mat_src1, int src1_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global double  *src0_y = (__global double *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global double  *src1_y = (__global double *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global double2 *dst_y  = (__global double2 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		double value1 = src0_y[x];\n"
"		double value2 = src1_y[x];\n"
"		\n"
"		dst_y[x] = (double2)(value1, value2);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D0_1(int rows, int cols,\n"
"                                   __global uchar *mat_dst,  int dst_step,\n"
"                                   __global uchar *mat_src0, int src0_step,\n"
"                                   __global uchar *mat_src1, int src1_step,\n"
"                                   __global uchar *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global uchar4  *src0_y = (__global uchar4 *)(mat_src0 + y * src0_step);\n"
"		__global uchar4  *src1_y = (__global uchar4 *)(mat_src1 + y * src1_step);\n"
"		__global uchar4  *src2_y = (__global uchar4 *)(mat_src2 + y * src0_step);\n"
"		\n"
"		__global uchar4 *dst_y  = (__global uchar4 *)(mat_dst  + y * dst_step);\n"
"		\n"
"		uchar4 value0 = src0_y[x];\n"
"		uchar4 value1 = src1_y[x];\n"
"		uchar4 value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = (uchar4)(value0.s0, value1.s0, value2.s0,\n"
"		                            value0.s1);\n"
"		                            \n"
"		dst_y[3 * x + 1] = (uchar4)(value1.s1, value2.s1,\n"
"		                            value0.s2, value1.s2);\n"
"		                            \n"
"		dst_y[3 * x + 2] = (uchar4)(value2.s2,\n"
"		                            value0.s3, value1.s3, value2.s3);\n"
"		                            \n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D1_1(int rows, int cols,\n"
"                                   __global char *mat_dst,  int dst_step,\n"
"                                   __global char *mat_src0, int src0_step,\n"
"                                   __global char *mat_src1, int src1_step,\n"
"                                   __global char *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global char4  *src0_y = (__global char4 *)(mat_src0 + y * src0_step);\n"
"		__global char4  *src1_y = (__global char4 *)(mat_src1 + y * src1_step);\n"
"		__global char4  *src2_y = (__global char4 *)(mat_src2 + y * src0_step);\n"
"		\n"
"		__global char4 *dst_y  = (__global char4 *)(mat_dst  + y * dst_step);\n"
"		\n"
"		char4 value0 = src0_y[x];\n"
"		char4 value1 = src1_y[x];\n"
"		char4 value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = (char4)(value0.s0, value1.s0, value2.s0,\n"
"		                           value0.s1);\n"
"		                           \n"
"		dst_y[3 * x + 1] = (char4)(value1.s1, value2.s1,\n"
"		                           value0.s2, value1.s2);\n"
"		                           \n"
"		dst_y[3 * x + 2] = (char4)(value2.s2,\n"
"		                           value0.s3, value1.s3, value2.s3);\n"
"		                           \n"
"		/* for test do not delete\n"
"		dst_y[3 * x + 0] = (char8)(value0.s0, value1.s0, value2.s0,\n"
"		                            value0.s1, value1.s1, value2.s1,\n"
"		                            value0.s2, value1.s2);\n"
"		\n"
"		dst_y[3 * x + 1] = (char8)(value2.s2,\n"
"		                            value0.s3, value1.s3, value2.s3,\n"
"		                            value0.s4, value1.s4, value2.s4,\n"
"		                            value0.s5);\n"
"		\n"
"		dst_y[3 * x + 2] = (char8)(value1.s5, value2.s5,\n"
"		                            value0.s6, value1.s6, value2.s6,\n"
"		                            value0.s7, value1.s7, value2.s7);\n"
"		                            */\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D2_1(int rows, int cols,\n"
"                                   __global ushort *mat_dst,  int dst_step,\n"
"                                   __global ushort *mat_src0, int src0_step,\n"
"                                   __global ushort *mat_src1, int src1_step,\n"
"                                   __global ushort *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global ushort2  *src0_y = (__global ushort2 *)((__global char *)mat_src0 + y * src0_step);\n"
"		__global ushort2  *src1_y = (__global ushort2 *)((__global char *)mat_src1 + y * src1_step);\n"
"		__global ushort2  *src2_y = (__global ushort2 *)((__global char *)mat_src2 + y * src0_step);\n"
"		\n"
"		__global ushort2 *dst_y  = (__global ushort2 *)((__global char *)mat_dst  + y * dst_step);\n"
"		\n"
"		ushort2 value0 = src0_y[x];\n"
"		ushort2 value1 = src1_y[x];\n"
"		ushort2 value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = (ushort2)(value0.x, value1.x);\n"
"		dst_y[3 * x + 1] = (ushort2)(value2.x, value0.y);\n"
"		dst_y[3 * x + 2] = (ushort2)(value1.y, value2.y);\n"
"		\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D3_1(int rows, int cols,\n"
"                                   __global short *mat_dst,  int dst_step,\n"
"                                   __global short *mat_src0, int src0_step,\n"
"                                   __global short *mat_src1, int src1_step,\n"
"                                   __global short *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global short2  *src0_y = (__global short2 *)((__global char *)mat_src0 + y * src0_step);\n"
"		__global short2  *src1_y = (__global short2 *)((__global char *)mat_src1 + y * src1_step);\n"
"		__global short2  *src2_y = (__global short2 *)((__global char *)mat_src2 + y * src0_step);\n"
"		\n"
"		__global short2 *dst_y  = (__global short2 *)((__global char *)mat_dst  + y * dst_step);\n"
"		\n"
"		short2 value0 = src0_y[x];\n"
"		short2 value1 = src1_y[x];\n"
"		short2 value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = (short2)(value0.x, value1.x);\n"
"		dst_y[3 * x + 1] = (short2)(value2.x, value0.y);\n"
"		dst_y[3 * x + 2] = (short2)(value1.y, value2.y);\n"
"		\n"
"		/*\n"
"		dst_y[3 * x + 0] = (short4)(value0.s0, value1.s0, value2.s0,\n"
"		                            value0.s1);\n"
"		\n"
"		dst_y[3 * x + 1] = (short4)(value1.s1, value2.s1,\n"
"		                            value0.s2, value1.s2);\n"
"		\n"
"		dst_y[3 * x + 2] = (short4)(value2.s2,\n"
"		                            value0.s3, value1.s3, value2.s3);\n"
"		                            */\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D4_1(int rows, int cols,\n"
"                                   __global int *mat_dst,  int dst_step,\n"
"                                   __global int *mat_src0, int src0_step,\n"
"                                   __global int *mat_src1, int src1_step,\n"
"                                   __global int *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global int  *src0_y = (__global int *)((__global char *)mat_src0 + y * src0_step);\n"
"		__global int  *src1_y = (__global int *)((__global char *)mat_src1 + y * src1_step);\n"
"		__global int  *src2_y = (__global int *)((__global char *)mat_src2 + y * src0_step);\n"
"		\n"
"		__global int *dst_y  = (__global int *)((__global char *)mat_dst  + y * dst_step);\n"
"		\n"
"		int value0 = src0_y[x];\n"
"		int value1 = src1_y[x];\n"
"		int value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = value0;\n"
"		dst_y[3 * x + 1] = value1;\n"
"		dst_y[3 * x + 2] = value2;\n"
"		\n"
"		/*for test do not delete\n"
"		dst_y[3 * x + 0] = (int2)(value0.x, value1.x);\n"
"		dst_y[3 * x + 1] = (int2)(value2.x, value0.y);\n"
"		dst_y[3 * x + 2] = (int2)(value1.y, value2.y);\n"
"		*/\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D5_1(int rows, int cols,\n"
"                                   __global float *mat_dst,  int dst_step,\n"
"                                   __global float *mat_src0, int src0_step,\n"
"                                   __global float *mat_src1, int src1_step,\n"
"                                   __global float *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global float  *src0_y = (__global float *)((__global char *)mat_src0 + y * src0_step);\n"
"		__global float  *src1_y = (__global float *)((__global char *)mat_src1 + y * src1_step);\n"
"		__global float  *src2_y = (__global float *)((__global char *)mat_src2 + y * src0_step);\n"
"		\n"
"		__global float *dst_y  = (__global float *)((__global char *)mat_dst  + y * dst_step);\n"
"		\n"
"		float value0 = src0_y[x];\n"
"		float value1 = src1_y[x];\n"
"		float value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = value0;\n"
"		dst_y[3 * x + 1] = value1;\n"
"		dst_y[3 * x + 2] = value2;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C3_D6_1(int rows, int cols,\n"
"                                   __global double *mat_dst,  int dst_step,\n"
"                                   __global double *mat_src0, int src0_step,\n"
"                                   __global double *mat_src1, int src1_step,\n"
"                                   __global double *mat_src2, int src2_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global double  *src0_y = (__global double *)((__global char *)mat_src0 + y * src0_step);\n"
"		__global double  *src1_y = (__global double *)((__global char *)mat_src1 + y * src1_step);\n"
"		__global double  *src2_y = (__global double *)((__global char *)mat_src2 + y * src0_step);\n"
"		\n"
"		__global double *dst_y  = (__global double *)((__global char *)mat_dst  + y * dst_step);\n"
"		\n"
"		double value0 = src0_y[x];\n"
"		double value1 = src1_y[x];\n"
"		double value2 = src2_y[x];\n"
"		\n"
"		dst_y[3 * x + 0] = value0;\n"
"		dst_y[3 * x + 1] = value1;\n"
"		dst_y[3 * x + 2] = value2;\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D0_1(int rows, int cols,\n"
"                                   __global uchar *mat_dst,  int dst_step,\n"
"                                   __global uchar *mat_src0, int src0_step,\n"
"                                   __global uchar *mat_src1, int src1_step,\n"
"                                   __global uchar *mat_src2, int src2_step,\n"
"                                   __global uchar *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global uchar4  *src0_y = (__global uchar4 *)(mat_src0 + y * src0_step);\n"
"		__global uchar4  *src1_y = (__global uchar4 *)(mat_src1 + y * src1_step);\n"
"		__global uchar4  *src2_y = (__global uchar4 *)(mat_src2 + y * src0_step);\n"
"		__global uchar4  *src3_y = (__global uchar4 *)(mat_src3 + y * src1_step);\n"
"		\n"
"		__global uchar16 *dst_y  = (__global uchar16 *)(mat_dst  + y * dst_step);\n"
"		\n"
"		uchar4 value0 = src0_y[x];\n"
"		uchar4 value1 = src1_y[x];\n"
"		uchar4 value2 = src2_y[x];\n"
"		uchar4 value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (uchar16)(value0.x, value1.x, value2.x, value3.x,\n"
"		                     value0.y, value1.y, value2.y, value3.y,\n"
"		                     value0.z, value1.z, value2.z, value3.z,\n"
"		                     value0.w, value1.w, value2.w, value3.w);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D1_1(int rows, int cols,\n"
"                                   __global char *mat_dst,  int dst_step,\n"
"                                   __global char *mat_src0, int src0_step,\n"
"                                   __global char *mat_src1, int src1_step,\n"
"                                   __global char *mat_src2, int src2_step,\n"
"                                   __global char *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global char4  *src0_y = (__global char4 *)(mat_src0 + y * src0_step);\n"
"		__global char4  *src1_y = (__global char4 *)(mat_src1 + y * src1_step);\n"
"		__global char4  *src2_y = (__global char4 *)(mat_src2 + y * src0_step);\n"
"		__global char4  *src3_y = (__global char4 *)(mat_src3 + y * src1_step);\n"
"		\n"
"		__global char16 *dst_y  = (__global char16 *)(mat_dst  + y * dst_step);\n"
"		\n"
"		char4 value0 = src0_y[x];\n"
"		char4 value1 = src1_y[x];\n"
"		char4 value2 = src2_y[x];\n"
"		char4 value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (char16)(value0.x, value1.x, value2.x, value3.x,\n"
"		                    value0.y, value1.y, value2.y, value3.y,\n"
"		                    value0.z, value1.z, value2.z, value3.z,\n"
"		                    value0.w, value1.w, value2.w, value3.w);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D2_1(int rows, int cols,\n"
"                                   __global ushort *mat_dst,  int dst_step,\n"
"                                   __global ushort *mat_src0, int src0_step,\n"
"                                   __global ushort *mat_src1, int src1_step,\n"
"                                   __global ushort *mat_src2, int src2_step,\n"
"                                   __global ushort *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global ushort2  *src0_y = (__global ushort2 *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global ushort2  *src1_y = (__global ushort2 *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global ushort2  *src2_y = (__global ushort2 *)((__global uchar *)mat_src2 + y * src0_step);\n"
"		__global ushort2  *src3_y = (__global ushort2 *)((__global uchar *)mat_src3 + y * src1_step);\n"
"		\n"
"		__global ushort8 *dst_y  = (__global ushort8 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		ushort2 value0 = src0_y[x];\n"
"		ushort2 value1 = src1_y[x];\n"
"		ushort2 value2 = src2_y[x];\n"
"		ushort2 value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (ushort8)(value0.x, value1.x, value2.x, value3.x,\n"
"		                     value0.y, value1.y, value2.y, value3.y);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D3_1(int rows, int cols,\n"
"                                   __global short *mat_dst,  int dst_step,\n"
"                                   __global short *mat_src0, int src0_step,\n"
"                                   __global short *mat_src1, int src1_step,\n"
"                                   __global short *mat_src2, int src2_step,\n"
"                                   __global short *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global short2  *src0_y = (__global short2 *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global short2  *src1_y = (__global short2 *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global short2  *src2_y = (__global short2 *)((__global uchar *)mat_src2 + y * src0_step);\n"
"		__global short2  *src3_y = (__global short2 *)((__global uchar *)mat_src3 + y * src1_step);\n"
"		\n"
"		__global short8 *dst_y  = (__global short8 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		short2 value0 = src0_y[x];\n"
"		short2 value1 = src1_y[x];\n"
"		short2 value2 = src2_y[x];\n"
"		short2 value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (short8)(value0.x, value1.x, value2.x, value3.x,\n"
"		                    value0.y, value1.y, value2.y, value3.y);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D4_1(int rows, int cols,\n"
"                                   __global int *mat_dst,  int dst_step,\n"
"                                   __global int *mat_src0, int src0_step,\n"
"                                   __global int *mat_src1, int src1_step,\n"
"                                   __global int *mat_src2, int src2_step,\n"
"                                   __global int *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global int *src0_y = (__global int *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global int *src1_y = (__global int *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global int *src2_y = (__global int *)((__global uchar *)mat_src2 + y * src0_step);\n"
"		__global int *src3_y = (__global int *)((__global uchar *)mat_src3 + y * src1_step);\n"
"		\n"
"		__global int4 *dst_y  = (__global int4 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		int value0 = src0_y[x];\n"
"		int value1 = src1_y[x];\n"
"		int value2 = src2_y[x];\n"
"		int value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (int4)(value0, value1, value2, value3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D5_1(int rows, int cols,\n"
"                                   __global float *mat_dst,  int dst_step,\n"
"                                   __global float *mat_src0, int src0_step,\n"
"                                   __global float *mat_src1, int src1_step,\n"
"                                   __global float *mat_src2, int src2_step,\n"
"                                   __global float *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global float *src0_y = (__global float *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global float *src1_y = (__global float *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global float *src2_y = (__global float *)((__global uchar *)mat_src2 + y * src0_step);\n"
"		__global float *src3_y = (__global float *)((__global uchar *)mat_src3 + y * src1_step);\n"
"		\n"
"		__global float4 *dst_y  = (__global float4 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		float value0 = src0_y[x];\n"
"		float value1 = src1_y[x];\n"
"		float value2 = src2_y[x];\n"
"		float value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (float4)(value0, value1, value2, value3);\n"
"	}\n"
"}\n"
"__kernel void merge_vector_C4_D6_1(int rows, int cols,\n"
"                                   __global double *mat_dst,  int dst_step,\n"
"                                   __global double *mat_src0, int src0_step,\n"
"                                   __global double *mat_src1, int src1_step,\n"
"                                   __global double *mat_src2, int src2_step,\n"
"                                   __global double *mat_src3, int src3_step)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) && (y < rows))\n"
"	{\n"
"		__global double *src0_y = (__global double *)((__global uchar *)mat_src0 + y * src0_step);\n"
"		__global double *src1_y = (__global double *)((__global uchar *)mat_src1 + y * src1_step);\n"
"		__global double *src2_y = (__global double *)((__global uchar *)mat_src2 + y * src0_step);\n"
"		__global double *src3_y = (__global double *)((__global uchar *)mat_src3 + y * src1_step);\n"
"		\n"
"		__global double4 *dst_y  = (__global double4 *)((__global uchar *)mat_dst  + y * dst_step);\n"
"		\n"
"		double value0 = src0_y[x];\n"
"		double value1 = src1_y[x];\n"
"		double value2 = src2_y[x];\n"
"		double value3 = src3_y[x];\n"
"		\n"
"		dst_y[x] = (double4)(value0, value1, value2, value3);\n"
"	}\n"
"}\n"
;
const char *operator_convertTo =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"#define F float\n"
"__kernel void convert_to_S4_C1_D0(\n"
"    __global const int *restrict srcMat,\n"
"    __global uchar *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0) << 2;\n"
"	int y = get_global_id(1);\n"
"	//int src_addr_start = mad24(y,srcStep_in_pixel,srcoffset_in_pixel);\n"
"	//int src_addr_end = mad24(y,srcStep_in_pixel,cols+srcoffset_in_pixel);\n"
"	int off_src = (dstoffset_in_pixel & 3);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel - off_src);\n"
"	int dst_addr_start = mad24(y, dstStep_in_pixel, dstoffset_in_pixel);\n"
"	int dst_addr_end = mad24(y, dstStep_in_pixel, cols + dstoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel & (int)0xfffffffc);\n"
"	\n"
"	if ((x < cols + off_src) & (y < rows))\n"
"	{\n"
"		float4 temp_src = convert_float4(vload4(0, srcMat + srcidx));\n"
"		uchar4 temp_dst = *(__global uchar4 *)(dstMat + dstidx);\n"
"		//int trans_src[10] = {temp_src1.y,temp_src1.z,temp_src1.w,temp_src.x,temp_src.y,temp_src.z,temp_src.w,temp_src2.x,temp_src2.y,temp_src2.z};\n"
"		temp_dst.x = (dstidx >= dst_addr_start) & (dstidx < dst_addr_end) ? convert_uchar_sat(temp_src.x * alpha + beta) : temp_dst.x;\n"
"		temp_dst.y = (dstidx + 1 >= dst_addr_start) & (dstidx + 1 < dst_addr_end) ? convert_uchar_sat(temp_src.y * alpha + beta) : temp_dst.y;\n"
"		temp_dst.z = (dstidx + 2 >= dst_addr_start) & (dstidx + 2 < dst_addr_end) ? convert_uchar_sat(temp_src.z * alpha + beta) : temp_dst.z;\n"
"		temp_dst.w = (dstidx + 3 >= dst_addr_start) & (dstidx + 3 < dst_addr_end) ? convert_uchar_sat(temp_src.w * alpha + beta) : temp_dst.w;\n"
"		*(__global uchar4 *)(dstMat + dstidx) = temp_dst;\n"
"	}\n"
"}\n"
"__kernel void convert_to_S4_C4_D0(\n"
"    __global const int4 *restrict srcMat,\n"
"    __global uchar4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float4 temp_src = convert_float4(srcMat[srcidx]);\n"
"		dstMat[dstidx] = convert_uchar4_sat(temp_src * alpha + beta);\n"
"	}\n"
"}\n"
"__kernel void convert_to_S5_C1_D0(\n"
"    __global const float *restrict srcMat,\n"
"    __global uchar *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0) << 2;\n"
"	int y = get_global_id(1);\n"
"	//int src_addr_start = mad24(y,srcStep_in_pixel,srcoffset_in_pixel);\n"
"	//int src_addr_end = mad24(y,srcStep_in_pixel,cols+srcoffset_in_pixel);\n"
"	int off_src = (dstoffset_in_pixel & 3);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel - off_src);\n"
"	int dst_addr_start = mad24(y, dstStep_in_pixel, dstoffset_in_pixel);\n"
"	int dst_addr_end = mad24(y, dstStep_in_pixel, cols + dstoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel & (int)0xfffffffc);\n"
"	\n"
"	if ((x < cols + off_src) & (y < rows))\n"
"	{\n"
"		float4 temp_src = vload4(0, srcMat + srcidx);\n"
"		uchar4 temp_dst = *(__global uchar4 *)(dstMat + dstidx);\n"
"		//int trans_src[10] = {temp_src1.y,temp_src1.z,temp_src1.w,temp_src.x,temp_src.y,temp_src.z,temp_src.w,temp_src2.x,temp_src2.y,temp_src2.z};\n"
"		temp_dst.x = (dstidx >= dst_addr_start) & (dstidx < dst_addr_end) ? convert_uchar_sat(temp_src.x * alpha + beta) : temp_dst.x;\n"
"		temp_dst.y = (dstidx + 1 >= dst_addr_start) & (dstidx + 1 < dst_addr_end) ? convert_uchar_sat(temp_src.y * alpha + beta) : temp_dst.y;\n"
"		temp_dst.z = (dstidx + 2 >= dst_addr_start) & (dstidx + 2 < dst_addr_end) ? convert_uchar_sat(temp_src.z * alpha + beta) : temp_dst.z;\n"
"		temp_dst.w = (dstidx + 3 >= dst_addr_start) & (dstidx + 3 < dst_addr_end) ? convert_uchar_sat(temp_src.w * alpha + beta) : temp_dst.w;\n"
"		*(__global uchar4 *)(dstMat + dstidx) = temp_dst;\n"
"	}\n"
"}\n"
"__kernel void convert_to_S5_C4_D0(\n"
"    __global const float4 *restrict srcMat,\n"
"    __global uchar4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float4 temp_src = srcMat[srcidx];\n"
"		dstMat[dstidx] = convert_uchar4_sat(temp_src * alpha + beta);\n"
"	}\n"
"}\n"
"__kernel void convert_to_S0_C1_D4(\n"
"    __global const uchar *restrict srcMat,\n"
"    __global int *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float temp_src = convert_float(srcMat[srcidx]);\n"
"		dstMat[dstidx] = convert_int_sat(temp_src * alpha + beta);\n"
"	}\n"
"}\n"
"__kernel void convert_to_S5_C1_D4(\n"
"    __global const float *restrict srcMat,\n"
"    __global int *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float temp_src = srcMat[srcidx];\n"
"		dstMat[dstidx] = convert_int_sat(temp_src * alpha + beta);\n"
"	}\n"
"}\n"
"__kernel void convert_to_S0_C4_D4(\n"
"    __global const uchar4 *restrict srcMat,\n"
"    __global int4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float4 temp_src = convert_float4(srcMat[srcidx]);\n"
"		dstMat[dstidx] = convert_int4_sat(temp_src * alpha + beta);\n"
"	}\n"
"}\n"
"__kernel void convert_to_S5_C4_D4(\n"
"    __global const float4 *restrict srcMat,\n"
"    __global int4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float4 temp_src = srcMat[srcidx];\n"
"		dstMat[dstidx] = convert_int4_sat(temp_src * alpha + beta);\n"
"	}\n"
"}\n"
"__kernel void convert_to_S0_C1_D5(\n"
"    __global const uchar *restrict srcMat,\n"
"    __global float *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float temp_src = convert_float(srcMat[srcidx]);\n"
"		dstMat[dstidx] = temp_src * alpha + beta;\n"
"	}\n"
"}\n"
"__kernel void convert_to_S4_C1_D5(\n"
"    __global const int *restrict srcMat,\n"
"    __global float *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float temp_src = convert_float(srcMat[srcidx]);\n"
"		dstMat[dstidx] = temp_src * alpha + beta;\n"
"	}\n"
"}\n"
"__kernel void convert_to_S0_C4_D5(\n"
"    __global const uchar4 *restrict srcMat,\n"
"    __global float4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float4 temp_src = convert_float4(srcMat[srcidx]);\n"
"		dstMat[dstidx] = temp_src * alpha + beta;\n"
"	}\n"
"}\n"
"__kernel void convert_to_S4_C4_D5(\n"
"    __global const int4 *restrict srcMat,\n"
"    __global float4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    F alpha,\n"
"    F beta)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		float4 temp_src = convert_float4(srcMat[srcidx]);\n"
"		dstMat[dstidx] = temp_src * alpha + beta;\n"
"	}\n"
"}\n"
;
const char *operator_copyToM =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"__kernel void copy_to_with_mask_C1_D0(\n"
"    __global const uchar *restrict srcMat,\n"
"    __global uchar *dstMat,\n"
"    __global const uchar *restrict maskMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0) << 2;\n"
"	int y = get_global_id(1);\n"
"	\n"
"	int dst_addr_start = mad24((uint)y, (uint)dstStep_in_pixel, (uint)dstoffset_in_pixel);\n"
"	int dst_addr_end = mad24((uint)y, (uint)dstStep_in_pixel, (uint)cols + dstoffset_in_pixel);\n"
"	int dstidx = mad24((uint)y, (uint)dstStep_in_pixel, (uint)x + dstoffset_in_pixel) & (int)0xfffffffc;\n"
"	\n"
"	int vector_off = dstoffset_in_pixel & 3;\n"
"	\n"
"	int srcidx = mad24((uint)y, (uint)srcStep_in_pixel, (uint)x + srcoffset_in_pixel - vector_off);\n"
"	\n"
"	int mask_addr_start = mad24((uint)y, (uint)maskStep, (uint)maskoffset);\n"
"	int mask_addr_end = mad24((uint)y, (uint)maskStep, (uint)cols + maskoffset);\n"
"	int maskidx = mad24((uint)y, (uint)maskStep, (uint)x + maskoffset - vector_off);\n"
"	\n"
"	if ((x < cols + dstoffset_in_pixel) & (y < rows))\n"
"	{\n"
"		uchar4 src_data  = vload4(0, srcMat + srcidx);\n"
"		uchar4 mask_data = vload4(0, maskMat + maskidx);\n"
"		uchar4 dst_data  = *((__global uchar4 *)(dstMat + dstidx));\n"
"		uchar4 tmp_data;\n"
"		\n"
"		mask_data.x = ((maskidx + 0 >= mask_addr_start) && (maskidx + 0 < mask_addr_end)) ? mask_data.x : 0;\n"
"		mask_data.y = ((maskidx + 1 >= mask_addr_start) && (maskidx + 1 < mask_addr_end)) ? mask_data.y : 0;\n"
"		mask_data.z = ((maskidx + 2 >= mask_addr_start) && (maskidx + 2 < mask_addr_end)) ? mask_data.z : 0;\n"
"		mask_data.w = ((maskidx + 3 >= mask_addr_start) && (maskidx + 3 < mask_addr_end)) ? mask_data.w : 0;\n"
"		\n"
"		tmp_data.x = ((dstidx + 0 >= dst_addr_start) && (dstidx + 0 < dst_addr_end) && (mask_data.x))\n"
"		             ? src_data.x : dst_data.x;\n"
"		tmp_data.y = ((dstidx + 1 >= dst_addr_start) && (dstidx + 1 < dst_addr_end) && (mask_data.y))\n"
"		             ? src_data.y : dst_data.y;\n"
"		tmp_data.z = ((dstidx + 2 >= dst_addr_start) && (dstidx + 2 < dst_addr_end) && (mask_data.z))\n"
"		             ? src_data.z : dst_data.z;\n"
"		tmp_data.w = ((dstidx + 3 >= dst_addr_start) && (dstidx + 3 < dst_addr_end) && (mask_data.w))\n"
"		             ? src_data.w : dst_data.w;\n"
"		             \n"
"		(*(__global uchar4 *)(dstMat + dstidx)) = tmp_data;\n"
"	}\n"
"}\n"
"__kernel void copy_to_with_mask_C4_D0(\n"
"    __global const uchar4 *restrict srcMat,\n"
"    __global uchar4 *dstMat,\n"
"    __global const uchar *restrict maskMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = srcMat[srcidx];\n"
"	}\n"
"}\n"
"__kernel void copy_to_with_mask_C1_D4(\n"
"    __global const int *restrict srcMat,\n"
"    __global int *dstMat,\n"
"    __global const uchar *restrict maskMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = srcMat[srcidx];\n"
"	}\n"
"}\n"
"__kernel void copy_to_with_mask_C4_D4(\n"
"    __global const int4 *restrict srcMat,\n"
"    __global int4 *dstMat,\n"
"    __global const uchar *restrict maskMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = srcMat[srcidx];\n"
"	}\n"
"}\n"
"__kernel void copy_to_with_mask_C1_D5(\n"
"    __global const float *restrict srcMat,\n"
"    __global float *dstMat,\n"
"    __global const uchar *restrict maskMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = srcMat[srcidx];\n"
"	}\n"
"}\n"
"__kernel void copy_to_with_mask_C4_D5(\n"
"    __global const float4 *restrict srcMat,\n"
"    __global float4 *dstMat,\n"
"    __global const uchar *restrict maskMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int srcStep_in_pixel,\n"
"    int srcoffset_in_pixel,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int srcidx = mad24(y, srcStep_in_pixel, x + srcoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = srcMat[srcidx];\n"
"	}\n"
"}\n"
;
const char *operator_setTo =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"/*\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"*/\n"
"__kernel void set_to_without_mask_C1_D0(float4 scalar, __global uchar *dstMat,\n"
"                                        int cols, int rows, int dstStep_in_pixel, int offset_in_pixel)\n"
"{\n"
"	int x = get_global_id(0) << 2;\n"
"	int y = get_global_id(1);\n"
"	int addr_start = mad24(y, dstStep_in_pixel, offset_in_pixel);\n"
"	int addr_end = mad24(y, dstStep_in_pixel, cols + offset_in_pixel);\n"
"	int idx = mad24(y, dstStep_in_pixel, (int)(x + offset_in_pixel & (int)0xfffffffc));\n"
"	uchar4 out;\n"
"	out.x = out.y = out.z = out.w = convert_uchar_sat(scalar.x);\n"
"	\n"
"	if ((idx >= addr_start) & (idx + 3 < addr_end) & (y < rows))\n"
"	{\n"
"		*(__global uchar4 *)(dstMat + idx) = out;\n"
"	}\n"
"	else if (y < rows)\n"
"	{\n"
"		uchar4 temp = *(__global uchar4 *)(dstMat + idx);\n"
"		temp.x = (idx >= addr_start) & (idx < addr_end) ? out.x : temp.x;\n"
"		temp.y = (idx + 1 >= addr_start) & (idx + 1 < addr_end) ? out.y : temp.y;\n"
"		temp.z = (idx + 2 >= addr_start) & (idx + 2 < addr_end) ? out.z : temp.z;\n"
"		temp.w = (idx + 3 >= addr_start) & (idx + 3 < addr_end) ? out.w : temp.w;\n"
"		*(__global uchar4 *)(dstMat + idx) = temp;\n"
"	}\n"
"}\n"
"__kernel void set_to_without_mask_C4_D0(float4 scalar, __global uchar4 *dstMat,\n"
"                                        int cols, int rows, int dstStep_in_pixel, int offset_in_pixel)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		int idx = mad24(y, dstStep_in_pixel, x + offset_in_pixel);\n"
"		dstMat[idx] = convert_uchar4_sat(scalar);\n"
"	}\n"
"}\n"
"__kernel void set_to_without_mask_C1_D4(float4 scalar, __global int *dstMat,\n"
"                                        int cols, int rows, int dstStep_in_pixel, int offset_in_pixel)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		int idx = mad24(y, dstStep_in_pixel, x + offset_in_pixel);\n"
"		dstMat[idx] = convert_int_sat(scalar.x);\n"
"	}\n"
"}\n"
"__kernel void set_to_without_mask_C4_D4(float4 scalar, __global int4 *dstMat,\n"
"                                        int cols, int rows, int dstStep_in_pixel, int offset_in_pixel)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		int idx = mad24(y, dstStep_in_pixel, x + offset_in_pixel);\n"
"		dstMat[idx] = convert_int4_sat(scalar);\n"
"	}\n"
"}\n"
"__kernel void set_to_without_mask_C1_D5(float4 scalar, __global float *dstMat,\n"
"                                        int cols, int rows, int dstStep_in_pixel, int offset_in_pixel)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		int idx = mad24(y, dstStep_in_pixel, x + offset_in_pixel);\n"
"		dstMat[idx] = scalar.x;\n"
"	}\n"
"}\n"
"__kernel void set_to_without_mask_C4_D5(float4 scalar, __global float4 *dstMat,\n"
"                                        int cols, int rows, int dstStep_in_pixel, int offset_in_pixel)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		int idx = mad24(y, dstStep_in_pixel, x + offset_in_pixel);\n"
"		dstMat[idx] = scalar;\n"
"	}\n"
"}\n"
;
const char *operator_setToM =
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Niko Li, Niko.li@amd.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//\n"
"/*#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"*/\n"
"/*\n"
"__kernel void set_to_with_mask_C1_D0(\n"
"		float4 scalar,\n"
"		__global uchar* dstMat,\n"
"		int cols,\n"
"		int rows,\n"
"		int dstStep_in_pixel,\n"
"		int dstoffset_in_pixel,\n"
"        __global const uchar * maskMat,\n"
"		int maskStep,\n"
"		int maskoffset)\n"
"{\n"
"		int x=get_global_id(0);\n"
"		int y=get_global_id(1);\n"
"		int dstidx = mad24(y,dstStep_in_pixel,x+ dstoffset_in_pixel);\n"
"		int maskidx = mad24(y,maskStep,x+ maskoffset);\n"
"		uchar mask = maskMat[maskidx];\n"
"		if ( (x < cols) & (y < rows) & mask)\n"
"		{\n"
"			dstMat[dstidx] = convert_uchar_sat(scalar.x);\n"
"		}\n"
"}\n"
"*/\n"
"//#pragma OPENCL EXTENSION cl_amd_printf : enable\n"
"__kernel void set_to_with_mask_C1_D0(\n"
"    float4 scalar,\n"
"    __global uchar *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    __global const uchar *restrict maskMat,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0) << 2;\n"
"	int y = get_global_id(1);\n"
"	int dst_addr_start = mad24(y, dstStep_in_pixel, dstoffset_in_pixel);\n"
"	int dst_addr_end = mad24(y, dstStep_in_pixel, cols + dstoffset_in_pixel);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel & (int)0xfffffffc);\n"
"	int mask_addr_start = mad24(y, maskStep, maskoffset);\n"
"	int mask_addr_end = mad24(y, maskStep, cols + maskoffset);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset & (int)0xfffffffc);\n"
"	uchar out = convert_uchar_sat(scalar.x);\n"
"	int off_mask = (maskoffset & 3) - (dstoffset_in_pixel & 3) + 3;\n"
"	\n"
"	if ((x < cols) & (y < rows))\n"
"	{\n"
"		uchar4 temp_dst = *(__global uchar4 *)(dstMat + dstidx);\n"
"		uchar4 temp_mask1 = *(__global uchar4 *)(maskMat + maskidx - 4);\n"
"		uchar4 temp_mask = *(__global uchar4 *)(maskMat + maskidx);\n"
"		uchar4 temp_mask2 = *(__global uchar4 *)(maskMat + maskidx + 4);\n"
"		temp_mask1.x = (maskidx - 4 >= mask_addr_start) & (maskidx - 4 < mask_addr_end) ? temp_mask1.x : 0;\n"
"		temp_mask1.y = (maskidx - 3 >= mask_addr_start) & (maskidx - 3 < mask_addr_end) ? temp_mask1.y : 0;\n"
"		temp_mask1.z = (maskidx - 2 >= mask_addr_start) & (maskidx - 2 < mask_addr_end) ? temp_mask1.z : 0;\n"
"		temp_mask1.w = (maskidx - 1 >= mask_addr_start) & (maskidx - 1 < mask_addr_end) ? temp_mask1.w : 0;\n"
"		temp_mask.x = (maskidx >= mask_addr_start) & (maskidx < mask_addr_end) ? temp_mask.x : 0;\n"
"		temp_mask.y = (maskidx + 1 >= mask_addr_start) & (maskidx + 1 < mask_addr_end) ? temp_mask.y : 0;\n"
"		temp_mask.z = (maskidx + 2 >= mask_addr_start) & (maskidx + 2 < mask_addr_end) ? temp_mask.z : 0;\n"
"		temp_mask.w = (maskidx + 3 >= mask_addr_start) & (maskidx + 3 < mask_addr_end) ? temp_mask.w : 0;\n"
"		temp_mask2.x = (maskidx + 4 >= mask_addr_start) & (maskidx + 4 < mask_addr_end) ? temp_mask2.x : 0;\n"
"		temp_mask2.y = (maskidx + 5 >= mask_addr_start) & (maskidx + 5 < mask_addr_end) ? temp_mask2.y : 0;\n"
"		temp_mask2.z = (maskidx + 6 >= mask_addr_start) & (maskidx + 6 < mask_addr_end) ? temp_mask2.z : 0;\n"
"		temp_mask2.w = (maskidx + 7 >= mask_addr_start) & (maskidx + 7 < mask_addr_end) ? temp_mask2.w : 0;\n"
"		uchar trans_mask[10] = {temp_mask1.y, temp_mask1.z, temp_mask1.w, temp_mask.x, temp_mask.y, temp_mask.z, temp_mask.w, temp_mask2.x, temp_mask2.y, temp_mask2.z};\n"
"		temp_dst.x = (dstidx >= dst_addr_start) & (dstidx < dst_addr_end)& trans_mask[off_mask] ? out : temp_dst.x;\n"
"		temp_dst.y = (dstidx + 1 >= dst_addr_start) & (dstidx + 1 < dst_addr_end)& trans_mask[off_mask + 1] ? out : temp_dst.y;\n"
"		temp_dst.z = (dstidx + 2 >= dst_addr_start) & (dstidx + 2 < dst_addr_end)& trans_mask[off_mask + 2] ? out : temp_dst.z;\n"
"		temp_dst.w = (dstidx + 3 >= dst_addr_start) & (dstidx + 3 < dst_addr_end)& trans_mask[off_mask + 3] ? out : temp_dst.w;\n"
"		*(__global uchar4 *)(dstMat + dstidx) = temp_dst;\n"
"	}\n"
"}\n"
"__kernel void set_to_with_mask_C4_D0(\n"
"    float4 scalar,\n"
"    __global uchar4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    __global const uchar *restrict maskMat,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = convert_uchar4_sat(scalar);\n"
"	}\n"
"	\n"
"}\n"
"__kernel void set_to_with_mask_C1_D4(\n"
"    float4 scalar,\n"
"    __global int *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    __global const uchar *restrict maskMat,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = convert_int_sat(scalar.x);\n"
"	}\n"
"	\n"
"}\n"
"__kernel void set_to_with_mask_C4_D4(\n"
"    float4 scalar,\n"
"    __global int4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    __global const uchar *restrict maskMat,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = convert_int4_sat(scalar);\n"
"	}\n"
"	\n"
"}\n"
"__kernel void set_to_with_mask_C1_D5(\n"
"    float4 scalar,\n"
"    __global float *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    __global const uchar *restrict maskMat,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = scalar.x;\n"
"	}\n"
"	\n"
"}\n"
"__kernel void set_to_with_mask_C4_D5(\n"
"    float4 scalar,\n"
"    __global float4 *dstMat,\n"
"    int cols,\n"
"    int rows,\n"
"    int dstStep_in_pixel,\n"
"    int dstoffset_in_pixel,\n"
"    __global const uchar *restrict maskMat,\n"
"    int maskStep,\n"
"    int maskoffset)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	int dstidx = mad24(y, dstStep_in_pixel, x + dstoffset_in_pixel);\n"
"	int maskidx = mad24(y, maskStep, x + maskoffset);\n"
"	uchar mask = maskMat[maskidx];\n"
"	\n"
"	if ((x < cols) & (y < rows) & mask)\n"
"	{\n"
"		dstMat[dstidx] = scalar;\n"
"	}\n"
"	\n"
"}\n"
;
const char *split_mat =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"///////////////////////////////////////////////////////////////////////////////////////////////\n"
"//////////////////////////////////optimized code using vector ////////////////////////////////\n"
"////////////vector fuction name format: split_vector_C(channels number)_D(data type depth)//////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void split_vector_C4_D0(__global uchar *mat_src,  int src_step,  int src_offset,\n"
"                                 __global uchar *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global uchar *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global uchar *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global uchar *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"		int src_idx  = mad24(y, src_step, src_offset + (x << 2));\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + x) & (int)0xfffffffc;\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + x) & (int)0xfffffffc;\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + x) & (int)0xfffffffc;\n"
"		\n"
"		int dst3_start = mad24(y, dst3_step, dst3_offset);\n"
"		int dst3_end   = mad24(y, dst3_step, dst3_offset + dst_step1);\n"
"		int dst3_idx   = mad24(y, dst3_step, dst3_offset + x) & (int)0xfffffffc;\n"
"		\n"
"		uchar4 data_0 = *((global uchar4 *)(mat_src + src_idx - 12));\n"
"		uchar4 data_1 = *((global uchar4 *)(mat_src + src_idx - 8));\n"
"		uchar4 data_2 = *((global uchar4 *)(mat_src + src_idx - 4));\n"
"		uchar4 data_3 = *((global uchar4 *)(mat_src + src_idx + 0));\n"
"		uchar4 data_4 = *((global uchar4 *)(mat_src + src_idx + 4));\n"
"		uchar4 data_5 = *((global uchar4 *)(mat_src + src_idx + 8));\n"
"		uchar4 data_6 = *((global uchar4 *)(mat_src + src_idx + 12));\n"
"		\n"
"		uchar4 tmp_data0 = 1, tmp_data1 = 2, tmp_data2, tmp_data3;\n"
"		\n"
"		if ((dst0_offset & 3) == 3)\n"
"		{\n"
"			tmp_data0 = (uchar4)(data_0.x, data_1.x, data_2.x, data_3.x);\n"
"		}\n"
"		\n"
"		if ((dst0_offset & 3) == 2)\n"
"		{\n"
"			tmp_data0 = (uchar4)(data_1.x, data_2.x, data_3.x, data_4.x);\n"
"		}\n"
"		\n"
"		if ((dst0_offset & 3) == 1)\n"
"		{\n"
"			tmp_data0 = (uchar4)(data_2.x, data_3.x, data_4.x, data_5.x);\n"
"		}\n"
"		\n"
"		if ((dst0_offset & 3) == 0)\n"
"		{\n"
"			tmp_data0 = (uchar4)(data_3.x, data_4.x, data_5.x, data_6.x);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 3)\n"
"		{\n"
"			tmp_data1 = (uchar4)(data_0.y, data_1.y, data_2.y, data_3.y);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 2)\n"
"		{\n"
"			tmp_data1 = (uchar4)(data_1.y, data_2.y, data_3.y, data_4.y);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 1)\n"
"		{\n"
"			tmp_data1 = (uchar4)(data_2.y, data_3.y, data_4.y, data_5.y);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 0)\n"
"		{\n"
"			tmp_data1 = (uchar4)(data_3.y, data_4.y, data_5.y, data_6.y);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 3)\n"
"		{\n"
"			tmp_data2 = (uchar4)(data_0.z, data_1.z, data_2.z, data_3.z);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 2)\n"
"		{\n"
"			tmp_data2 = (uchar4)(data_1.z, data_2.z, data_3.z, data_4.z);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 1)\n"
"		{\n"
"			tmp_data2 = (uchar4)(data_2.z, data_3.z, data_4.z, data_5.z);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 0)\n"
"		{\n"
"			tmp_data2 = (uchar4)(data_3.z, data_4.z, data_5.z, data_6.z);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 3)\n"
"		{\n"
"			tmp_data3 = (uchar4)(data_0.w, data_1.w, data_2.w, data_3.w);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 2)\n"
"		{\n"
"			tmp_data3 = (uchar4)(data_1.w, data_2.w, data_3.w, data_4.w);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 1)\n"
"		{\n"
"			tmp_data3 = (uchar4)(data_2.w, data_3.w, data_4.w, data_5.w);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 0)\n"
"		{\n"
"			tmp_data3 = (uchar4)(data_3.w, data_4.w, data_5.w, data_6.w);\n"
"		}\n"
"		\n"
"		uchar4 dst0_data  = *((__global uchar4 *)(mat_dst0 + dst0_idx));\n"
"		uchar4 dst1_data  = *((__global uchar4 *)(mat_dst1 + dst1_idx));\n"
"		uchar4 dst2_data  = *((__global uchar4 *)(mat_dst2 + dst2_idx));\n"
"		uchar4 dst3_data  = *((__global uchar4 *)(mat_dst3 + dst3_idx));\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 1 >= dst0_start) && (dst0_idx + 1 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		tmp_data0.z = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.z : dst0_data.z;\n"
"		tmp_data0.w = ((dst0_idx + 3 >= dst0_start) && (dst0_idx + 3 < dst0_end)) ? tmp_data0.w : dst0_data.w;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 1 >= dst1_start) && (dst1_idx + 1 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		tmp_data1.z = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.z : dst1_data.z;\n"
"		tmp_data1.w = ((dst1_idx + 3 >= dst1_start) && (dst1_idx + 3 < dst1_end)) ? tmp_data1.w : dst1_data.w;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 1 >= dst2_start) && (dst2_idx + 1 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		tmp_data2.z = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.z : dst2_data.z;\n"
"		tmp_data2.w = ((dst2_idx + 3 >= dst2_start) && (dst2_idx + 3 < dst2_end)) ? tmp_data2.w : dst2_data.w;\n"
"		\n"
"		tmp_data3.x = ((dst3_idx + 0 >= dst3_start) && (dst3_idx + 0 < dst3_end)) ? tmp_data3.x : dst3_data.x;\n"
"		tmp_data3.y = ((dst3_idx + 1 >= dst3_start) && (dst3_idx + 1 < dst3_end)) ? tmp_data3.y : dst3_data.y;\n"
"		tmp_data3.z = ((dst3_idx + 2 >= dst3_start) && (dst3_idx + 2 < dst3_end)) ? tmp_data3.z : dst3_data.z;\n"
"		tmp_data3.w = ((dst3_idx + 3 >= dst3_start) && (dst3_idx + 3 < dst3_end)) ? tmp_data3.w : dst3_data.w;\n"
"		\n"
"		*((__global uchar4 *)(mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global uchar4 *)(mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((__global uchar4 *)(mat_dst2 + dst2_idx)) = tmp_data2;\n"
"		*((__global uchar4 *)(mat_dst3 + dst3_idx)) = tmp_data3;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D0(__global uchar *mat_src,  int src_step,  int src_offset,\n"
"                                 __global uchar *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global uchar *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global uchar *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"		int src_idx  = mad24(y, src_step, src_offset);\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + x  & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar4 dst0_data  = *((__global uchar4 *)(mat_dst0 + dst0_idx));\n"
"		uchar4 dst1_data  = *((__global uchar4 *)(mat_dst1 + dst1_idx));\n"
"		uchar4 dst2_data  = *((__global uchar4 *)(mat_dst2 + dst2_idx));\n"
"		\n"
"		uchar4 tmp_data0, tmp_data1, tmp_data2;\n"
"		\n"
"		uchar src_data_0  =  *(mat_src + src_idx + 3 * x - 9);\n"
"		uchar src_data_1  =  *(mat_src + src_idx + 3 * x - 8);\n"
"		uchar src_data_2  =  *(mat_src + src_idx + 3 * x - 7);\n"
"		\n"
"		uchar src_data_3  =  *(mat_src + src_idx + 3 * x - 6);\n"
"		uchar src_data_4  =  *(mat_src + src_idx + 3 * x - 5);\n"
"		uchar src_data_5  =  *(mat_src + src_idx + 3 * x - 4);\n"
"		\n"
"		uchar src_data_6  =  *(mat_src + src_idx + 3 * x - 3);\n"
"		uchar src_data_7  =  *(mat_src + src_idx + 3 * x - 2);\n"
"		uchar src_data_8  =  *(mat_src + src_idx + 3 * x - 1);\n"
"		\n"
"		uchar src_data_9  =  *(mat_src + src_idx + 3 * x + 0);\n"
"		uchar src_data_10 =  *(mat_src + src_idx + 3 * x + 1);\n"
"		uchar src_data_11 =  *(mat_src + src_idx + 3 * x + 2);\n"
"		\n"
"		uchar src_data_12 =  *(mat_src + src_idx + 3 * x + 3);\n"
"		uchar src_data_13 =  *(mat_src + src_idx + 3 * x + 4);\n"
"		uchar src_data_14 =  *(mat_src + src_idx + 3 * x + 5);\n"
"		\n"
"		uchar src_data_15 =  *(mat_src + src_idx + 3 * x + 6);\n"
"		uchar src_data_16 =  *(mat_src + src_idx + 3 * x + 7);\n"
"		uchar src_data_17 =  *(mat_src + src_idx + 3 * x + 8);\n"
"		\n"
"		uchar src_data_18 =  *(mat_src + src_idx + 3 * x + 9);\n"
"		uchar src_data_19 =  *(mat_src + src_idx + 3 * x + 10);\n"
"		uchar src_data_20 =  *(mat_src + src_idx + 3 * x + 11);\n"
"		\n"
"		uchar data[7] = {src_data_0, src_data_3, src_data_6, src_data_9, src_data_12, src_data_15, src_data_18};\n"
"		int index = 3 - dst0_offset & 3;\n"
"		tmp_data0 = (uchar4)(data[index], data[index + 1], data[index + 2], data[index + 3]);\n"
"		\n"
"		uchar4 data0, data1, data2;\n"
"		\n"
"		data0     = (uchar4)(src_data_1, src_data_4, src_data_7, src_data_10);\n"
"		data1     = (dst1_offset & 3) == 2 ? (uchar4)(src_data_4, src_data_7, src_data_10, src_data_13)  : data0;\n"
"		data2     = (dst1_offset & 3) == 1 ? (uchar4)(src_data_7, src_data_10, src_data_13, src_data_16) : data1;\n"
"		tmp_data1 = (dst1_offset & 3) == 0 ? (uchar4)(src_data_10, src_data_13, src_data_16, src_data_19) : data2;\n"
"		\n"
"		data0     = (uchar4)(src_data_2, src_data_5, src_data_8, src_data_11);\n"
"		data1     = (dst2_offset & 3) == 2 ? (uchar4)(src_data_5, src_data_8, src_data_11, src_data_14)   : data0;\n"
"		data2     = (dst2_offset & 3) == 1 ? (uchar4)(src_data_8, src_data_11, src_data_14, src_data_17)  : data1;\n"
"		tmp_data2 = (dst2_offset & 3) == 0 ? (uchar4)(src_data_11, src_data_14, src_data_17, src_data_20) : data2;\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 1 >= dst0_start) && (dst0_idx + 1 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		tmp_data0.z = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.z : dst0_data.z;\n"
"		tmp_data0.w = ((dst0_idx + 3 >= dst0_start) && (dst0_idx + 3 < dst0_end)) ? tmp_data0.w : dst0_data.w;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 1 >= dst1_start) && (dst1_idx + 1 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		tmp_data1.z = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.z : dst1_data.z;\n"
"		tmp_data1.w = ((dst1_idx + 3 >= dst1_start) && (dst1_idx + 3 < dst1_end)) ? tmp_data1.w : dst1_data.w;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 1 >= dst2_start) && (dst2_idx + 1 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		tmp_data2.z = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.z : dst2_data.z;\n"
"		tmp_data2.w = ((dst2_idx + 3 >= dst2_start) && (dst2_idx + 3 < dst2_end)) ? tmp_data2.w : dst2_data.w;\n"
"		\n"
"		*((__global uchar4 *)(mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global uchar4 *)(mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((__global uchar4 *)(mat_dst2 + dst2_idx)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D0(__global uchar *mat_src,  int src_step,  int src_offset,\n"
"                                 __global uchar *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global uchar *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst0_align ((dst0_offset & 3) << 1)\n"
"#define dst1_align ((dst1_offset & 3) << 1)\n"
"		int src_idx_0  = mad24(y, src_step, src_offset - dst0_align + (x << 1));\n"
"		int src_idx_1  = mad24(y, src_step, src_offset - dst1_align + (x << 1));\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + x & (int)0xfffffffc);\n"
"		\n"
"		uchar8 src_data_0 = vload8(0, mat_src + src_idx_0);\n"
"		uchar8 src_data_1 = vload8(0, mat_src + src_idx_1);\n"
"		\n"
"		uchar4 dst0_data  = *((__global uchar4 *)(mat_dst0 + dst0_idx));\n"
"		uchar4 dst1_data  = *((__global uchar4 *)(mat_dst1 + dst1_idx));\n"
"		\n"
"		uchar4 tmp_data0, tmp_data1;\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? src_data_0.s0 : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 1 >= dst0_start) && (dst0_idx + 1 < dst0_end)) ? src_data_0.s2 : dst0_data.y;\n"
"		tmp_data0.z = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? src_data_0.s4 : dst0_data.z;\n"
"		tmp_data0.w = ((dst0_idx + 3 >= dst0_start) && (dst0_idx + 3 < dst0_end)) ? src_data_0.s6 : dst0_data.w;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? src_data_1.s1 : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 1 >= dst1_start) && (dst1_idx + 1 < dst1_end)) ? src_data_1.s3 : dst1_data.y;\n"
"		tmp_data1.z = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? src_data_1.s5 : dst1_data.z;\n"
"		tmp_data1.w = ((dst1_idx + 3 >= dst1_start) && (dst1_idx + 3 < dst1_end)) ? src_data_1.s7 : dst1_data.w;\n"
"		\n"
"		*((__global uchar4 *)(mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global uchar4 *)(mat_dst1 + dst1_idx)) = tmp_data1;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C4_D1(__global char *mat_src,  int src_step,  int src_offset,\n"
"                                 __global char *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global char *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global char *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global char *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"		int src_idx  = mad24(y, src_step, src_offset + (x << 2));\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst3_start = mad24(y, dst3_step, dst3_offset);\n"
"		int dst3_end   = mad24(y, dst3_step, dst3_offset + dst_step1);\n"
"		int dst3_idx   = mad24(y, dst3_step, dst3_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 data_0 = *((global char4 *)(mat_src + src_idx - 12));\n"
"		char4 data_1 = *((global char4 *)(mat_src + src_idx - 8));\n"
"		char4 data_2 = *((global char4 *)(mat_src + src_idx - 4));\n"
"		char4 data_3 = *((global char4 *)(mat_src + src_idx + 0));\n"
"		char4 data_4 = *((global char4 *)(mat_src + src_idx + 4));\n"
"		char4 data_5 = *((global char4 *)(mat_src + src_idx + 8));\n"
"		char4 data_6 = *((global char4 *)(mat_src + src_idx + 12));\n"
"		\n"
"		char4 tmp_data0 = 1, tmp_data1 = 2, tmp_data2, tmp_data3;\n"
"		\n"
"		if ((dst0_offset & 3) == 3)\n"
"		{\n"
"			tmp_data0 = (char4)(data_0.x, data_1.x, data_2.x, data_3.x);\n"
"		}\n"
"		\n"
"		if ((dst0_offset & 3) == 2)\n"
"		{\n"
"			tmp_data0 = (char4)(data_1.x, data_2.x, data_3.x, data_4.x);\n"
"		}\n"
"		\n"
"		if ((dst0_offset & 3) == 1)\n"
"		{\n"
"			tmp_data0 = (char4)(data_2.x, data_3.x, data_4.x, data_5.x);\n"
"		}\n"
"		\n"
"		if ((dst0_offset & 3) == 0)\n"
"		{\n"
"			tmp_data0 = (char4)(data_3.x, data_4.x, data_5.x, data_6.x);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 3)\n"
"		{\n"
"			tmp_data1 = (char4)(data_0.y, data_1.y, data_2.y, data_3.y);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 2)\n"
"		{\n"
"			tmp_data1 = (char4)(data_1.y, data_2.y, data_3.y, data_4.y);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 1)\n"
"		{\n"
"			tmp_data1 = (char4)(data_2.y, data_3.y, data_4.y, data_5.y);\n"
"		}\n"
"		\n"
"		if ((dst1_offset & 3) == 0)\n"
"		{\n"
"			tmp_data1 = (char4)(data_3.y, data_4.y, data_5.y, data_6.y);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 3)\n"
"		{\n"
"			tmp_data2 = (char4)(data_0.z, data_1.z, data_2.z, data_3.z);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 2)\n"
"		{\n"
"			tmp_data2 = (char4)(data_1.z, data_2.z, data_3.z, data_4.z);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 1)\n"
"		{\n"
"			tmp_data2 = (char4)(data_2.z, data_3.z, data_4.z, data_5.z);\n"
"		}\n"
"		\n"
"		if ((dst2_offset & 3) == 0)\n"
"		{\n"
"			tmp_data2 = (char4)(data_3.z, data_4.z, data_5.z, data_6.z);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 3)\n"
"		{\n"
"			tmp_data3 = (char4)(data_0.w, data_1.w, data_2.w, data_3.w);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 2)\n"
"		{\n"
"			tmp_data3 = (char4)(data_1.w, data_2.w, data_3.w, data_4.w);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 1)\n"
"		{\n"
"			tmp_data3 = (char4)(data_2.w, data_3.w, data_4.w, data_5.w);\n"
"		}\n"
"		\n"
"		if ((dst3_offset & 3) == 0)\n"
"		{\n"
"			tmp_data3 = (char4)(data_3.w, data_4.w, data_5.w, data_6.w);\n"
"		}\n"
"		\n"
"		char4 dst0_data  = *((__global char4 *)(mat_dst0 + dst0_idx));\n"
"		char4 dst1_data  = *((__global char4 *)(mat_dst1 + dst1_idx));\n"
"		char4 dst2_data  = *((__global char4 *)(mat_dst2 + dst2_idx));\n"
"		char4 dst3_data  = *((__global char4 *)(mat_dst3 + dst3_idx));\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 1 >= dst0_start) && (dst0_idx + 1 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		tmp_data0.z = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.z : dst0_data.z;\n"
"		tmp_data0.w = ((dst0_idx + 3 >= dst0_start) && (dst0_idx + 3 < dst0_end)) ? tmp_data0.w : dst0_data.w;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 1 >= dst1_start) && (dst1_idx + 1 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		tmp_data1.z = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.z : dst1_data.z;\n"
"		tmp_data1.w = ((dst1_idx + 3 >= dst1_start) && (dst1_idx + 3 < dst1_end)) ? tmp_data1.w : dst1_data.w;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 1 >= dst2_start) && (dst2_idx + 1 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		tmp_data2.z = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.z : dst2_data.z;\n"
"		tmp_data2.w = ((dst2_idx + 3 >= dst2_start) && (dst2_idx + 3 < dst2_end)) ? tmp_data2.w : dst2_data.w;\n"
"		\n"
"		tmp_data3.x = ((dst3_idx + 0 >= dst3_start) && (dst3_idx + 0 < dst3_end)) ? tmp_data3.x : dst3_data.x;\n"
"		tmp_data3.y = ((dst3_idx + 1 >= dst3_start) && (dst3_idx + 1 < dst3_end)) ? tmp_data3.y : dst3_data.y;\n"
"		tmp_data3.z = ((dst3_idx + 2 >= dst3_start) && (dst3_idx + 2 < dst3_end)) ? tmp_data3.z : dst3_data.z;\n"
"		tmp_data3.w = ((dst3_idx + 3 >= dst3_start) && (dst3_idx + 3 < dst3_end)) ? tmp_data3.w : dst3_data.w;\n"
"		\n"
"		*((__global char4 *)(mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global char4 *)(mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((__global char4 *)(mat_dst2 + dst2_idx)) = tmp_data2;\n"
"		*((__global char4 *)(mat_dst3 + dst3_idx)) = tmp_data3;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D1(__global char *mat_src,  int src_step,  int src_offset,\n"
"                                 __global char *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global char *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global char *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"		int src_idx  = mad24(y, src_step, src_offset);\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + x  & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char4 dst0_data  = *((__global char4 *)(mat_dst0 + dst0_idx));\n"
"		char4 dst1_data  = *((__global char4 *)(mat_dst1 + dst1_idx));\n"
"		char4 dst2_data  = *((__global char4 *)(mat_dst2 + dst2_idx));\n"
"		\n"
"		char4 tmp_data0, tmp_data1, tmp_data2;\n"
"		\n"
"		char src_data_0  =  *(mat_src + src_idx + 3 * x - 9);\n"
"		char src_data_1  =  *(mat_src + src_idx + 3 * x - 8);\n"
"		char src_data_2  =  *(mat_src + src_idx + 3 * x - 7);\n"
"		\n"
"		char src_data_3  =  *(mat_src + src_idx + 3 * x - 6);\n"
"		char src_data_4  =  *(mat_src + src_idx + 3 * x - 5);\n"
"		char src_data_5  =  *(mat_src + src_idx + 3 * x - 4);\n"
"		\n"
"		char src_data_6  =  *(mat_src + src_idx + 3 * x - 3);\n"
"		char src_data_7  =  *(mat_src + src_idx + 3 * x - 2);\n"
"		char src_data_8  =  *(mat_src + src_idx + 3 * x - 1);\n"
"		\n"
"		char src_data_9  =  *(mat_src + src_idx + 3 * x + 0);\n"
"		char src_data_10 =  *(mat_src + src_idx + 3 * x + 1);\n"
"		char src_data_11 =  *(mat_src + src_idx + 3 * x + 2);\n"
"		\n"
"		char src_data_12 =  *(mat_src + src_idx + 3 * x + 3);\n"
"		char src_data_13 =  *(mat_src + src_idx + 3 * x + 4);\n"
"		char src_data_14 =  *(mat_src + src_idx + 3 * x + 5);\n"
"		\n"
"		char src_data_15 =  *(mat_src + src_idx + 3 * x + 6);\n"
"		char src_data_16 =  *(mat_src + src_idx + 3 * x + 7);\n"
"		char src_data_17 =  *(mat_src + src_idx + 3 * x + 8);\n"
"		\n"
"		char src_data_18 =  *(mat_src + src_idx + 3 * x + 9);\n"
"		char src_data_19 =  *(mat_src + src_idx + 3 * x + 10);\n"
"		char src_data_20 =  *(mat_src + src_idx + 3 * x + 11);\n"
"		\n"
"		char data[7] = {src_data_0, src_data_3, src_data_6, src_data_9, src_data_12, src_data_15, src_data_18};\n"
"		int index = 3 - dst0_offset & 3;\n"
"		tmp_data0 = (char4)(data[index], data[index + 1], data[index + 2], data[index + 3]);\n"
"		\n"
"		char4 data0, data1, data2;\n"
"		\n"
"		data0     = (char4)(src_data_1, src_data_4, src_data_7, src_data_10);\n"
"		data1     = (dst1_offset & 3) == 2 ? (char4)(src_data_4, src_data_7, src_data_10, src_data_13)  : data0;\n"
"		data2     = (dst1_offset & 3) == 1 ? (char4)(src_data_7, src_data_10, src_data_13, src_data_16) : data1;\n"
"		tmp_data1 = (dst1_offset & 3) == 0 ? (char4)(src_data_10, src_data_13, src_data_16, src_data_19) : data2;\n"
"		\n"
"		data0     = (char4)(src_data_2, src_data_5, src_data_8, src_data_11);\n"
"		data1     = (dst2_offset & 3) == 2 ? (char4)(src_data_5, src_data_8, src_data_11, src_data_14)   : data0;\n"
"		data2     = (dst2_offset & 3) == 1 ? (char4)(src_data_8, src_data_11, src_data_14, src_data_17)  : data1;\n"
"		tmp_data2 = (dst2_offset & 3) == 0 ? (char4)(src_data_11, src_data_14, src_data_17, src_data_20) : data2;\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 1 >= dst0_start) && (dst0_idx + 1 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		tmp_data0.z = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.z : dst0_data.z;\n"
"		tmp_data0.w = ((dst0_idx + 3 >= dst0_start) && (dst0_idx + 3 < dst0_end)) ? tmp_data0.w : dst0_data.w;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 1 >= dst1_start) && (dst1_idx + 1 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		tmp_data1.z = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.z : dst1_data.z;\n"
"		tmp_data1.w = ((dst1_idx + 3 >= dst1_start) && (dst1_idx + 3 < dst1_end)) ? tmp_data1.w : dst1_data.w;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 1 >= dst2_start) && (dst2_idx + 1 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		tmp_data2.z = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.z : dst2_data.z;\n"
"		tmp_data2.w = ((dst2_idx + 3 >= dst2_start) && (dst2_idx + 3 < dst2_end)) ? tmp_data2.w : dst2_data.w;\n"
"		\n"
"		*((__global char4 *)(mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global char4 *)(mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((__global char4 *)(mat_dst2 + dst2_idx)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D1(__global char *mat_src,  int src_step,  int src_offset,\n"
"                                 __global char *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global char *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 2;\n"
"		\n"
"#define dst0_align ((dst0_offset & 3) << 1)\n"
"#define dst1_align ((dst1_offset & 3) << 1)\n"
"		int src_idx_0  = mad24(y, src_step, src_offset - dst0_align + (x << 1));\n"
"		int src_idx_1  = mad24(y, src_step, src_offset - dst1_align + (x << 1));\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + x & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + x & (int)0xfffffffc);\n"
"		\n"
"		char8 src_data_0 = vload8(0, mat_src + src_idx_0);\n"
"		char8 src_data_1 = vload8(0, mat_src + src_idx_1);\n"
"		\n"
"		char4 dst0_data  = *((__global char4 *)(mat_dst0 + dst0_idx));\n"
"		char4 dst1_data  = *((__global char4 *)(mat_dst1 + dst1_idx));\n"
"		\n"
"		char4 tmp_data0, tmp_data1;\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? src_data_0.s0 : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 1 >= dst0_start) && (dst0_idx + 1 < dst0_end)) ? src_data_0.s2 : dst0_data.y;\n"
"		tmp_data0.z = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? src_data_0.s4 : dst0_data.z;\n"
"		tmp_data0.w = ((dst0_idx + 3 >= dst0_start) && (dst0_idx + 3 < dst0_end)) ? src_data_0.s6 : dst0_data.w;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? src_data_1.s1 : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 1 >= dst1_start) && (dst1_idx + 1 < dst1_end)) ? src_data_1.s3 : dst1_data.y;\n"
"		tmp_data1.z = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? src_data_1.s5 : dst1_data.z;\n"
"		tmp_data1.w = ((dst1_idx + 3 >= dst1_start) && (dst1_idx + 3 < dst1_end)) ? src_data_1.s7 : dst1_data.w;\n"
"		\n"
"		*((__global char4 *)(mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global char4 *)(mat_dst1 + dst1_idx)) = tmp_data1;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C4_D2(__global ushort *mat_src,  int src_step,  int src_offset,\n"
"                                 __global ushort *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global ushort *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global ushort *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global ushort *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"		int src_idx_0  = mad24(y, src_step, src_offset + (x << 3) - 8);\n"
"		int src_idx_1  = mad24(y, src_step, src_offset + (x << 3) + 8);\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst3_start = mad24(y, dst3_step, dst3_offset);\n"
"		int dst3_end   = mad24(y, dst3_step, dst3_offset + dst_step1);\n"
"		int dst3_idx   = mad24(y, dst3_step, dst3_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort8 src_data0 = vload8(0, (__global ushort *)((__global char *)mat_src + src_idx_0));\n"
"		ushort4 src_data1 = *((__global ushort4 *)((__global char *)mat_src + src_idx_1));\n"
"		\n"
"		ushort2 dst0_data  = *((__global ushort2 *)((__global char *)mat_dst0 + dst0_idx));\n"
"		ushort2 dst1_data  = *((__global ushort2 *)((__global char *)mat_dst1 + dst1_idx));\n"
"		ushort2 dst2_data  = *((__global ushort2 *)((__global char *)mat_dst2 + dst2_idx));\n"
"		ushort2 dst3_data  = *((__global ushort2 *)((__global char *)mat_dst3 + dst3_idx));\n"
"		\n"
"		ushort2 tmp_data0, tmp_data1, tmp_data2, tmp_data3;\n"
"		\n"
"		tmp_data0 = (dst0_offset & 3) == 0 ? (ushort2)(src_data0.s4, src_data1.s0) : (ushort2)(src_data0.s0, src_data0.s4);\n"
"		tmp_data1 = (dst1_offset & 3) == 0 ? (ushort2)(src_data0.s5, src_data1.s1) : (ushort2)(src_data0.s1, src_data0.s5);\n"
"		tmp_data2 = (dst2_offset & 3) == 0 ? (ushort2)(src_data0.s6, src_data1.s2) : (ushort2)(src_data0.s2, src_data0.s6);\n"
"		tmp_data3 = (dst3_offset & 3) == 0 ? (ushort2)(src_data0.s7, src_data1.s3) : (ushort2)(src_data0.s3, src_data0.s7);\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		\n"
"		tmp_data3.x = ((dst3_idx + 0 >= dst3_start) && (dst3_idx + 0 < dst3_end)) ? tmp_data3.x : dst3_data.x;\n"
"		tmp_data3.y = ((dst3_idx + 2 >= dst3_start) && (dst3_idx + 2 < dst3_end)) ? tmp_data3.y : dst3_data.y;\n"
"		\n"
"		*((global ushort2 *)((__global char *)mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((global ushort2 *)((__global char *)mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((global ushort2 *)((__global char *)mat_dst2 + dst2_idx)) = tmp_data2;\n"
"		*((global ushort2 *)((__global char *)mat_dst3 + dst3_idx)) = tmp_data3;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D2(__global ushort *mat_src,  int src_step,  int src_offset,\n"
"                                 __global ushort *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global ushort *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global ushort *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"		int src_idx  = mad24(y, src_step, src_offset);\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort2 dst0_data  = *((__global ushort2 *)((__global char *)mat_dst0 + dst0_idx));\n"
"		ushort2 dst1_data  = *((__global ushort2 *)((__global char *)mat_dst1 + dst1_idx));\n"
"		ushort2 dst2_data  = *((__global ushort2 *)((__global char *)mat_dst2 + dst2_idx));\n"
"		\n"
"		ushort2 tmp_data0, tmp_data1, tmp_data2;\n"
"		\n"
"		ushort src_data_0 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x - 3];\n"
"		ushort src_data_1 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x - 2];\n"
"		ushort src_data_2 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x - 1];\n"
"		ushort src_data_3 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x + 0];\n"
"		ushort src_data_4 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x + 1];\n"
"		ushort src_data_5 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x + 2];\n"
"		ushort src_data_6 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x + 3];\n"
"		ushort src_data_7 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x + 4];\n"
"		ushort src_data_8 = ((__global ushort *)((__global char *)mat_src + src_idx))[3 * x + 5];\n"
"		\n"
"		tmp_data0 = (dst0_offset & 3) == 0 ? (ushort2)(src_data_3, src_data_6) : (ushort2)(src_data_0, src_data_3);\n"
"		tmp_data1 = (dst1_offset & 3) == 0 ? (ushort2)(src_data_4, src_data_7) : (ushort2)(src_data_1, src_data_4);\n"
"		tmp_data2 = (dst2_offset & 3) == 0 ? (ushort2)(src_data_5, src_data_8) : (ushort2)(src_data_2, src_data_5);\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		\n"
"		*((__global ushort2 *)((__global char *)mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global ushort2 *)((__global char *)mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((__global ushort2 *)((__global char *)mat_dst2 + dst2_idx)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D2(__global ushort *mat_src,  int src_step,  int src_offset,\n"
"                                 __global ushort *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global ushort *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst0_align ((dst0_offset & 3) << 1)\n"
"#define dst1_align ((dst1_offset & 3) << 1)\n"
"		int src_idx_0  = mad24(y, src_step, src_offset - dst0_align + (x << 2));\n"
"		int src_idx_1  = mad24(y, src_step, src_offset - dst1_align + (x << 2));\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		ushort4 src_data_0 = vload4(0, (__global ushort *)((__global char *)mat_src + src_idx_0));\n"
"		ushort4 src_data_1 = vload4(0, (__global ushort *)((__global char *)mat_src + src_idx_1));\n"
"		\n"
"		ushort2 dst0_data  = *((__global ushort2 *)((__global char *)mat_dst0 + dst0_idx));\n"
"		ushort2 dst1_data  = *((__global ushort2 *)((__global char *)mat_dst1 + dst1_idx));\n"
"		\n"
"		ushort2 tmp_data0, tmp_data1;\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? src_data_0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? src_data_0.z : dst0_data.y;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? src_data_1.y : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? src_data_1.w : dst1_data.y;\n"
"		\n"
"		*((global ushort2 *)((__global char *)mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((global ushort2 *)((__global char *)mat_dst1 + dst1_idx)) = tmp_data1;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C4_D3(__global short *mat_src,  int src_step,  int src_offset,\n"
"                                 __global short *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global short *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global short *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global short *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"		int src_idx_0  = mad24(y, src_step, src_offset + (x << 3) - 8);\n"
"		int src_idx_1  = mad24(y, src_step, src_offset + (x << 3) + 8);\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst3_start = mad24(y, dst3_step, dst3_offset);\n"
"		int dst3_end   = mad24(y, dst3_step, dst3_offset + dst_step1);\n"
"		int dst3_idx   = mad24(y, dst3_step, dst3_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short8 src_data0 = vload8(0, (__global short *)((__global char *)mat_src + src_idx_0));\n"
"		short4 src_data1 = *((__global short4 *)((__global char *)mat_src + src_idx_1));\n"
"		\n"
"		short2 dst0_data  = *((__global short2 *)((__global char *)mat_dst0 + dst0_idx));\n"
"		short2 dst1_data  = *((__global short2 *)((__global char *)mat_dst1 + dst1_idx));\n"
"		short2 dst2_data  = *((__global short2 *)((__global char *)mat_dst2 + dst2_idx));\n"
"		short2 dst3_data  = *((__global short2 *)((__global char *)mat_dst3 + dst3_idx));\n"
"		\n"
"		short2 tmp_data0, tmp_data1, tmp_data2, tmp_data3;\n"
"		\n"
"		tmp_data0 = (dst0_offset & 3) == 0 ? (short2)(src_data0.s4, src_data1.s0) : (short2)(src_data0.s0, src_data0.s4);\n"
"		tmp_data1 = (dst1_offset & 3) == 0 ? (short2)(src_data0.s5, src_data1.s1) : (short2)(src_data0.s1, src_data0.s5);\n"
"		tmp_data2 = (dst2_offset & 3) == 0 ? (short2)(src_data0.s6, src_data1.s2) : (short2)(src_data0.s2, src_data0.s6);\n"
"		tmp_data3 = (dst3_offset & 3) == 0 ? (short2)(src_data0.s7, src_data1.s3) : (short2)(src_data0.s3, src_data0.s7);\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		\n"
"		tmp_data3.x = ((dst3_idx + 0 >= dst3_start) && (dst3_idx + 0 < dst3_end)) ? tmp_data3.x : dst3_data.x;\n"
"		tmp_data3.y = ((dst3_idx + 2 >= dst3_start) && (dst3_idx + 2 < dst3_end)) ? tmp_data3.y : dst3_data.y;\n"
"		\n"
"		*((global short2 *)((__global char *)mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((global short2 *)((__global char *)mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((global short2 *)((__global char *)mat_dst2 + dst2_idx)) = tmp_data2;\n"
"		*((global short2 *)((__global char *)mat_dst3 + dst3_idx)) = tmp_data3;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D3(__global short *mat_src,  int src_step,  int src_offset,\n"
"                                 __global short *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global short *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global short *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"		int src_idx  = mad24(y, src_step, src_offset);\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst2_start = mad24(y, dst2_step, dst2_offset);\n"
"		int dst2_end   = mad24(y, dst2_step, dst2_offset + dst_step1);\n"
"		int dst2_idx   = mad24(y, dst2_step, dst2_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short2 dst0_data  = *((__global short2 *)((__global char *)mat_dst0 + dst0_idx));\n"
"		short2 dst1_data  = *((__global short2 *)((__global char *)mat_dst1 + dst1_idx));\n"
"		short2 dst2_data  = *((__global short2 *)((__global char *)mat_dst2 + dst2_idx));\n"
"		\n"
"		short2 tmp_data0, tmp_data1, tmp_data2;\n"
"		\n"
"		short src_data_0 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x - 3];\n"
"		short src_data_1 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x - 2];\n"
"		short src_data_2 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x - 1];\n"
"		short src_data_3 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x + 0];\n"
"		short src_data_4 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x + 1];\n"
"		short src_data_5 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x + 2];\n"
"		short src_data_6 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x + 3];\n"
"		short src_data_7 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x + 4];\n"
"		short src_data_8 = ((__global short *)((__global char *)mat_src + src_idx))[3 * x + 5];\n"
"		\n"
"		tmp_data0 = (dst0_offset & 3) == 0 ? (short2)(src_data_3, src_data_6) : (short2)(src_data_0, src_data_3);\n"
"		tmp_data1 = (dst1_offset & 3) == 0 ? (short2)(src_data_4, src_data_7) : (short2)(src_data_1, src_data_4);\n"
"		tmp_data2 = (dst2_offset & 3) == 0 ? (short2)(src_data_5, src_data_8) : (short2)(src_data_2, src_data_5);\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? tmp_data0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? tmp_data0.y : dst0_data.y;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? tmp_data1.x : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? tmp_data1.y : dst1_data.y;\n"
"		\n"
"		tmp_data2.x = ((dst2_idx + 0 >= dst2_start) && (dst2_idx + 0 < dst2_end)) ? tmp_data2.x : dst2_data.x;\n"
"		tmp_data2.y = ((dst2_idx + 2 >= dst2_start) && (dst2_idx + 2 < dst2_end)) ? tmp_data2.y : dst2_data.y;\n"
"		\n"
"		*((__global short2 *)((__global char *)mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((__global short2 *)((__global char *)mat_dst1 + dst1_idx)) = tmp_data1;\n"
"		*((__global short2 *)((__global char *)mat_dst2 + dst2_idx)) = tmp_data2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D3(__global short *mat_src,  int src_step,  int src_offset,\n"
"                                 __global short *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global short *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		x = x << 1;\n"
"		\n"
"#define dst0_align ((dst0_offset & 3) << 1)\n"
"#define dst1_align ((dst1_offset & 3) << 1)\n"
"		int src_idx_0  = mad24(y, src_step, src_offset - dst0_align + (x << 2));\n"
"		int src_idx_1  = mad24(y, src_step, src_offset - dst1_align + (x << 2));\n"
"		\n"
"		int dst0_start = mad24(y, dst0_step, dst0_offset);\n"
"		int dst0_end   = mad24(y, dst0_step, dst0_offset + dst_step1);\n"
"		int dst0_idx   = mad24(y, dst0_step, dst0_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		int dst1_start = mad24(y, dst1_step, dst1_offset);\n"
"		int dst1_end   = mad24(y, dst1_step, dst1_offset + dst_step1);\n"
"		int dst1_idx   = mad24(y, dst1_step, dst1_offset + (x << 1) & (int)0xfffffffc);\n"
"		\n"
"		short4 src_data_0 = vload4(0, (__global short *)((__global char *)mat_src + src_idx_0));\n"
"		short4 src_data_1 = vload4(0, (__global short *)((__global char *)mat_src + src_idx_1));\n"
"		\n"
"		short2 dst0_data  = *((__global short2 *)((__global char *)mat_dst0 + dst0_idx));\n"
"		short2 dst1_data  = *((__global short2 *)((__global char *)mat_dst1 + dst1_idx));\n"
"		\n"
"		short2 tmp_data0, tmp_data1;\n"
"		\n"
"		tmp_data0.x = ((dst0_idx + 0 >= dst0_start) && (dst0_idx + 0 < dst0_end)) ? src_data_0.x : dst0_data.x;\n"
"		tmp_data0.y = ((dst0_idx + 2 >= dst0_start) && (dst0_idx + 2 < dst0_end)) ? src_data_0.z : dst0_data.y;\n"
"		\n"
"		tmp_data1.x = ((dst1_idx + 0 >= dst1_start) && (dst1_idx + 0 < dst1_end)) ? src_data_1.y : dst1_data.x;\n"
"		tmp_data1.y = ((dst1_idx + 2 >= dst1_start) && (dst1_idx + 2 < dst1_end)) ? src_data_1.w : dst1_data.y;\n"
"		\n"
"		*((global short2 *)((__global char *)mat_dst0 + dst0_idx)) = tmp_data0;\n"
"		*((global short2 *)((__global char *)mat_dst1 + dst1_idx)) = tmp_data1;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C4_D4(__global int *mat_src,  int src_step,  int src_offset,\n"
"                                 __global int *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global int *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global int *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global int *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		int dst2_idx = mad24(y, dst2_step, dst2_offset);\n"
"		int dst3_idx = mad24(y, dst3_step, dst3_offset);\n"
"		\n"
"		int4 src_data = ((__global int4 *)((__global char *)mat_src + src_idx))[x];\n"
"		\n"
"		((__global int *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data.x;\n"
"		((__global int *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data.y;\n"
"		((__global int *)((__global char *)mat_dst2 + dst2_idx))[x] = src_data.z;\n"
"		((__global int *)((__global char *)mat_dst3 + dst3_idx))[x] = src_data.w;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D4(__global int *mat_src,  int src_step,  int src_offset,\n"
"                                 __global int *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global int *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global int *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		int dst2_idx = mad24(y, dst2_step, dst2_offset);\n"
"		\n"
"		int src_data_0 = ((__global int *)((__global char *)mat_src + src_idx))[3 * x + 0];\n"
"		int src_data_1 = ((__global int *)((__global char *)mat_src + src_idx))[3 * x + 1];\n"
"		int src_data_2 = ((__global int *)((__global char *)mat_src + src_idx))[3 * x + 2];\n"
"		\n"
"		((__global int *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data_0;\n"
"		((__global int *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data_1;\n"
"		((__global int *)((__global char *)mat_dst2 + dst2_idx))[x] = src_data_2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D4(__global int *mat_src,  int src_step,  int src_offset,\n"
"                                 __global int *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global int *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		\n"
"		int2 src_data = ((__global int2 *)((__global char *)mat_src + src_idx))[x];\n"
"		\n"
"		((__global int *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data.x;\n"
"		((__global int *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data.y;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C4_D5(__global float *mat_src,  int src_step,  int src_offset,\n"
"                                 __global float *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global float *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global float *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global float *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		int dst2_idx = mad24(y, dst2_step, dst2_offset);\n"
"		int dst3_idx = mad24(y, dst3_step, dst3_offset);\n"
"		\n"
"		float4 src_data = ((__global float4 *)((__global char *)mat_src + src_idx))[x];\n"
"		\n"
"		((__global float *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data.x;\n"
"		((__global float *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data.y;\n"
"		((__global float *)((__global char *)mat_dst2 + dst2_idx))[x] = src_data.z;\n"
"		((__global float *)((__global char *)mat_dst3 + dst3_idx))[x] = src_data.w;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D5(__global float *mat_src,  int src_step,  int src_offset,\n"
"                                 __global float *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global float *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global float *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		int dst2_idx = mad24(y, dst2_step, dst2_offset);\n"
"		\n"
"		float src_data_0 = ((__global float *)((__global char *)mat_src + src_idx))[3 * x + 0];\n"
"		float src_data_1 = ((__global float *)((__global char *)mat_src + src_idx))[3 * x + 1];\n"
"		float src_data_2 = ((__global float *)((__global char *)mat_src + src_idx))[3 * x + 2];\n"
"		\n"
"		((__global float *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data_0;\n"
"		((__global float *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data_1;\n"
"		((__global float *)((__global char *)mat_dst2 + dst2_idx))[x] = src_data_2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D5(__global float *mat_src,  int src_step,  int src_offset,\n"
"                                 __global float *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global float *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		\n"
"		float2 src_data = ((__global float2 *)((__global char *)mat_src + src_idx))[x];\n"
"		\n"
"		((__global float *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data.x;\n"
"		((__global float *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data.y;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C4_D6(__global double *mat_src,  int src_step,  int src_offset,\n"
"                                 __global double *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global double *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global double *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 __global double *mat_dst3, int dst3_step, int dst3_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		int dst2_idx = mad24(y, dst2_step, dst2_offset);\n"
"		int dst3_idx = mad24(y, dst3_step, dst3_offset);\n"
"		\n"
"		double4 src_data = ((__global double4 *)((__global char *)mat_src + src_idx))[x];\n"
"		\n"
"		((__global double *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data.x;\n"
"		((__global double *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data.y;\n"
"		((__global double *)((__global char *)mat_dst2 + dst2_idx))[x] = src_data.z;\n"
"		((__global double *)((__global char *)mat_dst3 + dst3_idx))[x] = src_data.w;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C3_D6(__global double *mat_src,  int src_step,  int src_offset,\n"
"                                 __global double *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global double *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 __global double *mat_dst2, int dst2_step, int dst2_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		int dst2_idx = mad24(y, dst2_step, dst2_offset);\n"
"		\n"
"		double src_data_0 = ((__global double *)((__global char *)mat_src + src_idx))[3 * x + 0];\n"
"		double src_data_1 = ((__global double *)((__global char *)mat_src + src_idx))[3 * x + 1];\n"
"		double src_data_2 = ((__global double *)((__global char *)mat_src + src_idx))[3 * x + 2];\n"
"		\n"
"		((__global double *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data_0;\n"
"		((__global double *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data_1;\n"
"		((__global double *)((__global char *)mat_dst2 + dst2_idx))[x] = src_data_2;\n"
"	}\n"
"}\n"
"__kernel void split_vector_C2_D6(__global double *mat_src,  int src_step,  int src_offset,\n"
"                                 __global double *mat_dst0, int dst0_step, int dst0_offset,\n"
"                                 __global double *mat_dst1, int dst1_step, int dst1_offset,\n"
"                                 int rows, int cols, int dst_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if ((x  < cols) && (y < rows))\n"
"	{\n"
"		int src_idx  = mad24(y, src_step,  src_offset);\n"
"		int dst0_idx = mad24(y, dst0_step, dst0_offset);\n"
"		int dst1_idx = mad24(y, dst1_step, dst1_offset);\n"
"		\n"
"		double2 src_data = ((__global double2 *)((__global char *)mat_src + src_idx))[x];\n"
"		\n"
"		((__global double *)((__global char *)mat_dst0 + dst0_idx))[x] = src_data.x;\n"
"		((__global double *)((__global char *)mat_dst1 + dst1_idx))[x] = src_data.y;\n"
"	}\n"
"}\n"
;
const char *stereobm =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#define ROWSperTHREAD 21     // the number of rows a thread will process\n"
"#define BLOCK_W       128    // the thread block width (464)\n"
"#define N_DISPARITIES 8\n"
"#define STEREO_MIND 0                    // The minimum d range to check\n"
"#define STEREO_DISP_STEP N_DISPARITIES   // the d step, must be <= 1 to avoid aliasing\n"
"int SQ(int a)\n"
"{\n"
"	return a * a;\n"
"}\n"
"unsigned int CalcSSD(volatile __local unsigned int *col_ssd_cache,\n"
"                     volatile __local unsigned int *col_ssd, int radius)\n"
"{\n"
"	unsigned int cache = 0;\n"
"	unsigned int cache2 = 0;\n"
"	\n"
"	for (int i = 1; i <= radius; i++)\n"
"	{\n"
"		cache += col_ssd[i];\n"
"	}\n"
"	\n"
"	col_ssd_cache[0] = cache;\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (get_local_id(0) < BLOCK_W - radius)\n"
"	{\n"
"		cache2 = col_ssd_cache[radius];\n"
"	}\n"
"	else\n"
"		for (int i = radius + 1; i < (2 * radius + 1); i++)\n"
"		{\n"
"			cache2 += col_ssd[i];\n"
"		}\n"
"		\n"
"	return col_ssd[0] + cache + cache2;\n"
"}\n"
"uint2 MinSSD(volatile __local unsigned int *col_ssd_cache,\n"
"             volatile __local unsigned int *col_ssd, int radius)\n"
"{\n"
"	unsigned int ssd[N_DISPARITIES];\n"
"	\n"
"	//See above:  #define COL_SSD_SIZE (BLOCK_W + 2 * radius)\n"
"	ssd[0] = CalcSSD(col_ssd_cache, col_ssd + 0 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[1] = CalcSSD(col_ssd_cache, col_ssd + 1 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[2] = CalcSSD(col_ssd_cache, col_ssd + 2 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[3] = CalcSSD(col_ssd_cache, col_ssd + 3 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[4] = CalcSSD(col_ssd_cache, col_ssd + 4 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[5] = CalcSSD(col_ssd_cache, col_ssd + 5 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[6] = CalcSSD(col_ssd_cache, col_ssd + 6 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	ssd[7] = CalcSSD(col_ssd_cache, col_ssd + 7 * (BLOCK_W + 2 * radius), radius);\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	unsigned int mssd = min(min(min(ssd[0], ssd[1]), min(ssd[4], ssd[5])), min(min(ssd[2], ssd[3]), min(ssd[6], ssd[7])));\n"
"	\n"
"	int bestIdx = 0;\n"
"	\n"
"	for (int i = 0; i < N_DISPARITIES; i++)\n"
"	{\n"
"		if (mssd == ssd[i])\n"
"		{\n"
"			bestIdx = i;\n"
"		}\n"
"	}\n"
"	\n"
"	return (uint2)(mssd, bestIdx);\n"
"}\n"
"void StepDown(int idx1, int idx2, __global unsigned char *imageL,\n"
"              __global unsigned char *imageR, int d, volatile  __local unsigned int *col_ssd, int radius)\n"
"{\n"
"	unsigned char leftPixel1;\n"
"	unsigned char leftPixel2;\n"
"	unsigned char rightPixel1[8];\n"
"	unsigned char rightPixel2[8];\n"
"	unsigned int diff1, diff2;\n"
"	\n"
"	leftPixel1 = imageL[idx1];\n"
"	leftPixel2 = imageL[idx2];\n"
"	\n"
"	idx1 = idx1 - d;\n"
"	idx2 = idx2 - d;\n"
"	\n"
"	rightPixel1[7] = imageR[idx1 - 7];\n"
"	rightPixel1[0] = imageR[idx1 - 0];\n"
"	rightPixel1[1] = imageR[idx1 - 1];\n"
"	rightPixel1[2] = imageR[idx1 - 2];\n"
"	rightPixel1[3] = imageR[idx1 - 3];\n"
"	rightPixel1[4] = imageR[idx1 - 4];\n"
"	rightPixel1[5] = imageR[idx1 - 5];\n"
"	rightPixel1[6] = imageR[idx1 - 6];\n"
"	\n"
"	rightPixel2[7] = imageR[idx2 - 7];\n"
"	rightPixel2[0] = imageR[idx2 - 0];\n"
"	rightPixel2[1] = imageR[idx2 - 1];\n"
"	rightPixel2[2] = imageR[idx2 - 2];\n"
"	rightPixel2[3] = imageR[idx2 - 3];\n"
"	rightPixel2[4] = imageR[idx2 - 4];\n"
"	rightPixel2[5] = imageR[idx2 - 5];\n"
"	rightPixel2[6] = imageR[idx2 - 6];\n"
"	\n"
"	//See above:  #define COL_SSD_SIZE (BLOCK_W + 2 * radius)\n"
"	diff1 = leftPixel1 - rightPixel1[0];\n"
"	diff2 = leftPixel2 - rightPixel2[0];\n"
"	col_ssd[0 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[1];\n"
"	diff2 = leftPixel2 - rightPixel2[1];\n"
"	col_ssd[1 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[2];\n"
"	diff2 = leftPixel2 - rightPixel2[2];\n"
"	col_ssd[2 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[3];\n"
"	diff2 = leftPixel2 - rightPixel2[3];\n"
"	col_ssd[3 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[4];\n"
"	diff2 = leftPixel2 - rightPixel2[4];\n"
"	col_ssd[4 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[5];\n"
"	diff2 = leftPixel2 - rightPixel2[5];\n"
"	col_ssd[5 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[6];\n"
"	diff2 = leftPixel2 - rightPixel2[6];\n"
"	col_ssd[6 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"	\n"
"	diff1 = leftPixel1 - rightPixel1[7];\n"
"	diff2 = leftPixel2 - rightPixel2[7];\n"
"	col_ssd[7 * (BLOCK_W + 2 * radius)] += SQ(diff2) - SQ(diff1);\n"
"}\n"
"void InitColSSD(int x_tex, int y_tex, int im_pitch, __global unsigned char *imageL,\n"
"                __global unsigned char *imageR, int d,\n"
"                volatile __local unsigned int *col_ssd, int radius)\n"
"{\n"
"	unsigned char leftPixel1;\n"
"	int idx;\n"
"	unsigned int diffa[] = {0, 0, 0, 0, 0, 0, 0, 0};\n"
"	\n"
"	for (int i = 0; i < (2 * radius + 1); i++)\n"
"	{\n"
"		idx = y_tex * im_pitch + x_tex;\n"
"		leftPixel1 = imageL[idx];\n"
"		idx = idx - d;\n"
"		\n"
"		diffa[0] += SQ(leftPixel1 - imageR[idx - 0]);\n"
"		diffa[1] += SQ(leftPixel1 - imageR[idx - 1]);\n"
"		diffa[2] += SQ(leftPixel1 - imageR[idx - 2]);\n"
"		diffa[3] += SQ(leftPixel1 - imageR[idx - 3]);\n"
"		diffa[4] += SQ(leftPixel1 - imageR[idx - 4]);\n"
"		diffa[5] += SQ(leftPixel1 - imageR[idx - 5]);\n"
"		diffa[6] += SQ(leftPixel1 - imageR[idx - 6]);\n"
"		diffa[7] += SQ(leftPixel1 - imageR[idx - 7]);\n"
"		\n"
"		y_tex += 1;\n"
"	}\n"
"	\n"
"	//See above:  #define COL_SSD_SIZE (BLOCK_W + 2 * radius)\n"
"	col_ssd[0 * (BLOCK_W + 2 * radius)] = diffa[0];\n"
"	col_ssd[1 * (BLOCK_W + 2 * radius)] = diffa[1];\n"
"	col_ssd[2 * (BLOCK_W + 2 * radius)] = diffa[2];\n"
"	col_ssd[3 * (BLOCK_W + 2 * radius)] = diffa[3];\n"
"	col_ssd[4 * (BLOCK_W + 2 * radius)] = diffa[4];\n"
"	col_ssd[5 * (BLOCK_W + 2 * radius)] = diffa[5];\n"
"	col_ssd[6 * (BLOCK_W + 2 * radius)] = diffa[6];\n"
"	col_ssd[7 * (BLOCK_W + 2 * radius)] = diffa[7];\n"
"}\n"
"__kernel void stereoKernel(__global unsigned char *left, __global unsigned char *right,\n"
"                           __global unsigned int *cminSSDImage, int cminSSD_step,\n"
"                           __global unsigned char *disp, int disp_step, int cwidth, int cheight,\n"
"                           int img_step, int maxdisp, int radius,\n"
"                           __local unsigned int *col_ssd_cache)\n"
"{\n"
"	volatile __local unsigned int *col_ssd = col_ssd_cache + BLOCK_W + get_local_id(0);\n"
"	volatile __local unsigned int *col_ssd_extra = get_local_id(0) < (2 * radius) ? col_ssd + BLOCK_W : 0;\n"
"	\n"
"	int X = get_group_id(0) * BLOCK_W + get_local_id(0) + maxdisp + radius;\n"
"	// int Y = get_group_id(1) * ROWSperTHREAD + radius;\n"
"	\n"
"#define Y (get_group_id(1) * ROWSperTHREAD + radius)\n"
"	\n"
"	volatile __global unsigned int *minSSDImage = cminSSDImage + X + Y * cminSSD_step;\n"
"	__global unsigned char *disparImage = disp + X + Y * disp_step;\n"
"	\n"
"	int end_row = ROWSperTHREAD < (cheight - Y) ? ROWSperTHREAD : (cheight - Y);\n"
"	int y_tex;\n"
"	int x_tex = X - radius;\n"
"	\n"
"	if (x_tex >= cwidth)\n"
"	{\n"
"		return;\n"
"	}\n"
"	\n"
"	for (int d = STEREO_MIND; d < maxdisp; d += STEREO_DISP_STEP)\n"
"	{\n"
"		y_tex = Y - radius;\n"
"		\n"
"		InitColSSD(x_tex, y_tex, img_step, left, right, d, col_ssd, radius);\n"
"		\n"
"		if (col_ssd_extra > 0)\n"
"			if (x_tex + BLOCK_W < cwidth)\n"
"			{\n"
"				InitColSSD(x_tex + BLOCK_W, y_tex, img_step, left, right, d, col_ssd_extra, radius);\n"
"			}\n"
"			\n"
"		barrier(CLK_LOCAL_MEM_FENCE); //before MinSSD function\n"
"		\n"
"		if (X < cwidth - radius && Y < cheight - radius)\n"
"		{\n"
"			uint2 minSSD = MinSSD(col_ssd_cache + get_local_id(0), col_ssd, radius);\n"
"			\n"
"			if (minSSD.x < minSSDImage[0])\n"
"			{\n"
"				disparImage[0] = (unsigned char)(d + minSSD.y);\n"
"				minSSDImage[0] = minSSD.x;\n"
"			}\n"
"		}\n"
"		\n"
"		for (int row = 1; row < end_row; row++)\n"
"		{\n"
"			int idx1 = y_tex * img_step + x_tex;\n"
"			int idx2 = (y_tex + (2 * radius + 1)) * img_step + x_tex;\n"
"			\n"
"			barrier(CLK_GLOBAL_MEM_FENCE);\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			\n"
"			StepDown(idx1, idx2, left, right, d, col_ssd, radius);\n"
"			\n"
"			if (col_ssd_extra > 0)\n"
"				if (x_tex + BLOCK_W < cwidth)\n"
"				{\n"
"					StepDown(idx1, idx2, left + BLOCK_W, right + BLOCK_W, d, col_ssd_extra, radius);\n"
"				}\n"
"				\n"
"			y_tex += 1;\n"
"			\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			\n"
"			if (X < cwidth - radius && row < cheight - radius - Y)\n"
"			{\n"
"				int idx = row * cminSSD_step;\n"
"				uint2 minSSD = MinSSD(col_ssd_cache + get_local_id(0), col_ssd, radius);\n"
"				\n"
"				if (minSSD.x < minSSDImage[idx])\n"
"				{\n"
"					disparImage[disp_step * row] = (unsigned char)(d + minSSD.y);\n"
"					minSSDImage[idx] = minSSD.x;\n"
"				}\n"
"			}\n"
"		} // for row loop\n"
"	} // for d loop\n"
"}\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////\n"
"//////////////////////////// Sobel Prefiler (signal channel)//////////////////////////////////////\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void prefilter_xsobel(__global unsigned char *input, __global unsigned char *output,\n"
"                               int rows, int cols, int prefilterCap)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		int cov = input[(y - 1) * cols + (x - 1)] * (-1) + input[(y - 1) * cols + (x + 1)] * (1) +\n"
"		          input[(y)   * cols + (x - 1)] * (-2) + input[(y)   * cols + (x + 1)] * (2) +\n"
"		          input[(y + 1) * cols + (x - 1)] * (-1) + input[(y + 1) * cols + (x + 1)] * (1);\n"
"		          \n"
"		cov = min(min(max(-prefilterCap, cov), prefilterCap) + prefilterCap, 255);\n"
"		output[y * cols + x] = cov & 0xFF;\n"
"	}\n"
"}\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////\n"
"/////////////////////////////////// Textureness filtering ////////////////////////////////////////\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////\n"
"float sobel(__global unsigned char *input, int x, int y, int rows, int cols)\n"
"{\n"
"	float conv = 0;\n"
"	int y1 = y == 0 ? 0 : y - 1;\n"
"	int x1 = x == 0 ? 0 : x - 1;\n"
"	\n"
"	if (x < cols && y < rows)\n"
"	{\n"
"		conv = (float)input[(y1)  * cols + (x1)] * (-1) + (float)input[(y1)  * cols + (x + 1)] * (1) +\n"
"		       (float)input[(y)   * cols + (x1)] * (-2) + (float)input[(y)   * cols + (x + 1)] * (2) +\n"
"		       (float)input[(y + 1) * cols + (x1)] * (-1) + (float)input[(y + 1) * cols + (x + 1)] * (1);\n"
"		       \n"
"	}\n"
"	\n"
"	return fabs(conv);\n"
"}\n"
"float CalcSums(__local float *cols, __local float *cols_cache, int winsz)\n"
"{\n"
"	float cache = 0;\n"
"	float cache2 = 0;\n"
"	int winsz2 = winsz / 2;\n"
"	\n"
"	int x = get_local_id(0);\n"
"	int group_size_x = get_local_size(0);\n"
"	\n"
"	for (int i = 1; i <= winsz2; i++)\n"
"	{\n"
"		cache += cols[i];\n"
"	}\n"
"	\n"
"	cols_cache[0] = cache;\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (x < group_size_x - winsz2)\n"
"	{\n"
"		cache2 = cols_cache[winsz2];\n"
"	}\n"
"	else\n"
"		for (int i = winsz2 + 1; i < winsz; i++)\n"
"		{\n"
"			cache2 += cols[i];\n"
"		}\n"
"		\n"
"	return cols[0] + cache + cache2;\n"
"}\n"
"#define RpT (2 * ROWSperTHREAD)  // got experimentally\n"
"__kernel void textureness_kernel(__global unsigned char *disp, int disp_rows, int disp_cols,\n"
"                                 int disp_step, __global unsigned char *input, int input_rows,\n"
"                                 int input_cols, int winsz, float threshold,\n"
"                                 __local float *cols_cache)\n"
"{\n"
"	int winsz2 = winsz / 2;\n"
"	int n_dirty_pixels = (winsz2) * 2;\n"
"	\n"
"	int local_id_x = get_local_id(0);\n"
"	int group_size_x = get_local_size(0);\n"
"	int group_id_y = get_group_id(1);\n"
"	\n"
"	__local float *cols = cols_cache + group_size_x + local_id_x;\n"
"	__local float *cols_extra = local_id_x < n_dirty_pixels ? cols + group_size_x : 0;\n"
"	\n"
"	int x = get_global_id(0);\n"
"	int beg_row = group_id_y * RpT;\n"
"	int end_row = min(beg_row + RpT, disp_rows);\n"
"	\n"
"	if (x < disp_cols)\n"
"	{\n"
"		int y = beg_row;\n"
"		\n"
"		float sum = 0;\n"
"		float sum_extra = 0;\n"
"		\n"
"		for (int i = y - winsz2; i <= y + winsz2; ++i)\n"
"		{\n"
"			sum += sobel(input, x - winsz2, i, input_rows, input_cols);\n"
"			\n"
"			if (cols_extra)\n"
"			{\n"
"				sum_extra += sobel(input, x + group_size_x - winsz2, i, input_rows, input_cols);\n"
"			}\n"
"		}\n"
"		\n"
"		*cols = sum;\n"
"		\n"
"		if (cols_extra)\n"
"		{\n"
"			*cols_extra = sum_extra;\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		float sum_win = CalcSums(cols, cols_cache + local_id_x, winsz) * 255;\n"
"		\n"
"		if (sum_win < threshold)\n"
"		{\n"
"			disp[y * disp_step + x] = 0;\n"
"		}\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		for (int y = beg_row + 1; y < end_row; ++y)\n"
"		{\n"
"			sum = sum - sobel(input, x - winsz2, y - winsz2 - 1, input_rows, input_cols) +\n"
"			      sobel(input, x - winsz2, y + winsz2, input_rows, input_cols);\n"
"			*cols = sum;\n"
"			\n"
"			if (cols_extra)\n"
"			{\n"
"				sum_extra = sum_extra - sobel(input, x + group_size_x - winsz2, y - winsz2 - 1, input_rows, input_cols)\n"
"				            + sobel(input, x + group_size_x - winsz2, y + winsz2, input_rows, input_cols);\n"
"				*cols_extra = sum_extra;\n"
"			}\n"
"			\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"			float sum_win = CalcSums(cols, cols_cache + local_id_x, winsz) * 255;\n"
"			\n"
"			if (sum_win < threshold)\n"
"			{\n"
"				disp[y * disp_step + x] = 0;\n"
"			}\n"
"			\n"
"			barrier(CLK_LOCAL_MEM_FENCE);\n"
"		}\n"
"	}\n"
"}\n"
;
const char *stereobp =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other GpuMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#if defined (__ATI__)\n"
"#pragma OPENCL EXTENSION cl_amd_fp64:enable\n"
"#elif defined (__NVIDIA__)\n"
"#pragma OPENCL EXTENSION cl_khr_fp64:enable\n"
"#endif\n"
"///////////////////////////////////////////////////////////////\n"
"/////////////////common///////////////////////////////////////\n"
"/////////////////////////////////////////////////////////////\n"
"short round_short(float v)\n"
"{\n"
"	return convert_short_sat_rte(v);\n"
"}\n"
"#define FLOAT_MAX 3.402823466e+38f\n"
"typedef struct\n"
"{\n"
"	int   cndisp;\n"
"	float cmax_data_term;\n"
"	float cdata_weight;\n"
"	float cmax_disc_term;\n"
"	float cdisc_single_jump;\n"
"} con_srtuct_t;\n"
"///////////////////////////////////////////////////////////////\n"
"////////////////////////// comp data //////////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"float pix_diff_1(__global const uchar *ls, __global const uchar *rs)\n"
"{\n"
"	return abs((int)(*ls) - *rs);\n"
"}\n"
"float pix_diff_3(__global const uchar *ls, __global const uchar *rs)\n"
"{\n"
"	const float tr = 0.299f;\n"
"	const float tg = 0.587f;\n"
"	const float tb = 0.114f;\n"
"	\n"
"	float val;\n"
"	\n"
"	val =  tb * abs((int)ls[0] - rs[0]);\n"
"	val += tg * abs((int)ls[1] - rs[1]);\n"
"	val += tr * abs((int)ls[2] - rs[2]);\n"
"	\n"
"	return val;\n"
"}\n"
"float pix_diff_4(__global const uchar *ls, __global const uchar *rs)\n"
"{\n"
"	uchar4 l, r;\n"
"	l = *((__global uchar4 *)ls);\n"
"	r = *((__global uchar4 *)rs);\n"
"	\n"
"	const float tr = 0.299f;\n"
"	const float tg = 0.587f;\n"
"	const float tb = 0.114f;\n"
"	\n"
"	float val;\n"
"	\n"
"	val  = tb * abs((int)l.x - r.x);\n"
"	val += tg * abs((int)l.y - r.y);\n"
"	val += tr * abs((int)l.z - r.z);\n"
"	\n"
"	return val;\n"
"}\n"
"__kernel void comp_data_0(__global uchar *left,  int left_rows,  int left_cols,  int left_step,\n"
"                          __global uchar *right, int right_step,\n"
"                          __global short  *data, int data_cols,  int data_step,\n"
"                          __constant con_srtuct_t *con_st, int cn)\n"
"//  int cndisp, float cmax_data_term, float cdata_weight, int cn)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y > 0 && y < (left_rows - 1) && x > 0 && x < (left_cols - 1))\n"
"	{\n"
"		const __global uchar *ls = left  + y * left_step  + x * cn;\n"
"		const __global uchar *rs = right + y * right_step + x * cn;\n"
"		\n"
"		__global short *ds = (__global short *)((__global uchar *)data + y * data_step) + x;\n"
"		\n"
"		const unsigned int disp_step = data_cols * left_rows ;\n"
"		\n"
"		for (int disp = 0; disp < con_st -> cndisp; disp++)\n"
"		{\n"
"			if (x - disp >= 1)\n"
"			{\n"
"				float val = 0;\n"
"				\n"
"				if (cn == 1)\n"
"				{\n"
"					val = pix_diff_1(ls, rs - disp * cn);\n"
"				}\n"
"				\n"
"				if (cn == 3)\n"
"				{\n"
"					val = pix_diff_3(ls, rs - disp * cn);\n"
"				}\n"
"				\n"
"				if (cn == 4)\n"
"				{\n"
"					val = pix_diff_4(ls, rs - disp * cn);\n"
"				}\n"
"				\n"
"				ds[disp * disp_step] =  round_short(fmin(con_st -> cdata_weight * val,\n"
"				                                    con_st -> cdata_weight * con_st -> cmax_data_term));\n"
"			}\n"
"			else\n"
"			{\n"
"				ds[disp * disp_step] =  round_short(con_st -> cdata_weight * con_st -> cmax_data_term);\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void comp_data_1(__global uchar *left,  int left_rows,  int left_cols,  int left_step,\n"
"                          __global uchar *right, int right_step,\n"
"                          __global float *data,  int data_cols,  int data_step,\n"
"                          __constant con_srtuct_t *con_st, int cn)\n"
"//int cndisp, float cmax_data_term, float cdata_weight, int cn)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y > 0 && y < left_rows - 1 && x > 0 && x < left_cols - 1)\n"
"	{\n"
"		const __global uchar *ls = left  + y * left_step  + x * cn;\n"
"		const __global uchar *rs = right + y * right_step + x * cn;\n"
"		\n"
"		__global float *ds = (__global float *)((__global char *)data + y * data_step) + x;\n"
"		\n"
"		const unsigned int disp_step = data_cols * left_rows;\n"
"		\n"
"		for (int disp = 0; disp < con_st -> cndisp; disp++)\n"
"		{\n"
"			if (x - disp >= 1)\n"
"			{\n"
"				float val = 0;\n"
"				\n"
"				if (cn == 1)\n"
"				{\n"
"					val = pix_diff_1(ls, rs - disp * cn);\n"
"				}\n"
"				\n"
"				if (cn == 3)\n"
"				{\n"
"					val = pix_diff_3(ls, rs - disp * cn);\n"
"				}\n"
"				\n"
"				if (cn == 4)\n"
"				{\n"
"					val = pix_diff_4(ls, rs - disp * cn);\n"
"				}\n"
"				\n"
"				ds[disp * disp_step] = fmin(con_st -> cdata_weight * val,\n"
"				                            con_st -> cdata_weight * con_st -> cmax_data_term);\n"
"			}\n"
"			else\n"
"			{\n"
"				ds[disp * disp_step] = con_st -> cdata_weight * con_st -> cmax_data_term;\n"
"			}\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"//////////////////////// data step down ///////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"__kernel void data_step_down_0(__global short *src, int src_rows, int src_cols,\n"
"                               __global short *dst, int dst_rows, int dst_cols, int dst_real_cols,\n"
"                               int cndisp)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);;\n"
"	\n"
"	if (x < dst_cols && y < dst_rows)\n"
"	{\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			//float dst_reg  = src.ptr(d * src_rows + (2*y+0))[(2*x+0)];\n"
"			float dst_reg;\n"
"			dst_reg  = src[(d * src_rows + (2 * y + 0)) * src_cols + 2 * x + 0];\n"
"			dst_reg += src[(d * src_rows + (2 * y + 1)) * src_cols + 2 * x + 0];\n"
"			dst_reg += src[(d * src_rows + (2 * y + 0)) * src_cols + 2 * x + 1];\n"
"			dst_reg += src[(d * src_rows + (2 * y + 1)) * src_cols + 2 * x + 1];\n"
"			\n"
"			//dst.ptr(d * dst_rows + y)[x] = saturate_cast<T>(dst_reg);\n"
"			dst[(d * dst_rows + y) * dst_real_cols + x] = round_short(dst_reg);\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void data_step_down_1(__global float *src, int src_rows, int src_cols,\n"
"                               __global float *dst, int dst_rows, int dst_cols, int dst_real_cols,\n"
"                               int cndisp)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);;\n"
"	\n"
"	if (x < dst_cols && y < dst_rows)\n"
"	{\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			//float dst_reg  = src.ptr(d * src_rows + (2*y+0))[(2*x+0)];\n"
"			float dst_reg;\n"
"			dst_reg = src[(d * src_rows + (2 * y + 0)) * src_cols + 2 * x + 0];\n"
"			dst_reg += src[(d * src_rows + (2 * y + 1)) * src_cols + 2 * x + 0];\n"
"			dst_reg += src[(d * src_rows + (2 * y + 0)) * src_cols + 2 * x + 1];\n"
"			dst_reg += src[(d * src_rows + (2 * y + 1)) * src_cols + 2 * x + 1];\n"
"			\n"
"			//dst.ptr(d * dst_rows + y)[x] = saturate_cast<T>(dst_reg);\n"
"			dst[(d * dst_rows + y) * dst_real_cols + x] = round_short(dst_reg);\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"/////////////////// level up messages  ////////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"__kernel void level_up_message_0(__global short *src, int src_rows, int src_step,\n"
"                                 __global short *dst, int dst_rows, int dst_cols, int dst_step,\n"
"                                 int cndisp)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);\n"
"	\n"
"	if (x < dst_cols && y < dst_rows)\n"
"	{\n"
"		const int dst_disp_step = (dst_step / sizeof(short)) * dst_rows;\n"
"		const int src_disp_step = (src_step / sizeof(short)) * src_rows;\n"
"		\n"
"		__global short        *dstr = (__global short *)((__global char *)dst + y   * dst_step) + x;\n"
"		__global const short  *srcr = (__global short *)((__global char *)src + y / 2 * src_step) + x / 2;\n"
"		\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			dstr[d * dst_disp_step] = srcr[d * src_disp_step];\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void level_up_message_1(__global float *src, int src_rows, int src_step,\n"
"                                 __global float *dst, int dst_rows, int dst_cols, int dst_step,\n"
"                                 int cndisp)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);\n"
"	\n"
"	if (x < dst_cols && y < dst_rows)\n"
"	{\n"
"		const int dst_disp_step = (dst_step / sizeof(float)) * dst_rows;\n"
"		const int src_disp_step = (src_step / sizeof(float)) * src_rows;\n"
"		\n"
"		__global float       *dstr = (__global float *)((__global char *)dst + y   * dst_step) + x;\n"
"		__global const float *srcr = (__global float *)((__global char *)src + y / 2 * src_step) + x / 2;\n"
"		\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			dstr[d * dst_disp_step] = srcr[d * src_disp_step];\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"////////////////////  calc all iterations /////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"void calc_min_linear_penalty_0(__global short *dst, int disp_step,\n"
"                               int cndisp, float cdisc_single_jump)\n"
"{\n"
"	float prev = dst[0];\n"
"	float cur;\n"
"	\n"
"	for (int disp = 1; disp < cndisp; ++disp)\n"
"	{\n"
"		prev += cdisc_single_jump;\n"
"		cur = dst[disp_step * disp];\n"
"		\n"
"		if (prev < cur)\n"
"		{\n"
"			cur = prev;\n"
"			dst[disp_step * disp] = round_short(prev);\n"
"		}\n"
"		\n"
"		prev = cur;\n"
"	}\n"
"	\n"
"	prev = dst[(cndisp - 1) * disp_step];\n"
"	\n"
"	for (int disp = cndisp - 2; disp >= 0; disp--)\n"
"	{\n"
"		prev += cdisc_single_jump;\n"
"		cur = dst[disp_step * disp];\n"
"		\n"
"		if (prev < cur)\n"
"		{\n"
"			cur = prev;\n"
"			dst[disp_step * disp] = round_short(prev);\n"
"		}\n"
"		\n"
"		prev = cur;\n"
"	}\n"
"}\n"
"void message_0(const __global short *msg1, const __global short *msg2,\n"
"               const __global short *msg3, const __global short *data, __global short *dst,\n"
"               int msg_disp_step, int data_disp_step, int cndisp, float cmax_disc_term, float cdisc_single_jump)\n"
"{\n"
"	float minimum = FLOAT_MAX;\n"
"	\n"
"	for (int i = 0; i < cndisp; ++i)\n"
"	{\n"
"		float dst_reg;\n"
"		dst_reg  = msg1[msg_disp_step * i];\n"
"		dst_reg += msg2[msg_disp_step * i];\n"
"		dst_reg += msg3[msg_disp_step * i];\n"
"		dst_reg += data[data_disp_step * i];\n"
"		\n"
"		if (dst_reg < minimum)\n"
"		{\n"
"			minimum = dst_reg;\n"
"		}\n"
"		\n"
"		dst[msg_disp_step * i] = round_short(dst_reg);\n"
"	}\n"
"	\n"
"	calc_min_linear_penalty_0(dst, msg_disp_step, cndisp, cdisc_single_jump);\n"
"	\n"
"	minimum += cmax_disc_term;\n"
"	\n"
"	float sum = 0;\n"
"	\n"
"	for (int i = 0; i < cndisp; ++i)\n"
"	{\n"
"		float dst_reg = dst[msg_disp_step * i];\n"
"		\n"
"		if (dst_reg > minimum)\n"
"		{\n"
"			dst_reg = minimum;\n"
"			dst[msg_disp_step * i] = round_short(minimum);\n"
"		}\n"
"		\n"
"		sum += dst_reg;\n"
"	}\n"
"	\n"
"	sum /= cndisp;\n"
"	\n"
"	for (int i = 0; i < cndisp; ++i)\n"
"	{\n"
"		dst[msg_disp_step * i] -= sum;\n"
"	}\n"
"}\n"
"__kernel void one_iteration_0(__global short *u,    int u_step,    int u_cols,\n"
"                              __global short *data, int data_step, int data_cols,\n"
"                              __global short *d,    __global short *l, __global short *r,\n"
"                              int t, int cols, int rows,\n"
"                              int cndisp, float cmax_disc_term, float cdisc_single_jump)\n"
"{\n"
"	const int y = get_global_id(1);\n"
"	const int x = ((get_global_id(0)) << 1) + ((y + t) & 1);\n"
"	\n"
"	if ((y > 0) && (y < rows - 1) && (x > 0) && (x < cols - 1))\n"
"	{\n"
"		__global short *us = (__global short *)((__global char *)u + y * u_step) + x;\n"
"		__global short *ds = d + y * u_cols + x;\n"
"		__global short *ls = l + y * u_cols + x;\n"
"		__global short *rs = r + y * u_cols + x;\n"
"		const __global  short *dt = (__global short *)((__global char *)data + y * data_step) + x;\n"
"		\n"
"		int msg_disp_step = u_cols * rows;\n"
"		int data_disp_step = data_cols * rows;\n"
"		\n"
"		message_0(us + u_cols, ls      + 1, rs - 1, dt, us, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"		message_0(ds - u_cols, ls      + 1, rs - 1, dt, ds, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"		          \n"
"		message_0(us + u_cols, ds - u_cols, rs - 1, dt, rs, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"		message_0(us + u_cols, ds - u_cols, ls + 1, dt, ls, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"	}\n"
"}\n"
"void calc_min_linear_penalty_1(__global float *dst, int step,\n"
"                               int cndisp, float cdisc_single_jump)\n"
"{\n"
"	float prev = dst[0];\n"
"	float cur;\n"
"	\n"
"	for (int disp = 1; disp < cndisp; ++disp)\n"
"	{\n"
"		prev += cdisc_single_jump;\n"
"		cur = dst[step * disp];\n"
"		\n"
"		if (prev < cur)\n"
"		{\n"
"			cur = prev;\n"
"			dst[step * disp] = prev;\n"
"		}\n"
"		\n"
"		prev = cur;\n"
"	}\n"
"	\n"
"	prev = dst[(cndisp - 1) * step];\n"
"	\n"
"	for (int disp = cndisp - 2; disp >= 0; disp--)\n"
"	{\n"
"		prev += cdisc_single_jump;\n"
"		cur = dst[step * disp];\n"
"		\n"
"		if (prev < cur)\n"
"		{\n"
"			cur = prev;\n"
"			dst[step * disp] = prev;\n"
"		}\n"
"		\n"
"		prev = cur;\n"
"	}\n"
"}\n"
"void message_1(const __global float *msg1, const __global float *msg2,\n"
"               const __global float *msg3, const __global float *data, __global float *dst,\n"
"               int msg_disp_step, int data_disp_step, int cndisp, float cmax_disc_term, float cdisc_single_jump)\n"
"{\n"
"	float minimum = FLOAT_MAX;\n"
"	\n"
"	for (int i = 0; i < cndisp; ++i)\n"
"	{\n"
"		float dst_reg = 0;\n"
"		dst_reg  = msg1[msg_disp_step * i];\n"
"		dst_reg += msg2[msg_disp_step * i];\n"
"		dst_reg += msg3[msg_disp_step * i];\n"
"		dst_reg += data[data_disp_step * i];\n"
"		\n"
"		if (dst_reg < minimum)\n"
"		{\n"
"			minimum = dst_reg;\n"
"		}\n"
"		\n"
"		dst[msg_disp_step * i] = dst_reg;\n"
"	}\n"
"	\n"
"	calc_min_linear_penalty_1(dst, msg_disp_step, cndisp, cdisc_single_jump);\n"
"	\n"
"	minimum += cmax_disc_term;\n"
"	\n"
"	float sum = 0;\n"
"	\n"
"	for (int i = 0; i < cndisp; ++i)\n"
"	{\n"
"		float dst_reg = dst[msg_disp_step * i];\n"
"		\n"
"		if (dst_reg > minimum)\n"
"		{\n"
"			dst_reg = minimum;\n"
"			dst[msg_disp_step * i] = minimum;\n"
"		}\n"
"		\n"
"		sum += dst_reg;\n"
"	}\n"
"	\n"
"	sum /= cndisp;\n"
"	\n"
"	for (int i = 0; i < cndisp; ++i)\n"
"	{\n"
"		dst[msg_disp_step * i] -= sum;\n"
"	}\n"
"}\n"
"__kernel void one_iteration_1(__global float *u,    int u_step,    int u_cols,\n"
"                              __global float *data, int data_step, int data_cols,\n"
"                              __global float *d,    __global float *l, __global float *r,\n"
"                              int t, int cols, int rows,\n"
"                              int cndisp, float cmax_disc_term, float cdisc_single_jump)\n"
"{\n"
"	const int y = get_global_id(1);\n"
"	const int x = ((get_global_id(0)) << 1) + ((y + t) & 1);\n"
"	\n"
"	if ((y > 0) && (y < rows - 1) && (x > 0) && (x < cols - 1))\n"
"	{\n"
"		__global float *us = (__global float *)((__global char *)u + y * u_step) + x;\n"
"		__global float *ds = d + y * u_cols + x;\n"
"		__global float *ls = l + y * u_cols + x;\n"
"		__global float *rs = r + y * u_cols + x;\n"
"		const __global float *dt = (__global float *)((__global char *)data + y * data_step) + x;\n"
"		\n"
"		int msg_disp_step = u_cols * rows;\n"
"		int data_disp_step = data_cols * rows;\n"
"		\n"
"		message_1(us + u_cols, ls      + 1, rs - 1, dt, us, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"		message_1(ds - u_cols, ls      + 1, rs - 1, dt, ds, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"		message_1(us + u_cols, ds - u_cols, rs - 1, dt, rs, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"		message_1(us + u_cols, ds - u_cols, ls + 1, dt, ls, msg_disp_step, data_disp_step, cndisp,\n"
"		          cmax_disc_term, cdisc_single_jump);\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"/////////////////////////// output ////////////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"__kernel void output_0(const __global short *u, int u_step, int u_cols,\n"
"                       const __global short *d, const __global short *l,\n"
"                       const __global short *r, const __global short *data,\n"
"                       __global short *disp, int disp_rows, int disp_cols, int disp_step,\n"
"                       int cndisp)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);\n"
"	\n"
"	if (y > 0 && y < disp_rows - 1 && x > 0 && x < disp_cols - 1)\n"
"	{\n"
"		const __global short *us = (__global short *)((__global char *)u + (y + 1) * u_step) + x;\n"
"		const __global short *ds = d + (y - 1) * u_cols + x;\n"
"		const __global short *ls = l + y * u_cols + (x + 1);\n"
"		const __global short *rs = r + y * u_cols + (x - 1);\n"
"		const __global short *dt = data + y * u_cols + x;\n"
"		\n"
"		int disp_steps = disp_rows * u_cols;\n"
"		\n"
"		int best = 0;\n"
"		float best_val = FLOAT_MAX;\n"
"		\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			float val;\n"
"			val  = us[d * disp_steps];\n"
"			val += ds[d * disp_steps];\n"
"			val += ls[d * disp_steps];\n"
"			val += rs[d * disp_steps];\n"
"			val += dt[d * disp_steps];\n"
"			\n"
"			if (val < best_val)\n"
"			{\n"
"				best_val = val;\n"
"				best = d;\n"
"			}\n"
"		}\n"
"		\n"
"		((__global short *)((__global char *)disp + y * disp_step))[x] = convert_short_sat(best);\n"
"	}\n"
"}\n"
"__kernel void output_1(const __global float *u, int u_step, int u_cols,\n"
"                       const __global float *d, const __global float *l,\n"
"                       const __global float *r, const __global float *data,\n"
"                       __global short *disp, int disp_rows, int disp_cols, int disp_step,\n"
"                       int cndisp)\n"
"{\n"
"	const int x = get_global_id(0);\n"
"	const int y = get_global_id(1);\n"
"	\n"
"	if (y > 0 && y < disp_rows - 1 && x > 0 && x < disp_cols - 1)\n"
"	{\n"
"		const __global float *us = (__global float *)((__global char *)u + (y + 1) * u_step) + x;\n"
"		const __global float *ds = d + (y - 1) * u_cols + x;\n"
"		const __global float *ls = l + y * u_cols + (x + 1);\n"
"		const __global float *rs = r + y * u_cols + (x - 1);\n"
"		const __global float *dt = data + y * u_cols + x;\n"
"		\n"
"		int disp_steps = disp_rows * u_cols;\n"
"		\n"
"		int best = 0;\n"
"		float best_val = FLOAT_MAX;\n"
"		\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			float val;\n"
"			val  = us[d * disp_steps];\n"
"			val += ds[d * disp_steps];\n"
"			val += ls[d * disp_steps];\n"
"			val += rs[d * disp_steps];\n"
"			val += dt[d * disp_steps];\n"
"			\n"
"			if (val < best_val)\n"
"			{\n"
"				best_val = val;\n"
"				best = d;\n"
"			}\n"
"		}\n"
"		\n"
"		//disp[y * disp_cols + x] = convert_short_sat(best);\n"
"		((__global short *)((__global char *)disp + y * disp_step))[x] = convert_short_sat(best);\n"
"	}\n"
"}\n"
;
const char *stereocsbp =
"/*M///////////////////////////////////////////////////////////////////////////////////////\n"
"//\n"
"//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.\n"
"//\n"
"//  By downloading, copying, installing or using the software you agree to this license.\n"
"//  If you do not agree to this license, do not download, install,\n"
"//  copy or use the software.\n"
"//\n"
"//\n"
"//                           License Agreement\n"
"//                For Open Source Computer Vision Library\n"
"//\n"
"// Copyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\n"
"// Copyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\n"
"// Third party copyrights are property of their respective owners.\n"
"//\n"
"// @Authors\n"
"//    Jia Haipeng, jiahaipeng95@gmail.com\n"
"//\n"
"// Redistribution and use in source and binary forms, with or without modification,\n"
"// are permitted provided that the following conditions are met:\n"
"//\n"
"//   * Redistribution's of source code must retain the above copyright notice,\n"
"//     this list of conditions and the following disclaimer.\n"
"//\n"
"//   * Redistribution's in binary form must reproduce the above copyright notice,\n"
"//     this list of conditions and the following disclaimer in the documentation\n"
"//     and/or other oclMaterials provided with the distribution.\n"
"//\n"
"//   * The name of the copyright holders may not be used to endorse or promote products\n"
"//     derived from this software without specific prior written permission.\n"
"//\n"
"// This software is provided by the copyright holders and contributors as is and\n"
"// any express or implied warranties, including, but not limited to, the implied\n"
"// warranties of merchantability and fitness for a particular purpose are disclaimed.\n"
"// In no event shall the Intel Corporation or contributors be liable for any direct,\n"
"// indirect, incidental, special, exemplary, or consequential damages\n"
"// (including, but not limited to, procurement of substitute goods or services;\n"
"// loss of use, data, or profits; or business interruption) however caused\n"
"// and on any theory of liability, whether in contract, strict liability,\n"
"// or tort (including negligence or otherwise) arising in any way out of\n"
"// the use of this software, even if advised of the possibility of such damage.\n"
"//\n"
"//M*/\n"
"#ifndef FLT_MAX\n"
"#define FLT_MAX  CL_FLT_MAX\n"
"#endif\n"
"#ifndef SHRT_MAX\n"
"#define SHRT_MAX  CL_SHORT_MAX\n"
"#endif\n"
"///////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////get_first_k_initial_global//////////////////////////////\n"
"//////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void get_first_k_initial_global_0(__global short *data_cost_selected_, __global short *selected_disp_pyr,\n"
"        __global short *ctemp, int h, int w, int nr_plane,\n"
"        int cmsg_step1, int cdisp_step1, int cndisp)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		__global short *selected_disparity = selected_disp_pyr      + y * cmsg_step1 + x;\n"
"		__global short *data_cost_selected = data_cost_selected_    + y * cmsg_step1 + x;\n"
"		__global short *data_cost          = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		for (int i = 0; i < nr_plane; i++)\n"
"		{\n"
"			short minimum = SHRT_MAX;\n"
"			int id = 0;\n"
"			\n"
"			for (int d = 0; d < cndisp; d++)\n"
"			{\n"
"				short cur = data_cost[d * cdisp_step1];\n"
"				\n"
"				if (cur < minimum)\n"
"				{\n"
"					minimum = cur;\n"
"					id = d;\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost_selected[i  * cdisp_step1] = minimum;\n"
"			selected_disparity[i  * cdisp_step1] = id;\n"
"			data_cost         [id * cdisp_step1] = SHRT_MAX;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void get_first_k_initial_global_1(__global  float *data_cost_selected_, __global float *selected_disp_pyr,\n"
"        __global  float *ctemp, int h, int w, int nr_plane,\n"
"        int cmsg_step1, int cdisp_step1, int cndisp)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		__global   float *selected_disparity = selected_disp_pyr      + y * cmsg_step1 + x;\n"
"		__global   float *data_cost_selected = data_cost_selected_    + y * cmsg_step1 + x;\n"
"		__global   float *data_cost          = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		for (int i = 0; i < nr_plane; i++)\n"
"		{\n"
"			float minimum = FLT_MAX;\n"
"			int id = 0;\n"
"			\n"
"			for (int d = 0; d < cndisp; d++)\n"
"			{\n"
"				float cur = data_cost[d * cdisp_step1];\n"
"				\n"
"				if (cur < minimum)\n"
"				{\n"
"					minimum = cur;\n"
"					id = d;\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost_selected[i  * cdisp_step1] = minimum;\n"
"			selected_disparity[i  * cdisp_step1] = id;\n"
"			data_cost         [id * cdisp_step1] = FLT_MAX;\n"
"		}\n"
"	}\n"
"}\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"///////////////////////////////////////////get_first_k_initial_local////////////////////////////////////\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void get_first_k_initial_local_0(__global  short *data_cost_selected_, __global short *selected_disp_pyr,\n"
"        __global  short *ctemp, int h, int w, int nr_plane,\n"
"        int cmsg_step1, int cdisp_step1, int cndisp)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		__global short *selected_disparity = selected_disp_pyr   + y * cmsg_step1 + x;\n"
"		__global short *data_cost_selected = data_cost_selected_ + y * cmsg_step1 + x;\n"
"		__global short *data_cost = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		int nr_local_minimum = 0;\n"
"		\n"
"		short prev = data_cost[0 * cdisp_step1];\n"
"		short cur  = data_cost[1 * cdisp_step1];\n"
"		short next = data_cost[2 * cdisp_step1];\n"
"		\n"
"		for (int d = 1; d < cndisp - 1 && nr_local_minimum < nr_plane; d++)\n"
"		{\n"
"		\n"
"			if (cur < prev && cur < next)\n"
"			{\n"
"				data_cost_selected[nr_local_minimum * cdisp_step1] = cur;\n"
"				selected_disparity[nr_local_minimum * cdisp_step1] = d;\n"
"				data_cost[d * cdisp_step1] = SHRT_MAX;\n"
"				\n"
"				nr_local_minimum++;\n"
"			}\n"
"			\n"
"			prev = cur;\n"
"			cur = next;\n"
"			next = data_cost[(d + 1) * cdisp_step1];\n"
"		}\n"
"		\n"
"		for (int i = nr_local_minimum; i < nr_plane; i++)\n"
"		{\n"
"			short minimum = SHRT_MAX;\n"
"			int id = 0;\n"
"			\n"
"			for (int d = 0; d < cndisp; d++)\n"
"			{\n"
"				cur = data_cost[d * cdisp_step1];\n"
"				\n"
"				if (cur < minimum)\n"
"				{\n"
"					minimum = cur;\n"
"					id = d;\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost_selected[i * cdisp_step1] = minimum;\n"
"			selected_disparity[i * cdisp_step1] = id;\n"
"			data_cost[id * cdisp_step1] = SHRT_MAX;\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void get_first_k_initial_local_1(__global float *data_cost_selected_, __global float *selected_disp_pyr,\n"
"        __global float *ctemp, int h, int w, int nr_plane,\n"
"        int cmsg_step1,  int cdisp_step1, int cndisp)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		__global float *selected_disparity = selected_disp_pyr   + y * cmsg_step1 + x;\n"
"		__global float *data_cost_selected = data_cost_selected_ + y * cmsg_step1 + x;\n"
"		__global float *data_cost = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		int nr_local_minimum = 0;\n"
"		\n"
"		float prev = data_cost[0 * cdisp_step1];\n"
"		float cur  = data_cost[1 * cdisp_step1];\n"
"		float next = data_cost[2 * cdisp_step1];\n"
"		\n"
"		for (int d = 1; d < cndisp - 1 && nr_local_minimum < nr_plane; d++)\n"
"		{\n"
"			if (cur < prev && cur < next)\n"
"			{\n"
"				data_cost_selected[nr_local_minimum * cdisp_step1] = cur;\n"
"				selected_disparity[nr_local_minimum * cdisp_step1] = d;\n"
"				data_cost[d * cdisp_step1] = FLT_MAX ;\n"
"				\n"
"				nr_local_minimum++;\n"
"			}\n"
"			\n"
"			prev = cur;\n"
"			cur = next;\n"
"			next = data_cost[(d + 1) * cdisp_step1];\n"
"		}\n"
"		\n"
"		for (int i = nr_local_minimum; i < nr_plane; i++)\n"
"		{\n"
"			float minimum = FLT_MAX;\n"
"			int id = 0;\n"
"			\n"
"			for (int d = 0; d < cndisp; d++)\n"
"			{\n"
"				cur = data_cost[d * cdisp_step1];\n"
"				\n"
"				if (cur < minimum)\n"
"				{\n"
"					minimum = cur;\n"
"					id = d;\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost_selected[i * cdisp_step1] = minimum;\n"
"			selected_disparity[i * cdisp_step1] = id;\n"
"			data_cost[id * cdisp_step1] = FLT_MAX;\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"/////////////////////// init data cost ////////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"float compute_3(__global uchar *left, __global uchar *right,\n"
"                float cdata_weight,  float cmax_data_term)\n"
"{\n"
"	float tb = 0.114f * abs((int)left[0] - right[0]);\n"
"	float tg = 0.587f * abs((int)left[1] - right[1]);\n"
"	float tr = 0.299f * abs((int)left[2] - right[2]);\n"
"	\n"
"	return fmin(cdata_weight * (tr + tg + tb), cdata_weight * cmax_data_term);\n"
"}\n"
"float compute_1(__global uchar *left, __global uchar *right,\n"
"                float cdata_weight,  float cmax_data_term)\n"
"{\n"
"	return fmin(cdata_weight * abs((int) * left - (int) * right), cdata_weight * cmax_data_term);\n"
"}\n"
"short round_short(float v)\n"
"{\n"
"	return convert_short_sat_rte(v);\n"
"}\n"
"///////////////////////////////////////////////////////////////////////////////////////////////\n"
"///////////////////////////////////init_data_cost///////////////////////////////////////////////\n"
"///////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void init_data_cost_0(__global short *ctemp, __global uchar *cleft, __global uchar *cright,\n"
"                               int h, int w, int level, int channels,\n"
"                               int cmsg_step1, float cdata_weight, float cmax_data_term, int cdisp_step1,\n"
"                               int cth, int cimg_step, int cndisp)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		int y0 = y << level;\n"
"		int yt = (y + 1) << level;\n"
"		\n"
"		int x0 = x << level;\n"
"		int xt = (x + 1) << level;\n"
"		\n"
"		__global short *data_cost = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			float val = 0.0f;\n"
"			\n"
"			for (int yi = y0; yi < yt; yi++)\n"
"			{\n"
"				for (int xi = x0; xi < xt; xi++)\n"
"				{\n"
"					int xr = xi - d;\n"
"					\n"
"					if (d < cth || xr < 0)\n"
"					{\n"
"						val += cdata_weight * cmax_data_term;\n"
"					}\n"
"					else\n"
"					{\n"
"						__global uchar *lle = cleft  + yi * cimg_step + xi * channels;\n"
"						__global uchar *lri = cright + yi * cimg_step + xr * channels;\n"
"						\n"
"						if (channels == 1)\n"
"						{\n"
"							val += compute_1(lle, lri, cdata_weight, cmax_data_term);\n"
"						}\n"
"						else\n"
"						{\n"
"							val += compute_3(lle, lri, cdata_weight, cmax_data_term);\n"
"						}\n"
"					}\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost[cdisp_step1 * d] = round_short(val);\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void init_data_cost_1(__global float *ctemp, __global uchar *cleft, __global uchar *cright,\n"
"                               int h, int w, int level, int channels,\n"
"                               int cmsg_step1, float cdata_weight, float cmax_data_term, int cdisp_step1,\n"
"                               int cth, int cimg_step, int cndisp)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		int y0 = y << level;\n"
"		int yt = (y + 1) << level;\n"
"		\n"
"		int x0 = x << level;\n"
"		int xt = (x + 1) << level;\n"
"		\n"
"		__global float *data_cost = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		for (int d = 0; d < cndisp; ++d)\n"
"		{\n"
"			float val = 0.0f;\n"
"			\n"
"			for (int yi = y0; yi < yt; yi++)\n"
"			{\n"
"				for (int xi = x0; xi < xt; xi++)\n"
"				{\n"
"					int xr = xi - d;\n"
"					\n"
"					if (d < cth || xr < 0)\n"
"					{\n"
"						val += cdata_weight * cmax_data_term;\n"
"					}\n"
"					else\n"
"					{\n"
"						__global uchar *lle = cleft  + yi * cimg_step + xi * channels;\n"
"						__global uchar *lri = cright + yi * cimg_step + xr * channels;\n"
"						\n"
"						if (channels == 1)\n"
"						{\n"
"							val += compute_1(lle, lri, cdata_weight, cmax_data_term);\n"
"						}\n"
"						else\n"
"						{\n"
"							val += compute_3(lle, lri, cdata_weight, cmax_data_term);\n"
"						}\n"
"					}\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost[cdisp_step1 * d] = val;\n"
"		}\n"
"	}\n"
"}\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"//////////////////////////////////init_data_cost_reduce//////////////////////////////////////////////////\n"
"//////////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void init_data_cost_reduce_0(__global short *ctemp, __global uchar *cleft, __global uchar *cright,\n"
"                                      __local float *smem, int level, int rows, int cols, int h, int winsz, int channels,\n"
"                                      int cndisp, int cimg_step, float cdata_weight, float cmax_data_term, int cth,\n"
"                                      int cdisp_step1, int cmsg_step1)\n"
"{\n"
"	int x_out = get_group_id(0);\n"
"	int y_out = get_group_id(1) % h;\n"
"	//int d = (blockIdx.y / h) * blockDim.z + threadIdx.z;\n"
"	int d = (get_group_id(1) / h) * get_local_size(2) + get_local_id(2);\n"
"	\n"
"	int tid = get_local_id(0);\n"
"	\n"
"	if (d < cndisp)\n"
"	{\n"
"		int x0 = x_out << level;\n"
"		int y0 = y_out << level;\n"
"		\n"
"		int len = min(y0 + winsz, rows) - y0;\n"
"		\n"
"		float val = 0.0f;\n"
"		\n"
"		if (x0 + tid < cols)\n"
"		{\n"
"			if (x0 + tid - d < 0 || d < cth)\n"
"			{\n"
"				val = cdata_weight * cmax_data_term * len;\n"
"			}\n"
"			else\n"
"			{\n"
"				__global uchar *lle =  cleft + y0 * cimg_step + channels * (x0 + tid);\n"
"				__global uchar *lri = cright + y0 * cimg_step + channels * (x0 + tid - d);\n"
"				\n"
"				for (int y = 0; y < len; ++y)\n"
"				{\n"
"					if (channels == 1)\n"
"					{\n"
"						val += compute_1(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					else\n"
"					{\n"
"						val += compute_3(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					\n"
"					lle += cimg_step;\n"
"					lri += cimg_step;\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		__local float *dline = smem + winsz * get_local_id(2);\n"
"		\n"
"		dline[tid] = val;\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		if (winsz >= 256)\n"
"		{\n"
"			if (tid < 128)\n"
"			{\n"
"				dline[tid] += dline[tid + 128];\n"
"			} barrier(CLK_LOCAL_MEM_FENCE);\n"
"		}\n"
"		\n"
"		if (winsz >= 128)\n"
"		{\n"
"			if (tid <  64)\n"
"			{\n"
"				dline[tid] += dline[tid + 64];\n"
"			}  barrier(CLK_LOCAL_MEM_FENCE);\n"
"		}\n"
"		\n"
"		__local volatile float *vdline = smem + winsz * get_local_id(2);\n"
"		\n"
"		if (winsz >= 64) if (tid < 32)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 32];\n"
"			}\n"
"			\n"
"		if (winsz >= 32) if (tid < 16)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 16];\n"
"			}\n"
"			\n"
"		if (winsz >= 16) if (tid <  8)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 8];\n"
"			}\n"
"			\n"
"		if (winsz >=  8) if (tid <  4)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 4];\n"
"			}\n"
"			\n"
"		if (winsz >=  4) if (tid <  2)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 2];\n"
"			}\n"
"			\n"
"		if (winsz >=  2) if (tid <  1)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 1];\n"
"			}\n"
"			\n"
"		__global short *data_cost = ctemp + y_out * cmsg_step1 + x_out;\n"
"		\n"
"		if (tid == 0)\n"
"		{\n"
"			data_cost[cdisp_step1 * d] = convert_short_sat_rte(dline[0]);\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void init_data_cost_reduce_1(__global float *ctemp, __global uchar *cleft, __global uchar *cright,\n"
"                                      __local float *smem, int level, int rows, int cols, int h, int winsz, int channels,\n"
"                                      int cndisp, int cimg_step, float cdata_weight, float cmax_data_term, int cth,\n"
"                                      int cdisp_step1, int cmsg_step1)\n"
"{\n"
"	int x_out = get_group_id(0);\n"
"	int y_out = get_group_id(1) % h;\n"
"	int d = (get_group_id(1) / h) * get_local_size(2) + get_local_id(2);\n"
"	\n"
"	int tid = get_local_id(0);\n"
"	\n"
"	if (d < cndisp)\n"
"	{\n"
"		int x0 = x_out << level;\n"
"		int y0 = y_out << level;\n"
"		\n"
"		int len = min(y0 + winsz, rows) - y0;\n"
"		\n"
"		float val = 0.0f;\n"
"		\n"
"		if (x0 + tid < cols)\n"
"		{\n"
"			if (x0 + tid - d < 0 || d < cth)\n"
"			{\n"
"				val = cdata_weight * cmax_data_term * len;\n"
"			}\n"
"			else\n"
"			{\n"
"				__global uchar *lle =  cleft + y0 * cimg_step + channels * (x0 + tid);\n"
"				__global uchar *lri = cright + y0 * cimg_step + channels * (x0 + tid - d);\n"
"				\n"
"				for (int y = 0; y < len; ++y)\n"
"				{\n"
"					if (channels == 1)\n"
"					{\n"
"						val += compute_1(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					else\n"
"					{\n"
"						val += compute_3(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					\n"
"					lle += cimg_step;\n"
"					lri += cimg_step;\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		__local float *dline = smem + winsz * get_local_id(2);\n"
"		\n"
"		dline[tid] = val;\n"
"		\n"
"		barrier(CLK_LOCAL_MEM_FENCE);\n"
"		\n"
"		if (winsz >= 256)\n"
"		{\n"
"			if (tid < 128)\n"
"			{\n"
"				dline[tid] += dline[tid + 128];\n"
"			} barrier(CLK_LOCAL_MEM_FENCE);\n"
"		}\n"
"		\n"
"		if (winsz >= 128)\n"
"		{\n"
"			if (tid <  64)\n"
"			{\n"
"				dline[tid] += dline[tid + 64];\n"
"			}  barrier(CLK_LOCAL_MEM_FENCE);\n"
"		}\n"
"		\n"
"		__local volatile float *vdline = smem + winsz * get_local_id(2);\n"
"		\n"
"		if (winsz >= 64) if (tid < 32)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 32];\n"
"			}\n"
"			\n"
"		if (winsz >= 32) if (tid < 16)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 16];\n"
"			}\n"
"			\n"
"		if (winsz >= 16) if (tid <  8)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 8];\n"
"			}\n"
"			\n"
"		if (winsz >=  8) if (tid <  4)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 4];\n"
"			}\n"
"			\n"
"		if (winsz >=  4) if (tid <  2)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 2];\n"
"			}\n"
"			\n"
"		if (winsz >=  2) if (tid <  1)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 1];\n"
"			}\n"
"			\n"
"		__global float *data_cost = ctemp + y_out * cmsg_step1 + x_out;\n"
"		\n"
"		if (tid == 0)\n"
"		{\n"
"			data_cost[cdisp_step1 * d] =  dline[0];\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"////////////////////// compute data cost //////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"__kernel void compute_data_cost_0(__global const short *selected_disp_pyr, __global short *data_cost_,\n"
"                                  __global uchar *cleft, __global uchar *cright,\n"
"                                  int h, int w, int level, int nr_plane, int channels,\n"
"                                  int cmsg_step1, int cmsg_step2, int cdisp_step1, int cdisp_step2, float cdata_weight,\n"
"                                  float cmax_data_term, int cimg_step, int cth)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		int y0 = y << level;\n"
"		int yt = (y + 1) << level;\n"
"		\n"
"		int x0 = x << level;\n"
"		int xt = (x + 1) << level;\n"
"		\n"
"		__global const short *selected_disparity = selected_disp_pyr + y / 2 * cmsg_step2 + x / 2;\n"
"		__global       short *data_cost          = data_cost_ + y * cmsg_step1 + x;\n"
"		\n"
"		for (int d = 0; d < nr_plane; d++)\n"
"		{\n"
"			float val = 0.0f;\n"
"			\n"
"			for (int yi = y0; yi < yt; yi++)\n"
"			{\n"
"				for (int xi = x0; xi < xt; xi++)\n"
"				{\n"
"					int sel_disp = selected_disparity[d * cdisp_step2];\n"
"					int xr = xi - sel_disp;\n"
"					\n"
"					if (xr < 0 || sel_disp < cth)\n"
"					{\n"
"						val += cdata_weight * cmax_data_term;\n"
"					}\n"
"					\n"
"					else\n"
"					{\n"
"						__global uchar *left_x  = cleft + yi * cimg_step + xi * channels;\n"
"						__global uchar *right_x = cright + yi * cimg_step + xr * channels;\n"
"						\n"
"						if (channels == 1)\n"
"						{\n"
"							val += compute_1(left_x, right_x, cdata_weight, cmax_data_term);\n"
"						}\n"
"						else\n"
"						{\n"
"							val += compute_3(left_x, right_x, cdata_weight, cmax_data_term);\n"
"						}\n"
"					}\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost[cdisp_step1 * d] = convert_short_sat_rte(val);\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void compute_data_cost_1(__global const float *selected_disp_pyr, __global float *data_cost_,\n"
"                                  __global uchar *cleft, __global uchar *cright,\n"
"                                  int h, int w, int level, int nr_plane, int channels,\n"
"                                  int cmsg_step1, int cmsg_step2, int cdisp_step1, int cdisp_step2, float cdata_weight,\n"
"                                  float cmax_data_term, int cimg_step, int cth)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		int y0 = y << level;\n"
"		int yt = (y + 1) << level;\n"
"		\n"
"		int x0 = x << level;\n"
"		int xt = (x + 1) << level;\n"
"		\n"
"		__global const float *selected_disparity = selected_disp_pyr + y / 2 * cmsg_step2 + x / 2;\n"
"		__global       float *data_cost          = data_cost_ + y * cmsg_step1 + x;\n"
"		\n"
"		for (int d = 0; d < nr_plane; d++)\n"
"		{\n"
"			float val = 0.0f;\n"
"			\n"
"			for (int yi = y0; yi < yt; yi++)\n"
"			{\n"
"				for (int xi = x0; xi < xt; xi++)\n"
"				{\n"
"					int sel_disp = selected_disparity[d * cdisp_step2];\n"
"					int xr = xi - sel_disp;\n"
"					\n"
"					if (xr < 0 || sel_disp < cth)\n"
"					{\n"
"						val += cdata_weight * cmax_data_term;\n"
"					}\n"
"					else\n"
"					{\n"
"						__global uchar *left_x  = cleft + yi * cimg_step + xi * channels;\n"
"						__global uchar *right_x = cright + yi * cimg_step + xr * channels;\n"
"						\n"
"						if (channels == 1)\n"
"						{\n"
"							val += compute_1(left_x, right_x, cdata_weight, cmax_data_term);\n"
"						}\n"
"						else\n"
"						{\n"
"							val += compute_3(left_x, right_x, cdata_weight, cmax_data_term);\n"
"						}\n"
"					}\n"
"				}\n"
"			}\n"
"			\n"
"			data_cost[cdisp_step1 * d] = val;\n"
"		}\n"
"	}\n"
"}\n"
"////////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"////////////////////////////////////////compute_data_cost_reduce//////////////////////////////////////////\n"
"/////////////////////////////////////////////////////////////////////////////////////////////////////////\n"
"__kernel void compute_data_cost_reduce_0(__global const short *selected_disp_pyr, __global short *data_cost_,\n"
"        __global uchar *cleft, __global uchar *cright, __local float *smem,\n"
"        int level, int rows, int cols, int h, int nr_plane,\n"
"        int channels, int winsz,\n"
"        int cmsg_step1, int cmsg_step2, int cdisp_step1, int cdisp_step2,\n"
"        float cdata_weight,  float cmax_data_term, int cimg_step, int cth)\n"
"{\n"
"	int x_out = get_group_id(0);\n"
"	int y_out = get_group_id(1) % h;\n"
"	int d = (get_group_id(1) / h) * get_local_size(2) + get_local_id(2);\n"
"	\n"
"	int tid = get_local_id(0);\n"
"	\n"
"	__global const short *selected_disparity = selected_disp_pyr + y_out / 2 * cmsg_step2 + x_out / 2;\n"
"	__global short *data_cost = data_cost_ + y_out * cmsg_step1 + x_out;\n"
"	\n"
"	if (d < nr_plane)\n"
"	{\n"
"		int sel_disp = selected_disparity[d * cdisp_step2];\n"
"		\n"
"		int x0 = x_out << level;\n"
"		int y0 = y_out << level;\n"
"		\n"
"		int len = min(y0 + winsz, rows) - y0;\n"
"		\n"
"		float val = 0.0f;\n"
"		\n"
"		if (x0 + tid < cols)\n"
"		{\n"
"			if (x0 + tid - sel_disp < 0 || sel_disp < cth)\n"
"			{\n"
"				val = cdata_weight * cmax_data_term * len;\n"
"			}\n"
"			else\n"
"			{\n"
"				__global uchar *lle =  cleft + y0 * cimg_step + channels * (x0 + tid);\n"
"				__global uchar *lri = cright + y0 * cimg_step + channels * (x0 + tid - sel_disp);\n"
"				\n"
"				for (int y = 0; y < len; ++y)\n"
"				{\n"
"					if (channels == 1)\n"
"					{\n"
"						val += compute_1(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					else\n"
"					{\n"
"						val += compute_3(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					\n"
"					lle += cimg_step;\n"
"					lri += cimg_step;\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		__local float *dline = smem + winsz * get_local_id(2);\n"
"		\n"
"		dline[tid] = val;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (d < nr_plane)\n"
"	{\n"
"	\n"
"		// if (winsz >= 256) { if (tid < 128) { dline[tid] += dline[tid + 128]; } barrier(CLK_LOCAL_MEM_FENCE); }\n"
"		//if (winsz >= 128) { if (tid <  64) { dline[tid] += dline[tid +  64]; } barrier(CLK_LOCAL_MEM_FENCE); }\n"
"		\n"
"		__local volatile float *vdline = smem + winsz * get_local_id(2);\n"
"		\n"
"		if (winsz >= 64) if (tid < 32)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 32];\n"
"			}\n"
"			\n"
"		if (winsz >= 32) if (tid < 16)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 16];\n"
"			}\n"
"			\n"
"		if (winsz >= 16) if (tid <  8)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 8];\n"
"			}\n"
"			\n"
"		if (winsz >=  8) if (tid <  4)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 4];\n"
"			}\n"
"			\n"
"		if (winsz >=  4) if (tid <  2)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 2];\n"
"			}\n"
"			\n"
"		if (winsz >=  2) if (tid <  1)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 1];\n"
"			}\n"
"			\n"
"		if (tid == 0)\n"
"		{\n"
"			data_cost[cdisp_step1 * d] = convert_short_sat_rte(vdline[0]);\n"
"		}\n"
"	}\n"
"}\n"
"__kernel void compute_data_cost_reduce_1(__global const float *selected_disp_pyr, __global float *data_cost_,\n"
"        __global uchar *cleft, __global uchar *cright, __local float *smem,\n"
"        int level, int rows, int cols, int h, int nr_plane,\n"
"        int channels, int winsz,\n"
"        int cmsg_step1, int cmsg_step2, int cdisp_step1, int cdisp_step2, float cdata_weight,\n"
"        float cmax_data_term, int cimg_step, int cth)\n"
"{\n"
"	int x_out = get_group_id(0);\n"
"	int y_out = get_group_id(1) % h;\n"
"	int d = (get_group_id(1) / h) * get_local_size(2) + get_local_id(2);\n"
"	\n"
"	int tid = get_local_id(0);\n"
"	\n"
"	__global const float *selected_disparity = selected_disp_pyr + y_out / 2 * cmsg_step2 + x_out / 2;\n"
"	__global float *data_cost = data_cost_ + y_out * cmsg_step1 + x_out;\n"
"	\n"
"	if (d < nr_plane)\n"
"	{\n"
"		int sel_disp = selected_disparity[d * cdisp_step2];\n"
"		\n"
"		int x0 = x_out << level;\n"
"		int y0 = y_out << level;\n"
"		\n"
"		int len = min(y0 + winsz, rows) - y0;\n"
"		\n"
"		float val = 0.0f;\n"
"		\n"
"		if (x0 + tid < cols)\n"
"		{\n"
"			if (x0 + tid - sel_disp < 0 || sel_disp < cth)\n"
"			{\n"
"				val = cdata_weight * cmax_data_term * len;\n"
"			}\n"
"			else\n"
"			{\n"
"				__global uchar *lle =  cleft + y0 * cimg_step + channels * (x0 + tid);\n"
"				__global uchar *lri = cright + y0 * cimg_step + channels * (x0 + tid - sel_disp);\n"
"				\n"
"				for (int y = 0; y < len; ++y)\n"
"				{\n"
"					if (channels == 1)\n"
"					{\n"
"						val += compute_1(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					else\n"
"					{\n"
"						val += compute_3(lle, lri, cdata_weight, cmax_data_term);\n"
"					}\n"
"					\n"
"					lle += cimg_step;\n"
"					lri += cimg_step;\n"
"				}\n"
"			}\n"
"		}\n"
"		\n"
"		__local float *dline = smem + winsz * get_local_id(2);\n"
"		\n"
"		dline[tid] = val;\n"
"	}\n"
"	\n"
"	barrier(CLK_LOCAL_MEM_FENCE);\n"
"	\n"
"	if (d < nr_plane)\n"
"	{\n"
"	\n"
"		//if (winsz >= 256) { if (tid < 128) { dline[tid] += dline[tid + 128]; } barrier(CLK_LOCAL_MEM_FENCE); }\n"
"		//if (winsz >= 128) { if (tid <  64) { dline[tid] += dline[tid +  64]; } barrier(CLK_LOCAL_MEM_FENCE); }\n"
"		\n"
"		__local volatile float *vdline = smem + winsz * get_local_id(2);\n"
"		\n"
"		if (winsz >= 64) if (tid < 32)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 32];\n"
"			}\n"
"			\n"
"		if (winsz >= 32) if (tid < 16)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 16];\n"
"			}\n"
"			\n"
"		if (winsz >= 16) if (tid <  8)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 8];\n"
"			}\n"
"			\n"
"		if (winsz >=  8) if (tid <  4)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 4];\n"
"			}\n"
"			\n"
"		if (winsz >=  4) if (tid <  2)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 2];\n"
"			}\n"
"			\n"
"		if (winsz >=  2) if (tid <  1)\n"
"			{\n"
"				vdline[tid] += vdline[tid + 1];\n"
"			}\n"
"			\n"
"		if (tid == 0)\n"
"		{\n"
"			data_cost[cdisp_step1 * d] = vdline[0];\n"
"		}\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"//////////////////////// init message /////////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"void get_first_k_element_increase_0(__global short *u_new, __global short *d_new, __global short *l_new,\n"
"                                    __global short *r_new, __global const short *u_cur, __global const short *d_cur,\n"
"                                    __global const short *l_cur, __global const short *r_cur,\n"
"                                    __global short *data_cost_selected, __global short *disparity_selected_new,\n"
"                                    __global short *data_cost_new, __global const short *data_cost_cur,\n"
"                                    __global const short *disparity_selected_cur,\n"
"                                    int nr_plane, int nr_plane2,\n"
"                                    int cdisp_step1, int cdisp_step2)\n"
"{\n"
"	for (int i = 0; i < nr_plane; i++)\n"
"	{\n"
"		short minimum = SHRT_MAX;\n"
"		int id = 0;\n"
"		\n"
"		for (int j = 0; j < nr_plane2; j++)\n"
"		{\n"
"			short cur = data_cost_new[j * cdisp_step1];\n"
"			\n"
"			if (cur < minimum)\n"
"			{\n"
"				minimum = cur;\n"
"				id = j;\n"
"			}\n"
"		}\n"
"		\n"
"		data_cost_selected[i * cdisp_step1] = data_cost_cur[id * cdisp_step1];\n"
"		disparity_selected_new[i * cdisp_step1] = disparity_selected_cur[id * cdisp_step2];\n"
"		\n"
"		u_new[i * cdisp_step1] = u_cur[id * cdisp_step2];\n"
"		d_new[i * cdisp_step1] = d_cur[id * cdisp_step2];\n"
"		l_new[i * cdisp_step1] = l_cur[id * cdisp_step2];\n"
"		r_new[i * cdisp_step1] = r_cur[id * cdisp_step2];\n"
"		\n"
"		data_cost_new[id * cdisp_step1] = SHRT_MAX;\n"
"	}\n"
"}\n"
"void get_first_k_element_increase_1(__global float *u_new, __global float *d_new, __global float *l_new,\n"
"                                    __global float *r_new, __global const float *u_cur, __global const float *d_cur,\n"
"                                    __global const float *l_cur, __global const float *r_cur,\n"
"                                    __global float *data_cost_selected, __global float *disparity_selected_new,\n"
"                                    __global float *data_cost_new, __global const float *data_cost_cur,\n"
"                                    __global const float *disparity_selected_cur,\n"
"                                    int nr_plane, int nr_plane2,\n"
"                                    int cdisp_step1, int cdisp_step2)\n"
"{\n"
"	for (int i = 0; i < nr_plane; i++)\n"
"	{\n"
"		float minimum = FLT_MAX;\n"
"		int id = 0;\n"
"		\n"
"		for (int j = 0; j < nr_plane2; j++)\n"
"		{\n"
"			float cur = data_cost_new[j * cdisp_step1];\n"
"			\n"
"			if (cur < minimum)\n"
"			{\n"
"				minimum = cur;\n"
"				id = j;\n"
"			}\n"
"		}\n"
"		\n"
"		data_cost_selected[i * cdisp_step1] = data_cost_cur[id * cdisp_step1];\n"
"		disparity_selected_new[i * cdisp_step1] = disparity_selected_cur[id * cdisp_step2];\n"
"		\n"
"		u_new[i * cdisp_step1] = u_cur[id * cdisp_step2];\n"
"		d_new[i * cdisp_step1] = d_cur[id * cdisp_step2];\n"
"		l_new[i * cdisp_step1] = l_cur[id * cdisp_step2];\n"
"		r_new[i * cdisp_step1] = r_cur[id * cdisp_step2];\n"
"		\n"
"		data_cost_new[id * cdisp_step1] = FLT_MAX;\n"
"	}\n"
"}\n"
"__kernel void init_message_0(__global short *u_new_, __global short *d_new_, __global short *l_new_,\n"
"                             __global short *r_new_, __global  short *u_cur_, __global const short *d_cur_,\n"
"                             __global const short *l_cur_, __global const short *r_cur_, __global short *ctemp,\n"
"                             __global short *selected_disp_pyr_new, __global const short *selected_disp_pyr_cur,\n"
"                             __global short *data_cost_selected_, __global const short *data_cost_,\n"
"                             int h, int w, int nr_plane, int h2, int w2, int nr_plane2,\n"
"                             int cdisp_step1, int cdisp_step2, int cmsg_step1, int cmsg_step2)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		__global const short *u_cur = u_cur_ + min(h2 - 1, y / 2 + 1) * cmsg_step2 + x / 2;\n"
"		__global const short *d_cur = d_cur_ + max(0, y / 2 - 1)    * cmsg_step2 + x / 2;\n"
"		__global const short *l_cur = l_cur_ + y / 2                * cmsg_step2 + min(w2 - 1, x / 2 + 1);\n"
"		__global const short *r_cur = r_cur_ + y / 2                * cmsg_step2 + max(0, x / 2 - 1);\n"
"		\n"
"		__global short *data_cost_new = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		__global const short *disparity_selected_cur = selected_disp_pyr_cur + y / 2 * cmsg_step2 + x / 2;\n"
"		__global const short *data_cost = data_cost_ + y * cmsg_step1 + x;\n"
"		\n"
"		for (int d = 0; d < nr_plane2; d++)\n"
"		{\n"
"			int idx2 = d * cdisp_step2;\n"
"			\n"
"			short val  = data_cost[d * cdisp_step1] + u_cur[idx2] + d_cur[idx2] + l_cur[idx2] + r_cur[idx2];\n"
"			data_cost_new[d * cdisp_step1] = val;\n"
"		}\n"
"		\n"
"		__global short *data_cost_selected = data_cost_selected_ + y * cmsg_step1 + x;\n"
"		__global short *disparity_selected_new = selected_disp_pyr_new + y * cmsg_step1 + x;\n"
"		\n"
"		__global short *u_new = u_new_ + y * cmsg_step1 + x;\n"
"		__global short *d_new = d_new_ + y * cmsg_step1 + x;\n"
"		__global short *l_new = l_new_ + y * cmsg_step1 + x;\n"
"		__global short *r_new = r_new_ + y * cmsg_step1 + x;\n"
"		\n"
"		u_cur = u_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		d_cur = d_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		l_cur = l_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		r_cur = r_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		\n"
"		get_first_k_element_increase_0(u_new, d_new, l_new, r_new, u_cur, d_cur, l_cur, r_cur,\n"
"		                               data_cost_selected, disparity_selected_new, data_cost_new,\n"
"		                               data_cost, disparity_selected_cur, nr_plane, nr_plane2,\n"
"		                               cdisp_step1, cdisp_step2);\n"
"	}\n"
"}\n"
"__kernel void init_message_1(__global float *u_new_, __global float *d_new_, __global float *l_new_,\n"
"                             __global float *r_new_, __global float *u_cur_, __global const float *d_cur_,\n"
"                             __global const float *l_cur_, __global const float *r_cur_, __global float *ctemp,\n"
"                             __global float *selected_disp_pyr_new, __global const float *selected_disp_pyr_cur,\n"
"                             __global float *data_cost_selected_, __global const float *data_cost_,\n"
"                             int h, int w, int nr_plane, int h2, int w2, int nr_plane2,\n"
"                             int cdisp_step1, int cdisp_step2, int cmsg_step1, int cmsg_step2)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y < h && x < w)\n"
"	{\n"
"		__global const float *u_cur = u_cur_ + min(h2 - 1, y / 2 + 1) * cmsg_step2 + x / 2;\n"
"		__global const float *d_cur = d_cur_ + max(0, y / 2 - 1)    * cmsg_step2 + x / 2;\n"
"		__global const float *l_cur = l_cur_ + y / 2                * cmsg_step2 + min(w2 - 1, x / 2 + 1);\n"
"		__global const float *r_cur = r_cur_ + y / 2                * cmsg_step2 + max(0, x / 2 - 1);\n"
"		\n"
"		__global float *data_cost_new = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		__global const float *disparity_selected_cur = selected_disp_pyr_cur + y / 2 * cmsg_step2 + x / 2;\n"
"		__global const float *data_cost = data_cost_ + y * cmsg_step1 + x;\n"
"		\n"
"		for (int d = 0; d < nr_plane2; d++)\n"
"		{\n"
"			int idx2 = d * cdisp_step2;\n"
"			\n"
"			float val  = data_cost[d * cdisp_step1] + u_cur[idx2] + d_cur[idx2] + l_cur[idx2] + r_cur[idx2];\n"
"			data_cost_new[d * cdisp_step1] = val;\n"
"		}\n"
"		\n"
"		__global float *data_cost_selected = data_cost_selected_ + y * cmsg_step1 + x;\n"
"		__global float *disparity_selected_new = selected_disp_pyr_new + y * cmsg_step1 + x;\n"
"		\n"
"		__global float *u_new = u_new_ + y * cmsg_step1 + x;\n"
"		__global float *d_new = d_new_ + y * cmsg_step1 + x;\n"
"		__global float *l_new = l_new_ + y * cmsg_step1 + x;\n"
"		__global float *r_new = r_new_ + y * cmsg_step1 + x;\n"
"		\n"
"		u_cur = u_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		d_cur = d_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		l_cur = l_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		r_cur = r_cur_ + y / 2 * cmsg_step2 + x / 2;\n"
"		\n"
"		get_first_k_element_increase_1(u_new, d_new, l_new, r_new, u_cur, d_cur, l_cur, r_cur,\n"
"		                               data_cost_selected, disparity_selected_new, data_cost_new,\n"
"		                               data_cost, disparity_selected_cur, nr_plane, nr_plane2,\n"
"		                               cdisp_step1, cdisp_step2);\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"////////////////////  calc all iterations /////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"void message_per_pixel_0(__global const short *data, __global short *msg_dst, __global const short *msg1,\n"
"                         __global const short *msg2, __global const short *msg3,\n"
"                         __global const short *dst_disp, __global const short *src_disp,\n"
"                         int nr_plane, __global short *temp,\n"
"                         float cmax_disc_term, int cdisp_step1, float cdisc_single_jump)\n"
"{\n"
"	short minimum = SHRT_MAX;\n"
"	\n"
"	for (int d = 0; d < nr_plane; d++)\n"
"	{\n"
"		int idx = d * cdisp_step1;\n"
"		short val  = data[idx] + msg1[idx] + msg2[idx] + msg3[idx];\n"
"		\n"
"		if (val < minimum)\n"
"		{\n"
"			minimum = val;\n"
"		}\n"
"		\n"
"		msg_dst[idx] = val;\n"
"	}\n"
"	\n"
"	float sum = 0;\n"
"	\n"
"	for (int d = 0; d < nr_plane; d++)\n"
"	{\n"
"		float cost_min = minimum + cmax_disc_term;\n"
"		short src_disp_reg = src_disp[d * cdisp_step1];\n"
"		\n"
"		for (int d2 = 0; d2 < nr_plane; d2++)\n"
"			cost_min = fmin(cost_min, (msg_dst[d2 * cdisp_step1] +\n"
"			                           cdisc_single_jump * abs(dst_disp[d2 * cdisp_step1] - src_disp_reg)));\n"
"			                           \n"
"		temp[d * cdisp_step1] = convert_short_sat_rte(cost_min);\n"
"		sum += cost_min;\n"
"	}\n"
"	\n"
"	sum /= nr_plane;\n"
"	\n"
"	for (int d = 0; d < nr_plane; d++)\n"
"	{\n"
"		msg_dst[d * cdisp_step1] = convert_short_sat_rte(temp[d * cdisp_step1] - sum);\n"
"	}\n"
"}\n"
"void message_per_pixel_1(__global const float *data, __global float *msg_dst, __global const float *msg1,\n"
"                         __global const float *msg2, __global const float *msg3,\n"
"                         __global const float *dst_disp, __global const float *src_disp,\n"
"                         int nr_plane, __global float *temp,\n"
"                         float cmax_disc_term, int cdisp_step1, float cdisc_single_jump)\n"
"{\n"
"	float minimum = FLT_MAX;\n"
"	\n"
"	for (int d = 0; d < nr_plane; d++)\n"
"	{\n"
"		int idx = d * cdisp_step1;\n"
"		float val  = data[idx] + msg1[idx] + msg2[idx] + msg3[idx];\n"
"		\n"
"		if (val < minimum)\n"
"		{\n"
"			minimum = val;\n"
"		}\n"
"		\n"
"		msg_dst[idx] = val;\n"
"	}\n"
"	\n"
"	float sum = 0;\n"
"	\n"
"	for (int d = 0; d < nr_plane; d++)\n"
"	{\n"
"		float cost_min = minimum + cmax_disc_term;\n"
"		float src_disp_reg = src_disp[d * cdisp_step1];\n"
"		\n"
"		for (int d2 = 0; d2 < nr_plane; d2++)\n"
"			cost_min = fmin(cost_min, (msg_dst[d2 * cdisp_step1] +\n"
"			                           cdisc_single_jump * fabs(dst_disp[d2 * cdisp_step1] - src_disp_reg)));\n"
"			                           \n"
"		temp[d * cdisp_step1] = cost_min;\n"
"		sum += cost_min;\n"
"	}\n"
"	\n"
"	sum /= nr_plane;\n"
"	\n"
"	for (int d = 0; d < nr_plane; d++)\n"
"	{\n"
"		msg_dst[d * cdisp_step1] = temp[d * cdisp_step1] - sum;\n"
"	}\n"
"}\n"
"__kernel void compute_message_0(__global short *u_, __global short *d_, __global short *l_, __global short *r_,\n"
"                                __global const short *data_cost_selected, __global const short *selected_disp_pyr_cur,\n"
"                                __global short *ctemp, int h, int w, int nr_plane, int i,\n"
"                                float cmax_disc_term, int cdisp_step1, int cmsg_step1, float cdisc_single_jump)\n"
"{\n"
"	int y = get_global_id(1);\n"
"	int x = ((get_global_id(0)) << 1) + ((y + i) & 1);\n"
"	\n"
"	if (y > 0 && y < h - 1 && x > 0 && x < w - 1)\n"
"	{\n"
"		__global const short *data = data_cost_selected + y * cmsg_step1 + x;\n"
"		\n"
"		__global short *u = u_ + y * cmsg_step1 + x;\n"
"		__global short *d = d_ + y * cmsg_step1 + x;\n"
"		__global short *l = l_ + y * cmsg_step1 + x;\n"
"		__global short *r = r_ + y * cmsg_step1 + x;\n"
"		\n"
"		__global const short *disp = selected_disp_pyr_cur + y * cmsg_step1 + x;\n"
"		\n"
"		__global short *temp = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		message_per_pixel_0(data, u, r - 1, u + cmsg_step1, l + 1, disp, disp - cmsg_step1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"		message_per_pixel_0(data, d, d - cmsg_step1, r - 1, l + 1, disp, disp + cmsg_step1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"		message_per_pixel_0(data, l, u + cmsg_step1, d - cmsg_step1, l + 1, disp, disp - 1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"		message_per_pixel_0(data, r, u + cmsg_step1, d - cmsg_step1, r - 1, disp, disp + 1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"	}\n"
"}\n"
"__kernel void compute_message_1(__global float *u_, __global float *d_, __global float *l_, __global float *r_,\n"
"                                __global const float *data_cost_selected, __global const float *selected_disp_pyr_cur,\n"
"                                __global float *ctemp, int h, int w, int nr_plane, int i,\n"
"                                float cmax_disc_term, int cdisp_step1, int cmsg_step1, float cdisc_single_jump)\n"
"{\n"
"	int y = get_global_id(1);\n"
"	int x = ((get_global_id(0)) << 1) + ((y + i) & 1);\n"
"	\n"
"	if (y > 0 && y < h - 1 && x > 0 && x < w - 1)\n"
"	{\n"
"		__global const float *data = data_cost_selected + y * cmsg_step1 + x;\n"
"		\n"
"		__global float *u = u_ + y * cmsg_step1 + x;\n"
"		__global float *d = d_ + y * cmsg_step1 + x;\n"
"		__global float *l = l_ + y * cmsg_step1 + x;\n"
"		__global float *r = r_ + y * cmsg_step1 + x;\n"
"		\n"
"		__global const float *disp = selected_disp_pyr_cur + y * cmsg_step1 + x;\n"
"		__global float *temp = ctemp + y * cmsg_step1 + x;\n"
"		\n"
"		message_per_pixel_1(data, u, r - 1, u + cmsg_step1, l + 1, disp, disp - cmsg_step1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"		message_per_pixel_1(data, d, d - cmsg_step1, r - 1, l + 1, disp, disp + cmsg_step1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"		message_per_pixel_1(data, l, u + cmsg_step1, d - cmsg_step1, l + 1, disp, disp - 1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"		message_per_pixel_1(data, r, u + cmsg_step1, d - cmsg_step1, r - 1, disp, disp + 1, nr_plane, temp,\n"
"		                    cmax_disc_term, cdisp_step1, cdisc_single_jump);\n"
"	}\n"
"}\n"
"///////////////////////////////////////////////////////////////\n"
"/////////////////////////// output ////////////////////////////\n"
"///////////////////////////////////////////////////////////////\n"
"__kernel void compute_disp_0(__global const short *u_, __global const short *d_, __global const short *l_,\n"
"                             __global const short *r_, __global const short *data_cost_selected,\n"
"                             __global const short *disp_selected_pyr,\n"
"                             __global short *disp,\n"
"                             int res_step, int cols, int rows, int nr_plane,\n"
"                             int cmsg_step1, int cdisp_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y > 0 && y < rows - 1 && x > 0 && x < cols - 1)\n"
"	{\n"
"		__global const short *data = data_cost_selected + y * cmsg_step1 + x;\n"
"		__global const short *disp_selected = disp_selected_pyr + y * cmsg_step1 + x;\n"
"		\n"
"		__global const short *u = u_ + (y + 1) * cmsg_step1 + (x + 0);\n"
"		__global const short *d = d_ + (y - 1) * cmsg_step1 + (x + 0);\n"
"		__global const short *l = l_ + (y + 0) * cmsg_step1 + (x + 1);\n"
"		__global const short *r = r_ + (y + 0) * cmsg_step1 + (x - 1);\n"
"		\n"
"		short best = 0;\n"
"		short best_val = SHRT_MAX;\n"
"		\n"
"		for (int i = 0; i < nr_plane; ++i)\n"
"		{\n"
"			int idx = i * cdisp_step1;\n"
"			short val = data[idx] + u[idx] + d[idx] + l[idx] + r[idx];\n"
"			\n"
"			if (val < best_val)\n"
"			{\n"
"				best_val = val;\n"
"				best = disp_selected[idx];\n"
"			}\n"
"		}\n"
"		\n"
"		disp[res_step * y + x] = best;\n"
"	}\n"
"}\n"
"__kernel void compute_disp_1(__global const float *u_, __global const float *d_, __global const float *l_,\n"
"                             __global const float *r_, __global const float *data_cost_selected,\n"
"                             __global const float *disp_selected_pyr,\n"
"                             __global short *disp,\n"
"                             int res_step, int cols, int rows, int nr_plane,\n"
"                             int cmsg_step1, int cdisp_step1)\n"
"{\n"
"	int x = get_global_id(0);\n"
"	int y = get_global_id(1);\n"
"	\n"
"	if (y > 0 && y < rows - 1 && x > 0 && x < cols - 1)\n"
"	{\n"
"		__global const float *data = data_cost_selected + y * cmsg_step1 + x;\n"
"		__global const float *disp_selected = disp_selected_pyr + y * cmsg_step1 + x;\n"
"		\n"
"		__global const float *u = u_ + (y + 1) * cmsg_step1 + (x + 0);\n"
"		__global const float *d = d_ + (y - 1) * cmsg_step1 + (x + 0);\n"
"		__global const float *l = l_ + (y + 0) * cmsg_step1 + (x + 1);\n"
"		__global const float *r = r_ + (y + 0) * cmsg_step1 + (x - 1);\n"
"		\n"
"		short best = 0;\n"
"		short best_val = SHRT_MAX;\n"
"		\n"
"		for (int i = 0; i < nr_plane; ++i)\n"
"		{\n"
"			int idx = i * cdisp_step1;\n"
"			float val = data[idx] + u[idx] + d[idx] + l[idx] + r[idx];\n"
"			\n"
"			if (val < best_val)\n"
"			{\n"
"				best_val = val;\n"
"				best = convert_short_sat_rte(disp_selected[idx]);\n"
"			}\n"
"		}\n"
"		\n"
"		disp[res_step * y + x] = best;\n"
"	}\n"
"}\n"
;
}}
